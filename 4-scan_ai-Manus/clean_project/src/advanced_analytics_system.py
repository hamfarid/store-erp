# File: /home/ubuntu/clean_project/src/advanced_analytics_system.py
"""
Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù: /home/ubuntu/clean_project/src/advanced_analytics_system.py

Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆØ°ÙƒØ§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„
ÙŠÙˆÙØ± ØªØ­Ù„ÙŠÙ„Ø§Øª Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø°ÙƒØ§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Union, Tuple, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta, date
from enum import Enum
import asyncio
import json
import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.offline as pyo
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest
from sklearn.metrics import silhouette_score
import warnings
warnings.filterwarnings('ignore')

# ØªÙƒÙˆÙŠÙ† matplotlib Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'Tahoma']
plt.rcParams['axes.unicode_minus'] = False

class AnalyticsType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"""
    DESCRIPTIVE = "descriptive"  # ÙˆØµÙÙŠØ©
    DIAGNOSTIC = "diagnostic"    # ØªØ´Ø®ÙŠØµÙŠØ©
    PREDICTIVE = "predictive"    # ØªÙ†Ø¨Ø¤ÙŠØ©
    PRESCRIPTIVE = "prescriptive"  # ØªÙˆØ¬ÙŠÙ‡ÙŠØ©

class ChartType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª"""
    LINE = "line"
    BAR = "bar"
    PIE = "pie"
    SCATTER = "scatter"
    HEATMAP = "heatmap"
    HISTOGRAM = "histogram"
    BOX = "box"
    VIOLIN = "violin"
    TREEMAP = "treemap"
    SUNBURST = "sunburst"
    GAUGE = "gauge"
    FUNNEL = "funnel"

class MetricType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³"""
    COUNT = "count"
    SUM = "sum"
    AVERAGE = "average"
    MEDIAN = "median"
    MIN = "min"
    MAX = "max"
    PERCENTAGE = "percentage"
    GROWTH_RATE = "growth_rate"
    CONVERSION_RATE = "conversion_rate"

class TimeGranularity(Enum):
    """Ø¯Ù‚Ø© Ø§Ù„ÙˆÙ‚Øª"""
    HOUR = "hour"
    DAY = "day"
    WEEK = "week"
    MONTH = "month"
    QUARTER = "quarter"
    YEAR = "year"

@dataclass
class AnalyticsQuery:
    """Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"""
    id: str
    name: str
    description: str
    analytics_type: AnalyticsType
    data_sources: List[str]
    metrics: List[Dict[str, Any]]
    dimensions: List[str]
    filters: Dict[str, Any] = field(default_factory=dict)
    time_range: Optional[Dict[str, Any]] = None
    granularity: TimeGranularity = TimeGranularity.DAY
    limit: Optional[int] = None
    sort_by: Optional[str] = None
    sort_order: str = "desc"

@dataclass
class AnalyticsResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
    query_id: str
    data: pd.DataFrame
    metadata: Dict[str, Any]
    insights: List[str]
    recommendations: List[str]
    charts: List[Dict[str, Any]]
    execution_time: float
    timestamp: datetime

@dataclass
class BusinessMetric:
    """Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„"""
    id: str
    name: str
    description: str
    formula: str
    category: str
    target_value: Optional[float] = None
    threshold_warning: Optional[float] = None
    threshold_critical: Optional[float] = None
    unit: str = ""
    format_type: str = "number"

@dataclass
class Dashboard:
    """Ù„ÙˆØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"""
    id: str
    name: str
    description: str
    widgets: List[Dict[str, Any]]
    layout: Dict[str, Any]
    filters: Dict[str, Any] = field(default_factory=dict)
    refresh_interval: int = 300  # Ø«ÙˆØ§Ù†ÙŠ
    permissions: List[str] = field(default_factory=list)
    created_by: str = ""
    created_at: datetime = field(default_factory=datetime.now)

class DataProcessor:
    """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    
    def __init__(self):
        self.logger = logging.getLogger('data_processor')
    
    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø©
            df = df.drop_duplicates()
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
            for column in df.columns:
                if df[column].dtype in ['int64', 'float64']:
                    # Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø¨Ø§Ù„Ù…ØªÙˆØ³Ø·
                    df[column] = df[column].fillna(df[column].mean())
                else:
                    # Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ© Ø¨Ù€ "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
                    df[column] = df[column].fillna('ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
            for column in df.select_dtypes(include=[np.number]).columns:
                Q1 = df[column].quantile(0.25)
                Q3 = df[column].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
            
            self.logger.info(f"Data cleaned: {len(df)} rows remaining")
            return df
            
        except Exception as e:
            self.logger.error(f"Error cleaning data: {e}")
            return df
    
    def aggregate_data(self, df: pd.DataFrame, group_by: List[str], 
                      metrics: List[Dict[str, Any]]) -> pd.DataFrame:
        """ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            agg_dict = {}
            
            for metric in metrics:
                column = metric['column']
                operation = metric['operation']
                
                if operation == 'count':
                    agg_dict[f"{column}_count"] = (column, 'count')
                elif operation == 'sum':
                    agg_dict[f"{column}_sum"] = (column, 'sum')
                elif operation == 'mean':
                    agg_dict[f"{column}_avg"] = (column, 'mean')
                elif operation == 'median':
                    agg_dict[f"{column}_median"] = (column, 'median')
                elif operation == 'min':
                    agg_dict[f"{column}_min"] = (column, 'min')
                elif operation == 'max':
                    agg_dict[f"{column}_max"] = (column, 'max')
                elif operation == 'std':
                    agg_dict[f"{column}_std"] = (column, 'std')
            
            result = df.groupby(group_by).agg(agg_dict).reset_index()
            
            # ØªØ³Ø·ÙŠØ­ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            result.columns = [col[0] if col[1] == '' else col[1] for col in result.columns]
            
            self.logger.info(f"Data aggregated: {len(result)} groups")
            return result
            
        except Exception as e:
            self.logger.error(f"Error aggregating data: {e}")
            return df
    
    def calculate_time_series_metrics(self, df: pd.DataFrame, 
                                    date_column: str, value_column: str) -> Dict[str, Any]:
        """Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ®
            df[date_column] = pd.to_datetime(df[date_column])
            df = df.sort_values(date_column)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            metrics = {
                'total_value': df[value_column].sum(),
                'average_value': df[value_column].mean(),
                'median_value': df[value_column].median(),
                'min_value': df[value_column].min(),
                'max_value': df[value_column].max(),
                'std_value': df[value_column].std(),
                'growth_rate': self._calculate_growth_rate(df, value_column),
                'trend': self._calculate_trend(df, value_column),
                'seasonality': self._detect_seasonality(df, date_column, value_column),
                'volatility': df[value_column].std() / df[value_column].mean() if df[value_column].mean() != 0 else 0
            }
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"Error calculating time series metrics: {e}")
            return {}
    
    def _calculate_growth_rate(self, df: pd.DataFrame, value_column: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ"""
        try:
            if len(df) < 2:
                return 0.0
            
            first_value = df[value_column].iloc[0]
            last_value = df[value_column].iloc[-1]
            
            if first_value == 0:
                return 0.0
            
            return ((last_value - first_value) / first_value) * 100
            
        except Exception:
            return 0.0
    
    def _calculate_trend(self, df: pd.DataFrame, value_column: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡"""
        try:
            if len(df) < 2:
                return "Ù…Ø³ØªÙ‚Ø±"
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ø§Ù„Ø¨Ø³ÙŠØ·
            x = np.arange(len(df))
            y = df[value_column].values
            
            slope = np.polyfit(x, y, 1)[0]
            
            if slope > 0.1:
                return "ØµØ§Ø¹Ø¯"
            elif slope < -0.1:
                return "Ù‡Ø§Ø¨Ø·"
            else:
                return "Ù…Ø³ØªÙ‚Ø±"
                
        except Exception:
            return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
    
    def _detect_seasonality(self, df: pd.DataFrame, date_column: str, value_column: str) -> bool:
        """ÙƒØ´Ù Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©"""
        try:
            if len(df) < 24:  # Ù†Ø­ØªØ§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©
                return False
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø±
            df['month'] = df[date_column].dt.month
            monthly_avg = df.groupby('month')[value_column].mean()
            
            # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ¨Ø§ÙŠÙ†
            cv = monthly_avg.std() / monthly_avg.mean()
            
            return cv > 0.2  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø£ÙƒØ¨Ø± Ù…Ù† 20%
            
        except Exception:
            return False

class ChartGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª"""
    
    def __init__(self):
        self.logger = logging.getLogger('chart_generator')
        self.color_palette = px.colors.qualitative.Set3
    
    def create_line_chart(self, df: pd.DataFrame, x_column: str, y_column: str,
                         title: str = "", **kwargs) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ø®Ø·ÙŠ"""
        try:
            fig = px.line(df, x=x_column, y=y_column, title=title,
                         color_discrete_sequence=self.color_palette)
            
            fig.update_layout(
                font=dict(family="Arial Unicode MS, Tahoma", size=12),
                title_font_size=16,
                xaxis_title=kwargs.get('x_title', x_column),
                yaxis_title=kwargs.get('y_title', y_column)
            )
            
            return {
                'type': 'line',
                'data': fig.to_json(),
                'config': {'displayModeBar': True, 'responsive': True}
            }
            
        except Exception as e:
            self.logger.error(f"Error creating line chart: {e}")
            return {}
    
    def create_bar_chart(self, df: pd.DataFrame, x_column: str, y_column: str,
                        title: str = "", orientation: str = "v", **kwargs) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ø£Ø¹Ù…Ø¯Ø©"""
        try:
            if orientation == "h":
                fig = px.bar(df, x=y_column, y=x_column, orientation='h', title=title,
                           color_discrete_sequence=self.color_palette)
            else:
                fig = px.bar(df, x=x_column, y=y_column, title=title,
                           color_discrete_sequence=self.color_palette)
            
            fig.update_layout(
                font=dict(family="Arial Unicode MS, Tahoma", size=12),
                title_font_size=16,
                xaxis_title=kwargs.get('x_title', x_column),
                yaxis_title=kwargs.get('y_title', y_column)
            )
            
            return {
                'type': 'bar',
                'data': fig.to_json(),
                'config': {'displayModeBar': True, 'responsive': True}
            }
            
        except Exception as e:
            self.logger.error(f"Error creating bar chart: {e}")
            return {}
    
    def create_pie_chart(self, df: pd.DataFrame, values_column: str, names_column: str,
                        title: str = "", **kwargs) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ"""
        try:
            fig = px.pie(df, values=values_column, names=names_column, title=title,
                        color_discrete_sequence=self.color_palette)
            
            fig.update_layout(
                font=dict(family="Arial Unicode MS, Tahoma", size=12),
                title_font_size=16
            )
            
            fig.update_traces(textposition='inside', textinfo='percent+label')
            
            return {
                'type': 'pie',
                'data': fig.to_json(),
                'config': {'displayModeBar': True, 'responsive': True}
            }
            
        except Exception as e:
            self.logger.error(f"Error creating pie chart: {e}")
            return {}
    
    def create_heatmap(self, df: pd.DataFrame, x_column: str, y_column: str, 
                      values_column: str, title: str = "", **kwargs) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±ÙŠØ©"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ©
            pivot_df = df.pivot(index=y_column, columns=x_column, values=values_column)
            
            fig = px.imshow(pivot_df, title=title, aspect="auto",
                          color_continuous_scale='RdYlBu_r')
            
            fig.update_layout(
                font=dict(family="Arial Unicode MS, Tahoma", size=12),
                title_font_size=16
            )
            
            return {
                'type': 'heatmap',
                'data': fig.to_json(),
                'config': {'displayModeBar': True, 'responsive': True}
            }
            
        except Exception as e:
            self.logger.error(f"Error creating heatmap: {e}")
            return {}
    
    def create_scatter_plot(self, df: pd.DataFrame, x_column: str, y_column: str,
                           title: str = "", size_column: str = None, 
                           color_column: str = None, **kwargs) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ù†Ù‚Ø·ÙŠ"""
        try:
            fig = px.scatter(df, x=x_column, y=y_column, title=title,
                           size=size_column, color=color_column,
                           color_discrete_sequence=self.color_palette)
            
            fig.update_layout(
                font=dict(family="Arial Unicode MS, Tahoma", size=12),
                title_font_size=16,
                xaxis_title=kwargs.get('x_title', x_column),
                yaxis_title=kwargs.get('y_title', y_column)
            )
            
            return {
                'type': 'scatter',
                'data': fig.to_json(),
                'config': {'displayModeBar': True, 'responsive': True}
            }
            
        except Exception as e:
            self.logger.error(f"Error creating scatter plot: {e}")
            return {}
    
    def create_gauge_chart(self, value: float, title: str = "", 
                          min_value: float = 0, max_value: float = 100,
                          threshold_ranges: List[Dict] = None) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ù…Ù‚ÙŠØ§Ø³"""
        try:
            if threshold_ranges is None:
                threshold_ranges = [
                    {'range': [0, 50], 'color': "red"},
                    {'range': [50, 80], 'color': "yellow"},
                    {'range': [80, 100], 'color': "green"}
                ]
            
            fig = go.Figure(go.Indicator(
                mode = "gauge+number+delta",
                value = value,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': title, 'font': {'size': 16}},
                delta = {'reference': (min_value + max_value) / 2},
                gauge = {
                    'axis': {'range': [min_value, max_value]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [min_value, max_value], 'color': "lightgray"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': max_value * 0.9
                    }
                }
            ))
            
            fig.update_layout(
                font=dict(family="Arial Unicode MS, Tahoma", size=12)
            )
            
            return {
                'type': 'gauge',
                'data': fig.to_json(),
                'config': {'displayModeBar': True, 'responsive': True}
            }
            
        except Exception as e:
            self.logger.error(f"Error creating gauge chart: {e}")
            return {}
    
    def create_funnel_chart(self, df: pd.DataFrame, values_column: str, 
                           stages_column: str, title: str = "") -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ù‚Ù…Ø¹"""
        try:
            fig = go.Figure(go.Funnel(
                y = df[stages_column],
                x = df[values_column],
                textinfo = "value+percent initial"
            ))
            
            fig.update_layout(
                title=title,
                font=dict(family="Arial Unicode MS, Tahoma", size=12),
                title_font_size=16
            )
            
            return {
                'type': 'funnel',
                'data': fig.to_json(),
                'config': {'displayModeBar': True, 'responsive': True}
            }
            
        except Exception as e:
            self.logger.error(f"Error creating funnel chart: {e}")
            return {}

class InsightGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø±Ø¤Ù‰ ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª"""
    
    def __init__(self):
        self.logger = logging.getLogger('insight_generator')
    
    def generate_insights(self, df: pd.DataFrame, metrics: Dict[str, Any]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¤Ù‰"""
        insights = []
        
        try:
            # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
            if 'trend' in metrics:
                trend = metrics['trend']
                if trend == "ØµØ§Ø¹Ø¯":
                    insights.append("ğŸ“ˆ ÙŠØ¸Ù‡Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§ØªØ¬Ø§Ù‡Ø§Ù‹ ØµØ§Ø¹Ø¯Ø§Ù‹ Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Ù‹")
                elif trend == "Ù‡Ø§Ø¨Ø·":
                    insights.append("ğŸ“‰ ÙŠØ¸Ù‡Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§ØªØ¬Ø§Ù‡Ø§Ù‹ Ù‡Ø§Ø¨Ø·Ø§Ù‹ ÙŠØ­ØªØ§Ø¬ Ø§Ù†ØªØ¨Ø§Ù‡")
                else:
                    insights.append("ğŸ“Š Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¸Ù‡Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§Ù‹ Ù†Ø³Ø¨ÙŠØ§Ù‹")
            
            # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ù†Ù…Ùˆ
            if 'growth_rate' in metrics:
                growth = metrics['growth_rate']
                if growth > 10:
                    insights.append(f"ğŸš€ Ù…Ø¹Ø¯Ù„ Ù†Ù…Ùˆ Ù…Ù…ØªØ§Ø²: {growth:.1f}%")
                elif growth > 0:
                    insights.append(f"ğŸ“ˆ Ù†Ù…Ùˆ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ: {growth:.1f}%")
                elif growth < -10:
                    insights.append(f"âš ï¸ Ø§Ù†Ø®ÙØ§Ø¶ ÙƒØ¨ÙŠØ±: {growth:.1f}%")
                else:
                    insights.append(f"ğŸ“Š ØªØºÙŠÙŠØ± Ø·ÙÙŠÙ: {growth:.1f}%")
            
            # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª
            if 'volatility' in metrics:
                volatility = metrics['volatility']
                if volatility > 0.5:
                    insights.append("âš¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¸Ù‡Ø± ØªÙ‚Ù„Ø¨Ø§Øª Ø¹Ø§Ù„ÙŠØ©")
                elif volatility > 0.2:
                    insights.append("ğŸ“Š Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¸Ù‡Ø± ØªÙ‚Ù„Ø¨Ø§Øª Ù…ØªÙˆØ³Ø·Ø©")
                else:
                    insights.append("âœ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø³ØªÙ‚Ø±Ø© Ù†Ø³Ø¨ÙŠØ§Ù‹")
            
            # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©
            if 'seasonality' in metrics and metrics['seasonality']:
                insights.append("ğŸ”„ ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù†Ù…Ø· Ù…ÙˆØ³Ù…ÙŠ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            
            # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹
            if len(df) > 0:
                numeric_columns = df.select_dtypes(include=[np.number]).columns
                for col in numeric_columns:
                    skewness = df[col].skew()
                    if abs(skewness) > 1:
                        if skewness > 0:
                            insights.append(f"ğŸ“Š {col}: ØªÙˆØ²ÙŠØ¹ Ù…Ù†Ø­Ø±Ù Ø¥Ù„Ù‰ Ø§Ù„ÙŠÙ…ÙŠÙ†")
                        else:
                            insights.append(f"ğŸ“Š {col}: ØªÙˆØ²ÙŠØ¹ Ù…Ù†Ø­Ø±Ù Ø¥Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±")
            
            # Ø±Ø¤Ù‰ Ø­ÙˆÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©
            outliers_count = self._detect_outliers_count(df)
            if outliers_count > 0:
                insights.append(f"âš ï¸ ØªÙ… Ø§ÙƒØªØ´Ø§Ù {outliers_count} Ù‚ÙŠÙ…Ø© Ø´Ø§Ø°Ø©")
            
            return insights[:10]  # Ø£Ù‚ØµÙ‰ 10 Ø±Ø¤Ù‰
            
        except Exception as e:
            self.logger.error(f"Error generating insights: {e}")
            return ["âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¤Ù‰"]
    
    def generate_recommendations(self, df: pd.DataFrame, metrics: Dict[str, Any]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
        recommendations = []
        
        try:
            # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªØ¬Ø§Ù‡
            if 'trend' in metrics:
                trend = metrics['trend']
                if trend == "Ù‡Ø§Ø¨Ø·":
                    recommendations.append("ğŸ” ÙŠÙÙ†ØµØ­ Ø¨ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø§Ù†Ø®ÙØ§Ø¶ ÙˆØ§ØªØ®Ø§Ø° Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ØªØµØ­ÙŠØ­ÙŠØ©")
                    recommendations.append("ğŸ“‹ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙˆØªØ·ÙˆÙŠØ± Ø®Ø·Ø· ØªØ­Ø³ÙŠÙ†")
                elif trend == "ØµØ§Ø¹Ø¯":
                    recommendations.append("ğŸ’ª Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± ÙÙŠ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø§Ù„Ù†Ø§Ø¬Ø­Ø©")
                    recommendations.append("ğŸ“ˆ Ø§Ø³ØªÙƒØ´Ø§Ù ÙØ±Øµ Ø§Ù„ØªÙˆØ³Ø¹ ÙˆØ§Ù„Ù†Ù…Ùˆ")
            
            # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª
            if 'volatility' in metrics:
                volatility = metrics['volatility']
                if volatility > 0.5:
                    recommendations.append("âš–ï¸ ØªØ·Ø¨ÙŠÙ‚ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª")
                    recommendations.append("ğŸ“Š Ø²ÙŠØ§Ø¯Ø© ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„")
            
            # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©
            if 'seasonality' in metrics and metrics['seasonality']:
                recommendations.append("ğŸ“… ØªØ·ÙˆÙŠØ± Ø®Ø·Ø· Ù…ÙˆØ³Ù…ÙŠØ© Ù„Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©")
                recommendations.append("ğŸ¯ ØªØ®ØµÙŠØµ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù…ÙˆØ³Ù…ÙŠØ©")
            
            # ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            missing_data_ratio = df.isnull().sum().sum() / (len(df) * len(df.columns))
            if missing_data_ratio > 0.1:
                recommendations.append("ğŸ”§ ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©")
                recommendations.append("ğŸ“ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¹Ù…Ù„ÙŠØ§Øª Ø¬Ù…Ø¹ ÙˆØ¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            
            # ØªÙˆØµÙŠØ§Øª Ø¹Ø§Ù…Ø©
            recommendations.append("ğŸ“Š Ø¥Ø¬Ø±Ø§Ø¡ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø¯ÙˆØ±ÙŠØ© Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ØªØ·ÙˆØ±Ø§Øª")
            recommendations.append("ğŸ¯ ØªØ­Ø¯ÙŠØ¯ Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø¯Ø§Ø¡ Ø±Ø¦ÙŠØ³ÙŠØ© (KPIs) Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø©")
            
            return recommendations[:8]  # Ø£Ù‚ØµÙ‰ 8 ØªÙˆØµÙŠØ§Øª
            
        except Exception as e:
            self.logger.error(f"Error generating recommendations: {e}")
            return ["âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª"]
    
    def _detect_outliers_count(self, df: pd.DataFrame) -> int:
        """Ø¹Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©"""
        try:
            outliers_count = 0
            numeric_columns = df.select_dtypes(include=[np.number]).columns
            
            for column in numeric_columns:
                Q1 = df[column].quantile(0.25)
                Q3 = df[column].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
                outliers_count += len(outliers)
            
            return outliers_count
            
        except Exception:
            return 0

class BusinessIntelligenceEngine:
    """Ù…Ø­Ø±Ùƒ Ø°ÙƒØ§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„"""
    
    def __init__(self):
        self.data_processor = DataProcessor()
        self.chart_generator = ChartGenerator()
        self.insight_generator = InsightGenerator()
        self.logger = logging.getLogger('business_intelligence_engine')
        self.metrics_registry = {}
        self.dashboards = {}
    
    def register_business_metric(self, metric: BusinessMetric):
        """ØªØ³Ø¬ÙŠÙ„ Ù…Ù‚ÙŠØ§Ø³ Ø£Ø¹Ù…Ø§Ù„"""
        self.metrics_registry[metric.id] = metric
        self.logger.info(f"Business metric registered: {metric.name}")
    
    def create_dashboard(self, dashboard: Dashboard):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù„ÙˆØ­Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"""
        self.dashboards[dashboard.id] = dashboard
        self.logger.info(f"Dashboard created: {dashboard.name}")
    
    async def execute_analytics_query(self, query: AnalyticsQuery) -> AnalyticsResult:
        """ØªÙ†ÙÙŠØ° Ø§Ø³ØªØ¹Ù„Ø§Ù… ØªØ­Ù„ÙŠÙ„ÙŠ"""
        start_time = datetime.now()
        
        try:
            # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df = await self._fetch_data(query.data_sources, query.filters, query.time_range)
            
            if df.empty:
                return AnalyticsResult(
                    query_id=query.id,
                    data=df,
                    metadata={'error': 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø©'},
                    insights=[],
                    recommendations=[],
                    charts=[],
                    execution_time=0,
                    timestamp=datetime.now()
                )
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df = self.data_processor.clean_data(df)
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª
            df = self._apply_filters(df, query.filters)
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if query.dimensions:
                df = self.data_processor.aggregate_data(df, query.dimensions, query.metrics)
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if query.sort_by:
                df = df.sort_values(query.sort_by, ascending=(query.sort_order == 'asc'))
            
            # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            if query.limit:
                df = df.head(query.limit)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            metrics = {}
            if len(df) > 0 and any(col for col in df.columns if df[col].dtype in ['int64', 'float64']):
                numeric_column = df.select_dtypes(include=[np.number]).columns[0]
                if 'date' in df.columns or 'timestamp' in df.columns:
                    date_column = 'date' if 'date' in df.columns else 'timestamp'
                    metrics = self.data_processor.calculate_time_series_metrics(df, date_column, numeric_column)
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª
            charts = await self._generate_charts(df, query)
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¤Ù‰ ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª
            insights = self.insight_generator.generate_insights(df, metrics)
            recommendations = self.insight_generator.generate_recommendations(df, metrics)
            
            # Ø­Ø³Ø§Ø¨ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return AnalyticsResult(
                query_id=query.id,
                data=df,
                metadata={
                    'row_count': len(df),
                    'column_count': len(df.columns),
                    'metrics': metrics,
                    'data_sources': query.data_sources
                },
                insights=insights,
                recommendations=recommendations,
                charts=charts,
                execution_time=execution_time,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            self.logger.error(f"Error executing analytics query {query.id}: {e}")
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return AnalyticsResult(
                query_id=query.id,
                data=pd.DataFrame(),
                metadata={'error': str(e)},
                insights=[f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: {str(e)}"],
                recommendations=["ğŸ”§ ÙŠÙØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙˆØ§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰"],
                charts=[],
                execution_time=execution_time,
                timestamp=datetime.now()
            )
    
    async def _fetch_data(self, data_sources: List[str], filters: Dict[str, Any], 
                         time_range: Optional[Dict[str, Any]]) -> pd.DataFrame:
        """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±"""
        try:
            # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† ØªØ·Ø¨ÙŠÙ‚ Ù…Ù†Ø·Ù‚ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠ Ù…Ù† Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            # Ù„Ù„ØªØ¬Ø±Ø¨Ø©ØŒ Ø³Ù†Ù†Ø´Ø¦ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ‡Ù…ÙŠØ©
            
            np.random.seed(42)
            dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='D')
            
            data = {
                'date': dates,
                'sales': np.random.normal(1000, 200, len(dates)) + np.sin(np.arange(len(dates)) * 2 * np.pi / 365) * 100,
                'customers': np.random.poisson(50, len(dates)),
                'revenue': np.random.normal(5000, 1000, len(dates)),
                'category': np.random.choice(['A', 'B', 'C'], len(dates)),
                'region': np.random.choice(['Ø§Ù„Ø´Ù…Ø§Ù„', 'Ø§Ù„Ø¬Ù†ÙˆØ¨', 'Ø§Ù„Ø´Ø±Ù‚', 'Ø§Ù„ØºØ±Ø¨'], len(dates))
            }
            
            df = pd.DataFrame(data)
            
            # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø·Ø§Ù‚ Ø²Ù…Ù†ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø­Ø¯Ø¯Ø§Ù‹
            if time_range:
                start_date = time_range.get('start_date')
                end_date = time_range.get('end_date')
                
                if start_date:
                    df = df[df['date'] >= pd.to_datetime(start_date)]
                if end_date:
                    df = df[df['date'] <= pd.to_datetime(end_date)]
            
            return df
            
        except Exception as e:
            self.logger.error(f"Error fetching data: {e}")
            return pd.DataFrame()
    
    def _apply_filters(self, df: pd.DataFrame, filters: Dict[str, Any]) -> pd.DataFrame:
        """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª"""
        try:
            for column, filter_value in filters.items():
                if column in df.columns:
                    if isinstance(filter_value, list):
                        df = df[df[column].isin(filter_value)]
                    elif isinstance(filter_value, dict):
                        if 'min' in filter_value:
                            df = df[df[column] >= filter_value['min']]
                        if 'max' in filter_value:
                            df = df[df[column] <= filter_value['max']]
                    else:
                        df = df[df[column] == filter_value]
            
            return df
            
        except Exception as e:
            self.logger.error(f"Error applying filters: {e}")
            return df
    
    async def _generate_charts(self, df: pd.DataFrame, query: AnalyticsQuery) -> List[Dict[str, Any]]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª"""
        charts = []
        
        try:
            if len(df) == 0:
                return charts
            
            # Ù…Ø®Ø·Ø· Ø®Ø·ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
            if 'date' in df.columns and len(df.select_dtypes(include=[np.number]).columns) > 0:
                numeric_col = df.select_dtypes(include=[np.number]).columns[0]
                chart = self.chart_generator.create_line_chart(
                    df, 'date', numeric_col, 
                    title=f"Ø§ØªØ¬Ø§Ù‡ {numeric_col} Ø¹Ø¨Ø± Ø§Ù„Ø²Ù…Ù†"
                )
                if chart:
                    charts.append(chart)
            
            # Ù…Ø®Ø·Ø· Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„ÙØ¦Ø§Øª
            categorical_cols = df.select_dtypes(include=['object']).columns
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            if len(categorical_cols) > 0 and len(numeric_cols) > 0:
                cat_col = categorical_cols[0]
                num_col = numeric_cols[0]
                
                # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ø®Ø·Ø·
                grouped_df = df.groupby(cat_col)[num_col].sum().reset_index()
                
                chart = self.chart_generator.create_bar_chart(
                    grouped_df, cat_col, num_col,
                    title=f"ØªÙˆØ²ÙŠØ¹ {num_col} Ø­Ø³Ø¨ {cat_col}"
                )
                if chart:
                    charts.append(chart)
                
                # Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ù‚Ù„ÙŠÙ„
                if len(grouped_df) <= 10:
                    chart = self.chart_generator.create_pie_chart(
                        grouped_df, num_col, cat_col,
                        title=f"Ù†Ø³Ø¨ {num_col} Ø­Ø³Ø¨ {cat_col}"
                    )
                    if chart:
                        charts.append(chart)
            
            # Ù…Ø®Ø·Ø· Ù†Ù‚Ø·ÙŠ Ù„Ù„Ø¹Ù„Ø§Ù‚Ø§Øª
            if len(numeric_cols) >= 2:
                chart = self.chart_generator.create_scatter_plot(
                    df, numeric_cols[0], numeric_cols[1],
                    title=f"Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† {numeric_cols[0]} Ùˆ {numeric_cols[1]}"
                )
                if chart:
                    charts.append(chart)
            
            return charts[:5]  # Ø£Ù‚ØµÙ‰ 5 Ù…Ø®Ø·Ø·Ø§Øª
            
        except Exception as e:
            self.logger.error(f"Error generating charts: {e}")
            return charts
    
    async def calculate_business_metric(self, metric_id: str, 
                                      data_context: Dict[str, Any]) -> Dict[str, Any]:
        """Ø­Ø³Ø§Ø¨ Ù…Ù‚ÙŠØ§Ø³ Ø£Ø¹Ù…Ø§Ù„"""
        try:
            if metric_id not in self.metrics_registry:
                return {'error': f'Ù…Ù‚ÙŠØ§Ø³ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {metric_id}'}
            
            metric = self.metrics_registry[metric_id]
            
            # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† ØªØ·Ø¨ÙŠÙ‚ Ù…Ù†Ø·Ù‚ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚ÙŠØ§Ø³ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØµÙŠØºØ©
            # Ù„Ù„ØªØ¬Ø±Ø¨Ø©ØŒ Ø³Ù†Ø­Ø³Ø¨ Ù‚ÙŠÙ…Ø§Ù‹ ÙˆÙ‡Ù…ÙŠØ©
            
            value = np.random.uniform(0, 100)
            
            # ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‚ÙŠØ§Ø³
            status = "normal"
            if metric.threshold_critical and value <= metric.threshold_critical:
                status = "critical"
            elif metric.threshold_warning and value <= metric.threshold_warning:
                status = "warning"
            elif metric.target_value and value >= metric.target_value:
                status = "excellent"
            
            return {
                'metric_id': metric_id,
                'name': metric.name,
                'value': value,
                'unit': metric.unit,
                'status': status,
                'target_value': metric.target_value,
                'calculated_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Error calculating business metric {metric_id}: {e}")
            return {'error': str(e)}
    
    async def generate_dashboard_data(self, dashboard_id: str) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙˆØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"""
        try:
            if dashboard_id not in self.dashboards:
                return {'error': f'Ù„ÙˆØ­Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {dashboard_id}'}
            
            dashboard = self.dashboards[dashboard_id]
            dashboard_data = {
                'id': dashboard.id,
                'name': dashboard.name,
                'description': dashboard.description,
                'widgets': [],
                'generated_at': datetime.now().isoformat()
            }
            
            # ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ„ widget
            for widget in dashboard.widgets:
                widget_data = await self._generate_widget_data(widget)
                dashboard_data['widgets'].append(widget_data)
            
            return dashboard_data
            
        except Exception as e:
            self.logger.error(f"Error generating dashboard data {dashboard_id}: {e}")
            return {'error': str(e)}
    
    async def _generate_widget_data(self, widget: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª widget"""
        try:
            widget_type = widget.get('type')
            
            if widget_type == 'metric':
                # widget Ù…Ù‚ÙŠØ§Ø³
                metric_id = widget.get('metric_id')
                if metric_id:
                    metric_data = await self.calculate_business_metric(metric_id, {})
                    return {
                        'type': 'metric',
                        'title': widget.get('title', ''),
                        'data': metric_data
                    }
            
            elif widget_type == 'chart':
                # widget Ù…Ø®Ø·Ø·
                query_config = widget.get('query')
                if query_config:
                    query = AnalyticsQuery(**query_config)
                    result = await self.execute_analytics_query(query)
                    
                    return {
                        'type': 'chart',
                        'title': widget.get('title', ''),
                        'data': {
                            'charts': result.charts,
                            'insights': result.insights[:3],  # Ø£ÙˆÙ„ 3 Ø±Ø¤Ù‰
                            'metadata': result.metadata
                        }
                    }
            
            elif widget_type == 'table':
                # widget Ø¬Ø¯ÙˆÙ„
                query_config = widget.get('query')
                if query_config:
                    query = AnalyticsQuery(**query_config)
                    result = await self.execute_analytics_query(query)
                    
                    return {
                        'type': 'table',
                        'title': widget.get('title', ''),
                        'data': {
                            'columns': result.data.columns.tolist(),
                            'rows': result.data.to_dict('records'),
                            'total_rows': len(result.data)
                        }
                    }
            
            return {
                'type': widget_type,
                'title': widget.get('title', ''),
                'data': {'error': 'Ù†ÙˆØ¹ widget ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…'}
            }
            
        except Exception as e:
            self.logger.error(f"Error generating widget data: {e}")
            return {
                'type': widget.get('type', 'unknown'),
                'title': widget.get('title', ''),
                'data': {'error': str(e)}
            }

# Ù…Ø«ÙŠÙ„ Ø¹Ø§Ù… Ù„Ù…Ø­Ø±Ùƒ Ø°ÙƒØ§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„
business_intelligence_engine = BusinessIntelligenceEngine()

# ØªØ³Ø¬ÙŠÙ„ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
default_metrics = [
    BusinessMetric(
        id="total_sales",
        name="Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
        description="Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
        formula="SUM(sales_amount)",
        category="Ù…Ø¨ÙŠØ¹Ø§Øª",
        unit="Ø±ÙŠØ§Ù„",
        format_type="currency"
    ),
    BusinessMetric(
        id="customer_count",
        name="Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡",
        description="Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡",
        formula="COUNT(DISTINCT customer_id)",
        category="Ø¹Ù…Ù„Ø§Ø¡",
        unit="Ø¹Ù…ÙŠÙ„",
        format_type="number"
    ),
    BusinessMetric(
        id="conversion_rate",
        name="Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„",
        description="Ù†Ø³Ø¨Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø²ÙˆØ§Ø± Ø¥Ù„Ù‰ Ø¹Ù…Ù„Ø§Ø¡",
        formula="(conversions / visitors) * 100",
        category="ØªØ³ÙˆÙŠÙ‚",
        target_value=5.0,
        threshold_warning=3.0,
        threshold_critical=1.0,
        unit="%",
        format_type="percentage"
    ),
    BusinessMetric(
        id="avg_order_value",
        name="Ù…ØªÙˆØ³Ø· Ù‚ÙŠÙ…Ø© Ø§Ù„Ø·Ù„Ø¨",
        description="Ù…ØªÙˆØ³Ø· Ù‚ÙŠÙ…Ø© Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„ÙˆØ§Ø­Ø¯",
        formula="SUM(order_value) / COUNT(orders)",
        category="Ù…Ø¨ÙŠØ¹Ø§Øª",
        unit="Ø±ÙŠØ§Ù„",
        format_type="currency"
    )
]

# ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
for metric in default_metrics:
    business_intelligence_engine.register_business_metric(metric)

# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
async def create_analytics_query(name: str, data_sources: List[str], 
                               metrics: List[Dict[str, Any]], 
                               dimensions: List[str] = None,
                               filters: Dict[str, Any] = None) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³ØªØ¹Ù„Ø§Ù… ØªØ­Ù„ÙŠÙ„ÙŠ"""
    query = AnalyticsQuery(
        id=f"query_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        name=name,
        description=f"Ø§Ø³ØªØ¹Ù„Ø§Ù… ØªØ­Ù„ÙŠÙ„ÙŠ: {name}",
        analytics_type=AnalyticsType.DESCRIPTIVE,
        data_sources=data_sources,
        metrics=metrics,
        dimensions=dimensions or [],
        filters=filters or {}
    )
    
    return query.id

async def execute_business_analysis(query_id: str) -> Dict[str, Any]:
    """ØªÙ†ÙÙŠØ° ØªØ­Ù„ÙŠÙ„ Ø£Ø¹Ù…Ø§Ù„"""
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³ØªØ¹Ù„Ø§Ù… ØªØ¬Ø±ÙŠØ¨ÙŠ
    query = AnalyticsQuery(
        id=query_id,
        name="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
        description="ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
        analytics_type=AnalyticsType.DESCRIPTIVE,
        data_sources=["sales", "customers"],
        metrics=[
            {"column": "sales", "operation": "sum"},
            {"column": "customers", "operation": "count"}
        ],
        dimensions=["region", "category"]
    )
    
    result = await business_intelligence_engine.execute_analytics_query(query)
    
    return {
        'query_id': result.query_id,
        'data_summary': {
            'rows': len(result.data),
            'columns': len(result.data.columns) if not result.data.empty else 0
        },
        'insights': result.insights,
        'recommendations': result.recommendations,
        'charts_count': len(result.charts),
        'execution_time': result.execution_time,
        'timestamp': result.timestamp.isoformat()
    }

if __name__ == "__main__":
    # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
    async def main():
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³ØªØ¹Ù„Ø§Ù… ØªØ­Ù„ÙŠÙ„ÙŠ
        query_id = await create_analytics_query(
            name="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ø´Ù‡Ø±ÙŠØ©",
            data_sources=["sales"],
            metrics=[{"column": "revenue", "operation": "sum"}],
            dimensions=["month", "region"]
        )
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„
        result = await execute_business_analysis(query_id)
        print(f"Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {json.dumps(result, indent=2, ensure_ascii=False)}")
        
        # Ø­Ø³Ø§Ø¨ Ù…Ù‚ÙŠØ§Ø³ Ø£Ø¹Ù…Ø§Ù„
        metric_result = await business_intelligence_engine.calculate_business_metric("total_sales", {})
        print(f"Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª: {json.dumps(metric_result, indent=2, ensure_ascii=False)}")
    
    asyncio.run(main())

