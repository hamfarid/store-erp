"""
Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù: /home/ubuntu/gaara_scan_ai_final_4.2/src/modules/plant_disease/advanced_processor.py
Ø§Ù„ÙˆØµÙ: Ù…Ø¹Ø§Ù„Ø¬ Ù…ØªÙ‚Ø¯Ù… Ù„ØªØ´Ø®ÙŠØµ Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†Ø¨Ø§ØªØ§Øª ÙŠØ¯Ù…Ø¬ Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ¹Ø¯Ø¯Ø©
Ø§Ù„Ù…Ø¤Ù„Ù: ÙØ±ÙŠÙ‚ ØªØ·ÙˆÙŠØ± Gaara ERP
ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡: 30 Ù…Ø§ÙŠÙˆ 2025
"""

import json
import logging
import os
from datetime import datetime

import numpy as np
import tensorflow as tf
import torch
from PIL import Image

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('advanced_plant_processor')


class AdvancedPlantDiseaseProcessor:
    """Ù…Ø¹Ø§Ù„Ø¬ Ù…ØªÙ‚Ø¯Ù… Ù„ØªØ´Ø®ÙŠØµ Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†Ø¨Ø§ØªØ§Øª ÙŠØ¯Ù…Ø¬ Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ¹Ø¯Ø¯Ø©"""

    def __init__(self, models_dir=None, config=None):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…

        Args:
            models_dir: Ù…Ø³Ø§Ø± Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ† (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        """
        self.models = {}
        self.processors = {}
        self.models_dir = models_dir or os.path.join(
            os.path.dirname(__file__), 'models')
        self.config = config or {}

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        os.makedirs(self.models_dir, exist_ok=True)

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©
        self.load_all_models()

        logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø¹Ø§Ù„Ø¬ Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†Ø¨Ø§ØªØ§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")

    def load_all_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©"""

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø­Ø³Ø¨ Ø§Ù„ØªÙƒÙˆÙŠÙ†
        if self.config.get('use_huggingface', True):
            self.load_huggingface_models()

        if self.config.get('use_tensorflow', True):
            self.load_tensorflow_hub_models()

        if self.config.get('use_pytorch', True):
            self.load_pytorch_models()

        if self.config.get('use_keras', True):
            self.load_keras_models()

        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.models)} Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")

    def load_huggingface_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Hugging Face"""

        try:
            from transformers import AutoImageProcessor, AutoModelForImageClassification

            hf_models = {
                'mobilenet_plant': "linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification",
                'vit_plant': "marwaALzaabi/plant-disease-detection-vit"}

            for name, model_id in hf_models.items():
                try:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù„ÙŠØ§Ù‹
                    local_model_path = os.path.join(self.models_dir, name)

                    if os.path.exists(local_model_path):
                        processor = AutoImageProcessor.from_pretrained(
                            local_model_path)
                        model = AutoModelForImageClassification.from_pretrained(
                            local_model_path)
                    else:
                        processor = AutoImageProcessor.from_pretrained(
                            model_id)
                        model = AutoModelForImageClassification.from_pretrained(
                            model_id)

                        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù„ÙŠØ§Ù‹
                        processor.save_pretrained(local_model_path)
                        model.save_pretrained(local_model_path)

                    self.processors[name] = processor
                    self.models[name] = model
                    logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {name}")
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ {name}: {e}")
        except ImportError:
            logger.warning(
                "Ù„Ù… ÙŠØªÙ… ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© transformersØŒ ØªØ®Ø·ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Hugging Face")

    def load_tensorflow_hub_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ TensorFlow Hub"""

        try:
            import tensorflow_hub as hub

            tf_models = {
                'cropnet_cassava': 'https://tfhub.dev/google/cropnet/classifier/cassava_disease_V1/2',
                'cropnet_feature': 'https://tfhub.dev/google/cropnet/feature_vector/cassava_disease_V1/1',
                'mobilenet_v3': 'https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5'}

            for name, url in tf_models.items():
                try:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù„ÙŠØ§Ù‹
                    local_model_path = os.path.join(self.models_dir, name)

                    if os.path.exists(local_model_path):
                        model = hub.load(local_model_path)
                    else:
                        model = hub.load(url)
                        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù„ÙŠØ§Ù‹ (Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­ÙØ¸Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø©)

                    self.models[name] = model
                    logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {name}")
                except Exception as e:
                    logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ {name}: {e}")
        except ImportError:
            logger.warning(
                "Ù„Ù… ÙŠØªÙ… ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© tensorflow_hubØŒ ØªØ®Ø·ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ TensorFlow Hub")

    def load_pytorch_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ PyTorch Ø§Ù„Ù…Ø®ØµØµØ©"""

        try:
            import torchvision.models as models

            # ØªØ­Ù…ÙŠÙ„ AlexNet Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø¹Ù„Ù‰ PlantVillage
            try:
                alexnet = models.alexnet(pretrained=False)
                alexnet.classifier[6] = torch.nn.Linear(
                    4096, 38)  # 38 ÙØ¦Ø© PlantVillage

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ù…Ø­Ù„ÙŠØ§Ù‹
                weights_path = os.path.join(
                    self.models_dir, 'alexnet_plantvillage.pth')

                if os.path.exists(weights_path):
                    alexnet.load_state_dict(torch.load(
                        weights_path, map_location='cpu'))
                    self.models['alexnet_plantvillage'] = alexnet
                    logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ AlexNet PlantVillage")
            except Exception as e:
                logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ AlexNet PlantVillage: {e}")
        except ImportError:
            logger.warning(
                "Ù„Ù… ÙŠØªÙ… ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø© torchvisionØŒ ØªØ®Ø·ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ PyTorch")

    def load_keras_models(self):
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Keras Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©"""

        try:
            # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ H5
            model_path = os.path.join(
                self.models_dir, 'plant_disease_model.h5')

            if os.path.exists(model_path):
                keras_model = tf.keras.models.load_model(model_path)
                self.models['keras_plant'] = keras_model
                logger.info("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Keras")
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Keras: {e}")

    def download_model(self, model_type, model_url, save_path=None):
        """
        ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ù…ØµØ¯Ø± Ø®Ø§Ø±Ø¬ÙŠ

        Args:
            model_type: Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (huggingface, tensorflow, pytorch, keras)
            model_url: Ø±Ø§Ø¨Ø· Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ùˆ Ù…Ø¹Ø±ÙÙ‡
            save_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø­ÙØ¸ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)

        Returns:
            bool: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ­Ù…ÙŠÙ„
        """
        try:
            if save_path is None:
                save_path = os.path.join(
                    self.models_dir, os.path.basename(model_url))

            if model_type == 'huggingface':
                from transformers import (
                    AutoImageProcessor,
                    AutoModelForImageClassification,
                )

                processor = AutoImageProcessor.from_pretrained(model_url)
                model = AutoModelForImageClassification.from_pretrained(
                    model_url)

                # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù„ÙŠØ§Ù‹
                processor.save_pretrained(save_path)
                model.save_pretrained(save_path)

                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬
                model_name = os.path.basename(save_path)
                self.processors[model_name] = processor
                self.models[model_name] = model

                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØ­ÙØ¸ {model_name} Ù…Ù† Hugging Face")
                return True

            elif model_type == 'tensorflow':
                import tensorflow_hub as hub

                model = hub.load(model_url)

                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬
                model_name = os.path.basename(save_path)
                self.models[model_name] = model

                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {model_name} Ù…Ù† TensorFlow Hub")
                return True

            elif model_type == 'pytorch':
                import torch

                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
                weights = torch.hub.load_state_dict_from_url(
                    model_url, map_location='cpu')
                torch.save(weights, save_path)

                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØ­ÙØ¸ Ø£ÙˆØ²Ø§Ù† PyTorch Ù…Ù† {model_url}")
                return True

            elif model_type == 'keras':
                import requests

                # ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù H5
                response = requests.get(model_url)
                with open(save_path, 'wb') as f:
                    f.write(response.content)

                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                keras_model = tf.keras.models.load_model(save_path)

                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬
                model_name = os.path.basename(save_path).split('.')[0]
                self.models[model_name] = keras_model

                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØ­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬ Keras Ù…Ù† {model_url}")
                return True

            else:
                logger.error(f"âŒ Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: {model_type}")
                return False

        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return False

    def preprocess_image(self, image_path, model_type):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©
            model_type: Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Returns:
            Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        """
        try:
            image = Image.open(image_path).convert('RGB')

            if model_type in ['mobilenet_plant', 'vit_plant']:
                # Hugging Face preprocessing
                processor = self.processors[model_type]
                inputs = processor(images=image, return_tensors="pt")
                return inputs

            elif model_type in ['cropnet_cassava', 'cropnet_feature', 'mobilenet_v3']:
                # TensorFlow preprocessing
                image = image.resize((224, 224))
                image_array = np.array(image) / 255.0
                return np.expand_dims(image_array, axis=0)

            elif model_type == 'alexnet_plantvillage':
                # PyTorch preprocessing
                from torchvision import transforms
                transform = transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                         std=[0.229, 0.224, 0.225])
                ])
                return transform(image).unsqueeze(0)

            elif model_type == 'keras_plant':
                # Keras preprocessing
                image = image.resize((224, 224))
                image_array = np.array(image) / 255.0
                return np.expand_dims(image_array, axis=0)

            else:
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                image = image.resize((224, 224))
                image_array = np.array(image) / 255.0
                return np.expand_dims(image_array, axis=0)

        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return None

    def predict_single_model(self, image_path, model_name):
        """
        Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ø­Ø¯

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©
            model_name: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Returns:
            dict: Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙ†Ø¨Ø¤
        """
        if model_name not in self.models:
            return {"error": f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_name} ØºÙŠØ± Ù…ØªØ§Ø­"}

        try:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
            processed_image = self.preprocess_image(image_path, model_name)

            if processed_image is None:
                return {"error": "ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©"}

            model = self.models[model_name]

            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            if model_name in ['mobilenet_plant', 'vit_plant']:
                # Hugging Face models
                with torch.no_grad():
                    outputs = model(**processed_image)
                    probabilities = torch.nn.functional.softmax(
                        outputs.logits, dim=-1)
                    prediction = torch.argmax(probabilities, dim=-1).item()
                    confidence = torch.max(probabilities).item()

                    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª
                    if hasattr(model.config, 'id2label'):
                        label = model.config.id2label[prediction]
                    else:
                        label = f"Ø§Ù„ÙØ¦Ø© {prediction}"

            elif model_name in ['cropnet_cassava', 'cropnet_feature', 'mobilenet_v3']:
                # TensorFlow models
                predictions = model(processed_image)

                if isinstance(predictions, dict) and 'logits' in predictions:
                    predictions = predictions['logits']

                if len(predictions.shape) > 1:
                    prediction = np.argmax(predictions, axis=-1)[0]
                    confidence = float(np.max(predictions))
                    probabilities = predictions.numpy() if hasattr(
                        predictions, 'numpy') else predictions
                else:
                    prediction = int(predictions)
                    confidence = float(predictions)
                    probabilities = [float(predictions)]

                # Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                label = f"Ø§Ù„ÙØ¦Ø© {prediction}"

            elif model_name == 'alexnet_plantvillage':
                # PyTorch models
                model.eval()
                with torch.no_grad():
                    outputs = model(processed_image)
                    probabilities = torch.nn.functional.softmax(outputs, dim=1)
                    prediction = torch.argmax(probabilities, dim=1).item()
                    confidence = torch.max(probabilities).item()

                    # Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                    label = f"Ø§Ù„ÙØ¦Ø© {prediction}"

            elif model_name == 'keras_plant':
                # Keras models
                predictions = model.predict(processed_image)
                prediction = np.argmax(predictions, axis=1)[0]
                confidence = float(np.max(predictions))
                probabilities = predictions.tolist()

                # Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
                label = f"Ø§Ù„ÙØ¦Ø© {prediction}"

            return {
                "model": model_name,
                "prediction": prediction,
                "label": label,
                "confidence": float(confidence),
                "probabilities": probabilities.tolist() if isinstance(
                    probabilities,
                    (np.ndarray,
                     torch.Tensor)) else probabilities}

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {model_name}: {e}")
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {str(e)}"}

    def ensemble_predict(self, image_path, models_to_use=None):
        """
        Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø¬Ù…Ø¹ Ù…Ù† Ø¹Ø¯Ø© Ù†Ù…Ø§Ø°Ø¬

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©
            models_to_use: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)

        Returns:
            dict: Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø¬Ù…Ø¹
        """
        if models_to_use is None:
            models_to_use = list(self.models.keys())

        predictions = {}
        valid_predictions = []

        for model_name in models_to_use:
            result = self.predict_single_model(image_path, model_name)
            predictions[model_name] = result

            if "error" not in result:
                valid_predictions.append({
                    'model': model_name,
                    'prediction': result['prediction'],
                    'label': result.get('label', f"Ø§Ù„ÙØ¦Ø© {result['prediction']}"),
                    'confidence': result['confidence']
                })

        if not valid_predictions:
            return {"error": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†Ù…Ø§Ø°Ø¬ ØµØ§Ù„Ø­Ø© Ù„Ù„ØªÙ†Ø¨Ø¤"}

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø¬Ù…Ø¹
        ensemble_result = self.calculate_ensemble(valid_predictions)

        return {
            "individual_predictions": predictions,
            "ensemble_prediction": ensemble_result,
            "models_used": len(valid_predictions),
            "total_models": len(models_to_use)
        }

    def calculate_ensemble(self, predictions):
        """
        Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø¬Ù…Ø¹

        Args:
            predictions: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª

        Returns:
            dict: Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø¬Ù…Ø¹
        """
        # Weighted voting based on confidence
        prediction_counts = {}
        confidence_sum = {}

        confidence_scores = []
        prediction_values = []
        labels = []

        for pred in predictions:
            prediction = pred['prediction']
            confidence = pred['confidence']
            label = pred['label']

            if prediction not in prediction_counts:
                prediction_counts[prediction] = 0
                confidence_sum[prediction] = 0

            prediction_counts[prediction] += 1
            confidence_sum[prediction] += confidence

            confidence_scores.append(confidence)
            prediction_values.append(prediction)
            labels.append(label)

        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹ Ù…Ø¹ Ø£Ø¹Ù„Ù‰ Ø«Ù‚Ø©
        max_count = 0
        max_confidence = 0
        ensemble_prediction = None
        ensemble_label = None

        for prediction, count in prediction_counts.items():
            avg_confidence = confidence_sum[prediction] / count

            if count > max_count or (
                    count == max_count and avg_confidence > max_confidence):
                max_count = count
                max_confidence = avg_confidence
                ensemble_prediction = prediction

                # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØªØ³Ù…ÙŠØ© Ù…Ù† Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ø£ÙƒØ«Ø± Ø«Ù‚Ø©
                for pred in predictions:
                    if pred['prediction'] == ensemble_prediction and pred['confidence'] == max_confidence:
                        ensemble_label = pred['label']
                        break

        if ensemble_label is None:
            ensemble_label = f"Ø§Ù„ÙØ¦Ø© {ensemble_prediction}"

        # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ØªÙØ§Ù‚
        unique_predictions = len(set(prediction_values))
        agreement_score = 1.0 - (unique_predictions - 1) / \
            len(predictions) if len(predictions) > 0 else 0

        return {
            "prediction": ensemble_prediction,
            "label": ensemble_label,
            "confidence": float(max_confidence),
            "agreement_score": float(agreement_score),
            "vote_count": max_count,
            "total_votes": len(predictions),
            "individual_confidences": confidence_scores
        }

    def analyze_image_comprehensive(self, image_path):
        """
        ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„ØµÙˆØ±Ø©

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©

        Returns:
            dict: Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
        """
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…Ø¬Ù…Ø¹
        ensemble_result = self.ensemble_predict(image_path)

        # ØªØ­Ù„ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ
        additional_analysis = {
            "image_quality": self.assess_image_quality(image_path),
            "leaf_detection": self.detect_leaf_regions(image_path),
            "stress_analysis": self.analyze_plant_stress(image_path),
            "recommendations": self.generate_recommendations(ensemble_result)
        }

        return {
            "predictions": ensemble_result,
            "analysis": additional_analysis,
            "timestamp": self.get_timestamp()
        }

    def assess_image_quality(self, image_path):
        """
        ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©

        Returns:
            dict: Ù†ØªÙŠØ¬Ø© ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø©
        """
        try:
            image = Image.open(image_path)

            # Basic quality metrics
            width, height = image.size
            aspect_ratio = width / height

            # Convert to numpy for analysis
            img_array = np.array(image)

            # Brightness analysis
            brightness = np.mean(img_array)

            # Contrast analysis
            contrast = np.std(img_array)

            # Blur detection (Laplacian variance)
            gray = np.mean(
                img_array, axis=2) if len(
                img_array.shape) == 3 else img_array
            blur_score = self.laplacian_variance(gray)

            return {
                "resolution": f"{width}x{height}",
                "aspect_ratio": float(aspect_ratio),
                "brightness": float(brightness),
                "contrast": float(contrast),
                "blur_score": float(blur_score),
                "quality_score": float(
                    self.calculate_quality_score(
                        brightness,
                        contrast,
                        blur_score))}
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}"}

    def laplacian_variance(self, image):
        """
        Ø­Ø³Ø§Ø¨ Laplacian variance Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ©

        Args:
            image: Ù…ØµÙÙˆÙØ© Ø§Ù„ØµÙˆØ±Ø©

        Returns:
            float: Ù‚ÙŠÙ…Ø© Laplacian variance
        """
        # Simplified Laplacian calculation
        laplacian = np.abs(np.diff(image, axis=0)).mean() + \
            np.abs(np.diff(image, axis=1)).mean()
        return laplacian

    def calculate_quality_score(self, brightness, contrast, blur_score):
        """
        Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©

        Args:
            brightness: Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ø·ÙˆØ¹
            contrast: Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ†
            blur_score: Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ©

        Returns:
            float: Ù†Ù‚Ø§Ø· Ø§Ù„Ø¬ÙˆØ¯Ø©
        """
        # Normalize scores
        brightness_score = min(1.0, brightness / 128.0)
        contrast_score = min(1.0, contrast / 50.0)
        blur_score_norm = min(1.0, blur_score / 100.0)

        # Weighted average
        quality = (
            brightness_score *
            0.3 +
            contrast_score *
            0.4 +
            blur_score_norm *
            0.3)
        return quality

    def detect_leaf_regions(self, image_path):
        """
        ÙƒØ´Ù Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©

        Returns:
            dict: Ù†ØªÙŠØ¬Ø© ÙƒØ´Ù Ø§Ù„Ø£ÙˆØ±Ø§Ù‚
        """
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… YOLOv8 Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
            if 'yolo_plant' in self.models:
                try:
                    results = self.models['yolo_plant'](image_path)
                    return {
                        "detected_leaves": len(
                            results.pandas().xyxy[0]),
                        "bounding_boxes": results.pandas().xyxy[0].to_dict('records'),
                        "confidence": float(
                            results.pandas().xyxy[0]['confidence'].mean())}
                except BaseException:
                    pass

            # Basic leaf detection using color analysis
            image = Image.open(image_path)
            img_array = np.array(image)

            # Simple green detection
            green_mask = self.detect_green_regions(img_array)
            leaf_percentage = np.sum(green_mask) / green_mask.size

            return {
                "leaf_coverage": float(leaf_percentage),
                "green_detected": bool(leaf_percentage > 0.1),
                "method": "color_analysis"
            }
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØ´Ù Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚: {e}")
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ ÙƒØ´Ù Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚: {str(e)}"}

    def detect_green_regions(self, img_array):
        """
        ÙƒØ´Ù Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø®Ø¶Ø±Ø§Ø¡

        Args:
            img_array: Ù…ØµÙÙˆÙØ© Ø§Ù„ØµÙˆØ±Ø©

        Returns:
            ndarray: Ù‚Ù†Ø§Ø¹ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø®Ø¶Ø±Ø§Ø¡
        """
        # Convert to HSV for better green detection
        # Simplified RGB to HSV conversion
        r, g, b = img_array[:, :, 0], img_array[:, :, 1], img_array[:, :, 2]

        # Simple green detection
        green_mask = (g > r) & (g > b) & (g > 50)

        return green_mask

    def analyze_plant_stress(self, image_path):
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ù‡Ø§Ø¯ Ø§Ù„Ù†Ø¨Ø§ØªÙŠ

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©

        Returns:
            dict: Ù†ØªÙŠØ¬Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ù‡Ø§Ø¯
        """
        try:
            image = Image.open(image_path)
            img_array = np.array(image)

            # Color analysis for stress indicators
            r_avg = np.mean(img_array[:, :, 0])
            g_avg = np.mean(img_array[:, :, 1])
            b_avg = np.mean(img_array[:, :, 2])

            # Stress indicators
            yellowing = r_avg > g_avg  # Indicates nitrogen deficiency
            browning = (
                r_avg > 100) and (
                g_avg < 80) and (
                b_avg < 60)  # Brown spots
            wilting = g_avg < 70  # Low green indicates wilting

            stress_score = (int(yellowing) + int(browning) + int(wilting)) / 3

            return {
                "yellowing_detected": bool(yellowing),
                "browning_detected": bool(browning),
                "wilting_detected": bool(wilting),
                "stress_score": float(stress_score),
                "color_averages": {
                    "red": float(r_avg),
                    "green": float(g_avg),
                    "blue": float(b_avg)
                }
            }
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ù‡Ø§Ø¯ Ø§Ù„Ù†Ø¨Ø§ØªÙŠ: {e}")
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ù‡Ø§Ø¯ Ø§Ù„Ù†Ø¨Ø§ØªÙŠ: {str(e)}"}

    def generate_recommendations(self, prediction_result):
        """
        ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù„Ø§Ø¬ÙŠØ©

        Args:
            prediction_result: Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙ†Ø¨Ø¤

        Returns:
            list: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª
        """
        if "error" in prediction_result:
            return ["ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©"]

        ensemble = prediction_result.get("ensemble_prediction", {})
        confidence = ensemble.get("confidence", 0)
        agreement = ensemble.get("agreement_score", 0)

        recommendations = []

        # Confidence-based recommendations
        if confidence < 0.7:
            recommendations.append(
                "Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„ØªØ´Ø®ÙŠØµ Ù…Ù†Ø®ÙØ¶Ø© - ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„Ø±Ø¬ÙˆØ¹ Ù„Ø®Ø¨ÙŠØ± Ø²Ø±Ø§Ø¹ÙŠ")

        if agreement < 0.6:
            recommendations.append(
                "Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØºÙŠØ± Ù…ØªÙÙ‚Ø© - ÙŠÙÙ†ØµØ­ Ø¨Ø£Ø®Ø° ØµÙˆØ± Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù† Ø²ÙˆØ§ÙŠØ§ Ù…Ø®ØªÙ„ÙØ©")

        # General plant care recommendations
        recommendations.extend([
            "ØªØ£ÙƒØ¯ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©",
            "Ø±Ø§Ù‚Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø±Ø·ÙˆØ¨Ø© ÙÙŠ Ø§Ù„ØªØ±Ø¨Ø©",
            "ÙØ­Øµ Ø¯ÙˆØ±ÙŠ Ù„Ù„Ø¢ÙØ§Øª ÙˆØ§Ù„Ø£Ù…Ø±Ø§Ø¶",
            "Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø³Ù…Ø¯Ø© Ø§Ù„Ø¹Ø¶ÙˆÙŠØ© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù†Ø¨Ø§Øª"
        ])

        return recommendations

    def get_timestamp(self):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø§Ø¨Ø¹ Ø§Ù„Ø²Ù…Ù†ÙŠ

        Returns:
            str: Ø§Ù„Ø·Ø§Ø¨Ø¹ Ø§Ù„Ø²Ù…Ù†ÙŠ
        """
        return datetime.now().isoformat()

    def save_analysis_result(self, result, output_path):
        """
        Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„

        Args:
            result: Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø­ÙØ¸

        Returns:
            bool: Ù†Ø¬Ø§Ø­ Ø§Ù„Ø­ÙØ¸
        """
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ {output_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
            return False

    def batch_process_images(self, images_folder, output_folder=None):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© ØµÙˆØ±

        Args:
            images_folder: Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµÙˆØ±
            output_folder: Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)

        Returns:
            dict: Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        """
        if output_folder is None:
            output_folder = os.path.join(
                os.path.dirname(images_folder), 'results')

        os.makedirs(output_folder, exist_ok=True)

        results = {}

        for image_file in os.listdir(images_folder):
            if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                image_path = os.path.join(images_folder, image_file)

                try:
                    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
                    result = self.analyze_image_comprehensive(image_path)
                    results[image_file] = result

                    # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                    output_path = os.path.join(
                        output_folder, f"{os.path.splitext(image_file)[0]}_result.json")
                    self.save_analysis_result(result, output_path)

                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© {image_file}: {e}")
                    results[image_file] = {"error": str(e)}

        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
        summary_path = os.path.join(
            output_folder, "batch_results_summary.json")
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        return results

    def get_available_models(self):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©

        Returns:
            list: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©
        """
        return list(self.models.keys())

    def get_model_info(self, model_name):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Args:
            model_name: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Returns:
            dict: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        if model_name not in self.models:
            return {"error": f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_name} ØºÙŠØ± Ù…ØªØ§Ø­"}

        model = self.models[model_name]

        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø©
        info = {
            "name": model_name,
            "type": self._get_model_type(model_name, model)
        }

        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        if model_name in ['mobilenet_plant', 'vit_plant']:
            # Hugging Face models
            if hasattr(model.config, 'id2label'):
                info["classes"] = len(model.config.id2label)
                info["labels"] = model.config.id2label

            if hasattr(model.config, 'model_type'):
                info["architecture"] = model.config.model_type

        return info

    def _get_model_type(self, model_name, model):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Args:
            model_name: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Returns:
            str: Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        if model_name in ['mobilenet_plant', 'vit_plant']:
            return "huggingface"
        elif model_name in ['cropnet_cassava', 'cropnet_feature', 'mobilenet_v3']:
            return "tensorflow"
        elif model_name == 'alexnet_plantvillage':
            return "pytorch"
        elif model_name == 'keras_plant':
            return "keras"
        else:
            return "unknown"


class DatasetManager:
    """Ù…Ø¯ÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù†Ø¨Ø§ØªØ§Øª ÙˆØ§Ù„Ø£Ù…Ø±Ø§Ø¶"""

    def __init__(self, datasets_dir=None):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

        Args:
            datasets_dir: Ù…Ø³Ø§Ø± Ù…Ø¬Ù„Ø¯ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        """
        self.datasets = {}
        self.download_queue = []
        self.datasets_dir = datasets_dir or os.path.join(
            os.path.dirname(__file__), 'datasets')

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        os.makedirs(self.datasets_dir, exist_ok=True)

        logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    def setup_all_datasets(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø¬Ù…ÙŠØ¹ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""

        self.download_plantvillage()
        self.download_plantdoc()
        self.download_cassava()
        self.download_additional_datasets()

        logger.info(f"ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ {len(self.datasets)} Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª")

    def download_plantvillage(self):
        """ØªØ­Ù…ÙŠÙ„ PlantVillage"""

        try:
            # Method 1: TensorFlow Datasets
            import tensorflow_datasets as tfds
            ds = tfds.load('plant_village', split='train')
            self.datasets['plantvillage_tfds'] = ds
            logger.info("âœ… PlantVillage Ù…Ù† TFDS")

        except BaseException:
            # Method 2: Manual download from GitHub
            self.download_from_github(
                "https://github.com/spMohanty/PlantVillage-Dataset.git",
                "plantvillage_github"
            )

    def download_plantdoc(self):
        """ØªØ­Ù…ÙŠÙ„ PlantDoc"""

        self.download_from_github(
            "https://github.com/pratikkayal/PlantDoc-Dataset.git",
            "plantdoc"
        )

    def download_cassava(self):
        """ØªØ­Ù…ÙŠÙ„ Cassava dataset"""

        try:
            import tensorflow_datasets as tfds
            ds = tfds.load('cassava', split=['train', 'validation', 'test'])
            self.datasets['cassava'] = ds
            logger.info("âœ… Cassava Ù…Ù† TFDS")
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Cassava: {e}")

    def download_from_github(self, repo_url, dataset_name):
        """
        ØªØ­Ù…ÙŠÙ„ Ù…Ù† GitHub

        Args:
            repo_url: Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
            dataset_name: Ø§Ø³Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        import subprocess

        try:
            dataset_path = os.path.join(self.datasets_dir, dataset_name)

            if not os.path.exists(dataset_path):
                subprocess.run(['git', 'clone', repo_url, dataset_path],
                               check=True, capture_output=True)
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {dataset_name}")
            else:
                logger.info(f"ğŸ“ {dataset_name} Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ø§Ù‹")

            self.datasets[dataset_name] = dataset_path

        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ {dataset_name}: {e}")

    def download_additional_datasets(self):
        """ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©"""

        additional_urls = {
            'new_plant_diseases': 'https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset',
            'plant_pathology': 'https://www.kaggle.com/competitions/plant-pathology-2020-fgvc7'}

        for name, url in additional_urls.items():
            self.download_queue.append((name, url))
            logger.info(f"ğŸ“‹ Ø¥Ø¶Ø§ÙØ© {name} Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„")

    def create_unified_dataset(self):
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ­Ø¯Ø©

        Returns:
            dict: Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ­Ø¯Ø©
        """
        unified_data = {
            'images': [],
            'labels': [],
            'sources': [],
            'metadata': []
        }

        for dataset_name, dataset in self.datasets.items():
            data = self.process_dataset(dataset, dataset_name)

            unified_data['images'].extend(data['images'])
            unified_data['labels'].extend(data['labels'])
            unified_data['sources'].extend(
                [dataset_name] * len(data['images']))
            unified_data['metadata'].extend(data['metadata'])

        logger.info(
            f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ­Ø¯Ø© Ø¨Ù€ {len(unified_data['images'])} ØµÙˆØ±Ø©")
        return unified_data

    def process_dataset(self, dataset, dataset_name):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ø­Ø¯Ø©

        Args:
            dataset: Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            dataset_name: Ø§Ø³Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

        Returns:
            dict: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        """
        if dataset_name == 'plantvillage_tfds':
            return self.process_tfds_dataset(dataset)
        elif dataset_name in ['plantdoc', 'plantvillage_github']:
            return self.process_folder_dataset(dataset)
        else:
            return {'images': [], 'labels': [], 'metadata': []}

    def process_tfds_dataset(self, dataset):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© TFDS dataset

        Args:
            dataset: Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

        Returns:
            dict: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        """
        images = []
        labels = []
        metadata = []

        for example in dataset.take(1000):  # Ø¹ÙŠÙ†Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
            images.append(example['image'].numpy())
            labels.append(example['label'].numpy())
            metadata.append({
                'width': example['image'].shape[1],
                'height': example['image'].shape[0],
                'channels': example['image'].shape[2]
            })

        return {
            'images': images,
            'labels': labels,
            'metadata': metadata
        }

    def process_folder_dataset(self, folder_path):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© dataset ÙÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª

        Args:
            folder_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø¬Ù„Ø¯

        Returns:
            dict: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        """
        import os

        from PIL import Image

        images = []
        labels = []
        metadata = []

        # Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    file_path = os.path.join(root, file)

                    try:
                        img = Image.open(file_path)
                        images.append(np.array(img))

                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØ³Ù…ÙŠØ© Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯
                        label = os.path.basename(root)
                        labels.append(label)

                        metadata.append({
                            'path': file_path,
                            'width': img.width,
                            'height': img.height,
                            'mode': img.mode
                        })

                    except Exception as e:
                        logger.error(f"ØªØ¬Ø§Ù‡Ù„ {file_path}: {e}")

        return {
            'images': images,
            'labels': labels,
            'metadata': metadata
        }

    def download_dataset_from_url(self, url, dataset_name):
        """
        ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø±Ø§Ø¨Ø·

        Args:
            url: Ø±Ø§Ø¨Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            dataset_name: Ø§Ø³Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

        Returns:
            bool: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ­Ù…ÙŠÙ„
        """
        try:
            import zipfile

            import requests

            dataset_path = os.path.join(self.datasets_dir, dataset_name)
            os.makedirs(dataset_path, exist_ok=True)

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
            zip_path = os.path.join(dataset_path, f"{dataset_name}.zip")

            logger.info(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ {dataset_name} Ù…Ù† {url}")

            response = requests.get(url, stream=True)
            with open(zip_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„Ù
            logger.info(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ {dataset_name}")

            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(dataset_path)

            # Ø¥Ø¶Ø§ÙØ© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            self.datasets[dataset_name] = dataset_path

            logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ {dataset_name}")
            return True

        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ {dataset_name}: {e}")
            return False

    def get_dataset_info(self, dataset_name):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

        Args:
            dataset_name: Ø§Ø³Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

        Returns:
            dict: Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        if dataset_name not in self.datasets:
            return {"error": f"Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª {dataset_name} ØºÙŠØ± Ù…ØªØ§Ø­Ø©"}

        dataset = self.datasets[dataset_name]

        if dataset_name == 'plantvillage_tfds':
            # TensorFlow Dataset
            info = {
                "name": dataset_name,
                "type": "tfds",
                "size": len(dataset),
                "classes": len(set(example['label'].numpy() for example in dataset.take(1000)))
            }
        else:
            # Folder dataset
            import os

            # Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ±
            image_count = 0
            classes = set()

            for root, dirs, files in os.walk(dataset):
                for file in files:
                    if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                        image_count += 1
                        classes.add(os.path.basename(root))

            info = {
                "name": dataset_name,
                "type": "folder",
                "path": dataset,
                "size": image_count,
                "classes": len(classes),
                "class_names": list(classes)
            }

        return info

    def get_available_datasets(self):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©

        Returns:
            list: Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
        """
        return list(self.datasets.keys())

    def export_dataset(self, dataset_name, output_format, output_path):
        """
        ØªØµØ¯ÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª

        Args:
            dataset_name: Ø§Ø³Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            output_format: ØµÙŠØºØ© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ (tfrecord, csv, json)
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬

        Returns:
            bool: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØµØ¯ÙŠØ±
        """
        if dataset_name not in self.datasets:
            logger.error(f"âŒ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª {dataset_name} ØºÙŠØ± Ù…ØªØ§Ø­Ø©")
            return False

        dataset = self.datasets[dataset_name]

        try:
            if output_format == 'tfrecord':
                self._export_to_tfrecord(dataset, dataset_name, output_path)
            elif output_format == 'csv':
                self._export_to_csv(dataset, dataset_name, output_path)
            elif output_format == 'json':
                self._export_to_json(dataset, dataset_name, output_path)
            else:
                logger.error(f"âŒ ØµÙŠØºØ© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ {output_format} ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©")
                return False

            logger.info(
                f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± {dataset_name} Ø¨ØµÙŠØºØ© {output_format} Ø¥Ù„Ù‰ {output_path}")
            return True

        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØµØ¯ÙŠØ± {dataset_name}: {e}")
            return False

    def _export_to_tfrecord(self, dataset, dataset_name, output_path):
        """
        ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ TFRecord

        Args:
            dataset: Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            dataset_name: Ø§Ø³Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
        """
        import tensorflow as tf

        def _bytes_feature(value):
            """Returns a bytes_list from a string / byte."""
            if isinstance(value, type(tf.constant(0))):
                value = value.numpy()
            return tf.train.Feature(
                bytes_list=tf.train.BytesList(
                    value=[value]))

        def _int64_feature(value):
            """Returns an int64_list from a bool / enum / int / uint."""
            return tf.train.Feature(
                int64_list=tf.train.Int64List(
                    value=[value]))

        with tf.io.TFRecordWriter(output_path) as writer:
            if dataset_name == 'plantvillage_tfds':
                # TensorFlow Dataset
                for example in dataset:
                    image = example['image'].numpy()
                    label = example['label'].numpy()

                    # Convert image to bytes
                    image_bytes = tf.io.encode_jpeg(image).numpy()

                    # Create a feature
                    feature = {
                        'image': _bytes_feature(image_bytes),
                        'label': _int64_feature(label)
                    }

                    # Create an example protocol buffer
                    example_proto = tf.train.Example(
                        features=tf.train.Features(feature=feature))

                    # Serialize to string and write to file
                    writer.write(example_proto.SerializeToString())
            else:
                # Folder dataset
                data = self.process_folder_dataset(dataset)

                for i in range(len(data['images'])):
                    image = data['images'][i]
                    label = data['labels'][i]

                    # Convert image to bytes
                    image_bytes = tf.io.encode_jpeg(image).numpy()

                    # Create a feature
                    feature = {
                        'image': _bytes_feature(image_bytes),
                        'label': _bytes_feature(label.encode('utf-8'))
                    }

                    # Create an example protocol buffer
                    example_proto = tf.train.Example(
                        features=tf.train.Features(feature=feature))

                    # Serialize to string and write to file
                    writer.write(example_proto.SerializeToString())

    def _export_to_csv(self, dataset, dataset_name, output_path):
        """
        ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ CSV

        Args:
            dataset: Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            dataset_name: Ø§Ø³Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
        """
        import csv

        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['image_path', 'label'])

            if dataset_name == 'plantvillage_tfds':
                # Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØµØ¯ÙŠØ± TensorFlow Dataset Ø¥Ù„Ù‰ CSV Ù…Ø¨Ø§Ø´Ø±Ø©
                logger.warning(
                    "âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØµØ¯ÙŠØ± TensorFlow Dataset Ø¥Ù„Ù‰ CSV Ù…Ø¨Ø§Ø´Ø±Ø©")
            else:
                # Folder dataset
                for root, dirs, files in os.walk(dataset):
                    for file in files:
                        if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                            file_path = os.path.join(root, file)
                            label = os.path.basename(root)
                            writer.writerow([file_path, label])

    def _export_to_json(self, dataset, dataset_name, output_path):
        """
        ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ JSON

        Args:
            dataset: Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            dataset_name: Ø§Ø³Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
        """
        import json

        data = []

        if dataset_name == 'plantvillage_tfds':
            # Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØµØ¯ÙŠØ± TensorFlow Dataset Ø¥Ù„Ù‰ JSON Ù…Ø¨Ø§Ø´Ø±Ø©
            logger.warning(
                "âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØµØ¯ÙŠØ± TensorFlow Dataset Ø¥Ù„Ù‰ JSON Ù…Ø¨Ø§Ø´Ø±Ø©")
        else:
            # Folder dataset
            for root, dirs, files in os.walk(dataset):
                for file in files:
                    if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                        file_path = os.path.join(root, file)
                        label = os.path.basename(root)

                        try:
                            from PIL import Image
                            img = Image.open(file_path)

                            data.append({
                                'image_path': file_path,
                                'label': label,
                                'width': img.width,
                                'height': img.height,
                                'mode': img.mode
                            })
                        except Exception as e:
                            logger.error(f"ØªØ¬Ø§Ù‡Ù„ {file_path}: {e}")

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)


class AdvancedTrainingSystem:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù†Ù…Ø§Ø°Ø¬"""

    def __init__(self, processor, dataset_manager):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…

        Args:
            processor: Ù…Ø¹Ø§Ù„Ø¬ Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†Ø¨Ø§ØªØ§Øª
            dataset_manager: Ù…Ø¯ÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        self.processor = processor
        self.dataset_manager = dataset_manager
        self.training_history = {}

        logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")

    def create_custom_model(self, num_classes=38):
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØµØµ ÙŠØ¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©

        Args:
            num_classes: Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª

        Returns:
            object: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØµØµ
        """
        try:
            # Knowledge Distillation Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
            student_model = self.create_student_architecture(num_classes)

            logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø·Ø§Ù„Ø¨ Ù…Ø®ØµØµ Ø¨Ù€ {num_classes} ÙØ¦Ø©")
            return student_model
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØµØµ: {e}")
            return None

    def create_student_architecture(self, num_classes=38):
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ø·Ø§Ù„Ø¨

        Args:
            num_classes: Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª

        Returns:
            object: Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ø·Ø§Ù„Ø¨
        """
        try:
            import torch.nn as nn

            class PlantDiseaseStudent(nn.Module):
                def __init__(self, num_classes=38):
                    super().__init__()

                    # Efficient backbone
                    self.backbone = self.create_efficient_backbone()

                    # Multi-task heads
                    self.disease_head = nn.Linear(512, num_classes)
                    self.severity_head = nn.Linear(512, 1)
                    self.stress_head = nn.Linear(512, 5)  # 5 stress types

                def create_efficient_backbone(self):
                    """Ø¥Ù†Ø´Ø§Ø¡ backbone ÙØ¹Ø§Ù„"""

                    return nn.Sequential(
                        # Depthwise separable convolutions
                        self.depthwise_separable_conv(3, 32, 3, 2),
                        self.depthwise_separable_conv(32, 64, 3, 1),
                        self.depthwise_separable_conv(64, 128, 3, 2),
                        self.depthwise_separable_conv(128, 256, 3, 1),
                        self.depthwise_separable_conv(256, 512, 3, 2),

                        nn.AdaptiveAvgPool2d((1, 1)),
                        nn.Flatten()
                    )

                def depthwise_separable_conv(
                        self, in_channels, out_channels, kernel_size, stride):
                    """Depthwise Separable Convolution"""

                    return nn.Sequential(
                        # Depthwise
                        nn.Conv2d(in_channels, in_channels, kernel_size, stride,
                                  padding=kernel_size // 2, groups=in_channels),
                        nn.BatchNorm2d(in_channels),
                        nn.ReLU6(inplace=True),

                        # Pointwise
                        nn.Conv2d(in_channels, out_channels, 1),
                        nn.BatchNorm2d(out_channels),
                        nn.ReLU6(inplace=True)
                    )

                def forward(self, x):
                    features = self.backbone(x)

                    disease_pred = self.disease_head(features)
                    severity_pred = self.severity_head(features)
                    stress_pred = self.stress_head(features)

                    return {
                        'disease': disease_pred,
                        'severity': severity_pred,
                        'stress': stress_pred
                    }

            return PlantDiseaseStudent(num_classes)
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ø·Ø§Ù„Ø¨: {e}")
            raise

    def train_with_ensemble_teachers(
            self,
            student_model,
            epochs=100,
            batch_size=32,
            learning_rate=1e-4):
        """
        ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ÙŠÙ†

        Args:
            student_model: Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø·Ø§Ù„Ø¨
            epochs: Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù‚Ø¨
            batch_size: Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø©
            learning_rate: Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…

        Returns:
            dict: ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        """
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†
            teachers = self.setup_teacher_models()

            if not teachers:
                logger.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¹Ù„Ù…Ø© Ù…ØªØ§Ø­Ø©")
                return None

            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            train_loader = self.prepare_training_data(batch_size)

            if train_loader is None:
                logger.error("âŒ ÙØ´Ù„ Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
                return None

            # ØªØ¯Ø±ÙŠØ¨ Knowledge Distillation
            history = self.knowledge_distillation_training(
                student_model, teachers, train_loader, epochs, learning_rate
            )

            logger.info(f"âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØµØµ Ù„Ù€ {epochs} Ø­Ù‚Ø¨Ø©")
            return history
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØµØµ: {e}")
            return None

    def setup_teacher_models(self):
        """
        Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¹Ù„Ù…Ø©

        Returns:
            dict: Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¹Ù„Ù…Ø©
        """
        teachers = {}

        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø© ÙƒÙ…Ø¹Ù„Ù…ÙŠÙ†
        for model_name, model in self.processor.models.items():
            if model_name in [
                'mobilenet_plant',
                'vit_plant',
                    'alexnet_plantvillage']:
                teachers[model_name] = model
                logger.info(f"âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ {model_name} ÙƒÙ†Ù…ÙˆØ°Ø¬ Ù…Ø¹Ù„Ù…")

        return teachers

    def knowledge_distillation_training(
            self,
            student,
            teachers,
            train_loader,
            epochs=100,
            learning_rate=1e-4):
        """
        ØªØ¯Ø±ÙŠØ¨ Knowledge Distillation

        Args:
            student: Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø·Ø§Ù„Ø¨
            teachers: Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¹Ù„Ù…Ø©
            train_loader: Ù…Ø­Ù…Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            epochs: Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù‚Ø¨
            learning_rate: Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…

        Returns:
            dict: ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        """
        try:
            import torch.optim as optim

            optimizer = optim.AdamW(student.parameters(), lr=learning_rate)
            scheduler = optim.lr_scheduler.CosineAnnealingLR(
                optimizer, T_max=epochs)

            student.train()

            history = {
                'loss': [],
                'classification_loss': [],
                'distillation_loss': []
            }

            for epoch in range(epochs):
                total_loss = 0
                total_classification_loss = 0
                total_distillation_loss = 0

                for batch_idx, (data, target) in enumerate(train_loader):
                    optimizer.zero_grad()

                    # Student prediction
                    student_output = student(data)

                    # Teacher predictions
                    teacher_outputs = self.get_teacher_predictions(
                        data, teachers)

                    # Calculate losses
                    classification_loss, distillation_loss, loss = self.calculate_distillation_loss(
                        student_output, teacher_outputs, target)

                    loss.backward()
                    optimizer.step()

                    total_loss += loss.item()
                    total_classification_loss += classification_loss.item()
                    total_distillation_loss += distillation_loss.item()

                scheduler.step()

                # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø³Ø§Ø±Ø©
                avg_loss = total_loss / len(train_loader)
                avg_classification_loss = total_classification_loss / \
                    len(train_loader)
                avg_distillation_loss = total_distillation_loss / \
                    len(train_loader)

                # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ§Ø±ÙŠØ®
                history['loss'].append(avg_loss)
                history['classification_loss'].append(avg_classification_loss)
                history['distillation_loss'].append(avg_distillation_loss)

                if epoch % 10 == 0:
                    logger.info(
                        f"Epoch {epoch}, Loss: {avg_loss:.4f}, Classification Loss: {avg_classification_loss:.4f}, Distillation Loss: {avg_distillation_loss:.4f}")

            return history
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ¯Ø±ÙŠØ¨ Knowledge Distillation: {e}")
            raise

    def get_teacher_predictions(self, data, teachers):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†

        Args:
            data: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            teachers: Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¹Ù„Ù…Ø©

        Returns:
            dict: ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†
        """
        import torch

        teacher_outputs = {}

        for name, teacher in teachers.items():
            try:
                teacher.eval()
                with torch.no_grad():
                    if hasattr(teacher, 'forward'):
                        output = teacher(data)
                        teacher_outputs[name] = output
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ù„Ù… {name}: {e}")

        return teacher_outputs

    def calculate_distillation_loss(
            self,
            student_output,
            teacher_outputs,
            target):
        """
        Ø­Ø³Ø§Ø¨ Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªÙ‚Ø·ÙŠØ±

        Args:
            student_output: Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ø·Ø§Ù„Ø¨
            teacher_outputs: Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†
            target: Ø§Ù„Ù‡Ø¯Ù

        Returns:
            tuple: Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªØµÙ†ÙŠÙØŒ Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªÙ‚Ø·ÙŠØ±ØŒ Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        """
        import torch.nn.functional as F

        # Classification loss
        classification_loss = F.cross_entropy(
            student_output['disease'], target)

        # Distillation loss from teachers
        distillation_loss = 0
        temperature = 4.0

        for teacher_name, teacher_output in teacher_outputs.items():
            if isinstance(
                    teacher_output,
                    dict) and 'disease' in teacher_output:
                teacher_logits = teacher_output['disease']
            else:
                teacher_logits = teacher_output

            # Soft targets from teacher
            teacher_soft = F.softmax(teacher_logits / temperature, dim=1)
            student_soft = F.log_softmax(
                student_output['disease'] / temperature, dim=1)

            kd_loss = F.kl_div(
                student_soft,
                teacher_soft,
                reduction='batchmean')
            distillation_loss += kd_loss

        # Weighted combination
        total_loss = 0.3 * classification_loss + 0.7 * distillation_loss

        return classification_loss, distillation_loss, total_loss

    def prepare_training_data(self, batch_size=32):
        """
        Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨

        Args:
            batch_size: Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø©

        Returns:
            object: Ù…Ø­Ù…Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        """
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ­Ø¯Ø©
            unified_data = self.dataset_manager.create_unified_dataset()

            if not unified_data['images']:
                logger.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨")
                return None

            # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ PyTorch DataLoader
            dataset = self.create_pytorch_dataset(unified_data)

            from torch.utils.data import DataLoader
            return DataLoader(dataset, batch_size=batch_size, shuffle=True)
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
            return None

    def create_pytorch_dataset(self, unified_data):
        """
        Ø¥Ù†Ø´Ø§Ø¡ PyTorch Dataset

        Args:
            unified_data: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ­Ø¯Ø©

        Returns:
            object: PyTorch Dataset
        """
        try:
            import torch
            from torch.utils.data import Dataset

            class PlantDiseaseDataset(Dataset):
                def __init__(self, data):
                    self.images = data['images']
                    self.labels = data['labels']
                    self.transform = self.get_transforms()

                def get_transforms(self):
                    from torchvision import transforms
                    return transforms.Compose([
                        transforms.ToPILImage(),
                        transforms.Resize((224, 224)),
                        transforms.ToTensor(),
                        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                             std=[0.229, 0.224, 0.225])
                    ])

                def __len__(self):
                    return len(self.images)

                def __getitem__(self, idx):
                    image = self.images[idx]
                    label = self.labels[idx]

                    if self.transform:
                        image = self.transform(image)

                    return image, torch.tensor(label, dtype=torch.long)

            return PlantDiseaseDataset(unified_data)
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ PyTorch Dataset: {e}")
            raise

    def save_model(self, model, model_path):
        """
        Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø­ÙØ¸

        Returns:
            bool: Ù†Ø¬Ø§Ø­ Ø§Ù„Ø­ÙØ¸
        """
        try:
            import torch

            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
            os.makedirs(os.path.dirname(model_path), exist_ok=True)

            # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            torch.save(model.state_dict(), model_path)

            logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ {model_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return False

    def load_model(self, model_path, num_classes=38):
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Args:
            model_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            num_classes: Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª

        Returns:
            object: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ù…Ù„
        """
        try:
            import torch

            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model = self.create_student_architecture(num_classes)

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
            model.load_state_dict(torch.load(model_path, map_location='cpu'))

            logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† {model_path}")
            return model
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return None

    def evaluate_model(self, model, test_loader):
        """
        ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            test_loader: Ù…Ø­Ù…Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±

        Returns:
            dict: Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        """
        try:
            import numpy as np
            import torch
            from sklearn.metrics import (
                accuracy_score,
                confusion_matrix,
                f1_score,
                precision_score,
                recall_score,
            )

            model.eval()

            all_predictions = []
            all_targets = []

            with torch.no_grad():
                for data, target in test_loader:
                    # Ø§Ù„ØªÙ†Ø¨Ø¤
                    output = model(data)

                    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
                    predictions = torch.argmax(output['disease'], dim=1)

                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù
                    all_predictions.extend(predictions.cpu().numpy())
                    all_targets.extend(target.cpu().numpy())

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            accuracy = accuracy_score(all_targets, all_predictions)
            precision = precision_score(
                all_targets, all_predictions, average='weighted')
            recall = recall_score(
                all_targets,
                all_predictions,
                average='weighted')
            f1 = f1_score(all_targets, all_predictions, average='weighted')
            conf_matrix = confusion_matrix(all_targets, all_predictions)

            # Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ÙØ¦Ø§Øª
            class_metrics = {}
            classes = np.unique(all_targets)

            for cls in classes:
                cls_precision = precision_score(
                    all_targets, all_predictions, labels=[cls], average='weighted')
                cls_recall = recall_score(
                    all_targets,
                    all_predictions,
                    labels=[cls],
                    average='weighted')
                cls_f1 = f1_score(
                    all_targets,
                    all_predictions,
                    labels=[cls],
                    average='weighted')

                class_metrics[int(cls)] = {
                    'precision': float(cls_precision),
                    'recall': float(cls_recall),
                    'f1_score': float(cls_f1)
                }

            results = {
                'accuracy': float(accuracy),
                'precision': float(precision),
                'recall': float(recall),
                'f1_score': float(f1),
                'confusion_matrix': conf_matrix.tolist(),
                'class_metrics': class_metrics
            }

            logger.info(f"âœ… ØªÙ… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ø§Ù„Ø¯Ù‚Ø©: {accuracy:.4f}")
            return results
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return None

    def optimize_model(self, model, method, config=None):
        """
        ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            method: Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ø³ÙŠÙ† (pruning, quantization, distillation)
            config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†

        Returns:
            object: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù†
        """
        try:
            if method == 'pruning':
                return self._apply_pruning(model, config)
            elif method == 'quantization':
                return self._apply_quantization(model, config)
            elif method == 'distillation':
                return self._apply_distillation(model, config)
            else:
                logger.error(f"âŒ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ø³ÙŠÙ† {method} ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©")
                return None
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return None

    def _apply_pruning(self, model, config=None):
        """
        ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ‚Ù„ÙŠÙ…

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙ‚Ù„ÙŠÙ…

        Returns:
            object: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù‚Ù„Ù…
        """
        try:
            import torch.nn.utils.prune as prune

            if config is None:
                config = {'pruning_ratio': 0.5}

            pruning_ratio = config.get('pruning_ratio', 0.5)

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ‚Ù„ÙŠÙ… Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø®Ø·ÙŠØ©
            for name, module in model.named_modules():
                if isinstance(
                        module,
                        torch.nn.Linear) or isinstance(
                        module,
                        torch.nn.Conv2d):
                    prune.l1_unstructured(
                        module, name='weight', amount=pruning_ratio)
                    prune.remove(module, 'weight')

            logger.info(f"âœ… ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ‚Ù„ÙŠÙ… Ø¨Ù†Ø³Ø¨Ø© {pruning_ratio}")
            return model
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ‚Ù„ÙŠÙ…: {e}")
            raise

    def _apply_quantization(self, model, config=None):
        """
        ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒÙ…ÙŠÙ…

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙƒÙ…ÙŠÙ…

        Returns:
            object: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙƒÙ…Ù…
        """
        try:
            import torch

            if config is None:
                config = {'quantization_type': 'int8'}

            quantization_type = config.get('quantization_type', 'int8')

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒÙ…ÙŠÙ…
            if quantization_type == 'int8':
                # INT8 quantization
                model_quantized = torch.quantization.quantize_dynamic(
                    model, {torch.nn.Linear, torch.nn.Conv2d}, dtype=torch.qint8
                )
            elif quantization_type == 'fp16':
                # FP16 quantization
                model_quantized = model.half()
            else:
                logger.error(f"âŒ Ù†ÙˆØ¹ Ø§Ù„ØªÙƒÙ…ÙŠÙ… {quantization_type} ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…")
                return model

            logger.info(f"âœ… ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒÙ…ÙŠÙ… Ø¨Ù†ÙˆØ¹ {quantization_type}")
            return model_quantized
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒÙ…ÙŠÙ…: {e}")
            raise

    def _apply_distillation(self, model, config=None):
        """
        ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ø·ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ©

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙ‚Ø·ÙŠØ±

        Returns:
            object: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù‚Ø·Ø±
        """
        try:
            if config is None or 'teacher_model_id' not in config:
                logger.error("âŒ ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ø±Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¹Ù„Ù…")
                return model

            teacher_model_id = config.get('teacher_model_id')

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¹Ù„Ù…
            if teacher_model_id not in self.processor.models:
                logger.error(f"âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¹Ù„Ù… {teacher_model_id} ØºÙŠØ± Ù…ØªØ§Ø­")
                return model

            # ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ø·ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ©
            # Ù‡Ø°Ø§ ÙŠØªØ·Ù„Ø¨ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¹Ù„Ù…
            # ÙˆÙ‡Ùˆ Ù…Ø§ ØªÙ… ØªÙ†ÙÙŠØ°Ù‡ ÙÙŠ Ø¯Ø§Ù„Ø© train_with_ensemble_teachers

            logger.info(
                f"âœ… ØªÙ… ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ø·ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {teacher_model_id}")
            return model
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ø·ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ©: {e}")
            raise

    def export_model(self, model, format, output_path):
        """
        ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            format: ØµÙŠØºØ© Ø§Ù„ØªØµØ¯ÙŠØ± (onnx, tflite, pytorch, coreml)
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬

        Returns:
            bool: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØµØ¯ÙŠØ±
        """
        try:
            if format == 'onnx':
                return self._export_to_onnx(model, output_path)
            elif format == 'tflite':
                return self._export_to_tflite(model, output_path)
            elif format == 'pytorch':
                return self._export_to_pytorch(model, output_path)
            elif format == 'coreml':
                return self._export_to_coreml(model, output_path)
            else:
                logger.error(f"âŒ ØµÙŠØºØ© Ø§Ù„ØªØµØ¯ÙŠØ± {format} ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©")
                return False
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return False

    def _export_to_onnx(self, model, output_path):
        """
        ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ ONNX

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬

        Returns:
            bool: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØµØ¯ÙŠØ±
        """
        try:
            import torch

            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯Ø®Ù„Ø§Øª ÙˆÙ‡Ù…ÙŠØ©
            dummy_input = torch.randn(1, 3, 224, 224)

            # ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            torch.onnx.export(
                model,
                dummy_input,
                output_path,
                export_params=True,
                opset_version=11,
                do_constant_folding=True,
                input_names=['input'],
                output_names=['output'],
                dynamic_axes={
                    'input': {
                        0: 'batch_size'},
                    'output': {
                        0: 'batch_size'}})

            logger.info(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ ONNX ÙÙŠ {output_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ ONNX: {e}")
            raise

    def _export_to_tflite(self, model, output_path):
        """
        ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ TensorFlow Lite

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬

        Returns:
            bool: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØµØ¯ÙŠØ±
        """
        try:
            # ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ ONNX Ø£ÙˆÙ„Ø§Ù‹
            onnx_path = output_path.replace('.tflite', '.onnx')
            self._export_to_onnx(model, onnx_path)

            # ØªØ­ÙˆÙŠÙ„ Ù…Ù† ONNX Ø¥Ù„Ù‰ TensorFlow
            import onnx
            from onnx_tf.backend import prepare

            onnx_model = onnx.load(onnx_path)
            tf_rep = prepare(onnx_model)

            # ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ TensorFlow Lite
            import tensorflow as tf

            converter = tf.lite.TFLiteConverter.from_saved_model(
                tf_rep.export_graph())
            tflite_model = converter.convert()

            with open(output_path, 'wb') as f:
                f.write(tflite_model)

            logger.info(
                f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ TensorFlow Lite ÙÙŠ {output_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ TensorFlow Lite: {e}")
            raise

    def _export_to_pytorch(self, model, output_path):
        """
        ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ PyTorch

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬

        Returns:
            bool: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØµØ¯ÙŠØ±
        """
        try:
            import torch

            # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            torch.save(model, output_path)

            logger.info(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ PyTorch ÙÙŠ {output_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ PyTorch: {e}")
            raise

    def _export_to_coreml(self, model, output_path):
        """
        ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ Core ML

        Args:
            model: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            output_path: Ù…Ø³Ø§Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬

        Returns:
            bool: Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØµØ¯ÙŠØ±
        """
        try:
            # ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ ONNX Ø£ÙˆÙ„Ø§Ù‹
            onnx_path = output_path.replace('.mlmodel', '.onnx')
            self._export_to_onnx(model, onnx_path)

            # ØªØ­ÙˆÙŠÙ„ Ù…Ù† ONNX Ø¥Ù„Ù‰ Core ML
            import coremltools as ct
            import onnx

            onnx_model = onnx.load(onnx_path)
            mlmodel = ct.converters.onnx.convert(
                model=onnx_model,
                minimum_ios_deployment_target='13'
            )

            # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            mlmodel.save(output_path)

            logger.info(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Core ML ÙÙŠ {output_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Core ML: {e}")
            raise
