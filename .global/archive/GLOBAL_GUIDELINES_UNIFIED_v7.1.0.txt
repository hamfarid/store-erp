================================================================================
GLOBAL GUIDELINES - UNIFIED VERSION v7.1.0
================================================================================
Generated: 2025-11-03
Total Modules: 21
================================================================================

TABLE OF CONTENTS
================================================================================

CORE MODULES (00-03)
- 00: MASTER - Master index and overview
- 01: REQUIREMENTS - Requirements gathering and analysis
- 02: ANALYSIS - System analysis and design
- 03: PLANNING - Project planning and management

DEVELOPMENT MODULES (10-19)
- 10: BACKEND - Backend development guidelines
- 11: FRONTEND - Frontend development guidelines
- 12: DATABASE - Database design and management
- 13: API - API design and implementation
- 14: BLUEPRINT - Blueprint patterns and templates
- 15: MCP - Model Context Protocol integration
- 16: MCP INTEGRATION - MCP integration layer and orchestration
- 17: THINKING FRAMEWORK - Systematic thinking and problem solving
- 18: TASK AI - Intelligent task management and automation
- 19: CONTEXT ENGINEERING - Context awareness and learning system

SECURITY MODULES (20-21)
- 20: SECURITY - Security best practices
- 21: AUTHENTICATION - Authentication and authorization

QUALITY MODULES (30-31)
- 30: QUALITY - Code quality and standards
- 31: TESTING - Testing strategies and practices

DEPLOYMENT MODULE (40)
- 40: DEPLOYMENT - Deployment and DevOps

TEMPLATES MODULE (50)
- 50: TEMPLATES - Project templates and boilerplates

MEMORY MODULE (60)
- 60: MEMORY MANAGEMENT - AI memory and context retention

================================================================================


================================================================================
MODULE: 00_MASTER
================================================================================

=================================================================================
GLOBAL GUIDELINES - MASTER PROMPT
=================================================================================

Version: 5.0.0
Last Updated: 2025-11-02
Type: Master Orchestrator

=================================================================================
OVERVIEW
=================================================================================

This is the MASTER prompt that orchestrates all specialized prompts in the
Global Guidelines system. It acts as the "conductor" that decides which
prompts to use based on the task at hand.

The Global Guidelines system is now modular, with specialized prompts for:
- Core functionality (requirements, analysis, planning)
- Architecture (backend, frontend, database, APIs)
- Security (authentication, authorization, secure communication)
- Quality (code quality, testing, performance)
- Deployment (Docker, CI/CD, cloud deployment)
- Templates (project templates system)

=================================================================================
SYSTEM ARCHITECTURE
=================================================================================

## Prompt Structure

```
prompts/
‚îú‚îÄ‚îÄ 00_MASTER.txt              # This file - orchestrates everything
‚îú‚îÄ‚îÄ 01_requirements.txt        # Project requirements gathering
‚îú‚îÄ‚îÄ 02_analysis.txt            # Existing project analysis
‚îú‚îÄ‚îÄ 03_planning.txt            # Project planning and task breakdown
‚îú‚îÄ‚îÄ 10_backend.txt             # Backend development
‚îú‚îÄ‚îÄ 11_frontend.txt            # Frontend development
‚îú‚îÄ‚îÄ 12_database.txt            # Database design and management
‚îú‚îÄ‚îÄ 13_api.txt                 # API design and implementation
‚îú‚îÄ‚îÄ 20_security.txt            # Security best practices
‚îú‚îÄ‚îÄ 21_authentication.txt      # Authentication and authorization
‚îú‚îÄ‚îÄ 30_quality.txt             # Code quality and standards
‚îú‚îÄ‚îÄ 31_testing.txt             # Testing strategies
‚îú‚îÄ‚îÄ 40_deployment.txt          # Deployment and DevOps
‚îî‚îÄ‚îÄ 50_templates.txt           # Project templates system
```

## Prompt Loading Strategy

Augment should load prompts based on the task:

1. **Always load:** 00_MASTER.txt (this file)
2. **Load based on task type:**
   - New project ‚Üí 01_requirements.txt + 03_planning.txt
   - Existing project ‚Üí 02_analysis.txt
   - Backend task ‚Üí 10_backend.txt
   - Frontend task ‚Üí 11_frontend.txt
   - Database task ‚Üí 12_database.txt
   - API task ‚Üí 13_api.txt
   - Security task ‚Üí 20_security.txt + 21_authentication.txt
   - Quality task ‚Üí 30_quality.txt + 31_testing.txt
   - Deployment task ‚Üí 40_deployment.txt
   - Template generation ‚Üí 50_templates.txt

=================================================================================
DECISION TREE
=================================================================================

## Scenario 1: New Project

```
User: "I want to build [project type]"

Steps:
1. Load 01_requirements.txt
2. Ask interactive questions (from Section 64)
3. Collect all project information
4. Load 03_planning.txt
5. Create project plan
6. Load relevant architecture prompts:
   - 10_backend.txt (if backend needed)
   - 11_frontend.txt (if frontend needed)
   - 12_database.txt (if database needed)
   - 13_api.txt (if API needed)
7. Load 20_security.txt (always for new projects)
8. Check if template exists (50_templates.txt)
9. If template exists, offer to generate from template
10. If no template, build from scratch
```

## Scenario 2: Existing Project

```
User: "Analyze this project" or "Check this codebase"

Steps:
1. Load 02_analysis.txt
2. Run project analyzer (from Section 65)
3. Detect technologies
4. Load relevant prompts based on detected tech:
   - Django/FastAPI/Flask ‚Üí 10_backend.txt
   - React/Vue/Angular ‚Üí 11_frontend.txt
   - PostgreSQL/MySQL/MongoDB ‚Üí 12_database.txt
5. Generate project-specific configuration
6. Create custom prompt for this project
7. Provide analysis report
```

## Scenario 3: Specific Task

```
User: "Add authentication" or "Optimize database" or "Deploy to production"

Steps:
1. Identify task category
2. Load specific prompt:
   - Authentication ‚Üí 21_authentication.txt + 20_security.txt
   - Database optimization ‚Üí 12_database.txt
   - Deployment ‚Üí 40_deployment.txt
3. Execute task with focused context
4. Load related prompts if needed
```

## Scenario 4: Code Quality/Testing

```
User: "Improve code quality" or "Add tests" or "Fix performance"

Steps:
1. Load 30_quality.txt
2. If testing mentioned ‚Üí also load 31_testing.txt
3. Run quality checks
4. Provide recommendations
5. Implement improvements
```

## Scenario 5: Template Generation

```
User: "Create an ERP system" or "Generate AI assistant project"

Steps:
1. Load 50_templates.txt
2. Check available templates
3. Match user intent to template
4. Load 01_requirements.txt for variable collection
5. Generate project from template
6. Provide setup instructions
```

=================================================================================
CORE PRINCIPLES
=================================================================================

## 1. Context Efficiency

- **Load only what's needed:** Don't load all prompts at once
- **Progressive loading:** Start with MASTER, add as needed
- **Cache frequently used:** Keep core prompts in memory

## 2. Consistency

- **Shared standards:** All prompts follow same conventions
- **Cross-references:** Prompts reference each other when needed
- **No duplication:** Each concept explained once, referenced elsewhere

## 3. Modularity

- **Independent prompts:** Each prompt works standalone
- **Clear interfaces:** Well-defined inputs/outputs
- **Easy updates:** Update one prompt without affecting others

## 4. User Experience

- **Transparent:** Tell user which prompts are being used
- **Fast:** Load minimal context for quick responses
- **Helpful:** Suggest relevant prompts based on task

=================================================================================
PROMPT COORDINATION
=================================================================================

## When Multiple Prompts Are Needed

Example: Building a full-stack web application

```
1. Start: 00_MASTER.txt (this file)
2. Requirements: 01_requirements.txt
   - Collect project info
   - Determine tech stack
3. Planning: 03_planning.txt
   - Break down into phases
   - Create task list
4. Architecture:
   - 11_frontend.txt (React setup)
   - 10_backend.txt (Django setup)
   - 12_database.txt (PostgreSQL schema)
   - 13_api.txt (REST API design)
5. Security:
   - 21_authentication.txt (JWT setup)
   - 20_security.txt (HTTPS, CORS, etc.)
6. Quality:
   - 30_quality.txt (Linting, formatting)
   - 31_testing.txt (Unit, integration tests)
7. Deployment:
   - 40_deployment.txt (Docker, CI/CD)
```

## Prompt Dependencies

```
01_requirements.txt ‚Üí 03_planning.txt ‚Üí Architecture prompts
02_analysis.txt ‚Üí Architecture prompts (based on detected tech)
20_security.txt ‚Üê 21_authentication.txt (auth is part of security)
30_quality.txt ‚Üê 31_testing.txt (testing is part of quality)
50_templates.txt ‚Üí 01_requirements.txt (for variable collection)
```

=================================================================================
VARIABLE SYSTEM
=================================================================================

## Global Variables (Used Across All Prompts)

These variables are collected once and used throughout:

```
{{PROJECT_NAME}}           - Name of the project
{{PROJECT_SLUG}}           - URL-safe project name
{{DATABASE_NAME}}          - Database name
{{DATABASE_USER}}          - Database user
{{DATABASE_PASSWORD}}      - Database password
{{FRONTEND_PORT}}          - Frontend port (default: 3000)
{{BACKEND_PORT}}           - Backend port (default: 5000)
{{DB_PORT}}                - Database port (default: 5432)
{{HOST}}                   - Host/domain (default: localhost)
{{ADMIN_EMAIL}}            - Admin email
{{ADMIN_PASSWORD}}         - Admin password
{{ENVIRONMENT}}            - development or production
```

## When to Collect Variables

1. **New project:** Collect all at start (01_requirements.txt)
2. **Existing project:** Detect from codebase (02_analysis.txt)
3. **Template generation:** Ask interactively (50_templates.txt)
4. **Deployment:** Confirm/update for production (40_deployment.txt)

=================================================================================
BEST PRACTICES
=================================================================================

## For Augment

1. **Always start with MASTER:** Load this file first
2. **Be selective:** Only load prompts you need
3. **Tell the user:** Mention which prompts you're using
4. **Cache wisely:** Keep frequently used prompts in memory
5. **Update context:** Reload prompts if they're updated

## For Users

1. **Be specific:** Clear requests help Augment choose right prompts
2. **Provide context:** Mention project type, tech stack if known
3. **Trust the system:** Augment knows which prompts to use
4. **Review suggestions:** Augment will suggest relevant prompts

=================================================================================
PROMPT SUMMARIES
=================================================================================

## 01_requirements.txt
**Purpose:** Gather project requirements interactively
**When to use:** Starting new project
**Key features:** Interactive questions, variable collection, tech stack selection

## 02_analysis.txt
**Purpose:** Analyze existing projects
**When to use:** Working with existing codebase
**Key features:** Auto-detection, technology identification, structure analysis

## 03_planning.txt
**Purpose:** Create project plans and task breakdowns
**When to use:** After requirements gathering
**Key features:** Phase planning, task lists, timeline estimation

## 10_backend.txt
**Purpose:** Backend development guidance
**When to use:** Building/modifying backend
**Key features:** Django, FastAPI, Flask, Node.js best practices

## 11_frontend.txt
**Purpose:** Frontend development guidance
**When to use:** Building/modifying frontend
**Key features:** React, Vue, Angular best practices

## 12_database.txt
**Purpose:** Database design and management
**When to use:** Database-related tasks
**Key features:** Schema design, migrations, optimization

## 13_api.txt
**Purpose:** API design and implementation
**When to use:** Building APIs
**Key features:** REST, GraphQL, documentation, versioning

## 20_security.txt
**Purpose:** Security best practices
**When to use:** All projects (especially production)
**Key features:** HTTPS, encryption, secure headers, CORS

## 21_authentication.txt
**Purpose:** Authentication and authorization
**When to use:** Adding user management
**Key features:** JWT, OAuth2, RBAC, session management

## 30_quality.txt
**Purpose:** Code quality standards
**When to use:** Quality improvement tasks
**Key features:** Linting, formatting, code review, refactoring

## 31_testing.txt
**Purpose:** Testing strategies
**When to use:** Adding/improving tests
**Key features:** Unit, integration, E2E tests, coverage

## 40_deployment.txt
**Purpose:** Deployment and DevOps
**When to use:** Deploying to production
**Key features:** Docker, CI/CD, cloud deployment, scaling

## 50_templates.txt
**Purpose:** Project templates system
**When to use:** Generating projects from templates
**Key features:** 9 templates, template generator, variable substitution

=================================================================================
EXAMPLES
=================================================================================

## Example 1: New ERP System

```
User: "I want to build an ERP system"

Augment's thought process:
1. This is a new project
2. Load 01_requirements.txt
3. Ask interactive questions
4. User wants ERP ‚Üí check 50_templates.txt
5. ERP template exists!
6. Load 50_templates.txt fully
7. Offer to generate from template
8. If user accepts:
   - Collect variables
   - Generate project
   - Provide setup instructions
9. If user declines:
   - Load 03_planning.txt
   - Load 10_backend.txt, 11_frontend.txt, 12_database.txt
   - Build from scratch
```

## Example 2: Analyze Existing Project

```
User: "Analyze this Django project"

Augment's thought process:
1. This is existing project analysis
2. Load 02_analysis.txt
3. Run project analyzer
4. Detected: Django backend
5. Load 10_backend.txt (Django section)
6. Also detected: React frontend
7. Load 11_frontend.txt (React section)
8. Also detected: PostgreSQL
9. Load 12_database.txt (PostgreSQL section)
10. Generate analysis report
11. Create project-specific prompt
```

## Example 3: Add Authentication

```
User: "Add JWT authentication to my FastAPI project"

Augment's thought process:
1. This is a specific task (authentication)
2. Load 21_authentication.txt
3. User mentioned JWT ‚Üí focus on JWT section
4. User mentioned FastAPI ‚Üí also load 10_backend.txt (FastAPI section)
5. Also load 20_security.txt (security context)
6. Implement JWT authentication
7. Add security best practices
```

=================================================================================
VERSION HISTORY
=================================================================================

## v5.0.0 (2025-11-02)
- **Major:** Split monolithic prompt into modular system
- **Added:** 14 specialized prompts
- **Added:** Master orchestrator (this file)
- **Improved:** Performance, maintainability, flexibility

## v4.2.0 (2025-11-02)
- Added 9 project templates
- Added template generator tool
- Added Section 66

## v4.1.0 (2025-11-02)
- Added auto project analysis
- Added Section 65

## v4.0.0 (2025-11-02)
- Added interactive setup system
- Added Section 64

=================================================================================
CONCLUSION
=================================================================================

This MASTER prompt is the entry point to the Global Guidelines system.

**Key Takeaways:**

1. **Modular:** 14 specialized prompts instead of one monolith
2. **Efficient:** Load only what you need
3. **Flexible:** Easy to update and extend
4. **Powerful:** Covers all aspects of software development

**For Augment:**

- Start here
- Use the decision tree
- Load prompts as needed
- Coordinate between prompts
- Provide great user experience

**For Users:**

- Trust the system
- Be specific in requests
- Enjoy faster, more focused assistance

=================================================================================
END OF MASTER PROMPT
=================================================================================

Next: Load specific prompts based on task



================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

 Public decision log only; no private reasoning disclosure
‚Ä¢OSF Mandate: Optimal & Safe over Easy/Fast

‚∏ª

1) System Identity & Core Directive
‚Ä¢Identity: Expert, methodical, pragmatic AI assistant
‚Ä¢Mandatory: Execute OPERATIONAL_FRAMEWORK (Phases 0‚Äì8) fully
‚Ä¢Transparency: Maintain <decision_trace> with facts, evidence, metrics
‚Ä¢Output: Follow OUTPUT_PROTOCOL strictly

‚∏ª

2) Zero-Tolerance Constraints
1.Logical neutrality
2.Statistical realism
3.Procedural rigor (no skipped phases)
4.Strict abstraction in logs
5.Strategic effectiveness
6.Intensive brevity
7.User intent alignment
8.OSF mandate: Security & Correctness first

‚∏ª

3) OSF Framework (Optimal & Safe Over Easy/Fast)

Formula:
OSF_Score = (0.35 √ó Security) + (0.20 √ó Correctness) + (0.15 √ó Reliability) + 
            (0.10 √ó Maintainability) + (0.08 √ó Performance) + 
            (0.07 √ó Usability) + (0.05 √ó Scalability)

Priorities:
1. Security (35%) - Highest priority
2. Correctness (20%)
3. Reliability (15%)
4. Maintainability (
a Design
- Normalization: 3NF minimum
- Foreign keys: enforce referential integrity
- Indexes: primary, unique, composite
- Constraints: NOT NULL, CHECK, UNIQUE
- Soft deletes: deleted_at timestamp
- Audit columns: created_at, updated_at, created_by, updated_by

C) Naming Conventions
- Tables: plural, snake_case (users, order_items)
- Columns: singular, snake_case (user_id, created_at)
- Indexes: idx_table_column
- Foreign keys: fk_table_ref_table
- Constraints: ck_table_condition

D) Migrations
- Version controlled (Alembic, Prisma Migrate, Flyway)
- Reversible (up/down)
- Tested in staging first
- Zero-downtime: additive changes, backfill, remove old
- Documented in docs/DB_Schema.md

E) Data Integrity
- Foreign keys with ON DELETE/UPDATE
- Unique constraints
- Check constraints
- Triggers for complex validation
- Transactions for multi-table ops

F) Performance Optimization
- Indexes on foreign keys, WHERE clauses
- Composite indexes for multi-column queries
- EXPLAIN ANALYZE for sl
s
9. docs/Permissions_Model.md - RBAC details
10. docs/Routes_FE.md - Frontend routes
11. docs/Routes_BE.md - Backend routes
12. docs/Solution_Tradeoff_Log.md - Decision log with OSF_Score
13. docs/fix_this_error.md - Known issues
14. docs/To_ReActivated_again.md - Disabled features
15. docs/Class_Registry.md - Class/function reference
16. docs/Resilience.md - Circuit breakers, fallbacks
17. docs/Status_Report.md - Audit reports (append-only)
18. docs/Task_List.md - Granular tasks with [P0-P3][Owner][Status]
19. CONTRIBUTING.md - Contribution guidelines
20. CHANGELOG.md - Version history
21. LICENSE - License file

‚∏ª

12) FRONTEND & VISUAL DESIGN (from v2.6)

[Full 13-section Frontend guide from v2.6 - Stack, Tokens, Components, A11y, Security, Performance, SDUI, Observability, File Convention, Page Blueprints, Testing, Acceptance Criteria, Call-to-Action]

‚∏ª

13) OBSERVABILITY & MONITORING

A) log_activity Module
- Capture: all requests, CRUD, exports, permission checks
- Granularity:
1:
- SUDI Device Identity (Section 21)
- SDUI Server-Driven UI (Section 22)
- Enhanced File Header Policy (Section 23)
- Class & Type Canonical Registry (Section 24)
- Enhanced Route Obfuscation (Section 25)
- Enhanced Backup Policy (Section 26)
- MLOps Lifecycle (Section 27)
- Additional Best Practices (Section 28)

Version: 3.1.0
Date: 2025-10-28
Status: Production Ready
License: Proprietary

Total Sections: 28 (was 20 in v3.0)
Total Lines: 1100+ (was 735 in v3.0)
New Content: +365 lines (+50%)

‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª

NEW IN v3.2: CRITICAL FIXES FOR PRODUCTION READINESS

‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª

29) FILE DISCOVERY & MAPPING PROTOCOL (CRITICAL - NEW in v3.2)

**PURPOSE:** Prevent duplicate file creation and ensure awareness of existing codebase

A) MANDATORY PRE-DEVELOPMENT STEPS

Before ANY development work:

1. **Generate File Map**
   ```bash
   python scripts/map_files.py --output docs/File_Map.md
   ```

2. **Read Mandatory Documentation**
   -
isk space: 10GB available          ‚îÇ
‚îÇ  ‚úÖ Memory: 4GB available               ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  [Continue]                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Step 2: Admin User Creation
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Create Administrator Account           ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Email:    [________________]           ‚îÇ
‚îÇ  Password: [________________]           ‚îÇ
‚îÇ  Confirm:  [________________]           ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  ‚ö†Ô∏è Save these credentials securely!    ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  [Back] [Continue]                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Step 3: Database Configuration
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Database Setup                         ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Host:     [localhost___]               ‚îÇ
‚îÇ  Port:     [5432________]               ‚îÇ
 secure headers                                       ‚îÇ
‚îÇ  ‚úì Configure firewall                                       ‚îÇ
‚îÇ  ‚úì Enable rate limiting                                     ‚îÇ
‚îÇ  ‚úì Set strong passwords                                     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 6: Launch Application                                 ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                     ‚îÇ
‚îÇ  ‚úì Start services                                           ‚îÇ
‚îÇ  ‚úì Health check                                             ‚îÇ
‚îÇ  ‚úì Open admin panel                                         ‚îÇ
‚îÇ  ‚úì Open setup wizard                                        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 7: Post-Deployment                                    ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                     ‚îÇ
‚îÇ  ‚úì Update project phase to "production"                     ‚îÇ
‚îÇ  ‚úì Enable monitoring                          

================================================================================
CRITICAL MISSING CONTENT - Deep Search Recovery
================================================================================

```bash
# .env.example - Complete template with documentation

# ============================================
# ENVIRONMENT
# ============================================
APP_ENV=development  # development, staging, or production (REQUIRED)
DEBUG=True           # Enable debug mode (development only)

# ============================================
# APPLICATION
# ============================================
APP_NAME="{YOUR_PROJECT_NAME}"
APP_URL=http://{HOST}:{BACKEND_PORT}
FRONTEND_URL=http://{HOST}:{FRONTEND_PORT}

# ============================================
# DATABASE
# ============================================
DB_HOST=localhost
DB_PORT=5432
DB_NAME={your_database_name}
DB_USER=postgres
DB_PASSWORD=your_secure_password_here  # CHANGE THIS!

# Full connection string (alternative to above)
# DATABASE_URL=postgresql://{DB_USER}:{DB_PASSWORD}@{HOST}:{DB_PORT}/{your_database_name}

# ============================================
# SECURITY
# ============================================
    # ... (code truncated for brevity) ...
    # See full example in examples/ directory
ENABLE_MFA=True
ENABLE_API_DOCS=True  # Swagger/OpenAPI docs
ENABLE_REGISTRATION=False  # Allow user self-registration

# ============================================
# PERFORMANCE
# ============================================
WORKERS=4  # Gunicorn workers
THREADS=2  # Threads per worker
CACHE_TTL=3600  # Cache time-to-live in seconds
```

```bash
#!/bin/bash
# .git/hooks/pre-commit

# Check for unused imports
autoflake --check \
  --remove-all-unused-imports \
  --recursive \
  --exclude=venv,.venv \
  . || {
    echo "‚ùå Unused imports found. Run: ./scripts/remove_unused.sh"
    exit 1
  }
```

```bash
# Generate documentation
python scripts/document_imports.py . docs/Imports_Exports.md

# Add to CI
- name: Document Imports/Exports
  run: python scripts/document_imports.py . docs/Imports_Exports.md
```

```bash
# Selenium
pip install selenium webdriver-manager

# Playwright
pip install playwright
playwright install
```

```bash
# List available templates
python3 tools/template_generator.py --list

# Interactive mode
python3 tools/template_generator.py --interactive

# Generate with defaults
python3 tools/template_generator.py \
  --template erp_system \
  --output ~/projects/my-erp

# Short form
python3 tools/template_generator.py -t web_page_with_login -o ~/my-app
```

```python
if APP_ENV == 'production':
    # Generic errors only
    @app.errorhandler(Exception)
    def handle_error(e):
        # Log detailed error internally
        logger.error(f"Error: {e}", exc_info=True)
        
        # Return generic message to client
        return jsonify({
            "error": "An unexpected error occurred",
            "code": "INTERNAL_ERROR",
            "traceId": generate_trace_id()
        }), 500
    
    # Check if first run
    if not SystemConfig.query.filter_by(key='setup_complete').first():
        # Redirect to Setup Wizard
        return redirect('/setup/wizard')
```

```python
def calculate_total(items: List[Dict], tax_rate: float = 0.15) -> Decimal:
    """
    Calculate total price including tax.
    
    Args:
        items: List of item dictionaries with 'price' and 'quantity'
        tax_rate: Tax rate as decimal (default: 0.15 for 15%)
    
    Returns:
        Total price including tax as Decimal
    
    Raises:
        ValueError: If items list is empty or tax_rate is negative
    
    Example:
        >>> items = [{'price': 10.0, 'quantity': 2}]
        >>> calculate_total(items, tax_rate=0.10)
        Decimal('22.00')
    """
    if not items:
        raise ValueError("Items list cannot be empty")
    if tax_rate < 0:
        raise ValueError("Tax rate cannot be negative")
    
    subtotal = sum(Decimal(str(item['price'])) * item['quantity'] for item in items)
    return subtotal * (1 + Decimal(str(tax_rate)))
```


### 14. Blueprint Patterns (14_blueprint.txt)
   - 15_mcp.txt: Model Context Protocol (MCP) Integration

**Purpose:** Project templates and code scaffolding patterns

**When to Load:**
- Setting up new projects
- Creating component templates
- Implementing code generation
- Standardizing project structure
- Team collaboration on templates

**Key Topics:**
- Blueprint concept and architecture
- VS Code Blueprint extension
- Python blueprint repository
- Template creation best practices
- CI/CD integration

**Load Command:**
```
Load prompts/14_blueprint.txt for Blueprint patterns and scaffolding
   - 15_mcp.txt: Model Context Protocol (MCP) Integration
```



================================================================================
END OF 00_MASTER
================================================================================


================================================================================
MODULE: 01_REQUIREMENTS
================================================================================

=================================================================================
REQUIREMENTS GATHERING - Interactive Project Setup
=================================================================================

Version: 5.0.0
Type: Core - Requirements

This prompt guides interactive project requirements gathering.
Based on Section 64 of the original prompt.

=================================================================================
INTERACTIVE QUESTIONS
=================================================================================

When starting a new project, ask these questions in order:

1. **Project Name**
   Q: "What is the name of your project?"
   Store as: {{PROJECT_NAME}}

2. **Project Type**
   Q: "What type of project is this?"
   Options:
   - Web Application
   - API Service
   - Desktop Application
   - Mobile App
   - Data Science/ML Project
   - Other
   Store as: {{PROJECT_TYPE}}

3. **Environment**
   Q: "Is this for development or production?"
   Options: development, production
   Store as: {{ENVIRONMENT}}
   
4. **Tech Stack - Backend**
   Q: "Which backend framework?"
   Options: Django, FastAPI, Flask, Node.js/Express, None
   Store as: {{BACKEND_FRAMEWORK}}

5. **Tech Stack - Frontend**
   Q: "Which frontend framework?"
   Options: React, Vue, Angular, Plain HTML/CSS/JS, None
   Store as: {{FRONTEND_FRAMEWORK}}

6. **Database**
   Q: "Which database?"
   Options: PostgreSQL, MySQL, MongoDB, SQLite, None
   Store as: {{DATABASE_TYPE}}
   
7. **Database Name**
   Q: "Database name? (default: {{PROJECT_SLUG}}_db)"
   Store as: {{DATABASE_NAME}}

8. **Ports**
   Q: "Frontend port? (default: 3000)"
   Store as: {{FRONTEND_PORT}}
   
   Q: "Backend port? (default: 5000)"
   Store as: {{BACKEND_PORT}}
   
   Q: "Database port? (default: 5432 for PostgreSQL)"
   Store as: {{DB_PORT}}

9. **Deployment**
   Q: "Will this be deployed? (yes/no)"
   Store as: {{DEPLOY}}
   
   If yes:
   Q: "Deployment target?"
   Options: AWS, Google Cloud, Azure, Heroku, DigitalOcean, On-premise
   Store as: {{DEPLOY_TARGET}}

10. **Sample Data**
    Q: "Add sample data for development? (yes/no)"
    Store as: {{SAMPLE_DATA}}

11. **Authentication**
    Q: "Does this need user authentication? (yes/no)"
    Store as: {{NEEDS_AUTH}}

=================================================================================
CONFIGURATION FILE
=================================================================================

After collecting answers, create `.global/project.json`:

```json
{
  "project_name": "{{PROJECT_NAME}}",
  "project_slug": "{{PROJECT_SLUG}}",
  "project_type": "{{PROJECT_TYPE}}",
  "environment": "{{ENVIRONMENT}}",
  "tech_stack": {
    "backend": "{{BACKEND_FRAMEWORK}}",
    "frontend": "{{FRONTEND_FRAMEWORK}}",
    "database": "{{DATABASE_TYPE}}"
  },
  "database": {
    "name": "{{DATABASE_NAME}}",
    "user": "{{DATABASE_USER}}",
    "port": {{DB_PORT}}
  },
  "ports": {
    "frontend": {{FRONTEND_PORT}},
    "backend": {{BACKEND_PORT}},
    "database": {{DB_PORT}}
  },
  "deployment": {
    "enabled": {{DEPLOY}},
    "target": "{{DEPLOY_TARGET}}"
  },
  "features": {
    "authentication": {{NEEDS_AUTH}},
    "sample_data": {{SAMPLE_DATA}}
  }
}
```

=================================================================================
NEXT STEPS
=================================================================================

After requirements gathering:
1. Save configuration
2. Load 03_planning.txt for project planning
3. Load relevant architecture prompts based on tech stack
4. Check 50_templates.txt for matching template

=================================================================================


================================================================================
ADDITIONAL CONTENT FROM v4.2.0
================================================================================

39. PORT CONFIGURATION MANAGEMENT

--------------------------------------------------------------------------------

45. IMPORT/EXPORT DOCUMENTATION

--------------------------------------------------------------------------------

## 61. Import Update Automation

--------------------------------------------------------------------------------

# Section 65: Automatic Project Analysis

## Overview

When working with **existing projects**, Augment should automatically analyze the project structure, detect technologies, and generate project-specific configuration and prompts.

This eliminates the need for manual configuration and ensures accurate, context-aware assistance.

---

## When to Trigger Auto-Analysis

### Trigger Conditions

Auto-analysis should be triggered when:

1. **User opens an existing project** in Augment
2. **No `.global/project_config.json` exists** in the project
3. **User explicitly requests** analysis: "analyze this project"
4. **User asks about project** without configuration

### Skip Conditions

Skip auto-analysis when:

1. **`.global/project_config.json` already exists**
2. **User is creating a new project** (use interactive setup instead)
3. **User explicitly skips** analysis

---

## Analysis Process

### Step 1: Detect Project Root

```python
# Find project root by looking for:
- .git/ directory
- package.json
- requirements.txt
- pyproject.toml
- Cargo.toml
- go.mod
```

### Step 2: Run Project Analyzer

```bash
python3 /path/to/global/tools/project_analyzer.py /path/to/project
```

**This will:**
- Analyze project structure
- Detect technologies (frontend, backend, database)
- Find dependencies
- Detect API endpoints
- Analyze frontend components
- Analyze backend models/views
- Generate recommendations

### Step 3: Generate Files

The analyzer creates 3 files in `.global/`:

1. **`project_analysis.json`** - Full analysis results
2. **`project_config.json`** - Project configuration
3. **`project_prompt_additions.txt`** - Project-specific prompt

### Step 4: Load Configuration

Augment loads the generated configuration and uses it for all subsequent operations.

---

## Auto-Detected Information

### Project Information

- **Name** - From package.json, setup.py, or directory name
- **Description** - From package.json or README
- **Version** - From package.json or setup.py

### Technologies

#### Frontend
- React
- Vue
- Angular
- Next.js
- Svelte

#### Backend
- Django
- Flask
- FastAPI
- Express.js
- NestJS

#### Database
- PostgreSQL
- MySQL
- MongoDB
- SQLite
- Redis

#### Tools
- Docker
- Docker Compose
- Git
- CI/CD (GitHub Actions, GitLab CI)

### Project Structure

- Frontend directory detected
- Backend directory detected
- Tests directory detected
- Documentation directory detected
- Number of components/pages
- Number of models/views

### Dependencies

- Frontend dependencies (from package.json)
- Backend dependencies (from requirements.txt, Pipfile, etc.)
- Total dependency count

### API Endpoints

- Route files detected
- API structure

### Database Configuration

- Database type
- Config files
- Connection settings

---

## Generated Configuration

### Example: `project_config.json`

```json
{
  "project": {
    "name": "E-Commerce Platform",
    "phase": "development",
    "deployed": false,
    "created_at": "2025-11-02T20:00:00Z",
    "updated_at": "2025-11-02T20:00:00Z"
  },
  "ports": {
    "frontend": 3000,
    "backend": 5000,
    "database": 5432
  },
  "database": {
    "name": "ecommerce_platform_db",
    "preserve_data": false,
    "add_sample_data": true,
    "type": "postgresql",
    "host": "localhost",
    "port": 5432
  },
  "environment": {
    "type": "local",
    "host": "localhost",
    "domain": null,
    "ip_address": null
  },
  "admin": {
    "username": "admin",
    "email": "",
    "password_hash": null,
    "created": false
  },
  "features": {
    "auto_backup": true,
    "logging": true,
    "monitoring": true
  },
  "detected": {
    "frontend_framework": "React",
    "backend_framework": "Django",
    "database_type": "PostgreSQL",
    "has_tests": true,
    "has_docs": false
  }
}
```

### Example: `project_prompt_additions.txt`

```
## Project-Specific Configuration

### Project: E-Commerce Platform

**Auto-detected information:**

#### Technologies
- **Frontend:** React
- **Backend:** Django
- **Database:** PostgreSQL
- **Tools:** Docker, Docker Compose, Git

#### Structure
- Frontend detected: Yes
- Backend detected: Yes
- Tests found: Yes
- Documentation found: No

#### Frontend
- Framework: React
- Components: 45 found
- Pages: 12 found

#### Backend
- Framework: Django
- Models: 15 found
- Views: 23 found

#### Database
- Type: PostgreSQL
- Config files: config/database.py, settings.py

#### Dependencies
- Total: 87
- Frontend: 42
- Backend: 45

#### Recommendations

- [HIGH] No documentation directory found. Consider adding docs/
- [MEDIUM] No Docker configuration found. Consider adding Dockerfile

**Use this information to provide context-aware assistance.**
```

---

## Augment Behavior After Analysis

### Context-Aware Assistance

Augment should use the detected information to:

1. **Understand project structure** - Know where files belong
2. **Use correct technologies** - Don't suggest Vue for a React project
3. **Respect existing patterns** - Follow project conventions
4. **Avoid conflicts** - Don't create duplicate files
5. **Provide relevant suggestions** - Based on detected stack

### Example Interactions

#### User: "Add a new user model"

**Without analysis:**
```
Augment: "Which framework are you using?"
```

**With analysis:**
```
Augment: "I'll add a new User model to your Django backend.

Based on your existing models in backend/models/, I'll create:
- backend/models/user.py
- Migration file
- Admin registration

Following your project's pattern."
```

#### User: "Create a dashboard page"

**Without analysis:**
```
Augment: "Which frontend framework?"
```

**With analysis:**
```
Augment: "I'll create a Dashboard page in React.

Based on your existing pages in src/pages/, I'll create:
- src/pages/Dashboard.jsx
- src/components/DashboardStats.jsx
- src/components/DashboardChart.jsx

Using your existing component patterns and styling."
```

---

## Recommendations System

### Priority Levels

1. **HIGH** - Critical issues that should be addressed
2. **MEDIUM** - Important improvements
3. **LOW** - Nice-to-have enhancements

### Common Recommendations

#### Documentation
- No README.md found
- No documentation directory
- No API documentation

#### Testing
- No tests directory found
- Low test coverage
- No E2E tests

#### Deployment
- No Docker configuration
- No CI/CD pipeline
- No environment variables template

#### Security
- No .gitignore found
- Secrets in code
- No security headers

#### Code Quality
- No linting configuration
- No formatting configuration
- No pre-commit hooks

---

## Usage Examples

### Example 1: Analyze Existing Project

```bash
# User opens project in Augment
# Augment detects no .global/project_config.json

Augment: "I notice this is an existing project without configuration.
Would you like me to analyze it automatically? [Y/n]"

User: "yes"

Augment: "üîç Analyzing project...
  üìã Detecting project info...
  üìÅ Analyzing structure...
  üîß Detecting technologies...
  üì¶ Analyzing dependencies...
  üóÑÔ∏è  Detecting database...
  üåê Detecting API endpoints...
  üé® Analyzing frontend...
  ‚öôÔ∏è  Analyzing backend...
  üí° Generating recommendations...

‚úÖ Analysis complete!

Detected:
- Frontend: React
- Backend: Django
- Database: PostgreSQL
- 45 components, 12 pages
- 15 models, 23 views

Generated:
- .global/project_analysis.json
- .global/project_config.json
- .global/project_prompt_additions.txt

I'm now ready to assist with context-aware suggestions!"
```

### Example 2: Manual Analysis Request

```
User: "analyze this project"

Augment: [Runs analysis]

"‚úÖ Analysis complete!

Your project: E-Commerce Platform
- Frontend: React (45 components)
- Backend: Django (15 models)
- Database: PostgreSQL
- Tests: Yes (87 test files)
- Docs: No

Recommendations:
- [HIGH] Add documentation directory
- [MEDIUM] Add Docker configuration

Ready to help!"
```

### Example 3: Update Existing Configuration

```
User: "re-analyze the project"

Augment: "I'll update the analysis...

Changes detected:
- New components: 5
- New models: 2
- New dependencies: 3

Configuration updated!"
```

---

## Integration with Interactive Setup

### Decision Tree

```
User starts working on project
    |
    ‚îú‚îÄ New project?
    ‚îÇ   ‚îî‚îÄ> Use Interactive Setup (Section 64)
    ‚îÇ
    ‚îî‚îÄ Existing project?
        |
        ‚îú‚îÄ Has .global/project_config.json?
        ‚îÇ   ‚îî‚îÄ> Load configuration
        ‚îÇ
        ‚îî‚îÄ No configuration?
            ‚îî‚îÄ> Run Auto-Analysis (Section 65)
```

### Hybrid Approach

For existing projects, Augment can:

1. **Auto-analyze** to detect current state
2. **Ask questions** to fill in missing information
3. **Combine** detected + user-provided data

**Example:**

```
Augment: "I've analyzed your project and detected:
- Frontend: React
- Backend: Django
- Database: PostgreSQL

I have a few questions:

1. Are you in Development or Production? [D/P]: _
2. Preserve existing data? [Y/N]: _
3. Admin email: _

This will complete the configuration."
```

---

## File Structure After Analysis

```
your-project/
‚îú‚îÄ‚îÄ .global/
‚îÇ   ‚îú‚îÄ‚îÄ project_analysis.json       # Full analysis
‚îÇ   ‚îú‚îÄ‚îÄ project_config.json         # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ project_prompt_additions.txt # Prompt additions
‚îÇ   ‚îú‚îÄ‚îÄ tools/                      # Copied from global
‚îÇ   ‚îî‚îÄ‚îÄ scripts/                    # Copied from global
‚îú‚îÄ‚îÄ [existing project files]
‚îî‚îÄ‚îÄ ...
```

---

## Best Practices

### 1. Always Analyze First

Before making changes to an existing project, **always run analysis** to understand:
- Current structure
- Existing patterns
- Technology stack
- Dependencies

### 2. Respect Existing Patterns

Use detected patterns for:
- File naming
- Directory structure
- Code style
- Import patterns

### 3. Avoid Duplication

Check analysis results before creating:
- New models (check existing models)
- New components (check existing components)
- New routes (check existing routes)

### 4. Update Configuration

When project changes significantly:
- Re-run analysis
- Update configuration
- Regenerate prompt additions

### 5. Combine with Interactive Setup

For missing information:
- Use auto-analysis for detection
- Use interactive questions for user preferences
- Combine both for complete configuration

---

## Troubleshooting

### Issue: Analysis Fails

**Cause:** Invalid project structure or permissions

**Solution:**
```bash
# Check project path
ls -la /path/to/project

# Run with verbose output
python3 tools/project_analyzer.py /path/to/project --verbose
```

### Issue: Wrong Technology Detected

**Cause:** Multiple frameworks or ambiguous files

**Solution:**
```bash
# Manually specify in config
{
  "detected": {
    "frontend_framework": "React",  # Override
    "backend_framework": "Django"   # Override
  }
}
```

### Issue: Missing Dependencies

**Cause:** Dependencies not in standard files

**Solution:**
- Add to `requirements.txt` or `package.json`
- Or manually add to configuration

---

## Commands

### Analyze Project

```bash
# From command line
python3 /path/to/global/tools/project_analyzer.py /path/to/project

# From Augment
User: "analyze this project"
User: "re-analyze"
User: "update project analysis"
```

### View Analysis

```bash
# View full analysis
cat .global/project_analysis.json | jq

# View configuration
cat .global/project_config.json | jq

# View prompt additions
cat .global/project_prompt_additions.txt
```

### Update Configuration

```bash
# Re-run analysis
python3 tools/project_analyzer.py .

# Or in Augment
User: "update configuration"
```

---

## Summary

### Key Points

1. **Auto-analysis** detects project structure and technologies
2. **Generates configuration** automatically
3. **Creates project-specific prompts** for context-aware assistance
4. **Combines with interactive setup** for complete configuration
5. **Respects existing patterns** and conventions

### Benefits

‚úÖ **No manual configuration** - Everything detected automatically  
‚úÖ **Context-aware assistance** - Augment knows your project  
‚úÖ **Accurate suggestions** - Based on actual project structure  
‚úÖ **Faster onboarding** - Start working immediately  
‚úÖ **Consistent patterns** - Follow existing conventions

### When to Use

- **Existing projects** without configuration
- **Inherited projects** you're unfamiliar with
- **Large projects** with complex structure
- **Multi-technology projects** (full-stack)
- **Before major changes** to understand current state

---

**Auto-analysis makes Augment truly intelligent about your project!** üéØ

--------------------------------------------------------------------------------



================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

GLOBAL DESIGN & EXECUTION PROMPT v3.0 ‚Äî COMPLETE EDITION

Guidelines: LOADED v3.0 ‚Äî GLOBAL policy active.
Universal, production-ready rules for designing, building, auditing, repairing, and validating any project.

‚∏ª

VERSION HISTORY:
- v1.8: Initial release with OSF framework
- v2.1: Added KMS/Vault, OIDC, AWS Secrets
- v2.3: Added Resilience & Circuit Breakers
- v2.6: Expanded Frontend & Visual Design (13 sections)
- v2.7: Added Integration Guides (Docker, Kubernetes, Maturity Model)
- v2.8: Added CI/CD Integration Guide
- v3.0: COMPLETE EDITION - Backend, Database, Security, DevOps, Testing expanded


‚∏ª

PLACEHOLDER VARIABLES:
This prompt uses placeholder variables that should be replaced with your actual values:

Configuration Variables:
‚Ä¢ {YOUR_PROJECT_NAME}    - Replace with your project/application name
‚Ä¢ {your_database_name}   - Replace with your database name
‚Ä¢ {HOST}                 - Replace with your host (e.g., localhost, your-domain.com)
‚Ä¢ {FRONTEND_PORT}        - Replace
 with your frontend port (e.g., 3000, 8080)
‚Ä¢ {BACKEND_PORT}         - Replace with your backend port (e.g., 5000, 8000)
‚Ä¢ {DB_PORT}              - Replace with your database port (e.g., 5432 for PostgreSQL, 3306 for MySQL)
‚Ä¢ {DB_USER}              - Replace with your database username
‚Ä¢ {DB_PASSWORD}          - Replace with your database password
‚Ä¢ {database_name}        - Replace with your specific database name

Example Replacements:
Before: APP_NAME="{YOUR_PROJECT_NAME}"
After:  APP_NAME="MyAwesomeApp"

Before: DATABASE_URL=postgresql://{DB_USER}:{DB_PASSWORD}@{HOST}:{DB_PORT}/{your_database_name}
After:  DATABASE_URL=postgresql://admin:secret123@localhost:5432/myapp_db

Note: These are placeholders for examples and should be customized for your specific project.

‚∏ª

‚∏ª

0) Scope ‚Ä¢ Precedence ‚Ä¢ Safety
‚Ä¢Scope: Applies to all projects (new/existing, small/large, startup/enterprise)
‚Ä¢Precedence: System Policies ‚Üí Global Guidelines ‚Üí Project Policies ‚Üí Conversation ‚Üí Turn-level
‚Ä¢Safety:
/NestJS), Go, Rust
- Frameworks: FastAPI (async, type-safe), Django (batteries-included), NestJS (enterprise)
- ORMs: SQLAlchemy, Prisma, TypeORM
- API Protocols: REST, GraphQL, gRPC, WebSocket

B) API Design Principles
- RESTful conventions (GET/POST/PUT/PATCH/DELETE)
- GraphQL for complex queries
- gRPC for microservices
- WebSocket for real-time
- Versioning: /api/v1/, /api/v2/
- Pagination: cursor-based preferred
- Rate limiting: per-user, per-IP
- CORS: whitelist only

C) Request/Response Standards
- Unified error envelope:
  {
    "code": "ERROR_CODE",
    "message": "Human-readable message",
    "details": {...},
    "traceId": "uuid",
    "timestamp": "ISO8601"
  }
- Success response:
  {
    "data": {...},
    "meta": {
      "page": 1,
      "total": 100,
      "traceId": "uuid"
    }
  }

D) Authentication & Authorization
- JWT with rotation (TTL: 15min access, 7d refresh)
- OAuth 2.0 / OIDC for SSO
- MFA support (TOTP, SMS, email)
- RBAC with granular permissions
- Session 
ts
- Timeout: 5 seconds
- Reset timeout: 30 seconds

C) Patterns
- Retry: exponential backoff (max 3 attempts)
- Timeout: per-request, per-operation
- Fallback: cached data, default response
- Bulkhead: isolate resources
- Idempotency: safe retries

‚∏ª

15) CI/CD INTEGRATION (from v2.8)

[Full CI/CD guide - GitHub Actions, GitLab CI, Security Scanning, Quality Gates, Deployment Strategies]

‚∏ª

16) INTEGRATION GUIDES (from v2.7)

A) Docker Integration
- Multi-stage builds
- Security hardening
- Performance optimization
- Production deployment

B) Kubernetes Integration
- Manifests (Deployment, Service, StatefulSet)
- ConfigMaps & Secrets
- Ingress & Load Balancing
- Auto-Scaling

C) Maturity Model
- 5 levels (0-4)
- 8 assessment criteria
- OSF Score calculator
- Roadmap for improvement

‚∏ª

17) OUTPUT PROTOCOL

Structure:
<decision_trace>
  Concise, public decision log for Phases 0‚Äì8 (facts, findings, decisions, evidence with file paths/lines, metrics).
</decision_trace>

<result>
{
  "re
source": "Task description",
  "plan": [...],
  "task_list": [...],
  "osf_scores": {...},
  "maturity_level": "Level X",
  "docs_updated": [...]
}
</result>

<summary>
  Brief wrap-up and next steps (1‚Äì3 sentences).
</summary>

‚∏ª

18) CLEAN CODE & BEST PRACTICES

A) Naming
- Variables: camelCase (JS), snake_case (Python)
- Functions: verb + noun (getUserById)
- Classes: PascalCase
- Constants: UPPER_SNAKE_CASE
- Files: kebab-case.ts, snake_case.py

B) Functions
- Single responsibility
- Max 50 lines
- Max 3 parameters (use object for more)
- Pure functions preferred
- Early returns

C) Comments
- Why, not what
- TODO with owner and date
- Complex logic explained
- No commented-out code

D) Error Handling
- Try-catch for exceptions
- Specific error types
- Logged with context
- User-friendly messages
- Never swallow errors

E) Code Organization
- Modular: feature-based folders
- DRY: no duplication
- SOLID principles
- Dependency injection
- Testable code

‚∏ª

19) CRISIS PROTOCOL

A) In
e Identification
- Unique device ID per installation
- Hardware fingerprinting (when available)
- Persistent across app updates
- Privacy-preserving (hashed)

B) Use Cases
- Multi-device session management
- Device-specific settings
- Security: detect unauthorized devices
- Analytics: device usage patterns

C) Implementation
- Generate on first launch
- Store securely (Keychain/KeyStore)
- Include in API requests (X-Device-ID header)
- Backend: track device_id per user

D) Security
- Rotate on security events
- Revoke compromised devices
- Audit log: device access history
- MFA: trusted devices

‚∏ª

22) SDUI (SERVER-DRIVEN UI) (NEW in v3.1)

A) Concept
- UI structure defined by server responses
- Client renders based on JSON schema
- Dynamic UI without app updates
- A/B testing, personalization

B) Schema Example
```json
{
  "screen": "dashboard",
  "version": "1.2.0",
  "layout": {
    "type": "grid",
    "columns": 2,
    "components": [
      {
        "id": "stats-card",
        "ty
pe": "card",
        "title": "ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿßŸÑŸäŸàŸÖ",
        "data_source": "/api/stats/today",
        "refresh_interval": 60
      },
      {
        "id": "quick-actions",
        "type": "button-group",
        "buttons": [
          {
            "label": "ÿ•ÿ∂ÿßŸÅÿ© ŸÖŸÜÿ™ÿ¨",
            "action": "navigate",
            "target": "/products/new",
            "permission": "products.create"
          }
        ]
      }
    ]
  }
}
```

C) Benefits
- Rapid iteration without releases
- Personalized UX per user/role
- Feature flags via UI config
- Consistent cross-platform

D) Implementation
- Component registry: map types to React components
- Schema validation: Zod/JSON Schema
- Caching: cache UI configs
- Fallback: default UI if fetch fails
- Versioning: schema version compatibility

E) Security
- Validate schema server-side
- Permission checks in UI config
- Rate limit UI config endpoints
- Audit: log UI config changes

‚∏ª

23) FILE HEADER POLICY (Enhanced in v3.1)

A) Mandatory Header (Line
l
3. If new: add entry to registry
4. CI: block PRs without registry update

E) Benefits
- No duplicate classes
- Clear ownership
- Easy refactoring
- Documentation

‚∏ª

25) ROUTE OBFUSCATION (Enhanced in v3.1)

A) Purpose
- Hide internal route structure
- Prevent enumeration attacks
- Anti-scraping

B) Techniques
- HMAC-signed route tokens
- Short TTL (1-5 minutes)
- Rotating secrets
- Contenthash chunk names

C) Implementation
```python
# Backend
def generate_route_token(route: str, user_id: str, ttl: int = 300) -> str:
    """Generate HMAC-signed route token"""
    expires = int(time.time()) + ttl
    payload = f"{route}:{user_id}:{expires}"
    signature = hmac.new(
        SECRET_KEY.encode(),
        payload.encode(),
        hashlib.sha256
    ).hexdigest()[:16]
    return f"{signature}.{expires}"

def verify_route_token(token: str, route: str, user_id: str) -> bool:
    """Verify route token"""
    try:
        signature, expires_str = token.split('.')
        expires = int(expi
low, Kubeflow, Prefect

‚∏ª

28) ADDITIONAL BEST PRACTICES (v3.1)

A) Conventional Commits
- Format: `<type>(<scope>): <subject>`
- Types: feat, fix, docs, style, refactor, test, chore
- Example: `feat(auth): add MFA support`

B) Branch Naming
- Feature: `feature/user-auth`
- Bugfix: `bugfix/login-error`
- Hotfix: `hotfix/security-patch`
- Release: `release/v1.2.0`

C) Structured Logging
```json
{
  "timestamp": "2025-10-28T15:30:00Z",
  "level": "INFO",
  "traceId": "abc-123",
  "userId": "user-456",
  "tenantId": "tenant-789",
  "route": "/api/users",
  "action": "CREATE",
  "severity": "normal",
  "timed_ms": 45,
  "outcome": "success"
}
```

D) Accessibility
- Keyboard navigation (Tab, Enter, Esc)
- Focus-visible styles
- ARIA labels and roles
- AA contrast (4.5:1 for text)
- Screen reader testing

E) Repository Privacy
- All repositories Private by default
- Explicit approval for Public
- Secret scanning enabled
- Branch protection rules

‚∏ª

END OF GLOBAL_GUIDELINES v3.1

New in v3.
/components/UserProfile.tsx` - User profile component
  - Exports: UserProfile (default)
  - Dependencies: api/user, hooks/useAuth
  - Last Modified: 2025-10-25
  - Owner: Frontend Team
```

C) SEMANTIC DUPLICATION DETECTION

Use AST (Abstract Syntax Tree) analysis to detect semantic duplicates:

```python
# Example: detect_duplicates.py
import ast
import difflib

def get_function_signatures(file_path):
    """Extract function signatures from Python file"""
    with open(file_path) as f:
        tree = ast.parse(f.read())
    
    signatures = []
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            args = [arg.arg for arg in node.args.args]
            signatures.append({
                'name': node.name,
                'args': args,
                'lineno': node.lineno
            })
    return signatures

def find_duplicate_functions(dir_path):
    """Find functions with similar signatures across files"""
    # Implementation...
    pass
```

D
find existing code  
‚úÖ Prevents wasted effort  
‚úÖ Maintains codebase sanity

‚∏ª

30) ENVIRONMENT DETECTION & CONFIGURATION (CRITICAL - NEW in v3.2)

**PURPOSE:** Ensure correct behavior for Development vs Production environments

A) MANDATORY ENVIRONMENT VARIABLE

**`.env` MUST include:**
```bash
APP_ENV=development  # or 'production' or 'staging'
```

**Validation on startup:**
```python
import os
import sys

APP_ENV = os.getenv('APP_ENV')
if not APP_ENV:
    print("‚ùå ERROR: APP_ENV not set in .env!")
    print("Set APP_ENV=development or APP_ENV=production")
    sys.exit(1)

if APP_ENV not in ['development', 'staging', 'production']:
    print(f"‚ùå ERROR: Invalid APP_ENV='{APP_ENV}'")
    print("Must be: development, staging, or production")
    sys.exit(1)

print(f"‚úÖ Running in {APP_ENV.upper()} mode")
```

B) ENVIRONMENT-SPECIFIC BEHAVIOR

### Development Mode (`APP_ENV=development`)

**Characteristics:**
- ‚úÖ Detailed error messages with stack traces
- ‚úÖ Hot reload enabled
- ‚úÖ Debug 
toolbar visible
- ‚úÖ Automatic seed data generation
- ‚úÖ CORSÂÖÅËÆ∏ all origins (for local dev)
- ‚úÖ SQL query logging
- ‚úÖ No caching (or minimal)

**Example:**
```python
if APP_ENV == 'development':
    # Detailed errors
    app.config['PROPAGATE_EXCEPTIONS'] = True
    app.config['DEBUG'] = True
    
    # Seed data
    if not User.query.first():
        create_test_users()
        create_test_products()
        print("‚úÖ Test data created")
    
    # CORS
    CORS(app, origins="*")
```

### Production Mode (`APP_ENV=production`)

**Characteristics:**
- ‚úÖ Generic error messages only
- ‚úÖ No stack traces to clients
- ‚úÖ Optimized builds
- ‚úÖ Setup Wizard on first run
- ‚úÖ Strict CORS
- ‚úÖ Aggressive caching
- ‚úÖ No debug info

**Example:**
```python
if APP_ENV == 'production':
    # Generic errors only
    @app.errorhandler(Exception)
    def handle_error(e):
        # Log detailed error internally
        logger.error(f"Error: {e}", exc_info=True)
        
        # Return generic message to clie
nt
        return jsonify({
            "error": "An unexpected error occurred",
            "code": "INTERNAL_ERROR",
            "traceId": generate_trace_id()
        }), 500
    
    # Check if first run
    if not SystemConfig.query.filter_by(key='setup_complete').first():
        # Redirect to Setup Wizard
        return redirect('/setup/wizard')
```

C) FIRST-RUN DETECTION

```python
def is_first_run():
    """Check if this is the first time running in production"""
    if APP_ENV != 'production':
        return False
    
    # Check for setup completion marker
    setup_complete = SystemConfig.query.filter_by(
        key='setup_complete'
    ).first()
    
    return setup_complete is None or not setup_complete.value

def mark_setup_complete():
    """Mark setup as complete"""
    config = SystemConfig(key='setup_complete', value=True)
    db.session.add(config)
    db.session.commit()
```

D) CONFIGURATION FILES PER ENVIRONMENT

```
config/
‚îú‚îÄ‚îÄ development.py    # Dev-specif
ic config
‚îú‚îÄ‚îÄ staging.py        # Staging config
‚îú‚îÄ‚îÄ production.py     # Production config
‚îî‚îÄ‚îÄ base.py          # Shared config
```

**Load config based on environment:**
```python
if APP_ENV == 'development':
    app.config.from_object('config.development')
elif APP_ENV == 'staging':
    app.config.from_object('config.staging')
elif APP_ENV == 'production':
    app.config.from_object('config.production')
```

E) FRONTEND ENVIRONMENT DETECTION

```typescript
// frontend/src/config/environment.ts
export const APP_ENV = import.meta.env.VITE_APP_ENV || 'development';

export const config = {
  isDevelopment: APP_ENV === 'development',
  isProduction: APP_ENV === 'production',
  apiUrl: APP_ENV === 'production' 
    ? 'https://api.example.com'
    : 'http://{HOST}:{BACKEND_PORT}',
  enableDebug: APP_ENV === 'development',
  showErrorDetails: APP_ENV === 'development',
};
```

F) BENEFITS

‚úÖ Appropriate behavior per environment  
‚úÖ No test data in production  
‚úÖ Detailed errors in dev, gene
ric in prod  
‚úÖ Setup wizard only in production  
‚úÖ Security: no debug info leaks

‚∏ª

31) PRODUCTION SETUP WIZARD (CRITICAL - NEW in v3.2)

**PURPOSE:** Guide production deployment with interactive setup

A) WIZARD ACTIVATION

Trigger on first production run:
```python
@app.before_first_request
def check_setup():
    if APP_ENV == 'production' and is_first_run():
        # Redirect all requests to setup wizard
        session['needs_setup'] = True

@app.before_request
def enforce_setup():
    if session.get('needs_setup') and request.endpoint != 'setup_wizard':
        return redirect(url_for('setup_wizard'))
```

B) SETUP WIZARD STEPS

### Step 1: Welcome & Requirements Check
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Welcome to Production Setup            ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Checking system requirements...       ‚îÇ
‚îÇ  ‚úÖ Python 3.11+                        ‚îÇ
‚îÇ  ‚úÖ PostgreSQL 14+                      ‚îÇ
‚îÇ  ‚úÖ Redis 6+                            ‚îÇ
‚îÇ  ‚úÖ D

‚îÇ  Database: [{your_database_name}___]               ‚îÇ
‚îÇ  Username: [postgres____]               ‚îÇ
‚îÇ  Password: [____________]               ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  [Test Connection]                      ‚îÇ
‚îÇ  Status: ‚úÖ Connected successfully      ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  [Back] [Continue]                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Step 4: Email Configuration (SMTP)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Email Configuration                    ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  SMTP Host:   [smtp.gmail.com]          ‚îÇ
‚îÇ  SMTP Port:   [587__________]           ‚îÇ
‚îÇ  Username:    [_______________]         ‚îÇ
‚îÇ  Password:    [_______________]         ‚îÇ
‚îÇ  From Email:  [_______________]         ‚îÇ
‚îÇ  From Name:   [{YOUR_PROJECT_NAME}_____]          ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  [Send Test Email]                      ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  [Ski
ord']
            
            if validate_admin_user(email, password):
                create_admin_user(email, password)
                return redirect('/setup/wizard?step=3')
            else:
                return render_template('setup/step2.html', error="Invalid input")
        
        elif step == '3':
            # Database config
            db_config = {
                'host': request.form['host'],
                'port': request.form['port'],
                'database': request.form['database'],
                'username': request.form['username'],
                'password': request.form['password'],
            }
            
            if validate_db_config(db_config):
                save_db_config(db_config)
                return redirect('/setup/wizard?step=4')
            else:
                return render_template('setup/step3.html', error="Connection failed")
        
        # ... more steps ...
        
        elif step == '6':
            # Complete setup

            mark_setup_complete()
            session.pop('needs_setup', None)
            return redirect('/login')
    
    return render_template(f'setup/step{step}.html')
```

D) POST-SETUP CONFIGURATION

After setup wizard, provide GUI settings screens:

**Settings Menu in Admin Panel:**
```
Settings
‚îú‚îÄ‚îÄ General
‚îÇ   ‚îú‚îÄ‚îÄ Company Info
‚îÇ   ‚îú‚îÄ‚îÄ Localization
‚îÇ   ‚îî‚îÄ‚îÄ Time Zone
‚îú‚îÄ‚îÄ Users & Permissions
‚îÇ   ‚îú‚îÄ‚îÄ User Management
‚îÇ   ‚îú‚îÄ‚îÄ Roles
‚îÇ   ‚îî‚îÄ‚îÄ Permissions
‚îú‚îÄ‚îÄ Email
‚îÇ   ‚îú‚îÄ‚îÄ SMTP Settings
‚îÇ   ‚îî‚îÄ‚îÄ Email Templates
‚îú‚îÄ‚îÄ Security
‚îÇ   ‚îú‚îÄ‚îÄ Password Policy
‚îÇ   ‚îú‚îÄ‚îÄ MFA Settings
‚îÇ   ‚îî‚îÄ‚îÄ Session Management
‚îú‚îÄ‚îÄ Integrations
‚îÇ   ‚îú‚îÄ‚îÄ Payment Gateways
‚îÇ   ‚îú‚îÄ‚îÄ SMS Providers
‚îÇ   ‚îî‚îÄ‚îÄ Third-party APIs
‚îî‚îÄ‚îÄ Advanced
    ‚îú‚îÄ‚îÄ Database
    ‚îú‚îÄ‚îÄ Cache
    ‚îî‚îÄ‚îÄ Backup
```

E) BENEFITS

‚úÖ Guided production setup  
‚úÖ No manual .env editing  
‚úÖ Validation at each step  
‚úÖ Test connections before saving  
‚úÖ Secure credential handling  
‚úÖ GUI for post-setup changes

‚∏ª

(Continuing with remaining sections...)

32) CROS
S-BROWSER TESTING (CRITICAL - NEW in v3.2)

**PURPOSE:** Ensure application works correctly across all major browsers and devices

A) MANDATORY BROWSER SUPPORT

**Desktop:**
- Chrome 90+ (primary)
- Firefox 88+
- Safari 14+
- Edge 90+

**Mobile:**
- Chrome Mobile (Android)
- Safari Mobile (iOS)
- Samsung Internet

B) AUTOMATED TESTING WITH PLAYWRIGHT

```javascript
// tests/e2e/cross-browser.spec.ts
import { test, expect, devices } from '@playwright/test';

// Test on multiple browsers
test.describe('Cross-browser compatibility', () => {
  test.use({ ...devices['Desktop Chrome'] });
  
  test('Login page renders correctly', async ({ page }) => {
    await page.goto('/login');
    
    // Check critical elements
    await expect(page.locator('input[name="email"]')).toBeVisible();
    await expect(page.locator('input[name="password"]')).toBeVisible();
    await expect(page.locator('button[type="submit"]')).toBeVisible();
    
    // Check styling
    const loginButton = page.locator('but
ton[type="submit"]');
    const bgColor = await loginButton.evaluate(el => 
      getComputedStyle(el).backgroundColor
    );
    expect(bgColor).toBe('rgb(59, 130, 246)'); // Primary color
  });
  
  test('Dashboard loads on mobile', async ({ page }) => {
    await page.setViewportSize({ width: 375, height: 667 }); // iPhone SE
    await page.goto('/dashboard');
    
    // Mobile menu should be visible
    await expect(page.locator('[data-testid="mobile-menu"]')).toBeVisible();
    
    // Desktop sidebar should be hidden
    await expect(page.locator('[data-testid="desktop-sidebar"]')).toBeHidden();
  });
});

// Run on all browsers
const browsers = ['chromium', 'firefox', 'webkit'];
browsers.forEach(browserName => {
  test.describe(`${browserName} specific tests`, () => {
    test.use({ browserName });
    
    test('All pages load', async ({ page }) => {
      const pages = ['/login', '/dashboard', '/products', '/sales'];
      for (const url of pages) {
        await page.goto(ur
l);
        await expect(page).not.toHaveTitle(/Error/);
      }
    });
  });
});
```

C) CSS COMPATIBILITY

**Use Autoprefixer:**
```javascript
// postcss.config.js
module.exports = {
  plugins: {
    autoprefixer: {
      browsers: ['last 2 versions', '> 1%', 'not dead']
    }
  }
};
```

**CSS Feature Detection:**
```css
/* Use @supports for modern features */
@supports (display: grid) {
  .container {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
  }
}

/* Fallback for older browsers */
@supports not (display: grid) {
  .container {
    display: flex;
    flex-wrap: wrap;
  }
}
```

D) JAVASCRIPT POLYFILLS

```javascript
// src/polyfills.ts
// For older browsers
import 'core-js/stable';
import 'regenerator-runtime/runtime';

// Fetch API polyfill
if (!window.fetch) {
  import('whatwg-fetch');
}

// IntersectionObserver polyfill
if (!('IntersectionObserver' in window)) {
  import('intersection-observer');
}
```

E) RESPONSIVE DESIGN TESTING

``
`javascript
// Test on various screen sizes
const viewports = [
  { name: 'Mobile', width: 375, height: 667 },
  { name: 'Tablet', width: 768, height: 1024 },
  { name: 'Desktop', width: 1920, height: 1080 },
];

viewports.forEach(({ name, width, height }) => {
  test(`Layout works on ${name}`, async ({ page }) => {
    await page.setViewportSize({ width, height });
    await page.goto('/dashboard');
    
    // Take screenshot for visual regression
    await page.screenshot({ 
      path: `screenshots/${name}-dashboard.png`,
      fullPage: true 
    });
    
    // Check no horizontal scroll
    const hasHorizontalScroll = await page.evaluate(() => 
      document.documentElement.scrollWidth > window.innerWidth
    );
    expect(hasHorizontalScroll).toBe(false);
  });
});
```

F) CI INTEGRATION

```yaml
# .github/workflows/cross-browser-tests.yml
name: Cross-Browser Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        browser: 
[chromium, firefox, webkit]
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      - name: Install dependencies
        run: npm ci
      - name: Install Playwright
        run: npx playwright install --with-deps ${{ matrix.browser }}
      - name: Run tests
        run: npx playwright test --project=${{ matrix.browser }}
      - name: Upload test results
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ matrix.browser }}
          path: test-results/
```

G) BENEFITS

‚úÖ Works on all major browsers  
‚úÖ Automated testing  
‚úÖ Early detection of issues  
‚úÖ Better user experience  
‚úÖ Professional quality

‚∏ª

33) UI ASSET MANAGEMENT (CRITICAL - NEW in v3.2)

**PURPOSE:** Ensure all UI assets (fonts, icons, images, CSS) load correctly

A) ASSET LOADING VERIFICATION

```typescript
// frontend/src/utils/assetChecker.ts
export async function checkAssets(): Promise<{
  fonts: boolean;
  icons: boolean;
  
images: boolean;
  css: boolean;
}> {
  const results = {
    fonts: await checkFonts(),
    icons: await checkIcons(),
    images: await checkImages(),
    css: await checkCSS(),
  };
  
  const allLoaded = Object.values(results).every(v => v);
  if (!allLoaded) {
    console.error('‚ùå Some assets failed to load:', results);
  }
  
  return results;
}

async function checkFonts(): Promise<boolean> {
  try {
    // Check if custom fonts are loaded
    await document.fonts.ready;
    const fonts = ['Cairo', 'Inter']; // Your custom fonts
    
    for (const font of fonts) {
      const loaded = document.fonts.check(`16px ${font}`);
      if (!loaded) {
        console.error(`‚ùå Font not loaded: ${font}`);
        return false;
      }
    }
    return true;
  } catch (error) {
    console.error('‚ùå Font check failed:', error);
    return false;
  }
}

async function checkIcons(): Promise<boolean> {
  // Check if icon font/library is loaded
  const testIcon = document.createElement('i');
  
testIcon.className = 'icon-test'; // Your icon class
  document.body.appendChild(testIcon);
  
  const computed = getComputedStyle(testIcon);
  const hasIconFont = computed.fontFamily.includes('your-icon-font');
  
  document.body.removeChild(testIcon);
  return hasIconFont;
}

async function checkImages(): Promise<boolean> {
  // Check critical images
  const criticalImages = [
    '/logo.png',
    '/favicon.ico',
  ];
  
  const promises = criticalImages.map(src => 
    new Promise((resolve) => {
      const img = new Image();
      img.onload = () => resolve(true);
      img.onerror = () => {
        console.error(`‚ùå Image failed to load: ${src}`);
        resolve(false);
      };
      img.src = src;
    })
  );
  
  const results = await Promise.all(promises);
  return results.every(v => v);
}

async function checkCSS(): Promise<boolean> {
  // Check if main CSS is loaded
  const stylesheets = Array.from(document.styleSheets);
  const hasMainCSS = stylesheets.some(sheet => 
    sh
eet.href && sheet.href.includes('main.css')
  );
  
  if (!hasMainCSS) {
    console.error('‚ùå Main CSS not loaded');
  }
  
  return hasMainCSS;
}
```

B) FALLBACK ASSETS

```typescript
// frontend/src/config/assets.ts
export const ASSET_FALLBACKS = {
  logo: '/assets/fallback-logo.png',
  avatar: '/assets/default-avatar.png',
  icon: '/assets/default-icon.svg',
};

export function getImageWithFallback(src: string, fallback: string) {
  return new Promise((resolve) => {
    const img = new Image();
    img.onload = () => resolve(src);
    img.onerror = () => {
      console.warn(`Image failed, using fallback: ${src} -> ${fallback}`);
      resolve(fallback);
    };
    img.src = src;
  });
}

// Usage in React
function UserAvatar({ src }: { src: string }) {
  const [imgSrc, setImgSrc] = useState(src);
  
  useEffect(() => {
    getImageWithFallback(src, ASSET_FALLBACKS.avatar)
      .then(setImgSrc);
  }, [src]);
  
  return <img src={imgSrc} alt="Avatar" />;
}
```

C) ASSET PRELOADING


```html
<!-- index.html -->
<head>
  <!-- Preload critical assets -->
  <link rel="preload" href="/fonts/Cairo-Regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/fonts/Inter-Regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/logo.png" as="image">
  <link rel="preload" href="/main.css" as="style">
  
  <!-- DNS prefetch for external resources -->
  <link rel="dns-prefetch" href="https://fonts.googleapis.com">
  <link rel="dns-prefetch" href="https://cdn.example.com">
</head>
```

D) CDN CONFIGURATION

```typescript
// frontend/src/config/cdn.ts
const CDN_URL = import.meta.env.VITE_CDN_URL || '';

export function getCDNUrl(path: string): string {
  if (!CDN_URL) return path;
  return `${CDN_URL}${path}`;
}

// Usage
<img src={getCDNUrl('/images/product.jpg')} />
```

E) ASSET LOADING MONITORING

```typescript
// Monitor asset loading performance
window.addEventListener('load', () => {
  const resources = performance.ge
tEntriesByType('resource');
  
  const slowAssets = resources.filter(resource => 
    resource.duration > 1000 // > 1 second
  );
  
  if (slowAssets.length > 0) {
    console.warn('‚ö†Ô∏è Slow assets detected:', slowAssets.map(r => ({
      name: r.name,
      duration: r.duration,
      size: r.transferSize,
    })));
  }
  
  // Report to monitoring service
  if (window.analytics) {
    window.analytics.track('Asset Loading', {
      totalAssets: resources.length,
      slowAssets: slowAssets.length,
      totalDuration: resources.reduce((sum, r) => sum + r.duration, 0),
    });
  }
});
```

F) BENEFITS

‚úÖ All assets load correctly  
‚úÖ Fallbacks for failures  
‚úÖ Performance monitoring  
‚úÖ Better user experience  
‚úÖ Professional appearance

‚∏ª

34) PRODUCTION ERROR HANDLING (CRITICAL - NEW in v3.2)

**PURPOSE:** Prevent error/stack trace leaks in production

A) GENERIC ERROR RESPONSES

**Backend (Python/Flask):**
```python
# backend/src/error_handlers.py
from flask import jsonify
import l
ogging
import traceback
import uuid

logger = logging.getLogger(__name__)

def generate_trace_id():
    """Generate unique trace ID for error tracking"""
    return str(uuid.uuid4())

@app.errorhandler(Exception)
def handle_exception(e):
    """Handle all unhandled exceptions"""
    trace_id = generate_trace_id()
    
    # Log detailed error internally
    logger.error(
        f"Unhandled exception [TraceID: {trace_id}]",
        exc_info=True,
        extra={
            'trace_id': trace_id,
            'error_type': type(e).__name__,
            'error_message': str(e),
            'stack_trace': traceback.format_exc(),
        }
    )
    
    # Return generic error to client
    if app.config['ENV'] == 'production':
        return jsonify({
            'error': 'An unexpected error occurred',
            'code': 'INTERNAL_ERROR',
            'traceId': trace_id,
            'message': 'Please contact support if the problem persists'
        }), 500
    else:
        # In develop
ment, return detailed error
        return jsonify({
            'error': str(e),
            'type': type(e).__name__,
            'traceback': traceback.format_exc().split('\n'),
            'traceId': trace_id
        }), 500

@app.errorhandler(404)
def handle_not_found(e):
    """Handle 404 errors"""
    # Don't reveal route structure
    return jsonify({
        'error': 'Resource not found',
        'code': 'NOT_FOUND'
    }), 404

@app.errorhandler(403)
def handle_forbidden(e):
    """Handle 403 errors"""
    # Don't reveal permission structure
    return jsonify({
        'error': 'Access denied',
        'code': 'FORBIDDEN'
    }), 403
```

B) FRONTEND ERROR BOUNDARY

```typescript
// frontend/src/components/ErrorBoundary.tsx
import React, { Component, ErrorInfo, ReactNode } from 'react';

interface Props {
  children: ReactNode;
}

interface State {
  hasError: boolean;
  error?: Error;
  errorInfo?: ErrorInfo;
  traceId?: string;
}

class ErrorBoundary extends Component<Prop
s, State> {
  constructor(props: Props) {
    super(props);
    this.state = { hasError: false };
  }

  static getDerivedStateFromError(error: Error): State {
    return { hasError: true, error };
  }

  componentDidCatch(error: Error, errorInfo: ErrorInfo) {
    const traceId = this.generateTraceId();
    
    // Log to monitoring service
    console.error('React Error Boundary caught:', {
      error: error.message,
    # ... (code truncated for brevity) ...
    # See full example in examples/ directory
  return (
    <ErrorBoundary>
      <Router>
        <Routes>
          {/* Your routes */}
        </Routes>
      </Router>
    </ErrorBoundary>
  );
}
```

C) API ERROR STANDARDIZATION

```typescript
// frontend/src/api/client.ts
export interface APIError {
  error: string;
  code: string;
  traceId?: string;
  message?: string;
  details?: any;
}

export async function apiCall<T>(
  url: string,
  options?: RequestInit
): Promise<T> {
  try {
    const response = await fetch(url
, options);
    
    if (!response.ok) {
      const error: APIError = await response.json();
      
      // Log error (but don't expose to user in production)
      console.error('API Error:', {
        url,
        status: response.status,
        error,
      });
      
      // Throw user-friendly error
      throw new Error(error.message || error.error || 'ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£');
    }
    
    return await response.json();
  } catch (error) {
    // Network error or JSON parse error
    console.error('Request failed:', error);
    throw new Error('ŸÅÿ¥ŸÑ ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ÿßŸÑÿÆÿßÿØŸÖ');
  }
}
```

D) ERROR LOGGING SERVICE

```python
# backend/src/services/error_logger.py
import logging
from datetime import datetime
from models import ErrorLog

class ErrorLogger:
    @staticmethod
    def log_error(
        trace_id: str,
        error_type: str,
        error_message: str,
        stack_trace: str,
        user_id: int = None,
        request_data: dict = None
    ):
        """Log error to database for anal
ysis"""
        error_log = ErrorLog(
            trace_id=trace_id,
            error_type=error_type,
            error_message=error_message,
            stack_trace=stack_trace,
            user_id=user_id,
            request_data=request_data,
            timestamp=datetime.utcnow()
        )
        db.session.add(error_log)
        db.session.commit()
        
        # Also log to file
        logging.error(
            f"[{trace_id}] {error_type}: {error_message}",
            extra={'stack_trace': stack_trace}
        )
        
        # Send alert if critical
        if error_type in ['DatabaseError', 'SecurityError']:
            send_alert_to_admin(trace_id, error_type, error_message)
```

E) BENEFITS

‚úÖ No stack traces leaked to clients  
‚úÖ Detailed logging internally  
‚úÖ Trace IDs for debugging  
‚úÖ User-friendly error messages  
‚úÖ Security: no information disclosure

‚∏ª

(Continuing with sections 35-38...)

35) .ENV VALIDATION & MANAGEMENT (CRITICAL - NEW in v3.2)

**PU
RPOSE:** Ensure .env is correctly configured with all required variables

A) COMPREHENSIVE .env.example

```bash
# .env.example - Complete template with documentation

# ============================================
# ENVIRONMENT
# ============================================
APP_ENV=development  # development, staging, or production (REQUIRED)
DEBUG=True           # Enable debug mode (development only)

# ============================================
# APPLICATION
# ============================================
APP_NAME="{YOUR_PROJECT_NAME}"
APP_URL=http://{HOST}:{BACKEND_PORT}
FRONTEND_URL=http://{HOST}:{FRONTEND_PORT}

# ============================================
# DATABASE
# ============================================
DB_HOST=localhost
DB_PORT=5432
DB_NAME={your_database_name}
DB_USER=postgres
DB_PASSWORD=your_secure_password_here  # CHANGE THIS!

# Full connection string (alternative to above)
# DATABASE_URL=postgresql://{DB_USER}:{DB_PASSWORD}@{HOST}:{DB_PORT}/{your_database_name
}

# ============================================
# SECURITY
# ============================================
    # ... (code truncated for brevity) ...
    # See full example in examples/ directory
ENABLE_MFA=True
ENABLE_API_DOCS=True  # Swagger/OpenAPI docs
ENABLE_REGISTRATION=False  # Allow user self-registration

# ============================================
# PERFORMANCE
# ============================================
WORKERS=4  # Gunicorn workers
THREADS=2  # Threads per worker
CACHE_TTL=3600  # Cache time-to-live in seconds
```

B) VALIDATION SCRIPT

```python
# scripts/validate_env.py
import os
import sys
from typing import List, Dict, Any
from dotenv import load_dotenv

# Load .env
load_dotenv()

# Define required variables
REQUIRED_VARS = {
    'APP_ENV': {
        'required': True,
        'allowed_values': ['development', 'staging', 'production'],
        'description': 'Application environment'
    },
    'SECRET_KEY': {
        'required': True,
        'min_length': 32,
  
      'description': 'Application secret key'
    },
    'JWT_SECRET_KEY': {
        'required': True,
        'min_length': 32,
        'description': 'JWT secret key'
    },
    'DB_HOST': {
        'required': True,
        'description': 'Database host'
    },
    # ... (code truncated for brevity) ...
    # See full example in examples/ directory
        return 0
    else:
        print(f"‚ùå Validation failed with {len(result['errors'])} error(s)")
        print()
        print("Please fix the errors above and run validation again.")
        print("See .env.example for reference.")
        return 1

if __name__ == '__main__':
    sys.exit(main())
```

C) AUTO-GENERATION OF .env

```python
# scripts/generate_env.py
import secrets

def generate_secret_key(length=32):
    """Generate secure random key"""
    return secrets.token_hex(length)

def generate_env_file():
    """Generate .env file with secure defaults"""
    template = f"""# Generated .env file - {datetime.now().isoformat()
}

# IMPORTANT: Review and update all values before use!

APP_ENV=development
SECRET_KEY={generate_secret_key()}
JWT_SECRET_KEY={generate_secret_key()}

DB_HOST=localhost
DB_PORT=5432
DB_NAME={your_database_name}
DB_USER=postgres
DB_PASSWORD={generate_secret_key(16)}

# Add other variables from .env.example
"""
    
    with open('.env', 'w') as f:
        f.write(template)
    
    print("‚úÖ .env file generated!")
    print("‚ö†Ô∏è Please review and update the values before running the application.")

if __name__ == '__main__':
    generate_env_file()
```

D) RUNTIME VALIDATION

```python
# backend/src/app.py
from scripts.validate_env import validate_env

# Validate on startup
result = validate_env()
if not result['valid']:
    print("‚ùå Environment validation failed!")
    for error in result['errors']:
        print(f"  {error}")
    sys.exit(1)

if result['warnings']:
    for warning in result['warnings']:
        print(f"  {warning}")
```

E) DOCUMENTATION

Create `/docs/Env.md`:
```mar
kdown
# Environment Variables Documentation

## Required Variables

### APP_ENV
- **Description**: Application environment
- **Required**: Yes
- **Allowed Values**: `development`, `staging`, `production`
- **Example**: `APP_ENV=production`

### SECRET_KEY
- **Description**: Secret key for session encryption
- **Required**: Yes
- **Min Length**: 32 characters
- **Generation**: `python -c "import secrets; print(secrets.token_hex(32))"`
- **Example**: `SECRET_KEY=a1b2c3d4...`

(Continue for all variables...)
```

F) BENEFITS

‚úÖ All required variables documented  
‚úÖ Validation before startup  
‚úÖ Secure defaults  
‚úÖ Clear error messages  
‚úÖ Production safety

‚∏ª

36) IMPORT/EXPORT DOCUMENTATION (CRITICAL - NEW in v3.2)

**PURPOSE:** Track all imports/exports to prevent circular dependencies and duplication

A) IMPORTS MAP

Create `/docs/Imports_Map.md`:
```markdown
# Imports Map - Generated: 2025-10-28

## Backend Imports

### models/user.py
```python
from sqlalchemy import Column, Integer, 
String
from database import db
from services.auth import hash_password
```

**Imports:**
- `sqlalchemy` (external)
- `database.db` (internal - database.py)
- `services.auth.hash_password` (internal - services/auth.py)

**Imported By:**
- `services/auth_service.py`
- `routes/user_routes.py`
- `routes/auth_routes.py`

---

### services/auth_service.py
```python
from models.user import User
from utils.jwt import generate_token
```

**Imports:**
- `models.user.User` (internal - models/user.py)
- `utils.jwt.generate_token` (internal - utils/jwt.py)

**Imported By:**
- `routes/auth_routes.py`

---

## Frontend Imports

### components/UserProfile.tsx
```typescript
import { User } from '../types/user';
import { useAuth } from '../hooks/useAuth';
import { api } from '../api/client';
```

**Imports:**
- `../types/user.User` (internal)
- `../hooks/useAuth` (internal)
- `../api/client.api` (internal)

**Imported By:**
- `pages/Dashboard.tsx`
- `pages/Profile.tsx`

---

## Circular Dependencies Det
ected

‚ö†Ô∏è **NONE** (Good!)

---

## Unused Imports Detected

‚ö†Ô∏è `utils/deprecated.py` - Not imported anywhere (consider removing)

---

## External Dependencies

### Python
- `sqlalchemy==2.0.23`
- `flask==3.0.0`
- `pydantic==2.5.0`

### JavaScript/TypeScript
- `react@18.2.0`
- `axios@1.6.0`
- `react-router-dom@6.20.0`
```

B) EXPORTS MAP

Create `/docs/Exports_Map.md`:
```markdown
# Exports Map - Generated: 2025-10-28

## Backend Exports

### models/user.py
**Exports:**
- `User` (class) - User model
- `create_user()` (function) - Create new user
- `get_user_by_email()` (function) - Find user by email

**Usage Count:** 15 imports across 8 files

---

### services/auth_service.py
**Exports:**
- `AuthService` (class) - Authentication service
- `login()` (function) - User login
- `logout()` (function) - User logout
- `verify_token()` (function) - Verify JWT token

**Usage Count:** 8 imports across 5 files

---

## Frontend Exports

### types/user.ts
**Exports:**
- `User` (interface) - Use
e, ast.Import):
            for alias in node.names:
                imports.append({
                    'module': alias.name,
                    'alias': alias.asname,
                    'type': 'import'
                })
        elif isinstance(node, ast.ImportFrom):
            for alias in node.names:
                imports.append({
                    'module': node.module,
                    'name': alias.name,
                    'alias': alias.asname,
                    'type': 'from'
                })
    
    return imports

def find_circular_dependencies(import_graph: Dict) -> List:
    """Detect circular dependencies"""
    # Implementation using DFS
    pass

def generate_imports_map(root_dir: str):
    """Generate complete imports map"""
    # Scan all Python files
    # Analyze imports
    # Detect circular dependencies
    # Generate markdown report
    pass

if __name__ == '__main__':
    generate_imports_map('./backend')
    generate_imports_map('./frontend')

rity threshold
    
    def get_function_signature(self, func_node: ast.FunctionDef) -> str:
        """Extract normalized function signature"""
        args = [arg.arg for arg in func_node.args.args]
        return f"{func_node.name}({', '.join(args)})"
    
    def get_class_signature(self, class_node: ast.ClassDef) -> str:
        """Extract class signature"""
        methods = []
        for node in class_node.body:
            if isinstance(node, ast.FunctionDef):
                methods.append(node.name)
        return f"{class_node.name}: {', '.join(sorted(methods))}"
    
    def normalize_code(self, code: str) -> str:
        """Normalize code for comparison"""
        # Remove comments, whitespace, docstrings
        tree = ast.parse(code)
        return ast.unparse(tree)
    
    def find_similar_files(self, dir_path: str) -> List[Dict]:
    # ... (code truncated for brevity) ...
    # See full example in examples/ directory
    
    if file_duplicates or func_duplicates:
  
 1. Check .env
    print("1. Checking environment...")
    env_result = validate_env()
    if not env_result['valid']:
        errors.extend(env_result['errors'])
    
    # 2. Check documentation exists
    print("2. Checking documentation...")
    required_docs = [
        'docs/File_Map.md',
        'docs/Class_Registry.md',
        'docs/Imports_Map.md',
        'docs/TODO.md',
    ]
    for doc in required_docs:
        if not Path(doc).exists():
            errors.append(f"‚ùå Missing required documentation: {doc}")
    
    # 3. Check for uncommitted changes
    print("3. Checking git status...")
    import subprocess
    result = subprocess.run(['git', 'status', '--porcelain'], capture_output=True)
    if result.stdout:
        errors.append("‚ö†Ô∏è You have uncommitted changes. Commit or stash them first.")
    
    # Summary
    if errors:
        print("\n‚ùå Pre-development checks failed:")
        for error in errors:
            print(f"  {error}")
        print("\nPlease fix the
7):**
- File duplication check
- .env validation
- Import/Export consistency
- Cross-browser tests
- Asset loading tests
- Error handling tests
- Class Registry sync

Version: 3.2.0
Date: 2025-10-28
Status: Production Ready - Critical Fixes Applied
License: Proprietary

Total Sections: 38 (was 28 in v3.1)
Total Lines: 3000+ (was 1147 in v3.1)
New Content: +1853 lines (+162%)

‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª

================================================================================
39. PORT CONFIGURATION MANAGEMENT
================================================================================

## Problem
- Applications use inconsistent ports (8000 vs 3000)
- Hard-coded ports in code
- Port conflicts between services
- .env values ignored

## Solution: Single Source of Truth

### config/ports.py
```python
import os
import sys

def get_port(env_var: str, default: int) -> int:
    """Get port from environment with validation"""
    try:
        port = int(os.getenv(env_va
r, default))
    except ValueError:
        print(f"ERROR: Invalid {env_var}. Must be integer.")
        sys.exit(1)
    
    if not (1024 <= port <= 65535):
        print(f"ERROR: {env_var}={port} invalid. Must be 1024-65535.")
        sys.exit(1)
    
    return port

BACKEND_PORT = get_port('BACKEND_PORT', 8000)
FRONTEND_PORT = get_port('FRONTEND_PORT', 3000)
DATABASE_PORT = get_port('DATABASE_PORT', 5432)
REDIS_PORT = get_port('REDIS_PORT', 6379)

# Conflict detection
ports = {
    'BACKEND': BACKEND_PORT,
    'FRONTEND': FRONTEND_PORT,
    'DATABASE': DATABASE_PORT,
    'REDIS': REDIS_PORT,
}

if len(set(ports.values())) != len(ports):
    print("ERROR: Port conflicts detected")
    sys.exit(1)
```

### Usage
```python
# main.py
from config.ports import BACKEND_PORT, FRONTEND_PORT

# FastAPI
app = FastAPI()
uvicorn.run(app, host="0.0.0.0", port=BACKEND_PORT)

# React/Next.js - package.json
{
  "scripts": {
    "dev": "next dev -p $FRONTEND_PORT"
  }
}
```

### .env Template
```bas
h
# Port Configuration
BACKEND_PORT=8000
FRONTEND_PORT=3000
DATABASE_PORT=5432
REDIS_PORT=6379
```

### CI Check
```yaml
- name: Validate Ports
  run: python -c "from config.ports import *"
```

## Rules
1. ‚úÖ NEVER hard-code ports
2. ‚úÖ Import from config.ports only
3. ‚úÖ Validate on startup
4. ‚úÖ Check for conflicts
5. ‚úÖ Document in .env.example

================================================================================
40. ORGANIZED DEFINITIONS STRUCTURE
================================================================================

## Problem
- Classes undefined or duplicated
- Import errors
- No central registry
- Inconsistent types

## Solution: Three-Tier Definition System

### Structure
```
config/
‚îú‚îÄ‚îÄ ports.py                    # Port configuration
‚îî‚îÄ‚îÄ definitions/
    ‚îú‚îÄ‚îÄ __init__.py             # Central registry
    ‚îú‚îÄ‚îÄ common.py               # General-purpose definitions
    ‚îú‚îÄ‚îÄ core.py                 # Base models & mixins
    ‚îî‚îÄ‚îÄ custom.py               # Project-
specific definitions
```

### common.py - General Purpose
```python
"""Common definitions used across entire project"""

from enum import Enum
from typing import TypedDict, Literal, Any

class Status(str, Enum):
    ACTIVE = "active"
    INACTIVE = "inactive"
    PENDING = "pending"
    DELETED = "deleted"

class UserRole(str, Enum):
    ADMIN = "admin"
    MANAGER = "manager"
    USER = "user"
    GUEST = "guest"

class Environment(str, Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"

class APIResponse(TypedDict):
    success: bool
    message: str
    data: dict[str, Any] | None
    errors: list[str] | None

# Constants
DEFAULT_PAGE_SIZE = 20
MAX_PAGE_SIZE = 100
MIN_PASSWORD_LENGTH = 8
EMAIL_REGEX = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
```

### core.py - Base Models
```python
"""Core base models and mixins"""

from datetime import datetime
from pydantic import BaseModel as PydanticBaseModel, Field

class BaseModel(PydanticBa
 __init__.py:F401
```

### pyproject.toml
```toml
[tool.autopep8]
max_line_length = 120
aggressive = 2

[tool.black]
line-length = 120
target-version = ['py310', 'py311', 'py312']

[tool.isort]
profile = "black"
line_length = 120
```

### Pre-commit Hook (.git/hooks/pre-commit)
```bash
#!/bin/bash

echo "Checking line length..."

# Check Python files
find . -name "*.py" -not -path "*/venv/*" -not -path "*/.venv/*" | \
  xargs grep -n ".\{121,\}" | \
  grep -v "^#" | \
  grep -v "http" | \
  grep -v '"""' && {
    echo "‚ùå Lines exceed 120 characters"
    exit 1
  }

echo "‚úÖ All lines ‚â§ 120 characters"
```

### Auto-fix Script
```bash
#!/bin/bash
# scripts/fix_line_length.sh

echo "Fixing line length..."

# Install tools
pip install autopep8 black isort

# Fix Python files
autopep8 --in-place --aggressive --aggressive \
  --max-line-length=120 \
  --recursive \
  --exclude=venv,.venv,migrations \
  .

black --line-length=120 .
isort --profile=black --line-length=120 .

echo "‚úÖ Line lengt


### middleware/error_handler.py
```python
"""Environment-based error handling middleware"""

import os
import uuid
import traceback
from fastapi import Request
from fastapi.responses import JSONResponse
from datetime import datetime

APP_ENV = os.getenv('APP_ENV', 'development')

async def error_handler_middleware(request: Request, call_next):
    """Handle errors based on environment"""
    try:
        return await call_next(request)
    
    except Exception as e:
        error_id = str(uuid.uuid4())
        
        # Log error (always)
        log_error(error_id, e, request)
        
        if APP_ENV == 'production':
            # Production: Generic error
            return JSONResponse(
                status_code=500,
                content={
                    "success": False,
                    "message": "An error occurred. Please contact support.",
                    "error_id": error_id,
                    "timestamp": datetime.utcnow().isoformat()
              
  }
            )
        else:
            # Development: Detailed error
            return JSONResponse(
                status_code=500,
                content={
                    "success": False,
                    "message": str(e),
                    "error_type": type(e).__name__,
                    "error_id": error_id,
                    "traceback": traceback.format_exc(),
                    "request": {
                        "method": request.method,
                        "url": str(request.url),
                        "headers": dict(request.headers)
                    },
                    "timestamp": datetime.utcnow().isoformat()
                }
            )

def log_error(error_id: str, error: Exception, request: Request):
    """Log error to file/service"""
    import logging
    logger = logging.getLogger(__name__)
    
    logger.error(
        f"Error ID: {error_id}\n"
        f"Type: {type(error).__name__}\n"
        f"Message: {str(error)}\n"
  
      f"URL: {request.url}\n"
        f"Method: {request.method}\n"
        f"Traceback:\n{traceback.format_exc()}"
    )
```

### Frontend Error Display

#### Development
```typescript
// Show detailed errors
if (process.env.NODE_ENV === 'development') {
  console.error('Error:', error);
  toast.error(
    <div>
      <strong>{error.error_type}</strong>
      <p>{error.message}</p>
      <code>{error.traceback}</code>
    </div>
  );
}
```

#### Production
```typescript
// Show generic error
if (process.env.NODE_ENV === 'production') {
  toast.error(
    'An error occurred. Please try again or contact support.'
  );
  // Send to error tracking service
  Sentry.captureException(error);
}
```

### Usage
```python
# main.py
from middleware.error_handler import error_handler_middleware

app = FastAPI()
app.middleware("http")(error_handler_middleware)
```

## Rules
1. ‚úÖ NO stack traces in production
2. ‚úÖ Generic messages in production
3. ‚úÖ Detailed errors in development
4. ‚úÖ Always log wit
h error_id
5. ‚úÖ Track errors in production


================================================================================
43. UNUSED CODE REMOVAL
================================================================================

## Problem
- Unused imports
- Unused variables/functions
- Dead code
- Causes errors and bloat

## Solution: Automated Cleanup

### scripts/remove_unused.sh
```bash
#!/bin/bash

echo "Removing unused code..."

# Install tools
pip install autoflake

# Remove unused imports and variables
autoflake --in-place \
  --remove-all-unused-imports \
  --remove-unused-variables \
  --remove-duplicate-keys \
  --recursive \
  --exclude=venv,.venv,migrations,node_modules \
  .

echo "‚úÖ Unused code removed"
```

### Pre-commit Hook
```bash
#!/bin/bash
# .git/hooks/pre-commit

# Check for unused imports
autoflake --check \
  --remove-all-unused-imports \
  --recursive \
  --exclude=venv,.venv \
  . || {
    echo "‚ùå Unused imports found. Run: ./scripts/remove_unused.sh"
   
 develop]

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
    # ... (code truncated for brevity) ...
    # See full example in examples/ directory
        run: npm ci
      
      - name: Run linter
        run: npm run lint
      
      - name: Run tests
        run: npm test
      
      - name: Build
        run: npm run build
```

### .github/workflows/deploy.yml
```yaml
name: Deploy to Production

on:
  push:
    branches: [main]
    tags: ['v*']

jobs:
  deploy:
    runs-on: ubuntu-latest
    environme
nt: production
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Run production checks
        run: |
          python scripts/validate_env.py
          python scripts/map_files.py . docs/File_Map.md
      
      - name: Deploy
        run: |
          # Your deployment script
          echo "Deploying to production..."
```

## Rules
1. ‚úÖ Test on multiple Python versions
2. ‚úÖ Install system dependencies
3. ‚úÖ Cache pip packages
4. ‚úÖ Run all checks
5. ‚úÖ Generate reports

================================================================================
45. IMPORT/EXPORT DOCUMENTATION
================================================================================

## Problem
- No documentation of imports/exports
- Circular dependencies
- Unclear module r
elationships

## Solution: Auto-Generated Documentation

### scripts/document_imports.py
```python
"""
File: scripts/document_imports.py
Generate import/export documentation
"""

import ast
import os
from pathlib import Path
from collections import defaultdict

def analyze_file(filepath: Path) -> dict:
    """Analyze Python file for imports and exports"""
    with open(filepath, 'r', encoding='utf-8') as f:
        try:
            tree = ast.parse(f.read())
        except:
            return {}
    
    imports = []
    exports = []
    
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                imports.append(alias.name)
        
        elif isinstance(node, ast.ImportFrom):
            module = node.module or ''
            for alias in node.names:
                imports.append(f"{module}.{alias.name}")
        
        elif isinstance(node, ast.Assign):
            for target in node.targets:
                if is
instance(target, ast.Name) and target.id == '__all__':
                    if isinstance(node.value, ast.List):
                        exports = [
                            elt.s for elt in node.value.elts
                            if isinstance(elt, ast.Str)
                        ]
    
    return {
        'imports': imports,
        'exports': exports
    }

def generate_documentation(root_dir: str, output_file: str):
    """Generate import/export documentation"""
    
    modules = {}
    
    for filepath in Path(root_dir).rglob('*.py'):
        if 'venv' in str(filepath) or '.venv' in str(filepath):
            continue
        
        rel_path = filepath.relative_to(root_dir)
        analysis = analyze_file(filepath)
        
        if analysis:
            modules[str(rel_path)] = analysis
    
    # Write documentation
    with open(output_file, 'w') as f:
        f.write("# Import/Export Documentation\n\n")
        f.write(f"Generated: {datetime.now().isoformat()}\n\
n")
        
        for module, data in sorted(modules.items()):
            f.write(f"## {module}\n\n")
            
            if data.get('exports'):
                f.write("### Exports\n")
                for exp in data['exports']:
                    f.write(f"- `{exp}`\n")
                f.write("\n")
            
            if data.get('imports'):
                f.write("### Imports\n")
                for imp in data['imports']:
                    f.write(f"- `{imp}`\n")
                f.write("\n")
            
            f.write("---\n\n")

if __name__ == "__main__":
    import sys
    from datetime import datetime
    
    root = sys.argv[1] if len(sys.argv) > 1 else "."
    output = sys.argv[2] if len(sys.argv) > 2 else "docs/Imports_Exports.md"
    
    generate_documentation(root, output)
    print(f"‚úÖ Documentation generated: {output}")
```

### Usage
```bash
# Generate documentation
python scripts/document_imports.py . docs/Imports_Exports.md

# Add to CI
- na
**Raises:**
- `ExceptionType`: When this happens

**Example:**
```python
from module_name import function_name

result = function_name(arg1, arg2=value)
print(result)
```

**Dependencies:**
- `dependency1`
- `dependency2`

**Used By:**
- `module_a.py`
- `module_b.py`

---
```

### 47.2 Documentation Standards

**Every shared function MUST have:**
1. ‚úÖ Docstring (Google or Sphinx style)
2. ‚úÖ Type hints
3. ‚úÖ Entry in `function_reference.md`
4. ‚úÖ Unit tests
5. ‚úÖ Usage examples

**Docstring Example (Google Style):**
```python
def calculate_total(items: List[Dict], tax_rate: float = 0.15) -> Decimal:
    """
    Calculate total price including tax.
    
    Args:
        items: List of item dictionaries with 'price' and 'quantity'
        tax_rate: Tax rate as decimal (default: 0.15 for 15%)
    
    Returns:
        Total price including tax as Decimal
    
    Raises:
        ValueError: If items list is empty or tax_rate is negative
    
    Example:
        >>> items = [{'price': 10.0, 
documented = []
    for file_path, func_name in functions:
        if f"`{func_name}`" not in content:
            undocumented.append(f"{file_path}::{func_name}")
    
    if undocumented:
        print("‚ùå Undocumented functions found:")
        for func in undocumented:
            print(f"  - {func}")
        print("\nPlease add them to docs/function_reference.md")
        return False
    
    print("‚úÖ All shared functions are documented")
    return True

if __name__ == '__main__':
    functions = find_shared_functions()
    if not check_documented(functions):
        sys.exit(1)
```

---

## 48. Error Tracking System

### 48.1 Error Log File (APPEND-ONLY)

**Location:** `docs/errors/Dont_make_this_error_again.md`

**Rules:**
- **APPEND-ONLY** - Never delete entries
- Document every significant error
- Include root cause and solution
- Add prevention measures

**Template:**
```markdown
## Error #XXX: [Brief Title]

**Date:** YYYY-MM-DD
**Severity:** Critical / High / Medium / Low

   patterns = []
    with open(error_file) as f:
        content = f.read()
    
    # Extract code patterns that caused errors
    # This is a simplified example
    pattern_blocks = re.findall(r'```python\n# WRONG:(.*?)```', content, re.DOTALL)
    for block in pattern_blocks:
        patterns.append(block.strip())
    
    return patterns

def check_files_for_patterns(patterns):
    """Check Python files for error patterns."""
    issues_found = False
    
    for py_file in Path('.').rglob('*.py'):
        if 'test_' in str(py_file) or '__pycache__' in str(py_file):
            continue
        
        with open(py_file) as f:
            content = f.read()
        
        for pattern in patterns:
            if pattern in content:
                print(f"‚ö†Ô∏è  Known error pattern found in {py_file}")
                print(f"   Pattern: {pattern[:50]}...")
                issues_found = True
    
    return issues_found

if __name__ == '__main__':
    patterns = load_error_patterns
ort ast
from pathlib import Path
from collections import defaultdict

def analyze_module(file_path):
    """Analyze a Python module."""
    with open(file_path) as f:
        try:
            tree = ast.parse(f.read())
        except SyntaxError:
            return None
    
    info = {
        'classes': [],
        'functions': [],
        'imports': [],
        'dependencies': set()
    }
    
    for node in ast.walk(tree):
        if isinstance(node, ast.ClassDef):
            info['classes'].append(node.name)
        elif isinstance(node, ast.FunctionDef):
            if not node.name.startswith('_'):
                info['functions'].append(node.name)
        elif isinstance(node, (ast.Import, ast.ImportFrom)):
            if isinstance(node, ast.ImportFrom) and node.module:
                info['dependencies'].add(node.module.split('.')[0])
    
    return info

def generate_map():
    """Generate module map."""
    modules = defaultdict(dict)
    
    for py_file in Path('.')
.rglob('*.py'):
        if '__pycache__' in str(py_file) or 'venv' in str(py_file):
            continue
        
        info = analyze_module(py_file)
        if info:
            modules[str(py_file)] = info
    
    # Write to markdown
    with open('docs/Module_Map.md', 'w') as f:
        f.write("# Module Map\n\n")
        f.write("**Generated:** Auto-generated\n\n")
        f.write("## Modules by Directory\n\n")
        
        # Group by directory
        by_dir = defaultdict(list)
        for path in sorted(modules.keys()):
            dir_name = str(Path(path).parent)
            by_dir[dir_name].append(path)
        
        for dir_name in sorted(by_dir.keys()):
            f.write(f"### `{dir_name}/`\n\n")
            for path in sorted(by_dir[dir_name]):
                info = modules[path]
                f.write(f"#### `{Path(path).name}`\n\n")
                
                if info['classes']:
                    f.write("**Classes:**\n")
                    for cls
 in info['classes']:
                        f.write(f"- `{cls}`\n")
                    f.write("\n")
                
                if info['functions']:
                    f.write("**Functions:**\n")
                    for func in info['functions']:
                        f.write(f"- `{func}()`\n")
                    f.write("\n")
                
                if info['dependencies']:
                    f.write("**Dependencies:**\n")
                    for dep in sorted(info['dependencies']):
                        f.write(f"- `{dep}`\n")
                    f.write("\n")
        
        # Dependency graph
        f.write("## Dependency Graph\n\n")
        f.write("```mermaid\n")
        f.write("graph TD\n")
        for path, info in modules.items():
            module_name = Path(path).stem
            for dep in info['dependencies']:
                f.write(f"  {module_name} --> {dep}\n")
        f.write("```\n")

if __name__ == '__main__':
    generate_map()
    pri
startswith(('django', 'flask', 'fastapi')):
                    deps.add(node.module.split('.')[0])
    
    return deps

def topological_sort(modules):
    """Sort modules by dependency order."""
    # Build dependency graph
    graph = {}
    in_degree = defaultdict(int)
    
    for module, deps in modules.items():
        graph[module] = deps
        for dep in deps:
            in_degree[dep] += 1
    
    # Find modules with no dependencies
    queue = [m for m in graph if in_degree[m] == 0]
    result = []
    
    while queue:
        module = queue.pop(0)
        result.append(module)
        
        for dep in graph.get(module, []):
            in_degree[dep] -= 1
            if in_degree[dep] == 0:
                queue.append(dep)
    
    return result

def main():
    """Analyze and print dependency order."""
    modules = {}
    
    for py_file in Path('.').rglob('*.py'):
        if '__pycache__' in str(py_file):
            continue
        
        module_name = str(
py_file).replace('/', '.').replace('.py', '')
        deps = get_dependencies(py_file)
        modules[module_name] = deps
    
    order = topological_sort(modules)
    
    print("üìä Module Build Order (Least Dependent First):\n")
    for i, module in enumerate(order, 1):
        deps = modules.get(module, set())
        print(f"{i:3d}. {module}")
        if deps:
            print(f"     Dependencies: {', '.join(sorted(deps))}")
    
    print(f"\n‚úÖ Total modules: {len(order)}")
    print(f"‚úÖ Start with: {order[0] if order else 'None'}")

if __name__ == '__main__':
    main()
```

**Usage:**
```bash
python scripts/analyze_dependencies.py
```

### 49.4 Reusability Guidelines

**Before Creating New Code:**
1. ‚úÖ Search existing modules
2. ‚úÖ Check function reference
3. ‚úÖ Review module map
4. ‚úÖ Analyze dependencies
5. ‚úÖ Reuse if possible
6. ‚úÖ Extend if needed
7. ‚úÖ Create only if necessary

**When Reusing:**
- Import, don't copy
- Extend via inheritance
- Compose via delegation
- Document 
functions
- Extract class into separate file
- Split file into multiple files
- Create submodules

### 51.2 Single Responsibility Principle (SRP)

**Each function/class should do ONE thing.**

**Bad Example:**
```python
def process_order(order_data):
    # Validates, calculates, saves, sends email - TOO MUCH!
    if not order_data.get('customer_id'):
        raise ValueError("Missing customer")
    
    total = sum(item['price'] * item['qty'] for item in order_data['items'])
    tax = total * 0.15
    final_total = total + tax
    
    order = Order.objects.create(
        customer_id=order_data['customer_id'],
        total=final_total
    )
    
    send_email(order.customer.email, f"Order {order.id} confirmed")
    
    return order
```

**Good Example:**
```python
def validate_order_data(order_data: Dict) -> None:
    """Validate order data."""
    if not order_data.get('customer_id'):
        raise ValueError("Missing customer")

def calculate_order_total(items: List[Dict]) -> Dec
imal:
    """Calculate order total with tax."""
    subtotal = sum(Decimal(str(item['price'])) * item['qty'] for item in items)
    tax = subtotal * Decimal('0.15')
    return subtotal + tax

def create_order(customer_id: int, total: Decimal) -> Order:
    """Create order in database."""
    return Order.objects.create(customer_id=customer_id, total=total)

def send_order_confirmation(order: Order) -> None:
    """Send order confirmation email."""
    send_email(order.customer.email, f"Order {order.id} confirmed")

def process_order(order_data: Dict) -> Order:
    """Process complete order workflow."""
    validate_order_data(order_data)
    total = calculate_order_total(order_data['items'])
    order = create_order(order_data['customer_id'], total)
    send_order_confirmation(order)
    return order
```

### 51.3 DRY (Don't Repeat Yourself)

**If code appears 3+ times, extract it.**

**Bad Example:**
```python
# In multiple files
def view1(request):
    if not request.user.is_authenti
cated:
        return JsonResponse({'error': 'Unauthorized'}, status=401)
    # ...

def view2(request):
    if not request.user.is_authenticated:
        return JsonResponse({'error': 'Unauthorized'}, status=401)
    # ...
```

**Good Example:**
```python
# utils/auth.py
def require_auth(view_func):
    """Decorator to require authentication."""
    @wraps(view_func)
    def wrapper(request, *args, **kwargs):
        if not request.user.is_authenticated:
            return JsonResponse({'error': 'Unauthorized'}, status=401)
        return view_func(request, *args, **kwargs)
    return wrapper

# views.py
@require_auth
def view1(request):
    # ...

@require_auth
def view2(request):
    # ...
```

### 51.4 Refactoring Large Files

**Script:** `scripts/suggest_refactoring.py`
```python
#!/usr/bin/env python3
"""Suggest refactoring for large files/functions."""

import ast
from pathlib import Path

def analyze_file(file_path):
    """Analyze file for refactoring opportunities."""
    wit
h open(file_path) as f:
        content = f.read()
        lines = content.split('\n')
    
    try:
        tree = ast.parse(content)
    except SyntaxError:
        return None
    
    issues = []
    
    # Check file length
    if len(lines) > 500:
        issues.append(f"File too long: {len(lines)} lines (max 500)")
    
    # Check function lengths
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            func_lines = node.end_lineno - node.lineno
            if func_lines > 50:
                issues.append(
                    f"Function '{node.name}' too long: {func_lines} lines (max 50)"
                )
        
        elif isinstance(node, ast.ClassDef):
            class_lines = node.end_lineno - node.lineno
            if class_lines > 300:
                issues.append(
                    f"Class '{node.name}' too long: {class_lines} lines (max 300)"
                )
    
    return issues

def main():
    """Check all Python files.""
"
    all_issues = {}
    
    for py_file in Path('.').rglob('*.py'):
        if '__pycache__' in str(py_file):
            continue
        
        issues = analyze_file(py_file)
        if issues:
            all_issues[str(py_file)] = issues
    
    if all_issues:
        print("üîß Refactoring Suggestions:\n")
        for file_path, issues in all_issues.items():
            print(f"üìÑ {file_path}")
            for issue in issues:
                print(f"   ‚ö†Ô∏è  {issue}")
            print()
        
        print(f"Total files needing refactoring: {len(all_issues)}")
    else:
        print("‚úÖ All files are well-modularized!")

if __name__ == '__main__':
    main()
```

**Usage:**
```bash
python scripts/suggest_refactoring.py
```

---

## 52. Enhanced File Header Policy

### 52.1 Mandatory File Header

**Every file MUST start with:**

**Python:**
```python
"""
File: path/to/file.py
Module: module_name
Created: YYYY-MM-DD
Last Modified: YYYY-MM-DD
Author: author_name
Description: Br
k Python file header."""
    with open(file_path) as f:
        content = f.read(500)  # First 500 chars
    
    if not content.startswith('"""'):
        return False, "Missing docstring header"
    
    for field in REQUIRED_FIELDS:
        if field not in content:
            return False, f"Missing field: {field}"
    
    return True, "OK"

def check_ts_header(file_path):
    """Check TypeScript/JavaScript file header."""
    with open(file_path) as f:
        content = f.read(500)
    
    if not content.startswith('/**'):
        return False, "Missing JSDoc header"
    
    for field in REQUIRED_FIELDS:
        if field not in content:
            return False, f"Missing field: {field}"
    
    return True, "OK"

def main():
    """Check all files."""
    issues = []
    
    for file_path in Path('.').rglob('*'):
        if file_path.suffix == '.py' and '__pycache__' not in str(file_path):
            ok, msg = check_python_header(file_path)
            if not ok:
          
      issues.append(f"{file_path}: {msg}")
        
        elif file_path.suffix in ('.ts', '.tsx', '.js', '.jsx'):
            ok, msg = check_ts_header(file_path)
            if not ok:
                issues.append(f"{file_path}: {msg}")
    
    if issues:
        print("‚ùå File header issues found:\n")
        for issue in issues:
            print(f"  {issue}")
        sys.exit(1)
    
    print("‚úÖ All file headers are correct")

if __name__ == '__main__':
    main()
```

### 52.3 Auto-generate Headers

**Script:** `scripts/add_file_headers.py`
```python
#!/usr/bin/env python3
"""Add headers to files missing them."""

from pathlib import Path
from datetime import date

PYTHON_TEMPLATE = '''"""
File: {path}
Module: {module}
Created: {date}
Last Modified: {date}
Author: {author}
Description: TODO: Add description

Dependencies:
- TODO: List dependencies

Related Files:
- TODO: List related files
"""

'''

def add_python_header(file_path, author="Team"):
    """Add header to Python 
file."""
    with open(file_path) as f:
        content = f.read()
    
    if content.startswith('"""'):
        print(f"‚è≠Ô∏è  {file_path} already has header")
        return
    
    module = str(file_path).replace('/', '.').replace('.py', '')
    header = PYTHON_TEMPLATE.format(
        path=file_path,
        module=module,
        date=date.today().isoformat(),
        author=author
    )
    
    with open(file_path, 'w') as f:
        f.write(header + content)
    
    print(f"‚úÖ Added header to {file_path}")

def main():
    """Add headers to all Python files."""
    for py_file in Path('.').rglob('*.py'):
        if '__pycache__' not in str(py_file):
            add_python_header(py_file)

if __name__ == '__main__':
    main()
```


---

## 53. Frontend/Backend Testing Strategy

### 53.1 Backend Testing (Python)

**Tools:**
```bash
pip install pytest pytest-cov pytest-django pytest-mock
pip install flake8 autopep8 pylint mypy
```

**Test Structure:**
```
tests/
‚îú‚îÄ‚îÄ unit/         
f):
        """Create OrderService instance."""
        return OrderService()
    
    @pytest.fixture
    def sample_order_data(self):
        """Sample order data."""
        return {
            'customer_id': 1,
            'items': [
                {'price': '10.00', 'qty': 2},
                {'price': '5.00', 'qty': 3}
            ]
        }
    
    def test_calculate_total_success(self, order_service, sample_order_data):
        """Test successful total calculation."""
        total = order_service.calculate_total(sample_order_data['items'])
        expected = Decimal('35.00') * Decimal('1.15')  # With 15% tax
        assert total == expected
    
    def test_calculate_total_empty_items(self, order_service):
        """Test calculation with empty items."""
        with pytest.raises(ValueError, match="Items list cannot be empty"):
            order_service.calculate_total([])
    
    @patch('services.order_service.Order.objects.create')
    def test_create_order(self, mock
-manager

# Playwright
pip install playwright
playwright install
```

**Test Structure:**
```
tests/frontend/
‚îú‚îÄ‚îÄ test_login.py
‚îú‚îÄ‚îÄ test_dashboard.py
‚îú‚îÄ‚îÄ test_orders.py
‚îî‚îÄ‚îÄ conftest.py
```

**Playwright Example:**
```python
"""
File: tests/frontend/test_login.py
Module: tests.frontend.test_login
Created: 2025-01-15
Author: Team
Description: Frontend tests for login functionality
"""

import pytest
from playwright.sync_api import Page, expect

@pytest.fixture(scope="function")
def page(browser):
    """Create new page for each test."""
    page = browser.new_page()
    yield page
    page.close()

def test_login_success(page: Page):
    """Test successful login."""
    # Navigate
    page.goto("http://{HOST}:{FRONTEND_PORT}/login")
    
    # Fill form
    page.fill('input[name="username"]', 'testuser')
    page.fill('input[name="password"]', 'testpass123')
    
    # Submit
    page.click('button[type="submit"]')
    
    # Verify redirect
    expect(page).to_have_url("http://{HOST}:{F
RONTEND_PORT}/dashboard")
    
    # Verify welcome message
    expect(page.locator('text=Welcome, testuser')).to_be_visible()

def test_login_invalid_credentials(page: Page):
    """Test login with invalid credentials."""
    page.goto("http://{HOST}:{FRONTEND_PORT}/login")
    
    page.fill('input[name="username"]', 'invalid')
    page.fill('input[name="password"]', 'wrong')
    page.click('button[type="submit"]')
    
    # Should show error
    expect(page.locator('text=Invalid credentials')).to_be_visible()
    
    # Should stay on login page
    expect(page).to_have_url("http://{HOST}:{FRONTEND_PORT}/login")

def test_login_validation(page: Page):
    """Test form validation."""
    page.goto("http://{HOST}:{FRONTEND_PORT}/login")
    
    # Try to submit empty form
    page.click('button[type="submit"]')
    
    # Should show validation errors
    expect(page.locator('text=Username is required')).to_be_visible()
    expect(page.locator('text=Password is required')).to_be_visi
ble()
```

**Selenium Example:**
```python
"""
File: tests/frontend/test_dashboard_selenium.py
Module: tests.frontend.test_dashboard_selenium
Created: 2025-01-15
Author: Team
Description: Selenium tests for dashboard
"""

import pytest
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

@pytest.fixture
def driver():
    """Create WebDriver instance."""
    driver = webdriver.Chrome()
    driver.implicitly_wait(10)
    yield driver
    driver.quit()

def test_dashboard_loads(driver):
    """Test dashboard page loads correctly."""
    driver.get("http://{HOST}:{FRONTEND_PORT}/dashboard")
    
    # Wait for page load
    WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CLASS_NAME, "dashboard"))
    )
    
    # Check title
    assert "Dashboard" in driver.title
    
    # Check key elements
    assert driver.find_eleme
nt(By.ID, "user-menu")
    assert driver.find_element(By.CLASS_NAME, "stats-widget")

def test_dashboard_navigation(driver):
    """Test navigation from dashboard."""
    driver.get("http://{HOST}:{FRONTEND_PORT}/dashboard")
    
    # Click on Orders link
    orders_link = driver.find_element(By.LINK_TEXT, "Orders")
    orders_link.click()
    
    # Should navigate to orders page
    WebDriverWait(driver, 10).until(
        EC.url_contains("/orders")
    )
    
    assert "/orders" in driver.current_url
```

**Running Frontend Tests:**
```bash
# Playwright
pytest tests/frontend/ --headed  # With browser UI
pytest tests/frontend/ --browser=firefox

# Selenium
pytest tests/frontend/test_dashboard_selenium.py
```

### 53.3 Integration Tests

**Example:**
```python
"""
File: tests/integration/test_order_api.py
Module: tests.integration.test_order_api
Created: 2025-01-15
Author: Team
Description: Integration tests for order API
"""

import pytest
from django.test import Client
from decima
l import Decimal
from models import Order, Customer

@pytest.fixture
def client():
    """Create test client."""
    return Client()

@pytest.fixture
def customer(db):
    """Create test customer."""
    return Customer.objects.create(
        name="Test Customer",
        email="test@example.com"
    )

@pytest.mark.django_db
def test_create_order_api(client, customer):
    """Test order creation via API."""
    data = {
        'customer_id': customer.id,
        'items': [
            {'product_id': 1, 'quantity': 2, 'price': '10.00'},
            {'product_id': 2, 'quantity': 1, 'price': '15.00'}
        ]
    }
    
    response = client.post('/api/orders/', data, content_type='application/json')
    
    assert response.status_code == 201
    assert 'id' in response.json()
    
    # Verify in database
    order = Order.objects.get(id=response.json()['id'])
    assert order.customer == customer
    assert order.total == Decimal('40.25')  # (20 + 15) * 1.15 tax
```

### 53.4 E2E T
ests

**Example:**
```python
"""
File: tests/e2e/test_order_workflow.py
Module: tests.e2e.test_order_workflow
Created: 2025-01-15
Author: Team
Description: End-to-end test for complete order workflow
"""

import pytest
from playwright.sync_api import Page, expect

def test_complete_order_workflow(page: Page):
    """Test complete order creation workflow."""
    # 1. Login
    page.goto("http://{HOST}:{FRONTEND_PORT}/login")
    page.fill('input[name="username"]', 'testuser')
    page.fill('input[name="password"]', 'testpass123')
    page.click('button[type="submit"]')
    expect(page).to_have_url("http://{HOST}:{FRONTEND_PORT}/dashboard")
    
    # 2. Navigate to orders
    page.click('text=Orders')
    expect(page).to_have_url("http://{HOST}:{FRONTEND_PORT}/orders")
    
    # 3. Create new order
    page.click('button:has-text("New Order")')
    expect(page.locator('h1:has-text("Create Order")')).to_be_visible()
    
    # 4. Fill order form
    page.select_option('select[name="cust
omer"]', label='Test Customer')
    page.click('button:has-text("Add Item")')
    page.select_option('select[name="items[0].product"]', label='Product A')
    page.fill('input[name="items[0].quantity"]', '2')
    
    # 5. Submit order
    page.click('button[type="submit"]:has-text("Create Order")')
    
    # 6. Verify success
    expect(page.locator('text=Order created successfully')).to_be_visible()
    expect(page).to_have_url("http://{HOST}:{FRONTEND_PORT}/orders")
    
    # 7. Verify order appears in list
    expect(page.locator('table tbody tr').first).to_contain_text('Test Customer')
```

---

## 54. Module Quality Standards

### 54.1 Follow 'sales' Module Standards

**The 'sales' module is the gold standard. All modules should match its quality.**

**Key Characteristics:**
1. **Professional Organization**
   - Separate folders for models, views, services, tests
   - Clear separation of concerns
   - Logical file structure

2. **Advanced Models**
   - Comprehensive relationshi
 ŸÑŸÑŸÜŸÖŸàÿ∞ÿ¨."""
        return f"{self.code} - {self.name}"
    
    def confirm(self):
        """
        ÿ™ÿ£ŸÉŸäÿØ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨.
        
        ŸäŸÇŸàŸÖ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿßŸÑÿ≠ÿßŸÑÿ© ÿ•ŸÑŸâ ŸÖÿ§ŸÉÿØ Ÿàÿ≠ŸÅÿ∏ ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ™ÿ£ŸÉŸäÿØ.
        
        Raises:
            ValueError: ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ŸÑŸäÿ≥ ŸÅŸä ÿ≠ÿßŸÑÿ© ŸÖÿ≥ŸàÿØÿ©
        """
        if self.state != self.STATE_DRAFT:
            raise ValueError("ŸÑÿß ŸäŸÖŸÉŸÜ ÿ™ÿ£ŸÉŸäÿØ ŸÜŸÖŸàÿ∞ÿ¨ ÿ∫Ÿäÿ± ŸÖÿ≥ŸàÿØÿ©")
        
        from django.utils import timezone
        self.state = self.STATE_CONFIRMED
        self.confirmed_at = timezone.now()
        self.save()
    
    def cancel(self):
        """
        ÿ•ŸÑÿ∫ÿßÿ° ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨.
        
        ŸäŸÇŸàŸÖ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿßŸÑÿ≠ÿßŸÑÿ© ÿ•ŸÑŸâ ŸÖŸÑÿ∫Ÿä.
        
        Raises:
            ValueError: ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ŸÖŸÑÿ∫Ÿä ÿ®ÿßŸÑŸÅÿπŸÑ
        """
        if self.state == self.STATE_CANCELLED:
            raise ValueError("ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ŸÖŸÑÿ∫Ÿä ÿ®ÿßŸÑŸÅÿπŸÑ")
        
        self.state = self.STATE_CANCELLED
        self.save()
    
    def compute_total(self):
        """
        ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿ•ÿ¨ŸÖÿßŸÑŸä.
        
        ŸäŸÇŸàŸÖ ÿ®
stants and definitions

Dependencies: None
"""

from decimal import Decimal

# Application
APP_NAME = "{YOUR_PROJECT_NAME}"
APP_VERSION = "1.0.0"
APP_DESCRIPTION = "Enterprise Resource Planning System"

# Ports (SINGLE SOURCE OF TRUTH)
BACKEND_PORT = 8000
FRONTEND_PORT = 3000
API_PORT = 8000

# URLs
BACKEND_URL = f"http://{HOST}:{BACKEND_PORT}"
FRONTEND_URL = f"http://{HOST}:{FRONTEND_PORT}"
API_BASE_URL = f"{BACKEND_URL}/api"

# Database
DEFAULT_PAGE_SIZE = 20
MAX_PAGE_SIZE = 100

# Business Rules
DEFAULT_TAX_RATE = Decimal('0.15')  # 15%
DEFAULT_CURRENCY = 'SAR'
DEFAULT_LANGUAGE = 'ar'

# File Upload
MAX_UPLOAD_SIZE = 5 * 1024 * 1024  # 5MB
ALLOWED_IMAGE_TYPES = ['image/jpeg', 'image/png', 'image/gif']
ALLOWED_DOCUMENT_TYPES = ['application/pdf', 'application/msword']

# Validation
MIN_PASSWORD_LENGTH = 8
MAX_USERNAME_LENGTH = 50
EMAIL_REGEX = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'

# States
STATE_DRAFT = 'draft'
STATE_CONFIRMED = 'confirmed'
STATE_CANCELLED = 'cancelled
'
STATE_DONE = 'done'

COMMON_STATES = [
    (STATE_DRAFT, 'ŸÖÿ≥ŸàÿØÿ©'),
    (STATE_CONFIRMED, 'ŸÖÿ§ŸÉÿØ'),
    (STATE_CANCELLED, 'ŸÖŸÑÿ∫Ÿä'),
    (STATE_DONE, 'ŸÖŸÜÿ™ŸáŸä'),
]

# Permissions
PERM_VIEW = 'view'
PERM_CREATE = 'create'
PERM_EDIT = 'edit'
PERM_DELETE = 'delete'
PERM_ADMIN = 'admin'

ALL_PERMISSIONS = [PERM_VIEW, PERM_CREATE, PERM_EDIT, PERM_DELETE, PERM_ADMIN]

# Error Messages
ERROR_REQUIRED_FIELD = "Ÿáÿ∞ÿß ÿßŸÑÿ≠ŸÇŸÑ ŸÖÿ∑ŸÑŸàÿ®"
ERROR_INVALID_EMAIL = "ÿßŸÑÿ®ÿ±ŸäÿØ ÿßŸÑÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸä ÿ∫Ÿäÿ± ÿµÿ≠Ÿäÿ≠"
ERROR_PASSWORD_TOO_SHORT = f"ŸÉŸÑŸÖÿ© ÿßŸÑŸÖÿ±Ÿàÿ± Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ŸÉŸàŸÜ {MIN_PASSWORD_LENGTH} ÿ£ÿ≠ÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿ£ŸÇŸÑ"
ERROR_UNAUTHORIZED = "ÿ∫Ÿäÿ± ŸÖÿµÿ±ÿ≠"
ERROR_NOT_FOUND = "ÿ∫Ÿäÿ± ŸÖŸàÿ¨ŸàÿØ"
ERROR_INTERNAL_SERVER = "ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑÿÆÿßÿØŸÖ"

# Success Messages
SUCCESS_CREATED = "ÿ™ŸÖ ÿßŸÑÿ•ŸÜÿ¥ÿßÿ° ÿ®ŸÜÿ¨ÿßÿ≠"
SUCCESS_UPDATED = "ÿ™ŸÖ ÿßŸÑÿ™ÿ≠ÿØŸäÿ´ ÿ®ŸÜÿ¨ÿßÿ≠"
SUCCESS_DELETED = "ÿ™ŸÖ ÿßŸÑÿ≠ÿ∞ŸÅ ÿ®ŸÜÿ¨ÿßÿ≠"
SUCCESS_CONFIRMED = "ÿ™ŸÖ ÿßŸÑÿ™ÿ£ŸÉŸäÿØ ÿ®ŸÜÿ¨ÿßÿ≠"
```

### 55.2 Type Definitions

**Location:** `config/definitions/types.py`

```python
"""
File: config/definitions/types.py
Module: config.definitions.types
Created: 20
ubtotal: Decimal
    tax: Decimal
    total: Decimal
    state: StateType
    created_at: datetime
```

### 55.3 Environment-Specific Configs

**Location:** `config/environments/`

```python
# config/environments/development.py
"""Development environment configuration."""

DEBUG = True
ALLOWED_HOSTS = ['localhost', '127.0.0.1']
DATABASE_URL = 'sqlite:///db.sqlite3'
LOG_LEVEL = 'DEBUG'
SHOW_ERRORS_IN_FRONTEND = True

# config/environments/production.py
"""Production environment configuration."""

DEBUG = False
ALLOWED_HOSTS = ['example.com', 'www.example.com']
DATABASE_URL = 'postgresql://user:pass@localhost/{database_name}'
LOG_LEVEL = 'WARNING'
SHOW_ERRORS_IN_FRONTEND = False
REQUIRE_HTTPS = True
```

### 55.4 Usage

**Import constants:**
```python
from config.constants import (
    BACKEND_PORT,
    DEFAULT_TAX_RATE,
    STATE_CONFIRMED,
    ERROR_REQUIRED_FIELD
)

# Use in code
app.run(port=BACKEND_PORT)
tax = subtotal * DEFAULT_TAX_RATE
if order.state == STATE_CONFIRMED:
    # ...

```

**No magic numbers/strings:**
```python
# ‚ùå BAD
if order.state == 'confirmed':
    tax = total * 0.15

# ‚úÖ GOOD
from config.constants import STATE_CONFIRMED, DEFAULT_TAX_RATE

if order.state == STATE_CONFIRMED:
    tax = total * DEFAULT_TAX_RATE
```


---

## 56. Dependency Management

### 56.1 Using pipreqs

**Install:**
```bash
pip install pipreqs
```

**Generate requirements AFTER finishing modules:**
```bash
# Generate from actual imports
pipreqs . --force

# For specific directory
pipreqs ./module_name --force

# Save to specific file
pipreqs . --savepath requirements-new.txt
```

**Why pipreqs?**
- Only includes actually used packages
- Avoids bloat from `pip freeze`
- Scans imports, not installed packages

### 56.2 Requirements Files Structure

```
requirements/
‚îú‚îÄ‚îÄ base.txt          # Core dependencies (always needed)
‚îú‚îÄ‚îÄ development.txt   # Dev tools (testing, linting)
‚îú‚îÄ‚îÄ production.txt    # Production-only (gunicorn, etc.)
‚îî‚îÄ‚îÄ testing.txt       # Testing-only (pytest, c
use ~= for minor updates
django~=4.2.0  # Allows 4.2.x, not 4.3.0
```

### 56.4 Security Updates

**Check for vulnerabilities:**
```bash
# Install safety
pip install safety

# Check dependencies
safety check

# Check specific file
safety check -r requirements.txt

# Auto-fix (with caution)
safety check --auto-update
```

**Update dependencies:**
```bash
# Check outdated
pip list --outdated

# Update specific package
pip install --upgrade package_name

# Regenerate requirements
pipreqs . --force
```

### 56.5 Workflow

**Development:**
```bash
# Install dev dependencies
pip install -r requirements/development.txt

# Work on code...

# Before committing
pipreqs . --force  # Regenerate base requirements
safety check       # Check security
```

**Production:**
```bash
# Install only production dependencies
pip install -r requirements/production.txt
```

**Testing:**
```bash
# Install test dependencies
pip install -r requirements/testing.txt

# Run tests
pytest
```

---

## 57. Design vs Im
                 models.add(node.name)
    
    return models

def load_design_spec(spec_file: str) -> Dict:
    """Load design specification."""
    with open(spec_file) as f:
        return json.load(f)

def analyze_gaps(spec_file: str = 'docs/design_spec.json'):
    """Analyze gaps between design and implementation."""
    print("üîç Analyzing Design vs Implementation Gaps\n")
    
    # Load design spec
    try:
        spec = load_design_spec(spec_file)
    except FileNotFoundError:
        print(f"‚ö†Ô∏è  Design spec not found: {spec_file}")
        print("   Create docs/design_spec.json with your design")
        return
    
    # Find implementation
    api_endpoints = find_api_endpoints()
    frontend_routes = find_frontend_routes()
    db_models = find_database_models()
    
    # Compare
    gaps = []
    
    # Check API endpoints
    if 'api_endpoints' in spec:
        for endpoint in spec['api_endpoints']:
            if endpoint not in api_endpoints:
                gaps.appen
d(f"Missing API endpoint: {endpoint}")
    
    # Check frontend routes
    if 'frontend_routes' in spec:
        for route in spec['frontend_routes']:
            if route not in frontend_routes:
                gaps.append(f"Missing frontend route: {route}")
    
    # Check database models
    if 'models' in spec:
        for model in spec['models']:
            if model not in db_models:
                gaps.append(f"Missing database model: {model}")
    
    # Report
    if gaps:
        print("‚ùå Gaps Found:\n")
        for gap in gaps:
            print(f"  ‚Ä¢ {gap}")
        print(f"\nTotal gaps: {len(gaps)}")
    else:
        print("‚úÖ No gaps found! Design matches implementation.")
    
    # Summary
    print("\nüìä Summary:")
    print(f"  API Endpoints: {len(api_endpoints)} implemented")
    print(f"  Frontend Routes: {len(frontend_routes)} implemented")
    print(f"  Database Models: {len(db_models)} implemented")

if __name__ == '__main__':
    analyze_gaps()
```

### 57.3 D
esign Specification Template

**Location:** `docs/design_spec.json`

```json
{
  "module_name": "orders",
  "version": "1.0.0",
  "api_endpoints": [
    "/api/orders/",
    "/api/orders/<id>/",
    "/api/orders/<id>/confirm/",
    "/api/orders/<id>/cancel/"
  ],
  "frontend_routes": [
    "/orders",
    "/orders/new",
    "/orders/:id",
    "/orders/:id/edit"
  ],
  "models": [
    "Order",
    "OrderItem",
    "Customer"
  ],
  "relationships": [
    {
      "from": "Order",
      "to": "Customer",
      "type": "ForeignKey"
    },
    {
      "from": "OrderItem",
      "to": "Order",
      "type": "ForeignKey"
    }
  ],
  "features": [
    "Create order",
    "Edit order",
    "Confirm order",
    "Cancel order",
    "View order list",
    "Search orders",
    "Filter by status",
    "Export to PDF"
  ]
}
```

### 57.4 Integration Testing

**Test that design features work end-to-end:**

```python
"""
File: tests/integration/test_order_integration.py
Module: tests.integration.test_or
der_integration
Created: 2025-01-15
Author: Team
Description: Integration tests for complete order workflow
"""

import pytest
from django.test import Client
from models import Order, Customer

@pytest.mark.django_db
class TestOrderIntegration:
    """Test complete order integration."""
    
    def test_order_workflow(self, client: Client):
        """Test complete order workflow from design spec."""
        # 1. Create customer
        customer = Customer.objects.create(name="Test", email="test@example.com")
        
        # 2. Create order via API
        response = client.post('/api/orders/', {
            'customer_id': customer.id,
            'items': [{'product_id': 1, 'quantity': 2}]
        }, content_type='application/json')
        assert response.status_code == 201
        order_id = response.json()['id']
        
        # 3. Retrieve order
        response = client.get(f'/api/orders/{order_id}/')
        assert response.status_code == 200
        assert response.json()
['state'] == 'draft'
        
        # 4. Confirm order
        response = client.post(f'/api/orders/{order_id}/confirm/')
        assert response.status_code == 200
        
        # 5. Verify state changed
        order = Order.objects.get(id=order_id)
        assert order.state == 'confirmed'
        
        # 6. Cancel order
        response = client.post(f'/api/orders/{order_id}/cancel/')
        assert response.status_code == 200
        
        # 7. Verify cancelled
        order.refresh_from_db()
        assert order.state == 'cancelled'
```

---

## Summary: v3.4.0 Additions

### New Sections (46-57)

**üî¥ Critical (46-49):**
- 46. Comprehensive Verification System
- 47. Function Reference System
- 48. Error Tracking System
- 49. Module Discovery & Reuse

**üü° High Priority (50-55):**
- 50. Task Management System
- 51. Code Modularization
- 52. Enhanced File Header Policy
- 53. Frontend/Backend Testing Strategy
- 54. Module Quality Standards
- 55. Constants & Definitions Reg
e updated automatically
module_name = "models.user_unified"
mod = __import__(module_name)
```
**Action:** Manual review required

**2. String References**
```python
# Cannot be updated automatically
MODELS = ["models.user_unified", "models.product"]
```
**Action:** Manual review required

**3. Comments**
```python
# See models.user_unified for details
```
**Action:** Update comments manually or with separate tool

### 61.7 Integration with Smart Merge

```bash
# Smart merge automatically calls update_imports
python scripts/smart_merge.py

# Internally calls:
# python scripts/update_imports.py old_module new_module
```

### 61.8 CI/CD Integration

```yaml
- name: Verify Imports
  run: |
    python -c "import sys; import importlib; \
    [importlib.import_module(m) for m in sys.argv[1:]]" \
    $(find . -name "*.py" -exec grep -l "^import\|^from" {} \;)
```

### 61.9 Post-Update Checklist

- [ ] All imports updated
- [ ] No syntax errors
- [ ] No import errors
- [ ] All tests pass
- [ ] 
ages:
    - core: Core functionality
    - models: Data models
    - services: Business logic
    - api: API endpoints
    - utils: Utility functions
"""

# Import commonly used items from subpackages
from .core import App, Config
from .models import User, Session
from .services import UserService, AuthService

# Version info
from .version import __version__, __version_info__

# Public API
__all__ = [
    # Core
    'App',
    'Config',
    # Models
    'User',
    'Session',
    # Services
    'UserService',
    'AuthService',
    # Version
    '__version__',
    '__version_info__',
]

# Subpackage references (for documentation)
__subpackages__ = [
    'core',
    'models',
    'services',
    'api',
    'utils',
]
```

### Pattern 6: Plugin System

```python
# plugins/__init__.py
"""
Plugin system with dynamic discovery
"""

import importlib
import pkgutil
from typing import Dict, Type

# Plugin registry
_plugins: Dict[str, Type] = {}


def discover_plugins():
    """Automatically di
scover and register plugins"""
    package = __package__
    for _, name, _ in pkgutil.iter_modules([package.replace('.', '/')]):
        module = importlib.import_module(f'{package}.{name}')
        if hasattr(module, 'register_plugin'):
            plugin = module.register_plugin()
            _plugins[plugin.name] = plugin


def get_plugin(name: str):
    """Get plugin by name"""
    if not _plugins:
        discover_plugins()
    return _plugins.get(name)


__all__ = [
    'discover_plugins',
    'get_plugin',
]
```

### Pattern 7: Conditional Imports

```python
# compat/__init__.py
"""
Compatibility layer for different Python versions
"""

import sys

# Version-specific imports
if sys.version_info >= (3, 10):
    from typing import TypeAlias
else:
    from typing_extensions import TypeAlias

# Platform-specific imports
if sys.platform == 'win32':
    from .windows import WindowsSpecific as PlatformSpecific
else:
    from .unix import UnixSpecific as PlatformSpecific

__all__ = [
 
m typing import TYPE_CHECKING, List

if TYPE_CHECKING:
    from .post import Post

class User:
    def get_posts(self) -> List['Post']:  # String annotation
        from .post import Post
        return Post.query.filter_by(user_id=self.id).all()

# ‚úÖ SOLUTION 3: Restructure - create base module
# models/base.py - common base classes
# models/user.py - imports from base
# models/post.py - imports from base
# models/__init__.py - imports both
```

### Problem 2: Import Order Issues

```python
# ‚úÖ CORRECT ORDER in __init__.py

# 1. Standard library imports
import os
import sys
from typing import Dict, List

# 2. Third-party imports
import requests
from sqlalchemy import create_engine

# 3. Local imports - order matters!
from .exceptions import ConfigError  # No dependencies
from .constants import DEFAULT_CONFIG  # Uses exceptions
from .validators import validate  # Uses constants and exceptions
from .config import Config  # Uses all above

# 4. __all__ definition
__all__ = [
    'Config'
,
    'ConfigError',
    'DEFAULT_CONFIG',
    'validate',
]
```

### Problem 3: Namespace Pollution

```python
# ‚ùå BAD: Pollutes namespace
# utils/__init__.py
from .helpers import *
from .validators import *
from .formatters import *
# Now namespace has 50+ items!

# ‚úÖ GOOD: Clean namespace
# utils/__init__.py
"""Utilities package - import submodules as needed"""

# Only export the most commonly used
from .helpers import format_date, parse_json
from .validators import is_valid_email

__all__ = [
    'format_date',
    'parse_json',
    'is_valid_email',
    # For less common items, use: from utils.helpers import ...
]

# Make submodules accessible
from . import helpers
from . import validators
from . import formatters
```

---

## 5. ÿ£ŸÖÿ´ŸÑÿ© ÿ≠ÿ≥ÿ® ÿ≠ÿ¨ŸÖ ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ / Examples by Project Size

### Small Project (< 10 modules)

```python
# mysmallapp/__init__.py
"""Small application - simple structure"""

from .main import run_app
from .config import Config
from .utils import helper_function

__v


import mypackage


def test_public_api_available():
    """Test that public API is accessible"""
    assert hasattr(mypackage, 'PublicClass')
    assert hasattr(mypackage, 'public_function')


def test_private_not_exposed():
    """Test that private items are not in public API"""
    assert not hasattr(mypackage, '_private_helper')


def test_all_defined():
    """Test that __all__ is properly defined"""
    assert hasattr(mypackage, '__all__')
    assert isinstance(mypackage.__all__, list)
    assert len(mypackage.__all__) > 0


def test_all_items_exist():
    """Test that all items in __all__ actually exist"""
    for item in mypackage.__all__:
        assert hasattr(mypackage, item), f"{item} in __all__ but not found"


def test_version_available():
    """Test that version info is available"""
    assert hasattr(mypackage, '__version__')
    assert isinstance(mypackage.__version__, str)


def test_no_import_side_effects():
    """Test that importing doesn't have side effects"""
 
 ÿ¨ÿØŸäÿØÿ©

### Testing
- [ ] ŸäŸàÿ¨ÿØ tests ŸÑŸÑŸÄ public API
- [ ] tests ÿ™ÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ `__all__`
- [ ] tests ÿ™ÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿπÿØŸÖ Ÿàÿ¨ŸàÿØ side effects

---

## 8. ÿ£ÿØŸàÿßÿ™ ŸÖÿ≥ÿßÿπÿØÿ© / Helper Tools

### Script ŸÑŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ __init__.py

```python
#!/usr/bin/env python3
"""
Script: check_init_py.py
Check __init__.py files for common issues
"""

import ast
import sys
from pathlib import Path


def check_init_file(filepath: Path) -> list[str]:
    """Check __init__.py for issues"""
    issues = []
    
    with open(filepath, 'r') as f:
        content = f.read()
    
    try:
        tree = ast.parse(content)
    except SyntaxError as e:
        return [f"Syntax error: {e}"]
    
    # Check for docstring
    if not ast.get_docstring(tree):
        issues.append("Missing module docstring")
    
    # Check for __all__
    has_all = any(
        isinstance(node, ast.Assign) and
        any(isinstance(t, ast.Name) and t.id == '__all__' for t in node.targets)
        for node in tree.body
    )
    
    # Check for star impor
ts
    has_star_import = any(
        isinstance(node, ast.ImportFrom) and
        any(isinstance(alias, ast.alias) and alias.name == '*' for alias in node.names)
        for node in tree.body
    )
    
    if has_star_import and not has_all:
        issues.append("Star import without __all__ definition")
    
    # Check for heavy initialization
    function_calls = [
        node for node in ast.walk(tree)
        if isinstance(node, ast.Call) and isinstance(node.func, ast.Name)
    ]
    
    if len(function_calls) > 5:
        issues.append(f"Many function calls ({len(function_calls)}) - possible heavy initialization")
    
    return issues


def main():
    """Check all __init__.py files in project"""
    project_root = Path.cwd()
    init_files = list(project_root.rglob('__init__.py'))
    
    print(f"Checking {len(init_files)} __init__.py files...\n")
    
    total_issues = 0
    for init_file in init_files:
        issues = check_init_file(init_file)
        if issues:
    
        print(f"‚ùå {init_file.relative_to(project_root)}")
            for issue in issues:
                print(f"   - {issue}")
            print()
            total_issues += len(issues)
    
    if total_issues == 0:
        print("‚úÖ All __init__.py files look good!")
    else:
        print(f"Found {total_issues} issues in {len(init_files)} files")
        sys.exit(1)


if __name__ == '__main__':
    main()
```

---

## 9. ÿßŸÑŸÇŸàÿßÿπÿØ ÿßŸÑÿ∞Ÿáÿ®Ÿäÿ© / Golden Rules

### ü•á Rule 1: Keep It Simple
**ÿ£ÿ®ÿ≥ÿ∑ __init__.py ŸáŸà ÿßŸÑÿ£ŸÅÿ∂ŸÑ**
- ŸÑÿß ÿ™ÿ∂ÿπ logic ŸÖÿπŸÇÿØ
- ŸÑÿß ÿ™ŸÇŸÖ ÿ®ŸÄ initialization ÿ´ŸÇŸäŸÑ
- ÿßÿ¨ÿπŸÑŸá ÿ≥ŸáŸÑ ÿßŸÑŸÇÿ±ÿßÿ°ÿ© ŸàÿßŸÑŸÅŸáŸÖ

### ü•à Rule 2: Be Explicit
**ÿßŸÑŸàÿ∂Ÿàÿ≠ ÿ£ŸÅÿ∂ŸÑ ŸÖŸÜ ÿßŸÑÿ•Ÿäÿ¨ÿßÿ≤**
- ÿßÿ≥ÿ™ÿÆÿØŸÖ explicit imports
- ÿ≠ÿØÿØ `__all__` ÿ®Ÿàÿ∂Ÿàÿ≠
- Ÿàÿ´ŸÇ ÿßŸÑŸÇÿ±ÿßÿ±ÿßÿ™ ÿßŸÑŸÖŸáŸÖÿ©

### ü•â Rule 3: Think About Users
**ŸÅŸÉÿ± ŸÅŸä ŸÖŸÜ ÿ≥Ÿäÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑŸÄ package**
- ÿßÿ¨ÿπŸÑ ÿßŸÑŸÄ public API Ÿàÿßÿ∂ÿ≠
- ÿ£ÿÆŸÅŸê ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ ÿßŸÑÿØÿßÿÆŸÑŸäÿ©
- ŸàŸÅÿ± Ÿàÿßÿ¨Ÿáÿ© ÿ≥ŸáŸÑÿ© ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ

### üèÖ Rule 4: Performance Matters
**ŸÑÿß ÿ™ÿ®ÿ∑ÿ¶ ÿßŸÑŸÄ import time**
- ÿßÿ≥ÿ™ÿÆÿØŸÖ lazy imports ŸÑŸÑŸÄ heavy modules
- ÿ™ÿ¨ŸÜÿ® ÿßŸÑŸÄ initializatio
lar):
  File 1: src/services/user_service.py (lines 45-62)
  File 2: src/services/admin_service.py (lines 78-95)
  
  Suggestion: Extract to common function in src/utils/auth.py

Duplication #2 (89% similar):
  File 1: src/models/user.py (lines 12-25)
  File 2: src/models/admin.py (lines 15-28)
  
  Suggestion: Create base model in src/models/base.py
```

**ÿßŸÑÿÆŸäÿßÿ±ÿßÿ™:**
```bash
# ÿ™ÿ≠ÿØŸäÿØ ÿ≠ÿØ ÿßŸÑÿ™ÿ¥ÿßÿ®Ÿá
python tools/detect_code_duplication.py . --threshold 0.85

# ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑÿ≠ÿØ ÿßŸÑÿ£ÿØŸÜŸâ ŸÑÿπÿØÿØ ÿßŸÑÿ£ÿ≥ÿ∑ÿ±
python tools/detect_code_duplication.py . --min-lines 10

# ÿ™ÿ¨ÿßŸáŸÑ ŸÖŸÑŸÅÿßÿ™ ŸÖÿπŸäŸÜÿ©
python tools/detect_code_duplication.py . --ignore tests/,migrations/
```

---

### 1.3 smart_merge.py

**ÿßŸÑŸàÿ∏ŸäŸÅÿ©:** ÿØŸÖÿ¨ ÿ∞ŸÉŸä ŸÑŸÑŸÖŸÑŸÅÿßÿ™ ŸÖÿπ ÿ≠ŸÑ ÿßŸÑÿ™ÿπÿßÿ±ÿ∂ÿßÿ™

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```bash
python tools/smart_merge.py --config merge_config.json
```

**ÿßŸÑŸÖŸäÿ≤ÿßÿ™:**
- ‚úÖ ÿØŸÖÿ¨ ÿ™ŸÑŸÇÿßÿ¶Ÿä ŸÑŸÑŸÖŸÑŸÅÿßÿ™
- ‚úÖ ŸÉÿ¥ŸÅ ÿßŸÑÿ™ÿπÿßÿ±ÿ∂ÿßÿ™
- ‚úÖ ÿ≠ŸÑ ÿ∞ŸÉŸä ŸÑŸÑÿ™ÿπÿßÿ±ÿ∂ÿßÿ™
- ‚úÖ ŸÜÿ≥ÿÆ ÿßÿ≠ÿ™Ÿäÿßÿ∑Ÿä ÿ™ŸÑŸÇÿßÿ¶Ÿä
- ‚úÖ Rollback ÿπŸÜÿØ ÿßŸÑŸÅÿ¥ŸÑ

**ŸÖŸÑŸÅ ÿßŸÑÿ™ŸÉŸàŸäŸÜ (merge_config.json):**
```json
{
  "source": "feature_branch/"
,
  "target": "main_branch/",
  "strategy": "smart",
  "backup": true,
  "auto_resolve": true,
  "conflict_resolution": {
    "imports": "merge",
    "functions": "prefer_target",
    "classes": "prefer_source"
  }
}
```

**ŸÖÿ´ÿßŸÑ ÿßŸÑÿ•ÿÆÿ±ÿßÿ¨:**
```
=== Smart Merge Report ===

Files to merge: 15
Conflicts detected: 3
Auto-resolved: 2
Manual intervention needed: 1

‚úÖ Merged successfully:
  - src/models/user.py
  - src/services/auth.py
  - src/utils/helpers.py

‚ö†Ô∏è Conflicts (auto-resolved):
  - src/config/settings.py (imports merged)
  - src/api/routes.py (functions merged)

‚ùå Manual intervention needed:
  - src/core/engine.py (conflicting logic)
    Please review and resolve manually
```

**ÿßŸÑÿÆŸäÿßÿ±ÿßÿ™:**
```bash
# ÿ™ÿ¥ÿ∫ŸäŸÑ ÿ™ÿ¨ÿ±Ÿäÿ®Ÿä (dry run)
python tools/smart_merge.py --config merge_config.json --dry-run

# ÿ™ÿ¨ÿßŸáŸÑ ÿßŸÑŸÜÿ≥ÿÆ ÿßŸÑÿßÿ≠ÿ™Ÿäÿßÿ∑Ÿä
python tools/smart_merge.py --config merge_config.json --no-backup

# Ÿàÿ∂ÿπ ÿ™ŸÅÿßÿπŸÑŸä
python tools/smart_merge.py --config merge_config.json --interactive
```

---

### 1.4 upda
onse     # ÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© ÿÆÿ∑ÿ£ ŸÖŸàÿ≠ÿØÿ©
)
```

#### core.py
**ÿßŸÑÿ™ÿπÿ±ŸäŸÅÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸÑŸÑŸÜŸÖÿßÿ∞ÿ¨:**
```python
from config.definitions import (
    BaseModel,        # ŸÜŸÖŸàÿ∞ÿ¨ ÿ£ÿ≥ÿßÿ≥Ÿä
    TimestampMixin,   # created_at, updated_at
    SoftDeleteMixin,  # deleted_at, is_deleted
    AuditMixin        # created_by, updated_by
)
```

#### custom.py
**ÿ™ÿπÿ±ŸäŸÅÿßÿ™ ŸÖÿÆÿµÿµÿ© ŸÑŸÑŸÖÿ¥ÿ±Ÿàÿπ:**
```python
from config.definitions import (
    ProjectStatus,    # PLANNING, IN_PROGRESS, COMPLETED
    Priority,         # LOW, MEDIUM, HIGH, CRITICAL
    TaskType          # BUG, FEATURE, ENHANCEMENT
)
```

---

## 3. Examples / ÿßŸÑÿ£ŸÖÿ´ŸÑÿ© üí°

### 3.1 simple-api/

**ÿßŸÑŸàÿµŸÅ:** ŸÖÿ´ÿßŸÑ ŸÉÿßŸÖŸÑ ŸÑŸÄ API ÿ®ÿ≥Ÿäÿ∑ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ FastAPI

**ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ:**
```
simple-api/
‚îú‚îÄ‚îÄ main.py              # ŸÜŸÇÿ∑ÿ© ÿßŸÑÿØÿÆŸàŸÑ
‚îú‚îÄ‚îÄ models.py            # ÿßŸÑŸÜŸÖÿßÿ∞ÿ¨
‚îú‚îÄ‚îÄ routes.py            # ÿßŸÑŸÖÿ≥ÿßÿ±ÿßÿ™
‚îú‚îÄ‚îÄ config.py            # ÿßŸÑÿ™ŸÉŸàŸäŸÜ
‚îî‚îÄ‚îÄ README.md            # ÿßŸÑÿØŸÑŸäŸÑ
```

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```bash
cd examples/simple-api/
pip install -r requirements.txt
uvicorn main:app --reload
```

**ÿßŸÑŸÖŸäÿ≤ÿßÿ™:**


    raise AttributeError(f"module has no attribute '{name}'")
```

#### Pattern 3: Plugin System
```python
# ŸÖŸÜ 03_plugin_system/__init__.py
def discover_plugins():
    # Auto-discover plugins
    pass

def get_plugin(name):
    # Get plugin by name
    pass
```

---

## 4. Scripts / ÿßŸÑÿ≥ŸÉÿ±Ÿäÿ®ÿ™ÿßÿ™ üîß

### 4.1 integrate.sh ‚≠ê‚≠ê‚≠ê

**ÿßŸÑŸàÿ∏ŸäŸÅÿ©:** ÿ™ÿ´ÿ®Ÿäÿ™ Global Guidelines ŸÅŸä ŸÖÿ¥ÿ±Ÿàÿπ ŸÇÿßÿ¶ŸÖ

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```bash
# Remote installation
curl -sSL https://raw.githubusercontent.com/hamfarid/global/main/scripts/integrate.sh | bash

# Local installation
./scripts/integrate.sh
```

**ŸÖÿß ŸäŸÅÿπŸÑŸá:**
1. ŸäŸÜÿ¥ÿ¶ `.global/` directory
2. Ÿäÿ≠ŸÖŸÑ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ŸÖŸÜ GitHub
3. Ÿäÿ≠ÿØÿ´ `.gitignore`
4. ŸäŸÜÿ¥ÿ¶ shortcuts
5. Ÿäÿ¨ÿπŸÑ ÿßŸÑÿ≥ŸÉÿ±Ÿäÿ®ÿ™ÿßÿ™ ŸÇÿßÿ®ŸÑÿ© ŸÑŸÑÿ™ŸÜŸÅŸäÿ∞

**ŸÑÿß Ÿäÿ§ÿ´ÿ± ÿπŸÑŸâ:**
- `.git/` directory
- ŸÖŸÑŸÅÿßÿ™ ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ ÿßŸÑŸÖŸàÿ¨ŸàÿØÿ©
- Git history

---

### 4.2 configure.sh

**ÿßŸÑŸàÿ∏ŸäŸÅÿ©:** ÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑŸÖŸÉŸàŸÜÿßÿ™ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```bash
.global/scripts/configure.sh
```

**ÿßŸÑŸÖŸÉŸàŸÜÿßÿ™:**
1. config/definitions
2. tools/
3. templates/
4. examples/
5. scripts/
6.
ŸäŸàÿ∂ÿ≠ ŸÜŸÖÿ∑ ŸÖÿπŸäŸÜ
   - ÿ∑ÿ®ŸÇ ÿßŸÑŸÜŸÖÿ∑ ÿßŸÑŸÖŸÜÿßÿ≥ÿ® ŸÑÿ≠ÿßŸÑÿ™ŸÉ

---

## 8. Integration with AI Tools / ÿßŸÑÿ™ŸÉÿßŸÖŸÑ ŸÖÿπ ÿ£ÿØŸàÿßÿ™ AI

### ŸÖÿπ Augment:

```python
# ŸÅŸä Augmentÿå ŸäŸÖŸÉŸÜŸÉ:
# 1. ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿ®ÿ±ŸàŸÖÿ®ÿ™ ŸÉŸÄ system prompt
# 2. ÿßŸÑÿ•ÿ¥ÿßÿ±ÿ© ŸÑŸÑÿ£ÿØŸàÿßÿ™ ÿπŸÜÿØ ÿßŸÑÿ≠ÿßÿ¨ÿ©
# 3. ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ£ŸÖÿ´ŸÑÿ© ŸÉŸÄ context

# ŸÖÿ´ÿßŸÑ:
augment.load_prompt("GLOBAL_GUIDELINES_v3.7.txt")
augment.add_tool("tools/analyze_dependencies.py")
augment.add_context("examples/simple-api/")
```

### ŸÖÿπ GitHub Copilot:

```python
# ŸÅŸä .github/copilot-instructions.md
# ÿ£ÿ∂ŸÅ:
"""
Use Global Guidelines from:
- Prompt: GLOBAL_GUIDELINES_v3.7.txt
- Tools: tools/
- Examples: examples/
- Templates: templates/
"""
```

### ŸÖÿπ Cursor:

```json
// ŸÅŸä .cursor/settings.json
{
  "cursor.rules": [
    "Follow GLOBAL_GUIDELINES_v3.7.txt",
    "Use tools/ for analysis",
    "Reference examples/ for patterns"
  ]
}
```

---

## 9. Troubleshooting / ÿ≠ŸÑ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ

### Issue 1: ÿßŸÑÿ£ÿØŸàÿßÿ™ ŸÑÿß ÿ™ÿπŸÖŸÑ

```bash
# ÿ™ÿ£ŸÉÿØ ŸÖŸÜ Python version
python --version  # Ÿäÿ¨ÿ® ÿ£ŸÜ ŸäŸÉŸàŸÜ >= 3.8

# ÿ´ÿ®ÿ™ ÿßŸÑŸÖÿ™ÿ∑ŸÑÿ®ÿßÿ™
pip install -r
 requirements.txt

# ÿ¥ÿ∫ŸÑ ŸÖÿπ verbose
python tools/analyze_dependencies.py . --verbose
```

### Issue 2: Templates ŸÑÿß ÿ™ÿπŸÖŸÑ

```bash
# ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿßŸÑÿ®ŸÜŸäÿ©
ls -la templates/config/definitions/

# ÿ™ÿ£ŸÉÿØ ŸÖŸÜ __init__.py
cat templates/config/definitions/__init__.py
```

### Issue 3: Examples ŸÑÿß ÿ™ÿ¥ÿ™ÿ∫ŸÑ

```bash
# ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿßŸÑŸÖÿ™ÿ∑ŸÑÿ®ÿßÿ™
cd examples/simple-api/
pip install -r requirements.txt

# ÿ¥ÿ∫ŸÑ ŸÖÿπ debug
python main.py --debug
```

---

## 10. References / ÿßŸÑŸÖÿ±ÿßÿ¨ÿπ

### ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ©:
- [GLOBAL_GUIDELINES_v3.7.txt](../GLOBAL_GUIDELINES_v3.7.txt)
- [INIT_PY_BEST_PRACTICES.md](../INIT_PY_BEST_PRACTICES.md)
- [OSF_FRAMEWORK.md](../OSF_FRAMEWORK.md)

### Workflows:
- [DEVELOPMENT_FLOW.md](../flows/DEVELOPMENT_FLOW.md)
- [INTEGRATION_FLOW.md](../flows/INTEGRATION_FLOW.md)
- [DEPLOYMENT_FLOW.md](../flows/DEPLOYMENT_FLOW.md)

### Tools Documentation:
- [tools/README.md](../tools/README.md)

### Scripts Documentation:
- [scripts/README.md](../scripts/README.md)

---

## Summary / ÿßŸÑŸÖŸÑÿÆÿµ

ŸÖÿ≥ÿ™ŸàÿØÿπ Global Guidelin
rst time
- When project configuration file doesn't exist

**Questions to Ask:**

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë           PROJECT CONFIGURATION QUESTIONNAIRE                  ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

I need to collect some information about your project to provide 
better assistance. Please answer the following questions:

1. PROJECT PHASE
   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   Are you in Development or Production phase?
   
   Options:
   [D] Development - Active development, testing, debugging
   [P] Production  - Live deployment, production environment
   
   Your choice: ___

2. PROJECT NAME
   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   What is your project/application name?
   
   Example: "MyAwesomeApp", "E-Commerce Platform", "Task Manager"
   
   Project Name: _______________

3. DEPLOYMENT STATUS
   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   Has this project been deployed before?
   
   Options:
   [Y] Yes - Already deployed to production
   [N] No  - First 
time deployment
   
   Your choice: ___

4. PORT CONFIGURATION
   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   
   a) Frontend Port (if applicable):
      Default: 3000
      Your port: _____ (press Enter for default)
   
   b) Backend/API Port:
      Default: 5000
      Your port: _____ (press Enter for default)
   
   c) Database Port:
      Default: 5432 (PostgreSQL) / 3306 (MySQL) / 27017 (MongoDB)
      Your port: _____ (press Enter for default)

5. DATABASE CONFIGURATION
   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   
   a) Database Name:
      Example: "myapp_db", "production_db"
      Database Name: _______________
   
   b) Should I preserve existing database data?
      [Y] Yes - Keep existing data (production mode)
      [N] No  - Fresh start, drop and recreate (development mode)
      
      Your choice: ___
   
   c) Add test/sample data? (Development only)
      [Y] Yes - Add sample data for testing
      [N] No  - Empty database
      
      Your choice: ___ (Only if Development phase)

6. ENVIRONMENT
   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   Where will this run?
   
   Options:
   [L] Local    - localhost, 127.0.0.1
   [E] External - Custom domain, cloud server
   
   Your choice: ___
   
   If External, please provide:
   - Host/Domain: _______________
   - IP Address (optional): _______________

7. ADMIN USER (Production only)
   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   
   a) Admin Username:
      Default: admin
      Username: _____ (press Enter for default)
   
   b) Admin Email:
      Email: _______________
   
   c) Admin Password:
      (Will be generated securely if not provided)
      Password: _____ (optional)

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    CONFIGURATION SUMMARY                       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

I will now create a configuration file with your answers.
You can review and modify it at any time.

Configuration file: .global/project_config.json

```

---

### 64.2 Configuration File Structure

**Loca
tion:** `.global/project_config.json`

**Structure:**

```json
{
  "project": {
    "name": "{PROJECT_NAME}",
    "phase": "development|production",
    "deployed": false,
    "created_at": "2025-11-02T10:30:00Z",
    "updated_at": "2025-11-02T10:30:00Z"
  },
  "ports": {
    "frontend": 3000,
    "backend": 5000,
    "database": 5432
  },
  "database": {
    "name": "{DATABASE_NAME}",
    "preserve_data": false,
    "add_sample_data": true,
    "type": "postgresql|mysql|mongodb",
    "host": "localhost",
    "port": 5432
  },
  "environment": {
    "type": "local|external",
    "host": "localhost",
    "domain": null,
    "ip_address": null
  },
  "admin": {
    "username": "admin",
    "email": "admin@example.com",
    "password_hash": null,
    "created": false
  },
  "features": {
    "auto_backup": true,
    "logging": true,
    "monitoring": true
  }
}
```

---

### 64.3 State Management

**Project States:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  
              ‚îÇ
‚îÇ  ‚úì Send deployment notification                             ‚îÇ
‚îÇ  ‚úì Create deployment log                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Command Usage:**

```bash
# User types:
start deploy

# Augment responds:
üöÄ Starting deployment process...

‚ö†Ô∏è  WARNING: This will transition your project to PRODUCTION mode.

Current configuration:
  - Project: {PROJECT_NAME}
  - Database: {DATABASE_NAME}
  - Frontend: http://{HOST}:{FRONTEND_PORT}
  - Backend: http://{HOST}:{BACKEND_PORT}

Are you sure you want to proceed? [Y/n]: _

# If Yes:
‚úì Pre-deployment checks passed
‚úì Database backed up to: backups/db_20251102_103000.sql
‚úì Production build created
‚úì Database migrations applied
‚úì Admin user created: {ADMIN_USERNAME}
‚úì Security hardening applied
‚úì Application started

üéâ Deployment successful!

Admin Panel: http://{HOST}:{BACKEND_PORT}/admin
Username: {ADM
IN_USERNAME}
Password: {GENERATED_PASSWORD}

Setup Wizard: http://{HOST}:{FRONTEND_PORT}/setup

Next steps:
1. Login to admin panel
2. Complete setup wizard
3. Configure your application
4. Verify everything works

Project phase updated: PRODUCTION ‚úì
```

---

### 64.7 Admin Panel Auto-Open

**After `start deploy`:**

1. **Create Admin User:**
   ```python
   admin_user = {
       "username": config["admin"]["username"],
       "email": config["admin"]["email"],
       "password": generate_secure_password(),
       "is_superuser": True,
       "is_staff": True
   }
   ```

2. **Open Admin Panel:**
   ```python
   admin_url = f"http://{config['environment']['host']}:{config['ports']['backend']}/admin"
   webbrowser.open(admin_url)
   ```

3. **Open Setup Wizard:**
   ```python
   setup_url = f"http://{config['environment']['host']}:{config['ports']['frontend']}/setup"
   webbrowser.open(setup_url)
   ```

4. **Display Credentials:**
   ```
   ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
   ‚ïë                  ADMIN CREDENTIALS                         ‚ïë
   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
   
   Admin Panel: http://{HOST}:{BACKEND_PORT}/admin
   
   Username: {ADMIN_USERNAME}
   Password: {GENERATED_PASSWORD}
   
   ‚ö†Ô∏è  IMPORTANT: Save these credentials securely!
   ‚ö†Ô∏è  Change the password after first login.
   
   Setup Wizard: http://{HOST}:{FRONTEND_PORT}/setup
   
   Follow the setup wizard to:
   - Configure application settings
   - Set up database connections
   - Configure email settings
   - Set up payment gateways (if applicable)
   - Configure integrations
   ```

---

### 64.8 Setup Wizard Flow

**After deployment, setup wizard guides through:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SETUP WIZARD STEPS                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  Step 
1: Welcome                                            ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                             ‚îÇ
‚îÇ  - Welcome message                                          ‚îÇ
‚îÇ  - System requirements check                                ‚îÇ
‚îÇ  - License agreement (if applicable)                        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 2: Database Configuration                             ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                 ‚îÇ
‚îÇ  - Database connection test                                 ‚îÇ
‚îÇ  - Run migrations                                           ‚îÇ
‚îÇ  - Create initial tables                                    ‚îÇ
‚îÇ  - Verify database setup                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 3: Admin Account                                      ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                      ‚îÇ
‚îÇ  - Confirm admin credentials                  
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                       ‚îÇ
‚îÇ  - Review all settings                                      ‚îÇ
‚îÇ  - Run final tests                                          ‚îÇ
‚îÇ  - Complete setup                                           ‚îÇ
‚îÇ  - Redirect to dashboard                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### 64.9 Augment Behavior Guidelines

**At Project Start:**

1. **Check for existing config:**
   ```python
   if not os.path.exists('.global/project_config.json'):
       # Ask all questions
       collect_project_info()
   else:
       # Load existing config
       config = load_config()
       print(f"Loaded config for: {config['project']['name']}")
       print(f"Phase: {config['project']['phase']}")
   ```

2. **Use config throughout:**
   ```python
   # Always use config values
   project_name = config['project']['name']
   db_nam
tput ~/projects/my-erp

# Short form
python3 tools/template_generator.py -t web_page_with_login -o ~/my-app
```

### Features

‚úÖ **Interactive mode** - Asks questions for each variable  
‚úÖ **Batch mode** - Uses default values  
‚úÖ **Variable substitution** - Replaces placeholders  
‚úÖ **Validation** - Checks requirements  
‚úÖ **Post-generation** - Runs setup scripts

---

## Template Structure

Each template includes:

```
template_name/
‚îú‚îÄ‚îÄ README.md              # Template-specific guide
‚îú‚îÄ‚îÄ frontend/              # Frontend code (if applicable)
‚îú‚îÄ‚îÄ backend/               # Backend code (if applicable)
‚îú‚îÄ‚îÄ database/              # Database schemas
‚îú‚îÄ‚îÄ docker/                # Docker configuration
‚îú‚îÄ‚îÄ tests/                 # Test files
‚îú‚îÄ‚îÄ docs/                  # Documentation
‚îú‚îÄ‚îÄ .env.example           # Environment variables
‚îú‚îÄ‚îÄ .gitignore             # Git ignore
‚îî‚îÄ‚îÄ config.json            # Template configuration
```

---

## Configuration System

### config.json

Each template has
 a `config.json`:

```json
{
  "template_name": "erp_system",
  "version": "1.0.0",
  "description": "Complete ERP system",
  "variables": {
    "PROJECT_NAME": "{{PROJECT_NAME}}",
    "DATABASE_NAME": "{{DATABASE_NAME}}",
    "FRONTEND_PORT": "{{FRONTEND_PORT}}",
    "BACKEND_PORT": "{{BACKEND_PORT}}"
  },
  "defaults": {
    "PROJECT_NAME": "My ERP System",
    "DATABASE_NAME": "erp_db",
    "FRONTEND_PORT": "3000",
    "BACKEND_PORT": "5000"
  },
  "modules": [...],
  "features": {...},
  "tech_stack": {...}
}
```

### Variable Substitution

Placeholders in files are automatically replaced:

**Before:**
```python
PROJECT_NAME = "{{PROJECT_NAME}}"
DATABASE_NAME = "{{DATABASE_NAME}}"
```

**After:**
```python
PROJECT_NAME = "My ERP System"
DATABASE_NAME = "erp_db"
```

---

## Augment Integration

### When to Use Templates

Augment should suggest templates when:

1. **User starts new project**
   ```
   User: "I want to create an ERP system"
   Augment: "I can generate a complete ERP 

================================================================================
END OF 01_REQUIREMENTS
================================================================================


================================================================================
MODULE: 02_ANALYSIS
================================================================================

=================================================================================
PROJECT ANALYSIS - Existing Project Analysis
=================================================================================

Version: 5.0.0
Type: Core - Analysis

This prompt guides analysis of existing projects.
Based on Section 65 and project_analyzer.py tool.

=================================================================================
OVERVIEW
=================================================================================

When a user provides an existing project, this prompt helps you:
1. Detect the project structure
2. Identify technologies used
3. Analyze code quality
4. Generate project-specific configuration
5. Create custom prompts for this project

=================================================================================
ANALYSIS WORKFLOW
=================================================================================

## Step 1: Initial Scan

```bash
# Run the project analyzer
python3 tools/project_analyzer.py /path/to/project
```

The analyzer will detect:
- Frontend framework (React, Vue, Angular, etc.)
- Backend framework (Django, Flask, FastAPI, Express, etc.)
- Database type (PostgreSQL, MySQL, MongoDB, etc.)
- Project structure
- Dependencies
- Configuration files

## Step 2: Technology Detection

### Frontend Detection

**React:**
- Look for: `package.json` with `"react"` dependency
- Look for: `src/App.js` or `src/App.tsx`
- Look for: JSX/TSX files
- Indicators: `create-react-app`, `next.js`, `gatsby`

**Vue:**
- Look for: `package.json` with `"vue"` dependency
- Look for: `src/App.vue`
- Look for: `.vue` files
- Indicators: `@vue/cli`, `nuxt`

**Angular:**
- Look for: `package.json` with `"@angular/core"`
- Look for: `angular.json`
- Look for: `src/app/app.component.ts`
- Indicators: `@angular/cli`

**Plain HTML/CSS/JS:**
- Look for: `index.html` in root
- No framework dependencies
- Simple file structure

### Backend Detection

**Django:**
- Look for: `manage.py`
- Look for: `settings.py`
- Look for: `requirements.txt` or `Pipfile` with `Django`
- Look for: `urls.py`, `models.py`, `views.py`

**FastAPI:**
- Look for: `main.py` with `from fastapi import FastAPI`
- Look for: `requirements.txt` with `fastapi`
- Look for: `uvicorn` in dependencies

**Flask:**
- Look for: `app.py` or `application.py`
- Look for: `requirements.txt` with `Flask`
- Look for: `from flask import Flask`

**Express (Node.js):**
- Look for: `package.json` with `"express"`
- Look for: `server.js` or `app.js`
- Look for: `const express = require('express')`

### Database Detection

**PostgreSQL:**
- Look for: `psycopg2` in Python requirements
- Look for: `pg` in Node.js dependencies
- Look for: Connection strings with `postgresql://`
- Look for: `DATABASE_URL` with postgres

**MySQL:**
- Look for: `mysqlclient` or `PyMySQL` in Python
- Look for: `mysql2` in Node.js
- Look for: Connection strings with `mysql://`

**MongoDB:**
- Look for: `pymongo` in Python
- Look for: `mongoose` in Node.js
- Look for: Connection strings with `mongodb://`

**SQLite:**
- Look for: `sqlite3` in Python
- Look for: `.db` or `.sqlite` files
- Look for: Django with `ENGINE: 'django.db.backends.sqlite3'`

## Step 3: Structure Analysis

### Directory Structure Patterns

**Monolithic:**
```
project/
‚îú‚îÄ‚îÄ frontend/
‚îú‚îÄ‚îÄ backend/
‚îî‚îÄ‚îÄ database/
```

**Microservices:**
```
project/
‚îú‚îÄ‚îÄ service-a/
‚îú‚îÄ‚îÄ service-b/
‚îú‚îÄ‚îÄ service-c/
‚îî‚îÄ‚îÄ gateway/
```

**Full-stack (Django):**
```
project/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ users/
‚îÇ   ‚îú‚îÄ‚îÄ products/
‚îÇ   ‚îî‚îÄ‚îÄ orders/
‚îú‚îÄ‚îÄ static/
‚îú‚îÄ‚îÄ templates/
‚îî‚îÄ‚îÄ manage.py
```

**Full-stack (MERN):**
```
project/
‚îú‚îÄ‚îÄ client/          # React
‚îú‚îÄ‚îÄ server/          # Express
‚îî‚îÄ‚îÄ package.json
```

## Step 4: Dependency Analysis

### Python Projects

```bash
# Check requirements.txt
cat requirements.txt

# Check Pipfile
cat Pipfile

# Check pyproject.toml
cat pyproject.toml
```

Common dependencies and their purposes:
- `django` ‚Üí Web framework
- `djangorestframework` ‚Üí API framework
- `celery` ‚Üí Background tasks
- `redis` ‚Üí Caching
- `gunicorn` ‚Üí WSGI server
- `pytest` ‚Üí Testing
- `black` ‚Üí Code formatting
- `flake8` ‚Üí Linting

### Node.js Projects

```bash
# Check package.json
cat package.json
```

Common dependencies:
- `express` ‚Üí Web framework
- `react` ‚Üí Frontend library
- `next` ‚Üí React framework
- `mongoose` ‚Üí MongoDB ORM
- `sequelize` ‚Üí SQL ORM
- `jest` ‚Üí Testing
- `eslint` ‚Üí Linting
- `prettier` ‚Üí Formatting

## Step 5: Configuration Detection

### Environment Variables

Look for:
- `.env` file
- `.env.example` file
- `config.py` or `settings.py`
- `config.js` or `config.json`

Common variables:
```
DATABASE_URL=postgresql://user:pass@localhost:5432/dbname
SECRET_KEY=your-secret-key
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1
FRONTEND_URL=http://localhost:3000
BACKEND_URL=http://localhost:5000
```

### Docker Configuration

Look for:
- `Dockerfile`
- `docker-compose.yml`
- `.dockerignore`

Analyze Docker setup:
- Which services are defined?
- What ports are exposed?
- What volumes are mounted?
- What networks are used?

## Step 6: Code Quality Analysis

### Python Code Quality

```bash
# Run flake8
flake8 . --count --statistics

# Run pylint
pylint **/*.py

# Check test coverage
pytest --cov=. --cov-report=html
```

### JavaScript Code Quality

```bash
# Run ESLint
eslint src/

# Run Prettier check
prettier --check src/

# Check test coverage
npm test -- --coverage
```

## Step 7: API Endpoint Discovery

### Django REST Framework

```python
# Look for urls.py patterns
from django.urls import path
from rest_framework.routers import DefaultRouter

# Common patterns:
# /api/users/
# /api/products/
# /api/orders/
```

### FastAPI

```python
# Look for @app.get, @app.post decorators
@app.get("/api/users")
@app.post("/api/users")
```

### Express

```javascript
// Look for app.get, app.post
app.get('/api/users', ...)
app.post('/api/users', ...)
```

## Step 8: Database Schema Analysis

### Django Models

```python
# Analyze models.py files
class User(models.Model):
    username = models.CharField(max_length=150)
    email = models.EmailField()
    ...
```

Extract:
- Model names
- Field types
- Relationships (ForeignKey, ManyToMany)
- Indexes

### SQL Migrations

Look for:
- Django: `migrations/` folders
- Alembic: `versions/` folder
- Sequelize: `migrations/` folder

Analyze migration files to understand schema evolution.

=================================================================================
ANALYSIS OUTPUT
=================================================================================

## Project Report

After analysis, generate a comprehensive report:

```markdown
# Project Analysis Report

## Overview
- **Project Name:** [detected from package.json, setup.py, etc.]
- **Project Type:** [Web App, API, Full-stack, etc.]
- **Structure:** [Monolithic, Microservices, etc.]

## Technology Stack

### Frontend
- **Framework:** React 18.2.0
- **State Management:** Redux Toolkit
- **Routing:** React Router v6
- **UI Library:** Material-UI
- **Build Tool:** Vite

### Backend
- **Framework:** Django 4.2
- **API:** Django REST Framework 3.14
- **Authentication:** JWT (djangorestframework-simplejwt)
- **Task Queue:** Celery with Redis
- **WSGI Server:** Gunicorn

### Database
- **Type:** PostgreSQL 15
- **ORM:** Django ORM
- **Migrations:** Django migrations
- **Schema:** 12 models, 45 fields

### DevOps
- **Containerization:** Docker + Docker Compose
- **CI/CD:** GitHub Actions
- **Testing:** pytest, Jest
- **Linting:** flake8, ESLint

## Project Structure

```
project/
‚îú‚îÄ‚îÄ frontend/           # React application
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ store/
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ backend/            # Django application
‚îÇ   ‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ users/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ products/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orders/
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ manage.py
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ README.md
```

## API Endpoints

### Users
- GET /api/users/ - List users
- POST /api/users/ - Create user
- GET /api/users/{id}/ - Get user
- PUT /api/users/{id}/ - Update user
- DELETE /api/users/{id}/ - Delete user

### Products
- GET /api/products/ - List products
- POST /api/products/ - Create product
- ...

## Database Schema

### Users Table
- id: AutoField (PK)
- username: CharField(150)
- email: EmailField
- password: CharField(128)
- created_at: DateTimeField

### Products Table
- id: AutoField (PK)
- name: CharField(200)
- price: DecimalField
- stock: IntegerField
- created_at: DateTimeField

## Code Quality

### Python
- **Lines of Code:** 5,234
- **Flake8 Issues:** 23 (mostly line length)
- **Test Coverage:** 78%
- **Pylint Score:** 8.5/10

### JavaScript
- **Lines of Code:** 3,456
- **ESLint Issues:** 12
- **Test Coverage:** 65%
- **Bundle Size:** 245 KB (gzipped)

## Configuration

### Environment Variables
- DATABASE_URL
- SECRET_KEY
- DEBUG
- ALLOWED_HOSTS
- FRONTEND_URL
- REDIS_URL
- CELERY_BROKER_URL

### Ports
- Frontend: 3000
- Backend: 8000
- Database: 5432
- Redis: 6379

## Recommendations

### High Priority
1. Increase test coverage to 80%+
2. Fix security issues in dependencies
3. Add API documentation (OpenAPI/Swagger)

### Medium Priority
1. Improve code quality (fix linting issues)
2. Add monitoring and logging
3. Optimize database queries

### Low Priority
1. Refactor large components
2. Update outdated dependencies
3. Improve error handling

## Next Steps

1. Load relevant prompts:
   - 10_backend.txt (Django)
   - 11_frontend.txt (React)
   - 12_database.txt (PostgreSQL)
   - 13_api.txt (REST API)

2. Generate project-specific configuration:
   - Create .global/project.json
   - Create custom prompt

3. Provide assistance based on detected tech stack
```

=================================================================================
PROJECT-SPECIFIC CONFIGURATION
=================================================================================

## Generate .global/project.json

Based on analysis, create configuration file:

```json
{
  "project_name": "MyProject",
  "project_slug": "my-project",
  "project_type": "full-stack-web-app",
  "detected": true,
  "tech_stack": {
    "backend": {
      "framework": "Django",
      "version": "4.2",
      "language": "Python",
      "language_version": "3.11"
    },
    "frontend": {
      "framework": "React",
      "version": "18.2.0",
      "language": "JavaScript",
      "build_tool": "Vite"
    },
    "database": {
      "type": "PostgreSQL",
      "version": "15",
      "orm": "Django ORM"
    }
  },
  "structure": {
    "type": "monolithic",
    "frontend_path": "frontend/",
    "backend_path": "backend/",
    "docker": true
  },
  "ports": {
    "frontend": 3000,
    "backend": 8000,
    "database": 5432
  },
  "features": {
    "authentication": true,
    "api": true,
    "celery": true,
    "docker": true,
    "ci_cd": true
  },
  "quality": {
    "test_coverage": {
      "backend": 78,
      "frontend": 65
    },
    "linting": {
      "backend": "flake8",
      "frontend": "eslint"
    }
  }
}
```

=================================================================================
CUSTOM PROMPT GENERATION
=================================================================================

## Create Project-Specific Prompt

Generate a custom prompt tailored to this project:

```
# Custom Prompt for MyProject

## Project Context
This is a full-stack web application built with:
- **Frontend:** React 18.2.0 with Redux Toolkit
- **Backend:** Django 4.2 with DRF
- **Database:** PostgreSQL 15

## Key Information
- Frontend runs on port 3000
- Backend runs on port 8000
- Uses JWT authentication
- Has Celery for background tasks
- Dockerized with docker-compose

## Common Tasks

### Start Development
```bash
docker-compose up -d
```

### Run Tests
```bash
# Backend
cd backend && pytest

# Frontend
cd frontend && npm test
```

### Apply Migrations
```bash
docker-compose exec backend python manage.py migrate
```

## Relevant Prompts
When working on this project, use:
- 10_backend.txt (Django-specific guidance)
- 11_frontend.txt (React-specific guidance)
- 12_database.txt (PostgreSQL guidance)
- 21_authentication.txt (JWT authentication)

## Code Style
- Python: Follow PEP 8, use Black formatter
- JavaScript: Follow Airbnb style guide, use Prettier
- Max line length: 88 (Python), 100 (JavaScript)

## Testing
- Backend: pytest with >80% coverage
- Frontend: Jest + React Testing Library with >70% coverage

## Deployment
- Uses Docker
- CI/CD with GitHub Actions
- Deployed to [deployment target]
```

=================================================================================
INTEGRATION WITH OTHER PROMPTS
=================================================================================

After analysis, load relevant prompts based on detected technologies:

**If Django detected:**
‚Üí Load 10_backend.txt (Django section)

**If React detected:**
‚Üí Load 11_frontend.txt (React section)

**If PostgreSQL detected:**
‚Üí Load 12_database.txt (PostgreSQL section)

**If API detected:**
‚Üí Load 13_api.txt

**If authentication detected:**
‚Üí Load 21_authentication.txt

**If Docker detected:**
‚Üí Load 40_deployment.txt (Docker section)

=================================================================================
TROUBLESHOOTING
=================================================================================

## Common Issues

### Cannot Detect Framework

**Problem:** Analyzer cannot identify framework
**Solution:**
1. Check for package.json or requirements.txt
2. Look for framework-specific files manually
3. Ask user directly

### Multiple Frameworks Detected

**Problem:** Project uses multiple frameworks (e.g., Django + FastAPI)
**Solution:**
1. Identify primary framework (most files)
2. Note secondary frameworks
3. Load prompts for both

### Outdated Dependencies

**Problem:** Project uses old versions
**Solution:**
1. Note in analysis report
2. Recommend updates
3. Check for security vulnerabilities

=================================================================================
BEST PRACTICES
=================================================================================

1. **Be thorough:** Check all common locations
2. **Be accurate:** Verify detections
3. **Be helpful:** Provide actionable recommendations
4. **Be respectful:** Don't modify code without permission
5. **Be transparent:** Show what you detected and how

=================================================================================
NEXT STEPS
=================================================================================

After completing analysis:
1. Present analysis report to user
2. Save project configuration
3. Load relevant prompts
4. Ask user what they want to do next:
   - Add new features?
   - Fix issues?
   - Improve quality?
   - Deploy?

=================================================================================
END OF ANALYSIS PROMPT
=================================================================================



================================================================================
ADDITIONAL CONTENT FROM v4.2.0
================================================================================

## 59. Comprehensive Dependency Management

--------------------------------------------------------------------------------



================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

e 2 ‚Äî System & Forces
- Map agents, variables, relationships
- Dependency/call/import graphs
- Flag cycles and bottlenecks

Phase 3 ‚Äî Probabilistic Behavior Modeling
- Model user/admin/API/attacker behaviors
- Justify with data/patterns
- Security threat modeling

Phase 4 ‚Äî Strategy Generation (‚â•3 options)
- Scope, cost, risk, impact, prerequisites
- OSF_Score for each option
- No feature disabling

Phase 5 ‚Äî Stress Testing & Forecasting
- Best/Worst/Most-Probable scenarios
- Triggers and rollback plans
- Load testing, chaos engineering

Phase 6 ‚Äî Self-Correction Loop
- Refinement ‚Üí Hybridization ‚Üí Inversion
- Reward Metric (0.0‚Äì1.0)
- Choose highest-reward path

Phase 7 ‚Äî Operational Principle Extraction
- Extract reusable, abstract rules
- Document in project memory
- Update guidelines

Phase 8 ‚Äî Final Review
- 100% adherence check
- Document exceptions
- Sign-off

‚∏ª

6) BACKEND & API DESIGN (Expanded in v3.0)

A) Stack Selection
- Languages: Python (FastAPI/Django), Node.js (Express
- Model selection
- Cross-validation
- Baseline comparison

C) Model Evaluation
- Metrics: accuracy, precision, recall, F1, AUC
- Confusion matrix
- Feature importance
- Bias/fairness checks
- A/B testing

D) Model Serving
- Model registry
- Versioning (semantic versioning)
- Deployment strategies (canary, blue-green)
- API endpoints
- Batch vs real-time

E) Monitoring
- Model performance metrics
- Data drift detection
- Concept drift detection
- Latency monitoring
- Error rate tracking

F) Retraining Pipeline
- Scheduled retraining (weekly, monthly)
- Trigger-based (performance degradation)
- Automated or manual approval
- Rollback capability

G) Governance
- Model cards (documentation)
- Audit trail
- Compliance (GDPR, HIPAA if applicable)
- Explainability (SHAP, LIME)

H) Tools
- Training: PyTorch, TensorFlow, scikit-learn
- Tracking: MLflow, Weights & Biases
- Serving: TorchServe, TensorFlow Serving, FastAPI
- Monitoring: Prometheus, Grafana, custom dashboards
- Orchestration: Airf
) CI ENFORCEMENT

Add to `.github/workflows/ci.yml`:
```yaml
- name: Check for duplicate files
  run: |
    python scripts/detect_duplicates.py --strict
    if [ $? -ne 0 ]; then
      echo "‚ùå Duplicate files detected!"
      exit 1
    fi

- name: Verify File Map is updated
  run: |
    python scripts/map_files.py --check
    git diff --exit-code docs/File_Map.md || \
      (echo "‚ùå File_Map.md is out of date!" && exit 1)
```

E) NAMING CONVENTIONS TO PREVENT CONFUSION

**WRONG:**
- `user.py`, `users.py`, `user_model.py`, `user_unified.py`

**CORRECT:**
- `models/user.py` (CANONICAL - the one true User model)
- All other files import from this canonical location

F) AUTOMATED FILE MAP GENERATION

Run after any file changes:
```bash
# Generate complete file map
python scripts/map_files.py

# Update imports map
python scripts/generate_imports_map.py

# Update exports map  
python scripts/generate_exports_map.py
```

G) BENEFITS

‚úÖ No duplicate files  
‚úÖ Clear file ownership  
‚úÖ Easy to 
 ‚îÇ
‚îÇ  ‚úÖ Email configured                    ‚îÇ
‚îÇ  ‚úÖ Security settings applied           ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Ready to complete setup?               ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  [Back] [Complete Setup]                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

C) IMPLEMENTATION

```python
# backend/src/setup/wizard.py
from flask import Blueprint, render_template, request, redirect, session
from .validators import validate_admin_user, validate_db_config, validate_smtp

setup_bp = Blueprint('setup', __name__, url_prefix='/setup')

@setup_bp.route('/wizard', methods=['GET', 'POST'])
def wizard():
    step = request.args.get('step', '1')
    
    if request.method == 'POST':
        if step == '1':
            # Requirements check passed
            return redirect('/setup/wizard?step=2')
        
        elif step == '2':
            # Create admin user
            email = request.form['email']
            password = request.form['passw
r type definition
- `UserRole` (enum) - User roles
- `UserStatus` (enum) - User statuses

**Usage Count:** 23 imports across 12 files

---

### hooks/useAuth.tsx
**Exports:**
- `useAuth` (hook) - Authentication hook
- `AuthProvider` (component) - Auth context provider

**Usage Count:** 18 imports across 10 files

---

## Duplicate Exports Detected

‚ùå **User class exported from multiple locations:**
- `models/user.py` (CANONICAL)
- `models/user_unified.py` (DUPLICATE - should be removed)
- `models/users.py` (DUPLICATE - should be removed)

**Action Required:** Consolidate into single canonical export
```

C) GENERATION SCRIPT

```python
# scripts/generate_imports_map.py
import ast
import os
from pathlib import Path
from typing import Dict, List, Set

def analyze_python_imports(file_path: str) -> Dict:
    """Analyze imports in a Python file"""
    with open(file_path) as f:
        tree = ast.parse(f.read())
    
    imports = []
    for node in ast.walk(tree):
        if isinstance(nod
```

D) CI CHECK

```yaml
# .github/workflows/imports-check.yml
- name: Check for circular dependencies
  run: |
    python scripts/generate_imports_map.py --check-circular
    if [ $? -ne 0 ]; then
      echo "‚ùå Circular dependencies detected!"
      exit 1
    fi

- name: Check for duplicate exports
  run: |
    python scripts/detect_duplicate_exports.py
    if [ $? -ne 0 ]; then
      echo "‚ùå Duplicate exports detected!"
      exit 1
    fi
```

E) BENEFITS

‚úÖ Clear dependency tracking  
‚úÖ Detect circular dependencies  
‚úÖ Identify duplicate exports  
‚úÖ Easy refactoring  
‚úÖ Better code organization

‚∏ª

37) DUPLICATION DETECTION & PREVENTION (CRITICAL - NEW in v3.2)

**PURPOSE:** Prevent and eliminate duplicate code/files

A) SEMANTIC DUPLICATION DETECTION

```python
# scripts/detect_duplicates.py
import ast
import difflib
from pathlib import Path
from typing import List, Dict

class DuplicateDetector:
    def __init__(self, threshold=0.8):
        self.threshold = threshold  # Simila
      return 1  # Exit with error
    else:
        print("‚úÖ No duplicates found!")
        return 0

if __name__ == '__main__':
    import sys
    sys.exit(main())
```

B) CONSOLIDATION PROCESS

When duplicates are found:

1. **Identify Canonical Version**
   - Most complete implementation
   - Best documented
   - Most recently updated
   - In the correct location

2. **Update All Imports**
   ```python
   # Before (scattered)
   from models.user import User
   from models.user_unified import User
   from models.users import User
   
   # After (consolidated)
   from models.user import User  # CANONICAL
   ```

3. **Move Duplicates to /unneeded**
   ```bash
   mkdir -p /unneeded/models
   mv models/user_unified.py /unneeded/models/user_unified.removed.py
   mv models/users.py /unneeded/models/users.removed.py
   ```

4. **Add Pointer File**
   ```python
   # /unneeded/models/user_unified.removed.py
   """
   REMOVED: 2025-10-28
   REASON: Duplicate of models/user.py
   COMMIT: abc123
def456
   CANONICAL: models/user.py
   
   This file was a duplicate and has been removed.
   All imports should use: from models.user import User
   """
   ```

5. **Document in Duplicates Log**
   ```markdown
   # /docs/Duplicates_Log.md
   
   ## 2025-10-28: User Model Consolidation
   
   **Canonical:** `models/user.py`
   
   **Removed Duplicates:**
   - `models/user_unified.py` ‚Üí `/unneeded/models/user_unified.removed.py`
   - `models/users.py` ‚Üí `/unneeded/models/users.removed.py`
   
   **Commit:** abc123def456
   
   **Files Updated:** 8 files
   - `services/auth_service.py`
   - `routes/user_routes.py`
   - (list all updated files)
   ```

C) CI ENFORCEMENT

```yaml
- name: Check for duplicates
  run: |
    python scripts/detect_duplicates.py --strict
    if [ $? -ne 0 ]; then
      echo "‚ùå Duplicates detected! Please consolidate."
      exit 1
    fi
```

D) BENEFITS

‚úÖ No duplicate code  
‚úÖ Single source of truth  
‚úÖ Easier maintenance  
‚úÖ Smaller codebase  
‚úÖ Clear history
r functions: `grep -r "def <function_name>"`
- [ ] Run semantic search: `python scripts/detect_duplicates.py --target "<name>"`

## 4. Plan Your Changes
- [ ] Identified canonical file/class to use or extend
- [ ] No duplication of existing functionality
- [ ] Changes documented in TODO.md
- [ ] Discussed with team (if applicable)

## 5. Testing Preparation
- [ ] Identified test files to update
- [ ] Planned new tests for new functionality
- [ ] Cross-browser testing plan (if frontend)

## 6. Ready to Code
- [ ] All above items checked
- [ ] Environment is clean (no uncommitted changes)
- [ ] Created feature branch: `git checkout -b feature/<name>`

---

**Sign-off:** I have completed this checklist.

**Date:** ___________

**Developer:** ___________
```

B) AUTOMATED ENFORCEMENT

```python
# scripts/pre_dev_check.py
import sys
from validate_env import validate_env
from pathlib import Path

def pre_development_check():
    """Run all pre-development checks"""
    errors = []
    
    #

34. Production Error Handling
35. .env Validation & Management
36. Import/Export Documentation
37. Duplication Detection & Prevention
38. Pre-Development Checklist

**PROBLEMS SOLVED:**
‚úÖ File duplication (user.py, user_unified.py, users.py)
‚úÖ No environment detection (dev vs prod)
‚úÖ No setup wizard for production
‚úÖ Cross-browser compatibility issues
‚úÖ UI assets not loading
‚úÖ Error leaks in production
‚úÖ .env misconfiguration
‚úÖ No import/export tracking
‚úÖ Duplicate code detection
‚úÖ No pre-development checks

**NEW SCRIPTS (6):**
- `map_files.py` - Generate file map
- `validate_env.py` - Validate .env
- `detect_duplicates.py` - Find duplicates
- `generate_imports_map.py` - Track imports
- `setup_wizard.py` - Production setup
- `pre_dev_check.py` - Pre-development checks

**NEW DOCUMENTATION (7):**
- `/docs/File_Map.md`
- `/docs/Imports_Map.md`
- `/docs/Exports_Map.md`
- `/docs/Env.md`
- `/docs/Duplicates_Log.md`
- `/docs/Cross_Browser_Tests.md`
- `/docs/Setup_Guide.md`

**CI/CD CHECKS (
seModel):
    """Base for all Pydantic models"""
    class Config:
        from_attributes = True
        validate_assignment = True

class TimestampMixin(BaseModel):
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)

class SoftDeleteMixin(BaseModel):
    is_deleted: bool = False
    deleted_at: datetime | None = None
```

### custom.py - Project Specific
```python
"""Project-specific definitions"""

from enum import Enum

class ProjectStatus(str, Enum):
    PLANNING = "planning"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"

class Priority(str, Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"
```

### __init__.py - Central Registry
```python
"""Central registry for all definitions"""

from .common import *
from .core import *
from .custom import *

__all__ = [
    # Common
    'Status', 'UserRole', 'APIResponse',
    # Core
    'BaseModel', 'Timestamp
Mixin', 'SoftDeleteMixin',
    # Custom
    'ProjectStatus', 'Priority',
]
```

### Usage
```python
# Import from central registry
from config.definitions import (
    Status,
    UserRole,
    APIResponse,
    BaseModel,
    TimestampMixin,
    ProjectStatus
)

class User(BaseModel, TimestampMixin):
    username: str
    role: UserRole
    status: Status
```

## Rules
1. ‚úÖ ONE definition per concept
2. ‚úÖ Import from config.definitions only
3. ‚úÖ Document all definitions
4. ‚úÖ Use type hints
5. ‚úÖ Export via __all__

================================================================================
41. LINE LENGTH ENFORCEMENT (‚â§120)
================================================================================

## Problem
- Lines too long (>120 chars)
- Hard to read and review
- No consistent standard

## Solution: Automated Enforcement

### .flake8
```ini
[flake8]
max-line-length = 120
exclude = .git,__pycache__,venv,.venv,migrations,node_modules
ignore = E203,W503
per-file-ignores =
   
 exit 1
  }
```

### CI Check
```yaml
- name: Check Unused Code
  run: |
    pip install autoflake
    autoflake --check --recursive --exclude=venv,.venv .
```

### Manual Check
```bash
# Find unused imports
flake8 . --select=F401 --exclude=venv,.venv,migrations

# Find unused variables
flake8 . --select=F841 --exclude=venv,.venv,migrations

# Find undefined names
flake8 . --select=F821 --exclude=venv,.venv,migrations
```

## Rules
1. ‚úÖ No unused imports
2. ‚úÖ No unused variables
3. ‚úÖ No dead code
4. ‚úÖ CI enforced
5. ‚úÖ Auto-fix available

================================================================================
44. GITHUB WORKFLOWS FIX
================================================================================

## Problem
- Workflows fail during installation
- Missing dependencies
- Incorrect setup steps

## Solution: Fixed CI/CD Pipeline

### .github/workflows/ci.yml
```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main,
me: Document Imports/Exports
  run: python scripts/document_imports.py . docs/Imports_Exports.md
```

## Rules
1. ‚úÖ Document all imports
2. ‚úÖ Document all exports (__all__)
3. ‚úÖ Auto-generate on CI
4. ‚úÖ Check for circular dependencies
5. ‚úÖ Keep up-to-date

================================================================================
v3.3 SUMMARY
================================================================================

## New Sections (39-45)

39. **Port Configuration Management** - Single source of truth for ports
40. **Organized Definitions Structure** - Three-tier definition system
41. **Line Length Enforcement** - Max 120 characters
42. **Environment-Based Error Handling** - Different errors for dev/prod
43. **Unused Code Removal** - Automated cleanup
44. **GitHub Workflows Fix** - Fixed CI/CD pipelines
45. **Import/Export Documentation** - Auto-generated docs

## Problems Solved

1. ‚úÖ Port conflicts (8000 vs 3000)
2. ‚úÖ Undefined classes
3. ‚úÖ No organized definitions
4. ‚úÖ
black
    rev: 23.12.1
    hooks:
      - id: black
        args: [--line-length=120]
  
  - repo: https://github.com/PyCQA/flake8
    rev: 7.0.0
    hooks:
      - id: flake8
        args: [--max-line-length=120, --extend-ignore=E203]
  
  - repo: https://github.com/PyCQA/isort
    rev: 5.13.2
    hooks:
      - id: isort
        args: [--profile=black, --line-length=120]
  
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.8.0
    hooks:
      - id: mypy
        args: [--strict, --ignore-missing-imports]
  
  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.6
    hooks:
      - id: bandit
        args: [-r, ., -f, json, -o, bandit-report.json]
```

**Enforcement:**
- Runs automatically on `git commit`
- Blocks commit if checks fail
- Can be bypassed with `--no-verify` (DISCOURAGED)

### 46.2 CI/CD Quality Gates (MANDATORY)

**Pipeline Stages:**
1. **Linting** (flake8 + pylint)
2. **Type Checking** (mypy --strict)
3. **Security** (bandit + safety)
4. **Tests** (pyte
st with coverage ‚â•80%)
5. **Complexity** (radon, max C)
6. **Dead Code** (vulture)

**Quality Metrics:**
- Line length: ‚â§120 characters
- Test coverage: ‚â•80%
- Cyclomatic complexity: ‚â§C (radon scale)
- Security issues: 0 high/critical
- Type coverage: 100%

**Failure = Build Fails**

### 46.3 Verification Script

**Location:** `scripts/verify_all.sh`

```bash
#!/bin/bash
# Comprehensive verification script

set -e

echo "üîç Running comprehensive verification..."

# 1. Code style
echo "üìù Checking code style..."
black --check --line-length=120 . || exit 1
isort --check-only --profile=black . || exit 1

# 2. Linting
echo "üîé Linting..."
flake8 . --max-line-length=120 --extend-ignore=E203 || exit 1
pylint --max-line-length=120 --disable=C0111 . || exit 1

# 3. Type checking
echo "üî¢ Type checking..."
mypy --strict --ignore-missing-imports . || exit 1

# 4. Security
echo "üîí Security checks..."
bandit -r . -f json -o bandit-report.json || exit 1
safety check || exit 1

# 5. Complexity
echo "üìä C
omplexity analysis..."
radon cc . -a -s -n C || exit 1
radon mi . -s -n B || exit 1

# 6. Dead code
echo "üíÄ Dead code detection..."
vulture . --min-confidence 80 || exit 1

# 7. Tests
echo "üß™ Running tests..."
pytest --cov=. --cov-report=term --cov-report=html --cov-fail-under=80 || exit 1

# 8. Line length check
echo "üìè Checking line length..."
bash scripts/fix_line_length.sh --check || exit 1

# 9. Unused imports
echo "üóëÔ∏è  Checking unused imports..."
bash scripts/remove_unused.sh --check || exit 1

echo "‚úÖ All verification checks passed!"
```

**Usage:**
```bash
# Before every PR
./scripts/verify_all.sh

# In CI/CD
./scripts/verify_all.sh || exit 1
```

### 46.4 Testing Pyramid

**Structure:**
```
         /\
        /E2E\        10% - End-to-End Tests
       /------\
      /Integr.\     20% - Integration Tests
     /----------\
    /   Unit     \  70% - Unit Tests
   /--------------\
```

**Requirements:**
- **Unit Tests:** 70% of total tests
  - Fast (<100ms each)
  - Isolated
  - 
ests/*", "*/migrations/*", "*/__pycache__/*"]

[tool.coverage.report]
fail_under = 80
precision = 2

[tool.mypy]
python_version = "3.11"
strict = true
ignore_missing_imports = true
```

---

## 47. Function Reference System

### 47.1 Function Reference File (APPEND-ONLY)

**Location:** `docs/function_reference.md`

**Rules:**
- **APPEND-ONLY** - Never delete entries
- Document ALL shared/reusable functions
- Update when adding new shared functions
- Include examples for each function

**Template:**
```markdown
## Function: `function_name`

**File:** `path/to/file.py`
**Module:** `module_name`
**Added:** YYYY-MM-DD
**Author:** Author Name

**Description:**
Brief description of what the function does.

**Signature:**
```python
def function_name(param1: Type1, param2: Type2 = default) -> ReturnType:
    """Docstring."""
    pass
```

**Parameters:**
- `param1` (Type1): Description
- `param2` (Type2, optional): Description. Defaults to `default`.

**Returns:**
- `ReturnType`: Description


'quantity': 2}]
        >>> calculate_total(items, tax_rate=0.10)
        Decimal('22.00')
    """
    if not items:
        raise ValueError("Items list cannot be empty")
    if tax_rate < 0:
        raise ValueError("Tax rate cannot be negative")
    
    subtotal = sum(Decimal(str(item['price'])) * item['quantity'] for item in items)
    return subtotal * (1 + Decimal(str(tax_rate)))
```

### 47.3 CI Enforcement

**Pre-commit Hook:**
```yaml
- repo: local
  hooks:
    - id: check-function-reference
      name: Check function reference is updated
      entry: python scripts/check_function_reference.py
      language: python
      pass_filenames: false
```

**Script:** `scripts/check_function_reference.py`
```python
#!/usr/bin/env python3
"""Check that all shared functions are documented in function_reference.md"""

import ast
import sys
from pathlib import Path

def find_shared_functions():
    """Find all functions in shared/common modules."""
    shared_dirs = ['utils', 'common', '
s
- Memory leaks
- Inefficient algorithms

**5. Security Errors**
- SQL injection
- XSS vulnerabilities
- Authentication bypass

### 48.3 Error Prevention Checklist

Before committing code:
- [ ] Read `Dont_make_this_error_again.md`
- [ ] Check for similar past errors
- [ ] Apply relevant prevention measures
- [ ] Add tests for error scenarios
- [ ] Update error log if new error type

### 48.4 CI Integration

**Pre-commit Hook:**
```yaml
- repo: local
  hooks:
    - id: check-error-patterns
      name: Check for known error patterns
      entry: python scripts/check_error_patterns.py
      language: python
```

**Script:** `scripts/check_error_patterns.py`
```python
#!/usr/bin/env python3
"""Check code for known error patterns from error log."""

import re
import sys
from pathlib import Path

def load_error_patterns():
    """Load error patterns from error log."""
    error_file = Path('docs/errors/Dont_make_this_error_again.md')
    if not error_file.exists():
        return []
    
 
()
    if check_files_for_patterns(patterns):
        print("\n‚ùå Known error patterns detected!")
        print("   Check docs/errors/Dont_make_this_error_again.md")
        sys.exit(1)
    
    print("‚úÖ No known error patterns found")
```

---

## 49. Module Discovery & Reuse

### 49.1 ALWAYS Search Before Creating (MANDATORY)

**Rule:** **NEVER** create a new module without searching for existing ones first.

**Search Process:**
1. **Search by functionality**
   ```bash
   grep -r "function_name" .
   find . -name "*keyword*"
   ```

2. **Check module map**
   ```bash
   python scripts/map_files.py . docs/Module_Map.md
   cat docs/Module_Map.md
   ```

3. **Search imports**
   ```bash
   grep -r "from.*import" . | grep "keyword"
   ```

4. **Check function reference**
   ```bash
   grep "keyword" docs/function_reference.md
   ```

### 49.2 Module Map Generation

**Script:** `scripts/generate_module_map.py`
```python
#!/usr/bin/env python3
"""Generate comprehensive module map."""

imp
nt("‚úÖ Module map generated: docs/Module_Map.md")
```

**Usage:**
```bash
# Generate module map
python scripts/generate_module_map.py

# View module map
cat docs/Module_Map.md

# Search in module map
grep "function_name" docs/Module_Map.md
```

### 49.3 Dependency Analysis

**Start with Least Dependent Modules**

**Script:** `scripts/analyze_dependencies.py`
```python
#!/usr/bin/env python3
"""Analyze module dependencies and suggest build order."""

import ast
from pathlib import Path
from collections import defaultdict

def get_dependencies(file_path):
    """Get internal dependencies of a module."""
    with open(file_path) as f:
        try:
            tree = ast.parse(f.read())
        except SyntaxError:
            return set()
    
    deps = set()
    for node in ast.walk(tree):
        if isinstance(node, ast.ImportFrom):
            if node.module and not node.module.startswith(('os', 'sys', 'json')):
                # Only internal imports
                if not node.module.
ief description of file purpose

Dependencies:
- dependency1
- dependency2

Related Files:
- related_file1.py
- related_file2.py
"""
```

**TypeScript/JavaScript:**
```typescript
/**
 * File: path/to/file.ts
 * Module: module_name
 * Created: YYYY-MM-DD
 * Last Modified: YYYY-MM-DD
 * Author: author_name
 * Description: Brief description of file purpose
 * 
 * Dependencies:
 * - dependency1
 * - dependency2
 * 
 * Related Files:
 * - related_file1.ts
 * - related_file2.ts
 */
```

### 52.2 CI Enforcement

**Pre-commit Hook:**
```yaml
- repo: local
  hooks:
    - id: check-file-headers
      name: Check file headers
      entry: python scripts/check_file_headers.py
      language: python
```

**Script:** `scripts/check_file_headers.py`
```python
#!/usr/bin/env python3
"""Check that all files have proper headers."""

import re
import sys
from pathlib import Path

REQUIRED_FIELDS = ['File:', 'Module:', 'Created:', 'Author:', 'Description:']

def check_python_header(file_path):
    """Chec
  # 70% of tests
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py
‚îÇ   ‚îú‚îÄ‚îÄ test_services.py
‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py
‚îú‚îÄ‚îÄ integration/    # 20% of tests
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îî‚îÄ‚îÄ test_database.py
‚îî‚îÄ‚îÄ e2e/            # 10% of tests
    ‚îî‚îÄ‚îÄ test_workflows.py
```

**pytest Configuration:** `pytest.ini`
```ini
[pytest]
DJANGO_SETTINGS_MODULE = config.settings.test
python_files = tests.py test_*.py *_tests.py
python_classes = Test*
python_functions = test_*
addopts = 
    --strict-markers
    --cov=.
    --cov-report=term-missing
    --cov-report=html
    --cov-fail-under=80
    -ra
    -q
```

**Example Unit Test:**
```python
"""
File: tests/unit/test_order_service.py
Module: tests.unit.test_order_service
Created: 2025-01-15
Author: Team
Description: Unit tests for order service
"""

import pytest
from decimal import Decimal
from unittest.mock import Mock, patch
from services.order_service import OrderService

class TestOrderService:
    """Test OrderService class."""
    
    @pytest.fixture
    def order_service(sel
   ‚îî‚îÄ‚îÄ utils/
‚îî‚îÄ‚îÄ README.md
```

### 54.3 Model Example (Following 'sales' Standards)

```python
"""
File: module_name/models/main_model.py
Module: module_name.models.main_model
Created: 2025-01-15
Author: Team
Description: ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä ŸÑŸÑŸàÿ≠ÿØÿ©

Dependencies:
- django.db.models
- django.contrib.auth.models
"""

from django.db import models
from django.contrib.auth.models import User
from decimal import Decimal

class MainModel(models.Model):
    """
    ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä ŸÑŸÑŸàÿ≠ÿØÿ©.
    
    Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿ¨ŸÖŸäÿπ ÿßŸÑÿ≠ŸÇŸàŸÑ ŸàÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©.
    """
    
    # ÿ≠ÿßŸÑÿßÿ™ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨
    STATE_DRAFT = 'draft'
    STATE_CONFIRMED = 'confirmed'
    STATE_CANCELLED = 'cancelled'
    
    STATES = [
        (STATE_DRAFT, 'ŸÖÿ≥ŸàÿØÿ©'),
        (STATE_CONFIRMED, 'ŸÖÿ§ŸÉÿØ'),
        (STATE_CANCELLED, 'ŸÖŸÑÿ∫Ÿä'),
    ]
    
    # ÿßŸÑÿ≠ŸÇŸàŸÑ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©
    name = models.CharField('ÿßŸÑÿßÿ≥ŸÖ', max_length=255)
    code = models.CharField('ÿßŸÑÿ±ŸÖÿ≤', max_length=50, unique=True)
    description = models.TextField('ÿßŸÑŸàÿµŸÅ', blank=True)
    
    
25-01-15
Author: Team
Description: Type definitions and type hints
"""

from typing import TypedDict, Literal, Optional, List, Dict, Any
from decimal import Decimal
from datetime import datetime

# State types
StateType = Literal['draft', 'confirmed', 'cancelled', 'done']
PermissionType = Literal['view', 'create', 'edit', 'delete', 'admin']

# API Response types
class APIResponse(TypedDict):
    """Standard API response structure."""
    success: bool
    message: str
    data: Optional[Dict[str, Any]]
    errors: Optional[List[str]]

class PaginatedResponse(TypedDict):
    """Paginated API response."""
    count: int
    next: Optional[str]
    previous: Optional[str]
    results: List[Dict[str, Any]]

# Business types
class OrderItem(TypedDict):
    """Order item structure."""
    product_id: int
    quantity: int
    price: Decimal
    subtotal: Decimal

class Order(TypedDict):
    """Order structure."""
    id: int
    code: str
    customer_id: int
    items: List[OrderItem]
    s
cal paths exist and pass
- [ ] Frontend tests exist and pass
- [ ] Coverage ‚â•80%

### 57.2 Gap Analysis Script

**Location:** `scripts/analyze_gaps.py`

```python
#!/usr/bin/env python3
"""
Analyze gaps between design and implementation.

File: scripts/analyze_gaps.py
Module: scripts.analyze_gaps
Created: 2025-01-15
Author: Team
Description: Compare design specs with actual implementation
"""

import ast
import json
from pathlib import Path
from typing import Dict, List, Set

def find_api_endpoints() -> Set[str]:
    """Find all defined API endpoints."""
    endpoints = set()
    
    for py_file in Path('.').rglob('*views.py'):
        with open(py_file) as f:
            content = f.read()
        
        # Find @api_view decorators
        import re
        patterns = re.findall(r'@api_view\([\'"]([A-Z]+)[\'"]\)', content)
        # Find route definitions
        routes = re.findall(r'path\([\'"]([^\'\"]+)[\'"]', content)
        
        endpoints.update(routes)
    
    return en
dpoints

def find_frontend_routes() -> Set[str]:
    """Find all frontend routes."""
    routes = set()
    
    # Check React Router
    for tsx_file in Path('.').rglob('*.tsx'):
        with open(tsx_file) as f:
            content = f.read()
        
        import re
        patterns = re.findall(r'<Route\s+path=[\'"]([^\'\"]+)[\'"]', content)
        routes.update(patterns)
    
    return routes

def find_database_models() -> Set[str]:
    """Find all database models."""
    models = set()
    
    for py_file in Path('.').rglob('models.py'):
        with open(py_file) as f:
            try:
                tree = ast.parse(f.read())
            except SyntaxError:
                continue
        
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # Check if it's a Django model
                for base in node.bases:
                    if isinstance(base, ast.Attribute):
                        if base.attr == 'Model':
           
istry

**üü¢ Medium Priority (56-57):**
- 56. Dependency Management
- 57. Design vs Implementation Gap Analysis

### Statistics

- **Total Sections:** 57 (was 45)
- **New Sections:** 12
- **Total Lines:** ~6,600 (was ~4,271)
    # ... (code truncated for brevity) ...
    # See full example in examples/ directory
   
4. **Report**
   - List all duplicate pairs
   - Show similarity score
   - Suggest merge candidates

### 58.3 Implementation

**Tool:** `scripts/detect_code_duplication.py`

```python
# Usage
python scripts/detect_code_duplication.py <project_root>

# Output
docs/Code_Duplication_Report.md
```

**Report Format:**

```markdown
# Code Duplication Report

## Duplicate Pair 1 (Similarity: 95%)

### File 1: models/user.py
Function: `create_user()`

### File 2: models/user_unified.py  
Function: `add_user()`

### Recommendation
Merge into `models/user.py::create_user()`
Update all imports in dependent files
```

### 58.4 Workflow

**Before Creating New Function:**

1. Run duplicat
 59. Comprehensive Dependency Management
================================================================================

### 59.1 Principle

**ALWAYS** maintain a comprehensive dependency table.  
**NEVER** make changes without consulting the dependency table.

### 59.2 Dependency Table Generation

**Tool:** `scripts/analyze_dependencies.py`

```bash
# Generate dependency table
python scripts/analyze_dependencies.py <project_root>

# Output
docs/Dependency_Table.md
docs/Dependency_Graph.json
docs/Circular_Dependencies.md
docs/Orphan_Files.md
```

### 59.3 Dependency Table Format

| Module | Path | Imports From | Imported By | Dependency Level |
|--------|------|--------------|-------------|------------------|
| `base` | `/models/base.py` | - | `user`, `product` | 0 |
| `user` | `/models/user.py` | `base`, `auth` | `views.user_view` | 2 |

**Dependency Level:**
- **0:** Leaf node (no project imports)
- **1:** Imports only level-0 modules
- **2:** Imports level-0 and level-1 modules
- 
**N:** Maximum dependency level in import chain

### 59.4 Workflow

**At Project Start:**

1. Generate dependency table
2. Review dependency levels
3. Identify circular dependencies
4. Fix circular dependencies

**Before Refactoring:**

1. Consult dependency table
2. Identify all affected files
3. Plan refactoring strategy
4. Update dependency table after changes

**Module Development Order:**

1. Start with level-0 modules (least dependent)
2. Then level-1 modules
3. Continue in ascending order
4. This minimizes rework

### 59.5 Circular Dependency Detection

**Report Format:**

```markdown
# Circular Dependencies

## Cycle 1
```
models.user ‚Üí models.auth ‚Üí models.session ‚Üí models.user
```

**Resolution:** Extract common code to `models.base`
```

**Resolution Strategies:**

1. **Extract Common Code:** Create a base module
2. **Lazy Import:** Import inside function
3. **Dependency Inversion:** Use interfaces/protocols
4. **Restructure:** Reorganize module boundaries

### 59.6 Orphan F
ile Detection

**Orphan Files:** Files not imported by any other file.

**Possible Reasons:**

1. Entry points (main.py, app.py)
2. Scripts (setup.py, manage.py)
3. Tests
4. **Dead code** ‚ö†Ô∏è

**Action:**

- Review orphan files
- If dead code ‚Üí delete
- If entry point ‚Üí document
- If test ‚Üí ensure it runs

### 59.7 Dependency Graph Visualization

```bash
# Generate visual graph (requires graphviz)
python scripts/visualize_dependencies.py docs/Dependency_Graph.json
```

### 59.8 CI/CD Integration

```yaml
- name: Analyze Dependencies
  run: |
    python scripts/analyze_dependencies.py .
    
- name: Check Circular Dependencies
  run: |
    if grep -q "Found.*circular" docs/Circular_Dependencies.md; then
      echo "‚ö†Ô∏è Circular dependencies detected!"
      cat docs/Circular_Dependencies.md
      exit 1
    fi
```

---

================================================================================
## 60. Intelligent Automatic Merging
=====================================================
`
   
   c. **Backup**
      ```
      Backing up:
      - models/user.py ‚Üí backups/2025-01-15_user.py
      - models/user_unified.py ‚Üí backups/2025-01-15_user_unified.py
      - All 5 dependent files
      ```
   
   d. **Merge**
      - Keep best implementation
      - Or merge features from both
      - Update docstrings
      - Update type hints
   
   e. **Update Imports**
      - Find all files importing from old location
      - Update to new location
      - Preserve import style
   
   f. **Run Tests**
      ```
      Running tests for affected modules...
      ‚úì test_user.py::test_create_user
      ‚úì test_api.py::test_user_endpoint
      ```
   
   g. **Commit or Rollback**
      - If tests pass ‚Üí commit
      - If tests fail ‚Üí rollback from backup

3. **Final Verification**
   - Run full test suite
   - Check code quality (flake8, mypy)
   - Generate new dependency table

### 60.4 Merge Strategies

**1. Keep Best Implementation**
- Choose implementation with:
  - Better docu
mentation
  - Better type hints
  - Better error handling
  - More features
  - Better tests

**2. Merge Features**
- Combine best parts from both
- Keep all functionality
- Resolve conflicts manually

**3. Deprecate Gradually**
- Keep both temporarily
- Mark old as deprecated
- Add migration guide
- Remove after grace period

### 60.5 Safety Measures

1. **Always Backup**
   - Backup all affected files
   - Keep backups for 30 days
   - Store in `backups/YYYY-MM-DD/`

2. **Always Test**
   - Run unit tests
   - Run integration tests
   - Check affected modules only (fast)
   - Then run full suite

3. **Always Rollback on Failure**
   - If any test fails ‚Üí rollback
   - If syntax error ‚Üí rollback
   - If import error ‚Üí rollback
   - Restore from backup automatically

4. **Always Log**
   - Log all merge operations
   - Log all file changes
   - Log all test results
   - Store in `logs/merge_YYYY-MM-DD.log`

### 60.6 Post-Merge Checklist

- [ ] All tests pass
- [ ] No import errors
- [ 
] No syntax errors
- [ ] Code quality checks pass (flake8, mypy)
- [ ] Documentation updated
- [ ] Dependency table updated
- [ ] Changelog updated
- [ ] Git commit with descriptive message

### 60.7 CI/CD Integration

```yaml
- name: Smart Merge (Dry Run)
  run: |
    python scripts/smart_merge.py --dry-run --report
    
- name: Check Merge Suggestions
  run: |
    if [ -f merge_suggestions.md ]; then
      echo "üìù Merge suggestions available"
      cat merge_suggestions.md
    fi
```

---

================================================================================
## 61. Import Update Automation
================================================================================

### 61.1 Principle

**NEVER** update imports manually.  
**ALWAYS** use automated tools to update imports across all files.

### 61.2 Import Update Tool

**Tool:** `scripts/update_imports.py`

```bash
# Update imports after moving/renaming module
python scripts/update_imports.py <old_module> <new_module>

#
 Example
python scripts/update_imports.py models.user_unified models.user

# Dry-run
python scripts/update_imports.py models.user_unified models.user --dry-run
```

### 61.3 Supported Import Styles

**1. Direct Import**
```python
# Before
import models.user_unified

# After
import models.user
```

**2. From Import**
```python
# Before
from models.user_unified import create_user

# After
from models.user import create_user
```

**3. Aliased Import**
```python
# Before
import models.user_unified as user_module

# After
import models.user as user_module
```

**4. Multiple Imports**
```python
# Before
from models.user_unified import create_user, delete_user

# After
from models.user import create_user, delete_user
```

**5. Relative Imports**
```python
# Before (in models/views.py)
from .user_unified import create_user

# After
from .user import create_user
```

### 61.4 Workflow

1. **Find Affected Files**
   - Use dependency table
   - Find all files importing from old module
   
2. **Fo
r Each File:**
   
   a. **Parse Imports**
      - Use AST to parse imports
      - Identify matching imports
   
   b. **Update Imports**
      - Replace old module with new module
      - Preserve import style
      - Preserve aliases
   
   c. **Verify Syntax**
      - Parse updated file to AST
      - Check for syntax errors
   
   d. **Backup**
      - Backup original file
      - Write updated file

3. **Verify**
   - Run `python -m py_compile` on all updated files
   - Check for import errors
   - Run tests

### 61.5 Safety Measures

1. **Always Backup**
   - Backup before any change
   - Store in `backups/imports_YYYY-MM-DD/`

2. **Always Verify Syntax**
   - Parse to AST after update
   - If syntax error ‚Üí rollback

3. **Always Test**
   - Run tests after update
   - If tests fail ‚Üí rollback

4. **Always Log**
   - Log all file changes
   - Log all import updates
   - Store in `logs/import_update_YYYY-MM-DD.log`

### 61.6 Edge Cases

**1. Dynamic Imports**
```python
# Cannot b
Dependency table updated
- [ ] Documentation updated

---

================================================================================
## Summary of v3.5 Additions
================================================================================

### New Sections (58-61):

1. **Section 58:** AST-Based Code Duplication Detection
   - Semantic analysis instead of name-based
   - Similarity threshold ‚â•80%
   - CI/CD integration

2. **Section 59:** Comprehensive Dependency Management
   - Dependency table generation
   - Circular dependency detection
   - Orphan file identification
   - Module development order

3. **Section 60:** Intelligent Automatic Merging
   - Safe automated merging
   - Backup before changes
   - Update all dependent files
   - Rollback on failure

4. **Section 61:** Import Update Automation
   - Automatic import updates
   - Support all import styles
   - Syntax verification
   - Integration with smart merge

### Tools Added:

1. `scripts/analyze_dependencies.py
` - Dependency analysis
2. `scripts/detect_code_duplication.py` - AST-based duplication detection
3. `scripts/smart_merge.py` - Intelligent merging
4. `scripts/update_imports.py` - Import updates

### Benefits:

- **Eliminate Duplication:** AST-based detection finds hidden duplicates
- **Safe Refactoring:** Dependency table shows impact of changes
- **Automated Merging:** Smart merge reduces manual work
- **Zero Import Errors:** Automatic import updates prevent breakage

### Version: 3.5.0
### Date: 2025-01-15
### Total Sections: 61
### Total Lines: ~7,700

# __init__.py Best Practices - ÿØŸÑŸäŸÑ ÿ¥ÿßŸÖŸÑ ŸÑŸÖŸÑŸÅÿßÿ™ __init__.py

**ÿßŸÑŸÇÿ≥ŸÖ ÿßŸÑŸÖŸÇÿ™ÿ±ÿ≠ ŸÑŸÑÿ•ÿ∂ÿßŸÅÿ© ÿ•ŸÑŸâ GLOBAL_GUIDELINES**

================================================================================
## 62. __INIT__.PY PATTERNS & BEST PRACTICES
================================================================================

## Overview

ŸÖŸÑŸÅ `__init__.py` ŸáŸà ÿßŸÑŸÇŸÑÿ® ÿßŸÑŸÜÿßÿ®ÿ∂ ŸÑÿ£Ÿä Python package. ŸÅŸáŸÖŸá ÿßŸÑÿµÿ≠Ÿäÿ≠ Ÿàÿßÿ≥ÿ™ÿÆÿØÿßŸÖŸá ÿ®ÿßŸÑÿ∑ÿ±ŸäŸÇÿ© ÿßŸÑŸÖÿ´ŸÑŸâ Ÿäÿ≠ÿØÿØ ÿ¨ŸàÿØÿ© ŸáŸäŸÉ
ŸÑÿ© ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ Ÿàÿ≥ŸáŸàŸÑÿ© ÿßÿ≥ÿ™ÿÆÿØÿßŸÖŸá.

The `__init__.py` file is the beating heart of any Python package. Understanding and using it correctly determines the quality of project structure and ease of use.

---

## 1. ÿßŸÑÿ£ŸÜŸÖÿßÿ∑ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© / Basic Patterns

### Pattern 1: Empty __init__.py (Marker File)

**ŸÖÿ™Ÿâ ÿ™ÿ≥ÿ™ÿÆÿØŸÖ / When to use:**
- Python 3.3+ namespace packages
- ÿπŸÜÿØŸÖÿß ŸÑÿß ÿ™ÿ≠ÿ™ÿßÿ¨ ŸÑÿ™ÿµÿØŸäÿ± ÿ£Ÿä ÿ¥Ÿäÿ°
- ŸÑŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ backward compatibility

```python
# config/__init__.py
# Empty file - just marks directory as package
```

**ÿßŸÑÿ•Ÿäÿ¨ÿßÿ®Ÿäÿßÿ™ / Pros:**
‚úÖ ÿ®ÿ≥Ÿäÿ∑ ŸàŸÜÿ∏ŸäŸÅ
‚úÖ ŸÑÿß Ÿäÿ∂ŸäŸÅ overhead
‚úÖ ŸÖŸÜÿßÿ≥ÿ® ŸÑŸÑŸÄ namespace packages

**ÿßŸÑÿ≥ŸÑÿ®Ÿäÿßÿ™ / Cons:**
‚ùå ŸÑÿß ŸäŸàŸÅÿ± Ÿàÿßÿ¨Ÿáÿ© Ÿàÿßÿ∂ÿ≠ÿ© ŸÑŸÑŸÄ package
‚ùå ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸàŸÜ Ÿäÿ≠ÿ™ÿßÿ¨ŸàŸÜ ŸÖÿπÿ±ŸÅÿ© ÿßŸÑÿ®ŸÜŸäÿ© ÿßŸÑÿØÿßÿÆŸÑŸäÿ©

---

### Pattern 2: Explicit Imports (Recommended)

**ŸÖÿ™Ÿâ ÿ™ÿ≥ÿ™ÿÆÿØŸÖ / When to use:**
- ÿπŸÜÿØŸÖÿß ÿ™ÿ±ŸäÿØ ÿ™ÿ≠ŸÉŸÖ ŸÉÿßŸÖŸÑ ŸÅŸä ÿßŸÑÿµÿßÿØÿ±ÿßÿ™
- ŸÑŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ ÿßŸÑŸÖÿ™Ÿàÿ≥ÿ∑ÿ© ŸàÿßŸÑŸÉÿ®Ÿäÿ±ÿ©
- ÿπŸÜÿØŸÖÿß ÿ™ÿ±ŸäÿØ ÿ™ÿ¨ŸÜÿ® namespace pollution

```python
# config/__init__.py
"""
File: config/__init__.py
Configuration package with explicit exports
"""

# Explicit import
s - clear and maintainable
from .settings import Settings, DatabaseConfig
from .constants import (
    DEFAULT_TIMEOUT,
    MAX_RETRIES,
    API_VERSION
)
from .validators import validate_config, ConfigError

# Explicit __all__ definition
__all__ = [
    # Settings
    'Settings',
    'DatabaseConfig',
    # Constants
    'DEFAULT_TIMEOUT',
    'MAX_RETRIES',
    'API_VERSION',
    # Validators
    'validate_config',
    'ConfigError',
]

# Package metadata
__version__ = '1.0.0'
__author__ = 'Your Team'
```

**ÿßŸÑÿ•Ÿäÿ¨ÿßÿ®Ÿäÿßÿ™ / Pros:**
‚úÖ Ÿàÿßÿ∂ÿ≠ Ÿàÿµÿ±Ÿäÿ≠ - ÿ™ÿπÿ±ŸÅ ÿ®ÿßŸÑÿ∂ÿ®ÿ∑ ŸÖÿß Ÿäÿ™ŸÖ ÿ™ÿµÿØŸäÿ±Ÿá
‚úÖ ÿ≥ŸáŸÑ ÿßŸÑÿµŸäÿßŸÜÿ© ŸàÿßŸÑÿ™ÿ™ÿ®ÿπ
‚úÖ ŸäÿπŸÖŸÑ ÿ®ÿ¥ŸÉŸÑ ŸÖŸÖÿ™ÿßÿ≤ ŸÖÿπ IDEs Ÿàtype checkers
‚úÖ ŸÑÿß ÿ™Ÿàÿ¨ÿØ ŸÖŸÅÿßÿ¨ÿ¢ÿ™ ŸÅŸä ÿßŸÑŸÄ namespace

**ÿßŸÑÿ≥ŸÑÿ®Ÿäÿßÿ™ / Cons:**
‚ùå Ÿäÿ≠ÿ™ÿßÿ¨ ÿ™ÿ≠ÿØŸäÿ´ ŸäÿØŸàŸä ÿπŸÜÿØ ÿ•ÿ∂ÿßŸÅÿ© exports ÿ¨ÿØŸäÿØÿ©
‚ùå ÿ£ÿ∑ŸàŸÑ ŸÇŸÑŸäŸÑÿßŸã ŸÖŸÜ star imports

**ÿßŸÑÿ™ŸàÿµŸäÿ©:** ‚≠ê **Ÿáÿ∞ÿß ŸáŸà ÿßŸÑŸÜŸÖÿ∑ ÿßŸÑŸÖŸàÿµŸâ ÿ®Ÿá ŸÑŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ ÿßŸÑÿßÿ≠ÿ™ÿ±ÿßŸÅŸäÿ©**

---

### Pattern 3: Star Imports (Use with Caution)

**ŸÖÿ™Ÿâ ÿ™ÿ≥ÿ™ÿÆÿØŸÖ / When to use:**
- ŸÑŸÑŸÄ packages ÿßŸÑÿµÿ∫Ÿäÿ±ÿ© ÿ¨ÿØÿßŸã
- ÿπŸÜÿØŸÖÿß ÿ™ÿ±ŸäÿØ re-export ŸÉŸÑ ÿ¥Ÿäÿ° ŸÖŸÜ submodule
- ÿπŸÜÿØŸÖÿß ÿ™ŸÉŸàŸÜ
 ŸÖÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿπÿØŸÖ Ÿàÿ¨ŸàÿØ name conflicts

```python
# config/definitions/__init__.py
"""Central registry for all definitions"""

from .common import *
from .core import *
from .custom import *

# MUST define __all__ when using star imports
__all__ = [
    # From common
    'Status',
    'UserRole',
    'Environment',
    'APIResponse',
    'ErrorResponse',
    # From core
    'BaseModel',
    'TimestampMixin',
    'SoftDeleteMixin',
    'AuditMixin',
    # From custom
    'ProjectStatus',
    'Priority',
    'TaskType',
]
```

**ÿßŸÑÿ•Ÿäÿ¨ÿßÿ®Ÿäÿßÿ™ / Pros:**
‚úÖ ŸÖÿÆÿ™ÿµÿ±
‚úÖ ŸÖŸÜÿßÿ≥ÿ® ŸÑŸÑŸÄ central registries

**ÿßŸÑÿ≥ŸÑÿ®Ÿäÿßÿ™ / Cons:**
‚ùå ŸäŸÖŸÉŸÜ ÿ£ŸÜ Ÿäÿ≥ÿ®ÿ® namespace pollution
‚ùå ÿµÿπÿ® ÿ™ÿ™ÿ®ÿπ ŸÖÿµÿØÿ± ÿßŸÑŸÄ imports
‚ùå Ÿäÿ≥ÿ®ÿ® ŸÖÿ¥ÿßŸÉŸÑ ŸÖÿπ linters (F403, F405)
‚ùå ŸäŸÖŸÉŸÜ ÿ£ŸÜ ŸäÿÆŸÅŸä name conflicts

**ÿßŸÑÿ™ŸàÿµŸäÿ©:** ‚ö†Ô∏è **ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸÅŸÇÿ∑ ŸÖÿπ __all__ ÿµÿ±Ÿäÿ≠ ŸàŸÑŸÄ packages ŸÖÿ≠ÿØÿØÿ© ÿ¨ÿØÿßŸã**

---

### Pattern 4: Lazy Imports (Performance)

**ŸÖÿ™Ÿâ ÿ™ÿ≥ÿ™ÿÆÿØŸÖ / When to use:**
- ÿπŸÜÿØŸÖÿß ŸäŸÉŸàŸÜ import time ŸÖŸáŸÖ
- ŸÑŸÑŸÄ modules ÿßŸÑÿ´ŸÇŸäŸÑÿ© ÿßŸÑÿ™Ÿä ŸÑÿß ÿ™Ÿèÿ≥ÿ™ÿÆÿØŸÖ ÿØÿßÿ¶ŸÖÿßŸã
- ŸÅŸä command-line tools

```python

# tools/__init__.py
"""
Tools package with lazy imports for better performance
"""

from typing import TYPE_CHECKING

# Always imported (lightweight)
from .utils import get_version

# Type hints only (no runtime cost)
if TYPE_CHECKING:
    from .analyzer import CodeAnalyzer
    from .formatter import CodeFormatter

__version__ = '1.0.0'

__all__ = [
    'get_version',
    'get_analyzer',  # Lazy loaded
    'get_formatter',  # Lazy loaded
]


def get_analyzer():
    """Lazy import of CodeAnalyzer"""
    from .analyzer import CodeAnalyzer
    return CodeAnalyzer


def get_formatter():
    """Lazy import of CodeFormatter"""
    from .formatter import CodeFormatter
    return CodeFormatter
```

**ÿßŸÑÿ•Ÿäÿ¨ÿßÿ®Ÿäÿßÿ™ / Pros:**
‚úÖ Ÿäÿ≠ÿ≥ŸÜ startup time ÿ®ÿ¥ŸÉŸÑ ŸÉÿ®Ÿäÿ±
‚úÖ ŸäŸÇŸÑŸÑ memory footprint
‚úÖ ŸÖŸÜÿßÿ≥ÿ® ŸÑŸÑŸÄ CLI tools

**ÿßŸÑÿ≥ŸÑÿ®Ÿäÿßÿ™ / Cons:**
‚ùå ÿ£ŸÉÿ´ÿ± ÿ™ÿπŸÇŸäÿØÿßŸã
‚ùå ŸäŸÖŸÉŸÜ ÿ£ŸÜ ŸäÿÆŸÅŸä import errors ÿ≠ÿ™Ÿâ runtime

**ÿßŸÑÿ™ŸàÿµŸäÿ©:** üéØ **ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸÑŸÑŸÄ performance-critical applications**

---

## 2. ÿ£ŸÅÿ∂ŸÑ ÿßŸÑŸÖŸÖÿßÿ±ÿ≥ÿßÿ™ / Best Practices

### ‚úÖ DO: ÿßÿ≥ÿ™
ÿÆÿØŸÖ Docstrings

```python
# mypackage/__init__.py
"""
MyPackage - A comprehensive solution for X

This package provides:
- Feature A: Description
- Feature B: Description
- Feature C: Description

Usage:
    from mypackage import FeatureA
    
    feature = FeatureA()
    feature.do_something()

See documentation at: https://docs.example.com
"""
```

### ‚úÖ DO: ÿ≠ÿØÿØ __all__ ÿ®Ÿàÿ∂Ÿàÿ≠

```python
# Always define __all__ explicitly
__all__ = [
    'PublicClass',
    'public_function',
    'PUBLIC_CONSTANT',
]

# Private items (not in __all__)
_private_helper = "internal use only"
```

### ‚úÖ DO: ÿ£ÿ∂ŸÅ Package Metadata

```python
# Package metadata
__version__ = '1.2.3'
__author__ = 'Your Name'
__email__ = 'your.email@example.com'
__license__ = 'MIT'
__copyright__ = 'Copyright 2025, Your Company'

# Useful for debugging
__all__ = [...]

# Make version easily accessible
from .version import __version__  # If in separate file
```

### ‚úÖ DO: ÿßÿ≥ÿ™ÿÆÿØŸÖ Absolute Imports ÿπŸÜÿØ ÿßŸÑÿ•ŸÖŸÉÿßŸÜ

```python
# Good - clea
r and explicit
from mypackage.submodule import MyClass

# Avoid - can be confusing
from .submodule import MyClass  # OK in __init__.py only
```

### ‚ùå DON'T: ÿ™ÿ∂ÿπ Logic ŸÖÿπŸÇÿØ ŸÅŸä __init__.py

```python
# ‚ùå BAD - complex initialization
def _initialize_database():
    # 50 lines of database setup
    pass

_initialize_database()  # Runs on import!

# ‚úÖ GOOD - defer to explicit initialization
def initialize():
    """Call this explicitly when needed"""
    # Setup code here
    pass
```

### ‚ùå DON'T: ÿ™ÿ≥ÿ™Ÿàÿ±ÿØ ŸÉŸÑ ÿ¥Ÿäÿ°

```python
# ‚ùå BAD - imports everything
from .module1 import *
from .module2 import *
from .module3 import *
# No __all__ defined!

# ‚úÖ GOOD - selective imports
from .module1 import ClassA, function_a
from .module2 import ClassB
from .module3 import CONSTANT_C

__all__ = ['ClassA', 'function_a', 'ClassB', 'CONSTANT_C']
```

---

## 3. ÿ£ŸÜŸÖÿßÿ∑ ŸÖÿ™ŸÇÿØŸÖÿ© / Advanced Patterns

### Pattern 5: Subpackage Organization

```python
# myapp/__init__.py
"""
MyApp - Main application package

Subpack
   'TypeAlias',
    'PlatformSpecific',
]
```

### Pattern 8: Deprecation Warnings

```python
# oldpackage/__init__.py
"""
Old package - deprecated, use newpackage instead
"""

import warnings

# Deprecation warning
warnings.warn(
    "oldpackage is deprecated and will be removed in version 2.0. "
    "Use newpackage instead.",
    DeprecationWarning,
    stacklevel=2
)

# Re-export from new location
from newpackage import *  # noqa: F401, F403

__all__ = ['OldClass', 'old_function']
```

---

## 4. ÿ≠ŸÑ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ÿßŸÑÿ¥ÿßÿ¶ÿπÿ© / Common Problems & Solutions

### Problem 1: Circular Imports

```python
# ‚ùå PROBLEM: Circular dependency
# models/__init__.py
from .user import User
from .post import Post  # Post imports User, User imports Post!

# ‚úÖ SOLUTION 1: Import at function level
# models/user.py
def get_user_posts(user_id):
    from .post import Post  # Import here, not at module level
    return Post.query.filter_by(user_id=user_id).all()

# ‚úÖ SOLUTION 2: Use TYPE_CHECKING
# models/user.py
fro
ersion__ = '0.1.0'
__all__ = ['run_app', 'Config', 'helper_function']
```

### Medium Project (10-50 modules)

```python
# myapp/__init__.py
"""
MyApp - Medium-sized application

Organized into logical subpackages with clear public API.
"""

# Core functionality
from .core import (
    App,
    Config,
    initialize,
)

# Models
from .models import (
    User,
    Session,
    Database,
)

# Services (most commonly used)
from .services import (
    UserService,
    AuthService,
)

# Version
from ._version import __version__, __version_info__

# Public API
__all__ = [
    # Core
    'App',
    'Config',
    'initialize',
    # Models
    'User',
    'Session',
    'Database',
    # Services
    'UserService',
    'AuthService',
    # Version
    '__version__',
    '__version_info__',
]

# Note: For other services, use:
# from myapp.services import SpecificService
```

### Large Project (50+ modules)

```python
# enterprise_app/__init__.py
"""
Enterprise Application

Large-scale applica
tion with multiple subpackages.
Import subpackages explicitly for better organization.

Usage:
    # Import main app
    from enterprise_app import App
    
    # Import specific modules
    from enterprise_app.core import Config
    from enterprise_app.models import User
    from enterprise_app.services.auth import AuthService
"""

# Only expose the absolute essentials at top level
from .core import App
from ._version import __version__

# Make subpackages easily accessible
from . import (
    core,
    models,
    services,
    api,
    utils,
    exceptions,
)

# Minimal public API at package level
__all__ = [
    'App',
    '__version__',
    # Subpackages
    'core',
    'models',
    'services',
    'api',
    'utils',
    'exceptions',
]

# Package metadata
__author__ = 'Enterprise Team'
__license__ = 'Proprietary'
__copyright__ = 'Copyright 2025, Enterprise Corp'
```

---

## 6. Testing __init__.py

```python
# tests/test_package_init.py
"""Test package __init__.py structure"""
   import sys
    import importlib
    
    # Remove module if already imported
    if 'mypackage' in sys.modules:
        del sys.modules['mypackage']
    
    # Import should not raise or print anything
    import mypackage  # noqa: F401
```

---

## 7. Checklist ŸÑŸÑŸÖÿ±ÿßÿ¨ÿπÿ© / Review Checklist

ÿπŸÜÿØ ŸÖÿ±ÿßÿ¨ÿπÿ© ŸÖŸÑŸÅ `__init__.py`ÿå ÿ™ÿ£ŸÉÿØ ŸÖŸÜ:

### Structure
- [ ] Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ docstring Ÿàÿßÿ∂ÿ≠
- [ ] ÿßŸÑŸÄ imports ŸÖŸÜÿ∏ŸÖÿ© (stdlib ‚Üí third-party ‚Üí local)
- [ ] `__all__` ŸÖÿ≠ÿØÿØ ÿ®Ÿàÿ∂Ÿàÿ≠
- [ ] Package metadata ŸÖŸàÿ¨ŸàÿØ (`__version__`, etc.)

### Imports
- [ ] ŸÑÿß ÿ™Ÿàÿ¨ÿØ star imports ÿ®ÿØŸàŸÜ `__all__`
- [ ] ŸÑÿß ÿ™Ÿàÿ¨ÿØ circular imports
- [ ] ÿßŸÑŸÄ imports ÿ∂ÿ±Ÿàÿ±Ÿäÿ© ŸÅŸÇÿ∑ (ŸÑÿß unused imports)
- [ ] ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ explicit imports ÿ®ÿØŸÑÿßŸã ŸÖŸÜ star imports

### Performance
- [ ] ŸÑÿß ŸäŸàÿ¨ÿØ initialization code ÿ´ŸÇŸäŸÑ
- [ ] ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ lazy imports ŸÑŸÑŸÄ modules ÿßŸÑÿ´ŸÇŸäŸÑÿ©
- [ ] ŸÑÿß Ÿäÿ™ŸÖ import modules ÿ∫Ÿäÿ± ÿ∂ÿ±Ÿàÿ±Ÿäÿ©

### Maintainability
- [ ] ÿßŸÑŸÄ public API Ÿàÿßÿ∂ÿ≠ ŸàŸÖÿ≠ÿØŸàÿØ
- [ ] ÿßŸÑŸÄ private items ÿ™ÿ®ÿØÿ£ ÿ®ŸÄ underscore
- [ ] ÿßŸÑÿ™ÿπŸÑŸäŸÇÿßÿ™ ÿ™Ÿàÿ∂ÿ≠ ÿßŸÑŸÇÿ±ÿßÿ±ÿßÿ™ ÿßŸÑŸÖŸáŸÖÿ©
- [ ] ÿ≥ŸáŸÑ ÿ•ÿ∂ÿßŸÅÿ© exports
n code
- ŸÇŸÑŸÑ ÿßŸÑŸÄ dependencies

### üéØ Rule 5: Maintain Backwards Compatibility
    # ... (code truncated for brevity) ...
    # See full example in examples/ directory
- Ready-made templates
- Integration scripts
- Workflow documentation

**Repository URL:** https://github.com/hamfarid/global

---

## Repository Structure / ÿ®ŸÜŸäÿ© ÿßŸÑŸÖÿ≥ÿ™ŸàÿØÿπ

```
global/
‚îú‚îÄ‚îÄ GLOBAL_GUIDELINES_v3.7.txt          # ÿßŸÑÿ®ÿ±ŸàŸÖÿ®ÿ™ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä (Ÿáÿ∞ÿß ÿßŸÑŸÖŸÑŸÅ)
‚îú‚îÄ‚îÄ GLOBAL_GUIDELINES_FINAL.txt         # ŸÜÿ≥ÿÆÿ© ŸÜŸáÿßÿ¶Ÿäÿ©
‚îú‚îÄ‚îÄ VERSION                              # ÿßŸÑÿ•ÿµÿØÿßÿ± ÿßŸÑÿ≠ÿßŸÑŸä
‚îÇ
‚îú‚îÄ‚îÄ tools/                               # ÿ£ÿØŸàÿßÿ™ ÿßŸÑÿ™ÿ∑ŸàŸäÿ± ‚öôÔ∏è
‚îÇ   ‚îú‚îÄ‚îÄ analyze_dependencies.py          # ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿßÿπÿ™ŸÖÿßÿØŸäÿßÿ™
‚îÇ   ‚îú‚îÄ‚îÄ detect_code_duplication.py       # ŸÉÿ¥ŸÅ ÿßŸÑÿ™ŸÉÿ±ÿßÿ±
‚îÇ   ‚îú‚îÄ‚îÄ smart_merge.py                   # ÿØŸÖÿ¨ ÿ∞ŸÉŸä
‚îÇ   ‚îú‚îÄ‚îÄ update_imports.py                # ÿ™ÿ≠ÿØŸäÿ´ ÿßŸÑÿßÿ≥ÿ™Ÿäÿ±ÿßÿØÿßÿ™
‚îÇ   ‚îî‚îÄ‚îÄ README.md                        # ÿØŸÑŸäŸÑ ÿßŸÑÿ£ÿØŸàÿßÿ™
‚îÇ
‚îú‚îÄ‚îÄ templates/                           # ÿßŸÑŸÇŸàÿßŸÑÿ® üìã
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îú‚îÄ‚îÄ ports.py                     # Ports
T_FLOW.md              # ÿ≥Ÿäÿ± ÿπŸÖŸÑ ÿßŸÑÿ™ÿ∑ŸàŸäÿ±
‚îÇ   ‚îú‚îÄ‚îÄ INTEGRATION_FLOW.md              # ÿ≥Ÿäÿ± ÿπŸÖŸÑ ÿßŸÑÿØŸÖÿ¨
‚îÇ   ‚îú‚îÄ‚îÄ DEPLOYMENT_FLOW.md               # ÿ≥Ÿäÿ± ÿπŸÖŸÑ ÿßŸÑŸÜÿ¥ÿ±
‚îÇ   ‚îî‚îÄ‚îÄ README.md                        # ÿØŸÑŸäŸÑ Flows
‚îÇ
‚îî‚îÄ‚îÄ docs/                                # ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ üìñ
    ‚îú‚îÄ‚îÄ INIT_PY_BEST_PRACTICES.md        # ÿ£ŸÅÿ∂ŸÑ ŸÖŸÖÿßÿ±ÿ≥ÿßÿ™ __init__.py
    ‚îú‚îÄ‚îÄ OSF_FRAMEWORK.md                 # ÿ•ÿ∑ÿßÿ± OSF
    ‚îú‚îÄ‚îÄ QUICK_START.md                   # ÿßŸÑÿ®ÿØÿ° ÿßŸÑÿ≥ÿ±Ÿäÿπ
    ‚îî‚îÄ‚îÄ CHANGELOG.md                     # ÿ≥ÿ¨ŸÑ ÿßŸÑÿ™ÿ∫ŸäŸäÿ±ÿßÿ™
```

---

## 1. Tools / ÿßŸÑÿ£ÿØŸàÿßÿ™ ‚öôÔ∏è

### 1.1 analyze_dependencies.py

**ÿßŸÑŸàÿ∏ŸäŸÅÿ©:** ÿ™ÿ≠ŸÑŸäŸÑ ÿ¥ÿßŸÖŸÑ ŸÑŸÑÿßÿπÿ™ŸÖÿßÿØŸäÿßÿ™ ŸÅŸä ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```bash
python tools/analyze_dependencies.py /path/to/project
```

**ÿßŸÑŸÖŸäÿ≤ÿßÿ™:**
- ‚úÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿßÿπÿ™ŸÖÿßÿØŸäÿßÿ™ ÿßŸÑŸÖÿ®ÿßÿ¥ÿ±ÿ© Ÿàÿ∫Ÿäÿ± ÿßŸÑŸÖÿ®ÿßÿ¥ÿ±ÿ©
- ‚úÖ ŸÉÿ¥ŸÅ ÿßŸÑÿßÿπÿ™ŸÖÿßÿØŸäÿßÿ™ ÿßŸÑÿØÿßÿ¶ÿ±Ÿäÿ© (Circular Dependencies)
- ‚úÖ ÿ™ÿ≠ŸÑŸäŸÑ ÿπŸÖŸÇ ÿßŸÑÿßÿπÿ™ŸÖÿßÿØŸäÿßÿ™
- ‚úÖ ÿ•ŸÜÿ¥ÿßÿ° ÿ±ÿ≥ŸÖ ÿ®ŸäÿßŸÜŸä ŸÑŸÑÿßÿπÿ™ŸÖÿßÿØŸäÿßÿ™
- ‚úÖ ÿ™ŸÇÿ±Ÿäÿ± ŸÖŸÅÿµŸÑ ÿ®ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ

**ŸÖÿ´ÿßŸÑ ÿßŸÑÿ•ÿÆÿ±ÿßÿ¨:**
```
=== Dependency Analysis Report ===

Total modules analyzed: 45
Direct dependencies: 123

Indirect dependencies: 67

‚ö†Ô∏è Circular Dependencies Found:
  - module_a ‚Üí module_b ‚Üí module_c ‚Üí module_a
  - service_x ‚Üí service_y ‚Üí service_x

Recommendations:
  1. Break circular dependency between module_a and module_c
  2. Consider using dependency injection for service_x
```

**ÿßŸÑÿÆŸäÿßÿ±ÿßÿ™:**
```bash
# ÿ™ÿ≠ŸÑŸäŸÑ ŸÖÿπ ÿ±ÿ≥ŸÖ ÿ®ŸäÿßŸÜŸä
python tools/analyze_dependencies.py . --graph deps.png

# ÿ™ÿ≠ŸÑŸäŸÑ ŸÖÿπ ÿ™ŸÇÿ±Ÿäÿ± JSON
python tools/analyze_dependencies.py . --format json > report.json

# ÿ™ÿ≠ŸÑŸäŸÑ ŸÖÿπ ÿπŸÖŸÇ ŸÖÿ≠ÿØÿØ
python tools/analyze_dependencies.py . --max-depth 3
```

---

### 1.2 detect_code_duplication.py

**ÿßŸÑŸàÿ∏ŸäŸÅÿ©:** ŸÉÿ¥ŸÅ ÿßŸÑÿ™ŸÉÿ±ÿßÿ± ŸÅŸä ÿßŸÑŸÉŸàÿØ

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```bash
python tools/detect_code_duplication.py /path/to/project
```

**ÿßŸÑŸÖŸäÿ≤ÿßÿ™:**
- ‚úÖ ŸÉÿ¥ŸÅ ÿßŸÑŸÉŸàÿØ ÿßŸÑŸÖŸÉÿ±ÿ± (>= 5 ÿ£ÿ≥ÿ∑ÿ±)
- ‚úÖ ÿ≠ÿ≥ÿßÿ® ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿ™ÿ¥ÿßÿ®Ÿá
- ‚úÖ ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ŸàÿßŸÑÿ£ÿ≥ÿ∑ÿ± ÿßŸÑŸÖŸÉÿ±ÿ±ÿ©
- ‚úÖ ÿßŸÇÿ™ÿ±ÿßÿ≠ÿßÿ™ ŸÑŸÑÿØŸÖÿ¨
- ‚úÖ ÿ™ŸÇÿ±Ÿäÿ± ŸÖŸÅÿµŸÑ

**ŸÖÿ´ÿßŸÑ ÿßŸÑÿ•ÿÆÿ±ÿßÿ¨:**
```
=== Code Duplication Report ===

Total files scanned: 45
Duplications found: 12
Average similarity: 87%

Duplication #1 (95% simi
te_imports.py

**ÿßŸÑŸàÿ∏ŸäŸÅÿ©:** ÿ™ÿ≠ÿØŸäÿ´ ÿßŸÑÿßÿ≥ÿ™Ÿäÿ±ÿßÿØÿßÿ™ ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã ÿπŸÜÿØ ÿ•ÿπÿßÿØÿ© ÿßŸÑÿ™ÿ≥ŸÖŸäÿ©

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```bash
python tools/update_imports.py old_module new_module /path/to/project
```

**ÿßŸÑŸÖŸäÿ≤ÿßÿ™:**
- ‚úÖ ÿ™ÿ≠ÿØŸäÿ´ ÿ¨ŸÖŸäÿπ ÿßŸÑÿßÿ≥ÿ™Ÿäÿ±ÿßÿØÿßÿ™ ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã
- ‚úÖ ÿØÿπŸÖ ÿßŸÑÿßÿ≥ÿ™Ÿäÿ±ÿßÿØÿßÿ™ ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ© (from, import, as)
- ‚úÖ ÿ™ÿ≠ÿØŸäÿ´ docstrings
- ‚úÖ ŸÜÿ≥ÿÆ ÿßÿ≠ÿ™Ÿäÿßÿ∑Ÿä ŸÇÿ®ŸÑ ÿßŸÑÿ™ÿ≠ÿØŸäÿ´
- ‚úÖ ÿ™ŸÇÿ±Ÿäÿ± ŸÖŸÅÿµŸÑ ÿ®ÿßŸÑÿ™ÿ∫ŸäŸäÿ±ÿßÿ™

**ÿ£ŸÖÿ´ŸÑÿ©:**
```bash
# ÿ™ÿ≠ÿØŸäÿ´ ÿßÿ≥ŸÖ module
python tools/update_imports.py old_auth new_auth .

# ÿ™ÿ≠ÿØŸäÿ´ ÿßÿ≥ŸÖ package
python tools/update_imports.py src.old_pkg src.new_pkg .

# ÿ™ÿ≠ÿØŸäÿ´ ŸÖÿπ ŸÜÿ≥ÿÆ ÿßÿ≠ÿ™Ÿäÿßÿ∑Ÿä
python tools/update_imports.py old new . --backup
```

**ŸÖÿ´ÿßŸÑ ÿßŸÑÿ•ÿÆÿ±ÿßÿ¨:**
```
=== Import Update Report ===

Files scanned: 45
Files updated: 12
Imports updated: 34

Updated files:
  ‚úÖ src/services/user_service.py (3 imports)
  ‚úÖ src/api/routes.py (5 imports)
  ‚úÖ src/models/user.py (2 imports)
  ...

Backup created at: .backup_20251102_120000/
```

**ÿßŸÑÿ™ÿ≠ÿØŸäÿ´ÿßÿ™ ÿßŸÑŸÖÿØÿπŸàŸÖÿ©:**
```python
# Before
from old_module import func
import old_module
import old_module as om
fr
om old_module.sub import Class

# After
from new_module import func
import new_module
import new_module as om
from new_module.sub import Class
```

---

## 2. Templates / ÿßŸÑŸÇŸàÿßŸÑÿ® üìã

### 2.1 config/ports.py

**ÿßŸÑŸàÿµŸÅ:** ŸÜŸÖÿ∑ Ports & Adapters (Hexagonal Architecture)

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```python
from config.ports import (
    UserRepositoryPort,
    EmailServicePort,
    PaymentGatewayPort
)

# Implement adapters
class PostgresUserRepository(UserRepositoryPort):
    def get_user(self, user_id: int) -> User:
        # Implementation
        pass
```

**ÿßŸÑŸÖŸäÿ≤ÿßÿ™:**
- ‚úÖ ŸÅÿµŸÑ ÿßŸÑŸÖŸÜÿ∑ŸÇ ÿπŸÜ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ
- ‚úÖ ÿ≥ŸáŸàŸÑÿ© ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ± (Mocking)
- ‚úÖ ŸÇÿßÿ®ŸÑŸäÿ© ÿßŸÑÿ™ÿ®ÿØŸäŸÑ (Swappable implementations)

---

### 2.2 config/definitions/

#### common.py
**ÿßŸÑÿ™ÿπÿ±ŸäŸÅÿßÿ™ ÿßŸÑÿπÿßŸÖÿ© ÿßŸÑŸÖÿ¥ÿ™ÿ±ŸÉÿ©:**
```python
from config.definitions import (
    Status,           # ACTIVE, INACTIVE, PENDING, DELETED
    UserRole,         # ADMIN, USER, GUEST, MODERATOR
    Environment,      # DEV, STAGING, PROD
    APIResponse,      # ÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© API ŸÖŸàÿ≠ÿØÿ©
    ErrorResp
- ‚úÖ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ config/definitions
- ‚úÖ Ports & Adapters pattern
- ‚úÖ Error handling ŸÖŸàÿ≠ÿØ
- ‚úÖ Logging ÿ¥ÿßŸÖŸÑ
- ‚úÖ Tests ŸÉÿßŸÖŸÑÿ©

---

### 3.2 code-samples/

**ÿßŸÑŸàÿµŸÅ:** ÿπŸäŸÜÿßÿ™ ŸÉŸàÿØ ŸÑÿ£ŸÜŸÖÿßÿ∑ ÿ¥ÿßÿ¶ÿπÿ©

**ÿßŸÑÿ£ŸÖÿ´ŸÑÿ© ÿßŸÑŸÖÿ™ŸàŸÅÿ±ÿ©:**
- `log_activity_example.py` - ÿ™ÿ≥ÿ¨ŸäŸÑ ÿßŸÑŸÜÿ¥ÿßÿ∑ÿßÿ™
- `error_handling_example.py` - ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ£ÿÆÿ∑ÿßÿ°
- `async_example.py` - ÿßŸÑÿ®ÿ±ŸÖÿ¨ÿ© ÿ∫Ÿäÿ± ÿßŸÑŸÖÿ™ÿ≤ÿßŸÖŸÜÿ©
- `database_example.py` - ÿπŸÖŸÑŸäÿßÿ™ ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™

---

### 3.3 init_py_patterns/

**ÿßŸÑŸàÿµŸÅ:** 3 ÿ£ŸÜŸÖÿßÿ∑ ŸÉÿßŸÖŸÑÿ© ŸÑŸÖŸÑŸÅÿßÿ™ `__init__.py`

#### Pattern 1: Central Registry
```python
# ŸÖŸÜ 01_central_registry/__init__.py
from .status_types import Status, UserRole
from .response_types import APIResponse, ErrorResponse
from .model_mixins import TimestampMixin, AuditMixin

__all__ = [
    'Status', 'UserRole',
    'APIResponse', 'ErrorResponse',
    'TimestampMixin', 'AuditMixin'
]
```

#### Pattern 2: Lazy Loading
```python
# ŸÖŸÜ 02_lazy_loading/__init__.py
def __getattr__(name):
    if name == 'Analyzer':
        from .analyzer import Analyzer
        return Analyzer
ŸÜÿ¥ÿ±
- Docker & Kubernetes
- CI/CD pipelines
- Monitoring & Rollback

---

## 6. How to Use in Augment / ŸÉŸäŸÅŸäÿ© ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÅŸä Augment

### ÿßŸÑÿ∑ÿ±ŸäŸÇÿ© ÿßŸÑŸÖŸàÿµŸâ ÿ®Ÿáÿß:

```bash
# 1. ŸÜÿ≥ÿÆ ÿßŸÑÿ®ÿ±ŸàŸÖÿ®ÿ™ ÿ•ŸÑŸâ Augment
cp GLOBAL_GUIDELINES_v3.7.txt /path/to/augment/prompts/

# 2. ŸÜÿ≥ÿÆ ÿßŸÑÿ£ÿØŸàÿßÿ™
cp -r tools/ /path/to/augment/tools/

# 3. ŸÜÿ≥ÿÆ ÿßŸÑÿ£ŸÖÿ´ŸÑÿ©
cp -r examples/ /path/to/augment/examples/

# 4. ŸÜÿ≥ÿÆ Templates
cp -r templates/ /path/to/augment/templates/

# 5. ŸÅŸä Augmentÿå ÿ£ÿ¥ÿ± ÿ•ŸÑŸâ:
# - ÿßŸÑÿ®ÿ±ŸàŸÖÿ®ÿ™: prompts/GLOBAL_GUIDELINES_v3.7.txt
# - ÿßŸÑÿ£ÿØŸàÿßÿ™: tools/
# - ÿßŸÑÿ£ŸÖÿ´ŸÑÿ©: examples/
```

### ŸÅŸä Augment Configuration:

```yaml
# augment.yml
prompts:
  - path: prompts/GLOBAL_GUIDELINES_v3.7.txt
    name: "Global Guidelines"
    version: "3.7.0"

tools:
  - path: tools/analyze_dependencies.py
    name: "Dependency Analyzer"
  - path: tools/detect_code_duplication.py
    name: "Duplication Detector"
  - path: tools/smart_merge.py
    name: "Smart Merge"
  - path: tools/update_imports.py
    name: "Import Updater"

examples:
  -
 path: examples/simple-api/
  - path: examples/code-samples/
  - path: examples/init_py_patterns/

templates:
  - path: templates/config/
```

---

## 7. Best Practices / ÿ£ŸÅÿ∂ŸÑ ÿßŸÑŸÖŸÖÿßÿ±ÿ≥ÿßÿ™

### ÿπŸÜÿØ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ£ÿØŸàÿßÿ™:

1. **analyze_dependencies.py**
   - ÿ¥ÿ∫ŸÑŸá ÿØŸàÿ±ŸäÿßŸã (ÿ£ÿ≥ÿ®ŸàÿπŸäÿßŸã)
   - ÿ±ÿßŸÇÿ® ÿßŸÑÿßÿπÿ™ŸÖÿßÿØŸäÿßÿ™ ÿßŸÑÿØÿßÿ¶ÿ±Ÿäÿ©
   - ÿßÿ≠ŸÅÿ∏ ÿßŸÑÿ™ŸÇÿßÿ±Ÿäÿ± ŸÑŸÑŸÖŸÇÿßÿ±ŸÜÿ©

2. **detect_code_duplication.py**
   - ÿ¥ÿ∫ŸÑŸá ŸÇÿ®ŸÑ ŸÉŸÑ merge
   - ÿßÿ≥ÿ™ŸáÿØŸÅ < 5% ÿ™ŸÉÿ±ÿßÿ±
   - ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿßŸÇÿ™ÿ±ÿßÿ≠ÿßÿ™ ŸÑŸÑÿØŸÖÿ¨

3. **smart_merge.py**
   - ÿßÿ≥ÿ™ÿÆÿØŸÖ dry-run ÿ£ŸàŸÑÿßŸã
   - ÿßÿ≠ŸÅÿ∏ ŸÜÿ≥ÿÆÿ© ÿßÿ≠ÿ™Ÿäÿßÿ∑Ÿäÿ© ÿØÿßÿ¶ŸÖÿßŸã
   - ÿ±ÿßÿ¨ÿπ ÿßŸÑÿ™ÿπÿßÿ±ÿ∂ÿßÿ™ ŸäÿØŸàŸäÿßŸã

4. **update_imports.py**
   - ÿßÿÆÿ™ÿ®ÿ± ŸÅŸä branch ŸÖŸÜŸÅÿµŸÑ
   - ÿ±ÿßÿ¨ÿπ ÿßŸÑÿ™ÿ∫ŸäŸäÿ±ÿßÿ™ ŸÇÿ®ŸÑ commit
   - ÿßÿ≠ŸÅÿ∏ ŸÜÿ≥ÿÆÿ© ÿßÿ≠ÿ™Ÿäÿßÿ∑Ÿäÿ©

---

### ÿπŸÜÿØ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Templates:

1. **ŸÑÿß ÿ™ÿπÿØŸÑ Templates ŸÖÿ®ÿßÿ¥ÿ±ÿ©**
   - ÿßŸÜÿ≥ÿÆŸáÿß ŸÑŸÖÿ¥ÿ±ŸàÿπŸÉ ÿ£ŸàŸÑÿßŸã
   - ÿπÿØŸÑ ÿßŸÑŸÜÿ≥ÿÆÿ© ŸÅŸä ŸÖÿ¥ÿ±ŸàÿπŸÉ

2. **ÿ≠ÿßŸÅÿ∏ ÿπŸÑŸâ ÿßŸÑÿ™ÿ≠ÿØŸäÿ´ÿßÿ™**
   - ÿ±ÿßÿ¨ÿπ templates ÿπŸÜÿØ ÿßŸÑÿ™ÿ≠ÿØŸäÿ´
   - ÿØŸÖÿ¨ ÿßŸÑÿ™ÿ≠ÿ≥ŸäŸÜÿßÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ©

---

### ÿπŸÜÿØ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Examples:

1. **ÿßÿ≥ÿ™ÿÆÿØŸÖŸáÿß ŸÉŸÖÿ±ÿ¨ÿπ**
   - ŸÑÿß ÿ™ŸÜÿ≥ÿÆŸáÿß ŸÉŸÖÿß ŸáŸä
   - ÿßŸÅŸáŸÖ ÿßŸÑŸÖŸÅÿßŸáŸäŸÖ Ÿàÿ∑ÿ®ŸÇŸáÿß

2. **ÿ™ÿπŸÑŸÖ ŸÖŸÜ ÿßŸÑÿ£ŸÜŸÖÿßÿ∑**
   - ŸÉŸÑ ŸÖÿ´ÿßŸÑ 
st** if no config exists
2. **Use config values** throughout the project
3. **Respect project phase** in all operations
4. **Never hardcode** project-specific values
5. **Backup before** destructive operations
6. **Verify** before production deployment
7. **Log** all important operations
8. **Notify user** of phase transitions

**For Users:**

1. **Answer questions carefully** - they affect the entire project
2. **Review config** before deployment
3. **Backup** before `start deploy`
4. **Test thoroughly** in development
5. **Use staging** if available
6. **Monitor** after deployment
7. **Keep credentials** secure

---

### 64.13 Integration with Existing Sections

**This section integrates with:**

- **Section 0-3:** Core directives and constraints
- **Section 40:** Definitions Registry (uses config)
- **Section 63:** Global Repository (tools use config)
- **All sections:** Use config values instead of hardcoded

**Example Integration:**

```python
# Section 40: Definitions Registry
# 
Before:
APP_NAME = "Gaara ERP"

# After:
from .global.project_config import load_config
config = load_config()
APP_NAME = config['project']['name']
```

---

### 64.14 Summary

**This section provides:**

‚úÖ Interactive project setup questionnaire  
‚úÖ Configuration file management  
‚úÖ State management (Development/Production)  
‚úÖ `start deploy` command workflow  
‚úÖ Admin panel auto-open  
‚úÖ Setup wizard integration  
‚úÖ Phase-specific behavior  
‚úÖ Best practices for Augment and users

**Result:**

- No more hardcoded values
- Project-specific configuration
- Smooth development-to-production transition
- Automated deployment process
- Professional setup experience

---

**End of Section 64**



================================================================================
# Section 65: Automatic Project Analysis

## Overview

When working with **existing projects**, Augment should automatically analyze the project structure, detect technologies, and generate project-specific configurati

================================================================================
CRITICAL MISSING CONTENT - Deep Search Recovery
================================================================================

```bash
# ÿ™ÿ£ŸÉÿØ ŸÖŸÜ Python version
python --version  # Ÿäÿ¨ÿ® ÿ£ŸÜ ŸäŸÉŸàŸÜ >= 3.8

# ÿ´ÿ®ÿ™ ÿßŸÑŸÖÿ™ÿ∑ŸÑÿ®ÿßÿ™
pip install -r requirements.txt

# ÿ¥ÿ∫ŸÑ ŸÖÿπ verbose
python tools/analyze_dependencies.py . --verbose
```

```python
# scripts/generate_imports_map.py
import ast
import os
from pathlib import Path
from typing import Dict, List, Set

def analyze_python_imports(file_path: str) -> Dict:
    """Analyze imports in a Python file"""
    with open(file_path) as f:
        tree = ast.parse(f.read())
    
    imports = []
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                imports.append({
                    'module': alias.name,
                    'alias': alias.asname,
                    'type': 'import'
                })
        elif isinstance(node, ast.ImportFrom):
            for alias in node.names:
                imports.append({
                    'module': node.module,
                    'name': alias.name,
                    'alias': alias.asname,
                    'type': 'from'
                })
    
    return imports

def find_circular_dependencies(import_graph: Dict) -> List:
    """Detect circular dependencies"""
    # Implementation using DFS
    pass

def generate_imports_map(root_dir: str):
    """Generate complete imports map"""
    # Scan all Python files
    # Analyze imports
    # Detect circular dependencies
    # Generate markdown report
    pass

if __name__ == '__main__':
    generate_imports_map('./backend')
    generate_imports_map('./frontend')
```

```python
# scripts/detect_duplicates.py
import ast
import difflib
from pathlib import Path
from typing import List, Dict

class DuplicateDetector:
    def __init__(self, threshold=0.8):
        self.threshold = threshold  # Similarity threshold
    
    def get_function_signature(self, func_node: ast.FunctionDef) -> str:
        """Extract normalized function signature"""
        args = [arg.arg for arg in func_node.args.args]
        return f"{func_node.name}({', '.join(args)})"
    
    def get_class_signature(self, class_node: ast.ClassDef) -> str:
        """Extract class signature"""
        methods = []
        for node in class_node.body:
            if isinstance(node, ast.FunctionDef):
                methods.append(node.name)
        return f"{class_node.name}: {', '.join(sorted(methods))}"
    
    def normalize_code(self, code: str) -> str:
        """Normalize code for comparison"""
        # Remove comments, whitespace, docstrings
        tree = ast.parse(code)
        return ast.unparse(tree)
    
    def find_similar_files(self, dir_path: str) -> List[Dict]:
    # ... (code truncated for brevity) ...
    # See full example in examples/ directory
    
    if file_duplicates or func_duplicates:
        return 1  # Exit with error
    else:
        print("‚úÖ No duplicates found!")
        return 0

if __name__ == '__main__':
    import sys
    sys.exit(main())
```

```python
# scripts/pre_dev_check.py
import sys
from validate_env import validate_env
from pathlib import Path

def pre_development_check():
    """Run all pre-development checks"""
    errors = []
    
    # 1. Check .env
    print("1. Checking environment...")
    env_result = validate_env()
    if not env_result['valid']:
        errors.extend(env_result['errors'])
    
    # 2. Check documentation exists
    print("2. Checking documentation...")
    required_docs = [
        'docs/File_Map.md',
        'docs/Class_Registry.md',
        'docs/Imports_Map.md',
        'docs/TODO.md',
    ]
    for doc in required_docs:
        if not Path(doc).exists():
            errors.append(f"‚ùå Missing required documentation: {doc}")
    
    # 3. Check for uncommitted changes
    print("3. Checking git status...")
    import subprocess
    result = subprocess.run(['git', 'status', '--porcelain'], capture_output=True)
    if result.stdout:
        errors.append("‚ö†Ô∏è You have uncommitted changes. Commit or stash them first.")
    
    # Summary
    if errors:
        print("\n‚ùå Pre-development checks failed:")
        for error in errors:
            print(f"  {error}")
        print("\nPlease fix the issues above before starting development.")
        return 1
    else:
        print("\n‚úÖ All pre-development checks passed!")
        print("You're ready to start coding.")
        return 0

if __name__ == '__main__':
    sys.exit(pre_development_check())
```

```python
"""
File: scripts/document_imports.py
Generate import/export documentation
"""

import ast
import os
from pathlib import Path
from collections import defaultdict

def analyze_file(filepath: Path) -> dict:
    """Analyze Python file for imports and exports"""
    with open(filepath, 'r', encoding='utf-8') as f:
        try:
            tree = ast.parse(f.read())
        except:
            return {}
    
    imports = []
    exports = []
    
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                imports.append(alias.name)
        
        elif isinstance(node, ast.ImportFrom):
            module = node.module or ''
            for alias in node.names:
                imports.append(f"{module}.{alias.name}")
        
        elif isinstance(node, ast.Assign):
            for target in node.targets:
                if isinstance(target, ast.Name) and target.id == '__all__':
                    if isinstance(node.value, ast.List):
                        exports = [
                            elt.s for elt in node.value.elts
                            if isinstance(elt, ast.Str)
                        ]
    
    return {
        'imports': imports,
        'exports': exports
    }

def generate_documentation(root_dir: str, output_file: str):
    """Generate import/export documentation"""
    
    modules = {}
    
    for filepath in Path(root_dir).rglob('*.py'):
        if 'venv' in str(filepath) or '.venv' in str(filepath):
            continue
        
        rel_path = filepath.relative_to(root_dir)
        analysis = analyze_file(filepath)
        
        if analysis:
            modules[str(rel_path)] = analysis
    
    # Write documentation
    with open(output_file, 'w') as f:
        f.write("# Import/Export Documentation\n\n")
        f.write(f"Generated: {datetime.now().isoformat()}\n\n")
        
        for module, data in sorted(modules.items()):
            f.write(f"## {module}\n\n")
            
            if data.get('exports'):
                f.write("### Exports\n")
                for exp in data['exports']:
                    f.write(f"- `{exp}`\n")
                f.write("\n")
            
            if data.get('imports'):
                f.write("### Imports\n")
                for imp in data['imports']:
                    f.write(f"- `{imp}`\n")
                f.write("\n")
            
            f.write("---\n\n")

if __name__ == "__main__":
    import sys
    from datetime import datetime
    
    root = sys.argv[1] if len(sys.argv) > 1 else "."
    output = sys.argv[2] if len(sys.argv) > 2 else "docs/Imports_Exports.md"
    
    generate_documentation(root, output)
    print(f"‚úÖ Documentation generated: {output}")
```

```python
#!/usr/bin/env python3
"""Generate comprehensive module map."""

import ast
from pathlib import Path
from collections import defaultdict

def analyze_module(file_path):
    """Analyze a Python module."""
    with open(file_path) as f:
        try:
            tree = ast.parse(f.read())
        except SyntaxError:
            return None
    
    info = {
        'classes': [],
        'functions': [],
        'imports': [],
        'dependencies': set()
    }
    
    for node in ast.walk(tree):
        if isinstance(node, ast.ClassDef):
            info['classes'].append(node.name)
        elif isinstance(node, ast.FunctionDef):
            if not node.name.startswith('_'):
                info['functions'].append(node.name)
        elif isinstance(node, (ast.Import, ast.ImportFrom)):
            if isinstance(node, ast.ImportFrom) and node.module:
                info['dependencies'].add(node.module.split('.')[0])
    
    return info

def generate_map():
    """Generate module map."""
    modules = defaultdict(dict)
    
    for py_file in Path('.').rglob('*.py'):
        if '__pycache__' in str(py_file) or 'venv' in str(py_file):
            continue
        
        info = analyze_module(py_file)
        if info:
            modules[str(py_file)] = info
    
    # Write to markdown
    with open('docs/Module_Map.md', 'w') as f:
        f.write("# Module Map\n\n")
        f.write("**Generated:** Auto-generated\n\n")
        f.write("## Modules by Directory\n\n")
        
        # Group by directory
        by_dir = defaultdict(list)
        for path in sorted(modules.keys()):
            dir_name = str(Path(path).parent)
            by_dir[dir_name].append(path)
        
        for dir_name in sorted(by_dir.keys()):
            f.write(f"### `{dir_name}/`\n\n")
            for path in sorted(by_dir[dir_name]):
                info = modules[path]
                f.write(f"#### `{Path(path).name}`\n\n")
                
                if info['classes']:
                    f.write("**Classes:**\n")
                    for cls in info['classes']:
                        f.write(f"- `{cls}`\n")
                    f.write("\n")
                
                if info['functions']:
                    f.write("**Functions:**\n")
                    for func in info['functions']:
                        f.write(f"- `{func}()`\n")
                    f.write("\n")
                
                if info['dependencies']:
                    f.write("**Dependencies:**\n")
                    for dep in sorted(info['dependencies']):
                        f.write(f"- `{dep}`\n")
                    f.write("\n")
        
        # Dependency graph
        f.write("## Dependency Graph\n\n")
        f.write("```mermaid\n")
        f.write("graph TD\n")
        for path, info in modules.items():
            module_name = Path(path).stem
            for dep in info['dependencies']:
                f.write(f"  {module_name} --> {dep}\n")
        f.write("```\n")

if __name__ == '__main__':
    generate_map()
    print("‚úÖ Module map generated: docs/Module_Map.md")
```

```python
#!/usr/bin/env python3
"""Suggest refactoring for large files/functions."""

import ast
from pathlib import Path

def analyze_file(file_path):
    """Analyze file for refactoring opportunities."""
    with open(file_path) as f:
        content = f.read()
        lines = content.split('\n')
    
    try:
        tree = ast.parse(content)
    except SyntaxError:
        return None
    
    issues = []
    
    # Check file length
    if len(lines) > 500:
        issues.append(f"File too long: {len(lines)} lines (max 500)")
    
    # Check function lengths
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            func_lines = node.end_lineno - node.lineno
            if func_lines > 50:
                issues.append(
                    f"Function '{node.name}' too long: {func_lines} lines (max 50)"
                )
        
        elif isinstance(node, ast.ClassDef):
            class_lines = node.end_lineno - node.lineno
            if class_lines > 300:
                issues.append(
                    f"Class '{node.name}' too long: {class_lines} lines (max 300)"
                )
    
    return issues

def main():
    """Check all Python files."""
    all_issues = {}
    
    for py_file in Path('.').rglob('*.py'):
        if '__pycache__' in str(py_file):
            continue
        
        issues = analyze_file(py_file)
        if issues:
            all_issues[str(py_file)] = issues
    
    if all_issues:
        print("üîß Refactoring Suggestions:\n")
        for file_path, issues in all_issues.items():
            print(f"üìÑ {file_path}")
            for issue in issues:
                print(f"   ‚ö†Ô∏è  {issue}")
            print()
        
        print(f"Total files needing refactoring: {len(all_issues)}")
    else:
        print("‚úÖ All files are well-modularized!")

if __name__ == '__main__':
    main()
```

```python
# Good - clear and explicit
from mypackage.submodule import MyClass

# Avoid - can be confusing
from .submodule import MyClass  # OK in __init__.py only
```

```python
# plugins/__init__.py
"""
Plugin system with dynamic discovery
"""

import importlib
import pkgutil
from typing import Dict, Type

# Plugin registry
_plugins: Dict[str, Type] = {}


def discover_plugins():
    """Automatically discover and register plugins"""
    package = __package__
    for _, name, _ in pkgutil.iter_modules([package.replace('.', '/')]):
        module = importlib.import_module(f'{package}.{name}')
        if hasattr(module, 'register_plugin'):
            plugin = module.register_plugin()
            _plugins[plugin.name] = plugin


def get_plugin(name: str):
    """Get plugin by name"""
    if not _plugins:
        discover_plugins()
    return _plugins.get(name)


__all__ = [
    'discover_plugins',
    'get_plugin',
]
```

```python
# compat/__init__.py
"""
Compatibility layer for different Python versions
"""

import sys

# Version-specific imports
if sys.version_info >= (3, 10):
    from typing import TypeAlias
else:
    from typing_extensions import TypeAlias

# Platform-specific imports
if sys.platform == 'win32':
    from .windows import WindowsSpecific as PlatformSpecific
else:
    from .unix import UnixSpecific as PlatformSpecific

__all__ = [
    'TypeAlias',
    'PlatformSpecific',
]
```

```python
# mysmallapp/__init__.py
"""Small application - simple structure"""

from .main import run_app
from .config import Config
from .utils import helper_function

__version__ = '0.1.0'
__all__ = ['run_app', 'Config', 'helper_function']
```

```python
#!/usr/bin/env python3
"""
Script: check_init_py.py
Check __init__.py files for common issues
"""

import ast
import sys
from pathlib import Path


def check_init_file(filepath: Path) -> list[str]:
    """Check __init__.py for issues"""
    issues = []
    
    with open(filepath, 'r') as f:
        content = f.read()
    
    try:
        tree = ast.parse(content)
    except SyntaxError as e:
        return [f"Syntax error: {e}"]
    
    # Check for docstring
    if not ast.get_docstring(tree):
        issues.append("Missing module docstring")
    
    # Check for __all__
    has_all = any(
        isinstance(node, ast.Assign) and
        any(isinstance(t, ast.Name) and t.id == '__all__' for t in node.targets)
        for node in tree.body
    )
    
    # Check for star imports
    has_star_import = any(
        isinstance(node, ast.ImportFrom) and
        any(isinstance(alias, ast.alias) and alias.name == '*' for alias in node.names)
        for node in tree.body
    )
    
    if has_star_import and not has_all:
        issues.append("Star import without __all__ definition")
    
    # Check for heavy initialization
    function_calls = [
        node for node in ast.walk(tree)
        if isinstance(node, ast.Call) and isinstance(node.func, ast.Name)
    ]
    
    if len(function_calls) > 5:
        issues.append(f"Many function calls ({len(function_calls)}) - possible heavy initialization")
    
    return issues


def main():
    """Check all __init__.py files in project"""
    project_root = Path.cwd()
    init_files = list(project_root.rglob('__init__.py'))
    
    print(f"Checking {len(init_files)} __init__.py files...\n")
    
    total_issues = 0
    for init_file in init_files:
        issues = check_init_file(init_file)
        if issues:
            print(f"‚ùå {init_file.relative_to(project_root)}")
            for issue in issues:
                print(f"   - {issue}")
            print()
            total_issues += len(issues)
    
    if total_issues == 0:
        print("‚úÖ All __init__.py files look good!")
    else:
        print(f"Found {total_issues} issues in {len(init_files)} files")
        sys.exit(1)


if __name__ == '__main__':
    main()
```

```python
# Before
from old_module import func
import old_module
import old_module as om
from old_module.sub import Class

# After
from new_module import func
import new_module
import new_module as om
from new_module.sub import Class
```

```python
# ŸÖŸÜ 02_lazy_loading/__init__.py
def __getattr__(name):
    if name == 'Analyzer':
        from .analyzer import Analyzer
        return Analyzer
    raise AttributeError(f"module has no attribute '{name}'")
```

```python
# Section 40: Definitions Registry
# Before:
APP_NAME = "Gaara ERP"

# After:
from .global.project_config import load_config
config = load_config()
APP_NAME = config['project']['name']
```



================================================================================
END OF 02_ANALYSIS
================================================================================


================================================================================
MODULE: 03_PLANNING
================================================================================

=================================================================================
PROJECT PLANNING - Task Breakdown and Planning
=================================================================================

Version: 5.0.0
Type: Core - Planning

This prompt guides project planning and task breakdown.

=================================================================================
OVERVIEW
=================================================================================

After gathering requirements (01_requirements.txt) or analyzing existing project
(02_analysis.txt), use this prompt to:

1. Break down project into phases
2. Create task lists
3. Estimate timelines
4. Set priorities
5. Define milestones

=================================================================================
PLANNING WORKFLOW
=================================================================================

## Step 1: Define Project Scope

### Questions to Answer:
- What is the main goal?
- Who are the users?
- What are the core features?
- What are nice-to-have features?
- What are the constraints (time, budget, resources)?

### Output: Project Scope Document

```markdown
# Project Scope: {{PROJECT_NAME}}

## Goal
[One-sentence description of the project goal]

## Target Users
- [User type 1]
- [User type 2]

## Core Features (Must-Have)
1. [Feature 1]
2. [Feature 2]
3. [Feature 3]

## Additional Features (Nice-to-Have)
1. [Feature A]
2. [Feature B]

## Constraints
- **Timeline:** [X weeks/months]
- **Budget:** [if applicable]
- **Team Size:** [number of developers]
- **Technology:** [any tech constraints]

## Out of Scope
- [What we're NOT building]
```

## Step 2: Break Down into Phases

### Standard Phases for New Projects:

**Phase 1: Setup & Foundation (Week 1)**
- Project initialization
- Development environment setup
- Database schema design
- Basic project structure
- CI/CD pipeline setup

**Phase 2: Core Backend (Weeks 2-3)**
- Database models
- API endpoints
- Authentication
- Business logic
- Unit tests

**Phase 3: Core Frontend (Weeks 3-4)**
- UI components
- Pages/Views
- State management
- API integration
- Responsive design

**Phase 4: Integration (Week 5)**
- Frontend-Backend integration
- End-to-end testing
- Bug fixes
- Performance optimization

**Phase 5: Polish & Deploy (Week 6)**
- UI/UX improvements
- Documentation
- Security audit
- Deployment
- Monitoring setup

### Adjust Based on Project Type:

**API-Only Project:**
- Skip Phase 3 (Frontend)
- Expand Phase 2 (Backend)
- Add API documentation phase

**Data Science Project:**
- Phase 1: Data collection & exploration
- Phase 2: Data cleaning & preprocessing
- Phase 3: Model development
- Phase 4: Model evaluation
- Phase 5: Deployment & monitoring

**Mobile App:**
- Add platform-specific phases (iOS, Android)
- Add app store submission phase

## Step 3: Create Detailed Task Lists

### Phase 1 Example: Setup & Foundation

```markdown
## Phase 1: Setup & Foundation

### 1.1 Project Initialization
- [ ] Create Git repository
- [ ] Initialize backend project (Django/FastAPI/etc.)
- [ ] Initialize frontend project (React/Vue/etc.)
- [ ] Set up project structure
- [ ] Create README.md

### 1.2 Development Environment
- [ ] Create .env.example
- [ ] Set up Docker containers
- [ ] Create docker-compose.yml
- [ ] Configure database
- [ ] Test local development setup

### 1.3 Database Schema
- [ ] Design ER diagram
- [ ] Create models/schemas
- [ ] Create migrations
- [ ] Seed initial data
- [ ] Document schema

### 1.4 CI/CD Setup
- [ ] Create GitHub Actions workflow
- [ ] Set up linting
- [ ] Set up testing
- [ ] Configure deployment pipeline

**Estimated Time:** 5-7 days
**Dependencies:** None
**Deliverables:** Working development environment
```

### Phase 2 Example: Core Backend

```markdown
## Phase 2: Core Backend

### 2.1 User Management
- [ ] User model
- [ ] Registration endpoint
- [ ] Login endpoint
- [ ] JWT token generation
- [ ] Password reset
- [ ] Email verification
- [ ] Unit tests

### 2.2 Core Models
- [ ] [Model 1] model & serializer
- [ ] [Model 2] model & serializer
- [ ] [Model 3] model & serializer
- [ ] Relationships between models
- [ ] Model validation
- [ ] Unit tests

### 2.3 API Endpoints
- [ ] CRUD for [Model 1]
- [ ] CRUD for [Model 2]
- [ ] CRUD for [Model 3]
- [ ] Filtering & pagination
- [ ] API documentation
- [ ] Integration tests

### 2.4 Business Logic
- [ ] [Business rule 1]
- [ ] [Business rule 2]
- [ ] Error handling
- [ ] Logging
- [ ] Unit tests

**Estimated Time:** 10-14 days
**Dependencies:** Phase 1 complete
**Deliverables:** Functional API
```

## Step 4: Estimate Timelines

### Estimation Techniques:

**1. T-Shirt Sizing:**
- XS: 1-2 hours
- S: 2-4 hours
- M: 4-8 hours (half day to full day)
- L: 1-2 days
- XL: 3-5 days
- XXL: 1+ weeks

**2. Story Points (Fibonacci):**
- 1 point: Very simple task
- 2 points: Simple task
- 3 points: Medium task
- 5 points: Complex task
- 8 points: Very complex task
- 13 points: Extremely complex (should be broken down)

**3. Time-Based:**
- Break tasks into 1-4 hour chunks
- Sum up for total estimate
- Add 20-30% buffer for unknowns

### Example Timeline:

```
Project: E-commerce Platform
Total Estimated Time: 8 weeks

Week 1: Setup & Foundation
  - Days 1-2: Project initialization
  - Days 3-4: Database schema
  - Day 5: CI/CD setup

Week 2-3: Backend Development
  - Week 2: User management & authentication
  - Week 3: Product catalog & cart

Week 4-5: Frontend Development
  - Week 4: User interface & navigation
  - Week 5: Product pages & checkout

Week 6: Integration & Testing
  - Days 1-3: Integration
  - Days 4-5: Testing & bug fixes

Week 7: Polish
  - Days 1-2: UI/UX improvements
  - Days 3-4: Performance optimization
  - Day 5: Security audit

Week 8: Deployment
  - Days 1-2: Staging deployment
  - Days 3-4: Production deployment
  - Day 5: Monitoring & documentation
```

## Step 5: Set Priorities

### Priority Levels:

**P0 (Critical):**
- Blocks entire project
- Must be done first
- Example: Database setup, authentication

**P1 (High):**
- Core features
- Needed for MVP
- Example: User registration, product listing

**P2 (Medium):**
- Important but not critical
- Can be done after MVP
- Example: Email notifications, advanced search

**P3 (Low):**
- Nice to have
- Can be postponed
- Example: Dark mode, social sharing

### Prioritization Matrix:

```
High Impact, Low Effort ‚Üí Do First (P0-P1)
High Impact, High Effort ‚Üí Do Second (P1)
Low Impact, Low Effort ‚Üí Do Third (P2)
Low Impact, High Effort ‚Üí Do Last or Skip (P3)
```

## Step 6: Define Milestones

### Milestone Types:

**1. Development Milestones:**
- Backend API complete
- Frontend UI complete
- Integration complete

**2. Feature Milestones:**
- User authentication working
- Payment processing working
- Admin dashboard complete

**3. Quality Milestones:**
- 80% test coverage achieved
- All security issues resolved
- Performance targets met

**4. Deployment Milestones:**
- Staging deployment successful
- Production deployment successful
- Monitoring active

### Example Milestones:

```
Milestone 1: Development Environment Ready (End of Week 1)
  - Git repository set up
  - Docker containers running
  - Database schema created
  - CI/CD pipeline active

Milestone 2: Backend MVP Complete (End of Week 3)
  - User authentication working
  - Core API endpoints functional
  - 70% test coverage
  - API documentation published

Milestone 3: Frontend MVP Complete (End of Week 5)
  - All main pages implemented
  - API integration complete
  - Responsive design working
  - Basic tests passing

Milestone 4: Production Ready (End of Week 7)
  - All features complete
  - 80% test coverage
  - Security audit passed
  - Performance optimized

Milestone 5: Deployed (End of Week 8)
  - Production deployment successful
  - Monitoring active
  - Documentation complete
  - Handoff ready
```

=================================================================================
PLANNING TEMPLATES
=================================================================================

## Template 1: Simple Web Application

```
Phase 1: Setup (3 days)
  - Initialize project
  - Set up database
  - Create basic structure

Phase 2: Backend (1 week)
  - Models & migrations
  - API endpoints
  - Authentication

Phase 3: Frontend (1 week)
  - UI components
  - Pages
  - API integration

Phase 4: Deploy (2 days)
  - Docker setup
  - Deployment
  - Monitoring

Total: 3 weeks
```

## Template 2: API Service

```
Phase 1: Setup (2 days)
  - Initialize project
  - Database schema
  - CI/CD

Phase 2: Core API (1 week)
  - Endpoints
  - Authentication
  - Validation

Phase 3: Advanced Features (1 week)
  - Rate limiting
  - Caching
  - Webhooks

Phase 4: Documentation & Deploy (3 days)
  - OpenAPI docs
  - Deployment
  - Monitoring

Total: 3 weeks
```

## Template 3: Data Science Project

```
Phase 1: Data Collection (1 week)
  - Identify data sources
  - Collect data
  - Store data

Phase 2: Data Preparation (1 week)
  - Clean data
  - Transform data
  - Feature engineering

Phase 3: Model Development (2 weeks)
  - Exploratory analysis
  - Model training
  - Model evaluation

Phase 4: Deployment (1 week)
  - Create API
  - Deploy model
  - Set up monitoring

Total: 5 weeks
```

=================================================================================
RISK MANAGEMENT
=================================================================================

## Identify Risks

**Technical Risks:**
- New technology/framework
- Complex integrations
- Performance requirements
- Scalability needs

**Resource Risks:**
- Limited team size
- Skill gaps
- Time constraints
- Budget limitations

**External Risks:**
- Third-party API dependencies
- Regulatory requirements
- Market changes

## Mitigation Strategies

**For Technical Risks:**
- Proof of concept early
- Allocate buffer time
- Have backup solutions

**For Resource Risks:**
- Training/upskilling
- Hire contractors if needed
- Reduce scope if necessary

**For External Risks:**
- Have fallback providers
- Stay updated on regulations
- Build flexibility into design

=================================================================================
AGILE PLANNING
=================================================================================

## Sprint Planning (2-week sprints)

**Sprint 1:**
- Goal: Development environment ready
- Tasks: [from Phase 1]

**Sprint 2:**
- Goal: User authentication working
- Tasks: [from Phase 2.1]

**Sprint 3:**
- Goal: Core API complete
- Tasks: [from Phase 2.2-2.3]

**Sprint 4:**
- Goal: Frontend foundation
- Tasks: [from Phase 3.1]

And so on...

## Daily Standups

**Questions:**
1. What did I complete yesterday?
2. What will I work on today?
3. Any blockers?

## Sprint Reviews

**End of each sprint:**
- Demo completed features
- Gather feedback
- Adjust plan if needed

=================================================================================
TRACKING PROGRESS
=================================================================================

## Tools

**Project Management:**
- GitHub Projects
- Jira
- Trello
- Asana

**Time Tracking:**
- Toggl
- Harvest
- Clockify

**Documentation:**
- Notion
- Confluence
- Google Docs

## Metrics to Track

**Velocity:**
- Story points completed per sprint
- Tasks completed per week

**Quality:**
- Test coverage %
- Bug count
- Code review time

**Timeline:**
- On track / ahead / behind
- Estimated completion date
- Actual vs estimated time

=================================================================================
COMMUNICATION PLAN
=================================================================================

## Stakeholder Updates

**Daily:** Team standup
**Weekly:** Progress report to stakeholders
**Bi-weekly:** Sprint review & planning
**Monthly:** Milestone review

## Status Report Template

```
# Weekly Status Report - Week [X]

## Completed This Week
- [Task 1]
- [Task 2]
- [Task 3]

## In Progress
- [Task A] - 60% complete
- [Task B] - 30% complete

## Planned for Next Week
- [Task X]
- [Task Y]

## Blockers
- [Blocker 1] - Waiting for [X]
- [Blocker 2] - Need help with [Y]

## Risks
- [Risk 1] - Mitigation: [action]

## Overall Status
On Track / At Risk / Behind Schedule
```

=================================================================================
NEXT STEPS
=================================================================================

After creating the plan:

1. **Review with team/stakeholders**
2. **Get approval**
3. **Set up project management tool**
4. **Create first sprint/phase tasks**
5. **Start development!**

Load relevant prompts based on tech stack:
- Backend ‚Üí 10_backend.txt
- Frontend ‚Üí 11_frontend.txt
- Database ‚Üí 12_database.txt
- APIs ‚Üí 13_api.txt

=================================================================================
END OF PLANNING PROMPT
=================================================================================



================================================================================
ADDITIONAL CONTENT FROM v4.2.0
================================================================================

40. ORGANIZED DEFINITIONS STRUCTURE

--------------------------------------------------------------------------------

## 62. __INIT__.PY PATTERNS & BEST PRACTICES

--------------------------------------------------------------------------------



================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

idation, allowlist
- Clickjacking: X-Frame-Options
- Brute force: rate limiting, lockout

G) Compliance
- GDPR: data export, deletion, consent
- HIPAA: encryption, audit logs (if applicable)
- SOC 2: security controls, audits
- PCI DSS: if handling payments

‚∏ª

9) DEVOPS & INFRASTRUCTURE (Expanded in v3.0)

A) Containerization (Docker)
- Multi-stage builds
- Non-root user
- Minimal base images (Alpine)
- .dockerignore for efficiency
- Health checks in Dockerfile
- Security scanning (Trivy)

B) Orchestration (Kubernetes)
- Deployments with rolling updates
- Services: ClusterIP, LoadBalancer
- ConfigMaps & Secrets
- Horizontal Pod Autoscaler (HPA)
- Ingress with TLS
- Resource limits & requests

C) CI/CD Pipelines
- GitHub Actions / GitLab CI
- Stages: Lint ‚Üí Test ‚Üí Security ‚Üí Build ‚Üí Deploy
- Quality gates: coverage >80%, no critical vulns
- Automated deployments: staging (auto), production (manual)
- Rollback strategy: blue-green, canary

D) Infrastructure as Code
- Terraform for cloud
 configurable (high/normal/low)
- Storage: append-only DB table
- Retention: 12 months, then archive
- UI: filterable timeline
- Security: alert on suspicious patterns

B) backup_management Module
- Automated: daily full, hourly incremental
- Storage: S3/GCS, encrypted
- Retention: 30 days online, 1 year archive
- Tested restore: monthly
- Monitoring: backup success rate

C) system_health Module
- Endpoints: /health, /ready
- Checks: DB connection, Redis, external APIs
- Response time: <100ms
- Used by: load balancers, Kubernetes

D) system_monitoring Module
- Metrics: CPU, memory, disk, network
- Application: request rate, latency, errors
- Business: active users, transactions
- Dashboards: Grafana
- Alerts: threshold-based + anomaly detection

‚∏ª

14) RESILIENCE & CIRCUIT BREAKERS (from v2.3)

A) Circuit Breaker States
- CLOSED: normal operation
- OPEN: failures exceed threshold, fail fast
- HALF_OPEN: test if service recovered

B) Configuration
- Failure threshold: 50% over 10 reques
tests pass

Documentation:
- [ ] All 30+ docs files present
- [ ] API docs complete
- [ ] Runbooks written
- [ ] Architecture diagrams updated

Infrastructure:
- [ ] Docker images scanned
- [ ] Kubernetes manifests validated
- [ ] HPA configured
- [ ] Backups automated
- [ ] Monitoring configured

CI/CD:
- [ ] All pipelines green
- [ ] Quality gates passed
- [ ] Deployment strategy tested
- [ ] Rollback procedure tested

‚∏ª

END OF GLOBAL_GUIDELINES v3.0

This is the COMPLETE, production-ready edition consolidating all previous versions and expansions.

For implementation details, see:
- guides/DOCKER_INTEGRATION.md
- guides/KUBERNETES_INTEGRATION.md
- guides/CICD_INTEGRATION.md
- guides/MATURITY_MODEL.md
- examples/code-samples/log_activity_example.py

OSF Score: Aim for 0.85+ (Level 4: Optimizing)
Maturity Level: Target Level 3-4 for production systems

‚∏ª

Version: 3.0.0
Date: 2025-10-28
Status: Production Ready
License: Proprietary

‚∏ª

21) SUDI DEVICE IDENTITY (NEW in v3.1)

A) Devic
**Module:** module_name
**File:** path/to/file.py

### Description
Detailed description of the error that occurred.

### Root Cause
What caused this error to happen.

### Impact
- What broke
- Who was affected
- Duration of issue

### Solution Applied
```python
# Code that fixed the issue
def fixed_function():
    # Corrected implementation
    pass
```

### Prevention Measures
1. Added validation for X
2. Implemented error handling for Y
3. Added unit test to catch this scenario

### Related Errors
- Error #YYY (similar issue)

### Lessons Learned
- Always validate input X
- Never assume Y
- Use Z pattern for this scenario

---
```

### 48.2 Error Categories

**1. Logic Errors**
- Incorrect algorithm
- Wrong assumptions
- Edge cases not handled

**2. Integration Errors**
- API mismatch
- Database schema mismatch
- Frontend/Backend disconnect

**3. Configuration Errors**
- Wrong environment variables
- Missing dependencies
- Incorrect permissions

**4. Performance Errors**
- N+1 querie
ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿ•ÿ¨ŸÖÿßŸÑŸä ŸÖŸÜ ÿßŸÑÿπŸÜÿßÿµÿ± ÿßŸÑŸÖÿ±ÿ™ÿ®ÿ∑ÿ©.
        
        Returns:
            Decimal: ÿßŸÑÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑŸÖÿ≠ÿ≥Ÿàÿ®
        """
        total = sum(
            item.subtotal for item in self.items.all()
        )
        self.total = Decimal(str(total))
        self.save()
        return self.total
```

### 54.4 Quality Checklist

**Every module MUST have:**
- [ ] Professional folder structure
- [ ] Comprehensive models with relationships
- [ ] State management (if applicable)
- [ ] Arabic docstrings
- [ ] Custom methods (confirm/cancel/compute)
- [ ] Validation logic
- [ ] Unit tests (‚â•80% coverage)
- [ ] Integration tests
- [ ] API endpoints
- [ ] Frontend components
- [ ] Permissions/RBAC
- [ ] README.md
- [ ] Custom reports (if applicable)
- [ ] Smart filters

---

## 55. Constants & Definitions Registry

### 55.1 Centralized Constants

**Location:** `config/constants.py`

```python
"""
File: config/constants.py
Module: config.constants
Created: 2025-01-15
Author: Team
Description: System-wide con
plementation Gap Analysis

### 57.1 Gap Analysis Checklist

**Before marking module as complete:**

**Frontend/Backend Integration:**
- [ ] All backend endpoints have frontend consumers
- [ ] All frontend features have backend support
- [ ] API contracts match on both sides
- [ ] Error handling is consistent

**Sub-screens and Buttons:**
- [ ] All designed screens are implemented
- [ ] All buttons have click handlers
- [ ] All forms submit to correct endpoints
- [ ] All modals/dialogs work correctly

**Routing:**
- [ ] All routes are defined
- [ ] Navigation works between all pages
- [ ] Deep linking works
- [ ] 404 pages handled
- [ ] Protected routes require auth

**Database Integration:**
- [ ] All models are created
- [ ] Migrations are applied
- [ ] Relationships are correct (ForeignKey, ManyToMany)
- [ ] Indexes are in place
- [ ] Constraints are enforced (unique, check)

**Testing:**
- [ ] Unit tests exist and pass
- [ ] Integration tests exist and pass
- [ ] E2E tests for criti
 pattern
‚îÇ       ‚îî‚îÄ‚îÄ definitions/
‚îÇ           ‚îú‚îÄ‚îÄ __init__.py
‚îÇ           ‚îú‚îÄ‚îÄ common.py                # ÿ™ÿπÿ±ŸäŸÅÿßÿ™ ÿπÿßŸÖÿ©
‚îÇ           ‚îú‚îÄ‚îÄ core.py                  # ÿ™ÿπÿ±ŸäŸÅÿßÿ™ ÿ£ÿ≥ÿßÿ≥Ÿäÿ©
‚îÇ           ‚îî‚îÄ‚îÄ custom.py                # ÿ™ÿπÿ±ŸäŸÅÿßÿ™ ŸÖÿÆÿµÿµÿ©
‚îÇ
‚îú‚îÄ‚îÄ examples/                            # ÿßŸÑÿ£ŸÖÿ´ŸÑÿ© üí°
‚îÇ   ‚îú‚îÄ‚îÄ simple-api/                      # ŸÖÿ´ÿßŸÑ API ÿ®ÿ≥Ÿäÿ∑
‚îÇ   ‚îú‚îÄ‚îÄ code-samples/                    # ÿπŸäŸÜÿßÿ™ ŸÉŸàÿØ
‚îÇ   ‚îî‚îÄ‚îÄ init_py_patterns/                # ÿ£ŸÜŸÖÿßÿ∑ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ 01_central_registry/
‚îÇ       ‚îú‚îÄ‚îÄ 02_lazy_loading/
‚îÇ       ‚îî‚îÄ‚îÄ 03_plugin_system/
‚îÇ
‚îú‚îÄ‚îÄ scripts/                             # ÿ≥ŸÉÿ±Ÿäÿ®ÿ™ÿßÿ™ ÿßŸÑÿ™ŸÉÿßŸÖŸÑ üîß
‚îÇ   ‚îú‚îÄ‚îÄ integrate.sh                     # ÿ™ÿ´ÿ®Ÿäÿ™ ÿ±ÿ¶Ÿäÿ≥Ÿä
‚îÇ   ‚îú‚îÄ‚îÄ configure.sh                     # ÿ™ŸÉŸàŸäŸÜ
‚îÇ   ‚îú‚îÄ‚îÄ apply.sh                         # ÿ™ÿ∑ÿ®ŸäŸÇ
‚îÇ   ‚îú‚îÄ‚îÄ update.sh                        # ÿ™ÿ≠ÿØŸäÿ´
‚îÇ   ‚îú‚îÄ‚îÄ uninstall.sh                     # ÿ•ÿ≤ÿßŸÑÿ©
‚îÇ   ‚îî‚îÄ‚îÄ README.md                        # ÿØŸÑŸäŸÑ ÿßŸÑÿ≥ŸÉÿ±Ÿäÿ®ÿ™ÿßÿ™
‚îÇ
‚îú‚îÄ‚îÄ flows/                               # ÿ≥Ÿäÿ± ÿßŸÑÿπŸÖŸÑ üìö
‚îÇ   ‚îú‚îÄ‚îÄ DEVELOPMEN
tion
- **Inherited projects** you're unfamiliar with
- **Large projects** with complex structure
- **Multi-technology projects** (full-stack)
- **Before major changes** to understand current state

---

**Auto-analysis makes Augment truly intelligent about your project!** üéØ



================================================================================

# SECTION 66: PROJECT TEMPLATES SYSTEM

**Professional, production-ready templates for rapid project initialization**

---

## Overview

The Global Guidelines includes a comprehensive template system with **9 professional templates** covering common project types. Each template is production-ready with best practices, complete documentation, and automated setup.

---

## Available Templates

### 1. ERP System Template ‚≠ê‚≠ê‚≠ê

**Path:** `templates/erp_system/`

**Description:** Complete Enterprise Resource Planning system

**Modules:**
- Inventory Management
- Sales & Purchases
- Accounting & Finance
- HR & Payroll

**Tech Stack:**
- Fr
ontend: React + TypeScript
- Backend: Django + DRF
- Database: PostgreSQL
- Cache: Redis

**Use Cases:**
- Business management systems
- Manufacturing ERP
- Distribution management
- Multi-company systems

---

### 2. Web Page Template ‚≠ê‚≠ê

**Path:** `templates/web_page/`

**Description:** Simple static/dynamic website

**Features:**
- Responsive design
- SEO optimized
- Contact forms
- Fast loading

**Tech Stack:**
- HTML5 + CSS3
- JavaScript
- Optional backend

**Use Cases:**
- Landing pages
- Portfolios
- Company websites
- Product pages

---

### 3. Web Page with Login Template ‚≠ê‚≠ê‚≠ê

**Path:** `templates/web_page_with_login/`

**Description:** Web application with authentication

**Features:**
- User registration/login
- Password reset
- User profiles
- Protected pages
- Session management

**Tech Stack:**
- Frontend: React/Vue
- Backend: Django/Flask/FastAPI
- Database: PostgreSQL
- Auth: JWT/Session

**Use Cases:**
- Web applications
- Dashboards
- Member areas
- SaaS products

---


### 4. ML Template ‚≠ê‚≠ê‚≠ê

**Path:** `templates/ml_template/`

**Description:** Machine Learning project structure

**Features:**
- Data preprocessing
- Model training
- Model evaluation
- API deployment
- Experiment tracking

**Tech Stack:**
- Python 3.9+
- TensorFlow/PyTorch
- FastAPI
- MLflow

**Use Cases:**
- ML projects
- Data science
- Model deployment
- Research projects

---

### 5. Test Template ‚≠ê‚≠ê

**Path:** `templates/test_template/`

**Description:** Comprehensive testing setup

**Features:**
- Unit tests
- Integration tests
- E2E tests
- Coverage reports
- CI/CD integration

**Tech Stack:**
- pytest (Python)
- Jest (JavaScript)
- Selenium/Playwright
- Coverage.py

**Use Cases:**
- Testing any project
- QA automation
- CI/CD pipelines

---

### 6. Email Template ‚≠ê‚≠ê

**Path:** `templates/email_template/`

**Description:** Professional email templates

**Features:**
- Responsive design
- Multiple layouts
- Variables support
- Preview tool

**Types:**
- Welcome emails
- Notific
template for you..."
   ```

2. **User mentions specific project type**
   ```
   User: "Build a charity donation platform"
   Augment: "We have a Charity Management template..."
   ```

3. **User asks for project structure**
   ```
   User: "How should I structure an AI assistant?"
   Augment: "Use our AI Assistant template..."
   ```

### Template Selection

Match user intent to template:

| User Intent | Template |
|-------------|----------|
| "ERP", "business management" | ERP System |
| "landing page", "website" | Web Page |
| "web app", "login system" | Web Page with Login |
| "machine learning", "ML project" | ML Template |
| "testing", "test automation" | Test Template |
| "email campaign", "newsletter" | Email Template |
| "chatbot", "AI assistant" | AI Assistant |
| "charity", "donations", "NGO" | Charity Management |
| "prediction", "forecasting" | AI Prediction |

### Generation Workflow

1. **Identify need**
   - Detect project type from user request

2. **Suggest template

================================================================================
END OF 03_PLANNING
================================================================================


================================================================================
MODULE: 10_BACKEND
================================================================================

=================================================================================
BACKEND DEVELOPMENT - Django, FastAPI, Flask, Express
=================================================================================

Version: 5.0.0
Type: Architecture - Backend

This prompt provides comprehensive guidance for backend development across
multiple frameworks and languages.

=================================================================================
FRAMEWORK SELECTION
=================================================================================

## When to Use Each Framework

**Django:**
- Full-featured web applications
- Admin panel needed
- ORM preferred
- Batteries-included approach
- Python ecosystem

**FastAPI:**
- Modern async APIs
- High performance needed
- Auto-generated docs important
- Type hints preferred
- Python 3.7+

**Flask:**
- Lightweight applications
- Microservices
- Custom architecture needed
- Flexibility over convention
- Python ecosystem

**Express (Node.js):**
- JavaScript full-stack
- Real-time applications
- NPM ecosystem
- Event-driven architecture
- High concurrency

=================================================================================
DJANGO BEST PRACTICES
=================================================================================

## Project Structure

```
project/
‚îú‚îÄ‚îÄ manage.py
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ settings/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ development.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ production.py
‚îÇ   ‚îú‚îÄ‚îÄ urls.py
‚îÇ   ‚îî‚îÄ‚îÄ wsgi.py
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ users/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ views.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ serializers.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ urls.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ products/
‚îÇ   ‚îî‚îÄ‚îÄ orders/
‚îú‚îÄ‚îÄ static/
‚îú‚îÄ‚îÄ media/
‚îú‚îÄ‚îÄ templates/
‚îî‚îÄ‚îÄ requirements/
    ‚îú‚îÄ‚îÄ base.txt
    ‚îú‚îÄ‚îÄ development.txt
    ‚îî‚îÄ‚îÄ production.txt
```

## Models Best Practices

```python
from django.db import models
from django.contrib.auth.models import AbstractUser

class User(AbstractUser):
    """Custom user model."""
    email = models.EmailField(unique=True)
    phone = models.CharField(max_length=20, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        db_table = 'users'
        ordering = ['-created_at']
        indexes = [
            models.Index(fields=['email']),
            models.Index(fields=['created_at']),
        ]
    
    def __str__(self):
        return self.email

class Product(models.Model):
    """Product model."""
    name = models.CharField(max_length=200)
    description = models.TextField()
    price = models.DecimalField(max_digits=10, decimal_places=2)
    stock = models.IntegerField(default=0)
    is_active = models.BooleanField(default=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        db_table = 'products'
        ordering = ['-created_at']
    
    def __str__(self):
        return self.name
    
    @property
    def is_in_stock(self):
        return self.stock > 0
```

## Views & ViewSets

```python
from rest_framework import viewsets, permissions, status
from rest_framework.decorators import action
from rest_framework.response import Response
from .models import Product
from .serializers import ProductSerializer

class ProductViewSet(viewsets.ModelViewSet):
    """Product CRUD operations."""
    queryset = Product.objects.filter(is_active=True)
    serializer_class = ProductSerializer
    permission_classes = [permissions.IsAuthenticatedOrReadOnly]
    
    def get_queryset(self):
        queryset = super().get_queryset()
        # Filter by query params
        category = self.request.query_params.get('category')
        if category:
            queryset = queryset.filter(category=category)
        return queryset
    
    @action(detail=True, methods=['post'])
    def purchase(self, request, pk=None):
        """Custom action for purchasing."""
        product = self.get_object()
        quantity = request.data.get('quantity', 1)
        
        if product.stock < quantity:
            return Response(
                {'error': 'Not enough stock'},
                status=status.HTTP_400_BAD_REQUEST
            )
        
        product.stock -= quantity
        product.save()
        
        return Response({'status': 'purchased'})
```

## Serializers

```python
from rest_framework import serializers
from .models import Product

class ProductSerializer(serializers.ModelSerializer):
    is_in_stock = serializers.ReadOnlyField()
    
    class Meta:
        model = Product
        fields = [
            'id', 'name', 'description', 'price', 
            'stock', 'is_in_stock', 'created_at'
        ]
        read_only_fields = ['id', 'created_at']
    
    def validate_price(self, value):
        if value <= 0:
            raise serializers.ValidationError(
                "Price must be positive"
            )
        return value
```

## URLs

```python
from django.urls import path, include
from rest_framework.routers import DefaultRouter
from .views import ProductViewSet

router = DefaultRouter()
router.register(r'products', ProductViewSet)

urlpatterns = [
    path('api/', include(router.urls)),
]
```

## Settings Organization

**base.py:**
```python
import os
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent.parent.parent

SECRET_KEY = os.environ.get('SECRET_KEY')

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    # Third party
    'rest_framework',
    'corsheaders',
    # Local apps
    'apps.users',
    'apps.products',
]

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_PAGINATION_CLASS': 
        'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': 20,
}
```

**development.py:**
```python
from .base import *

DEBUG = True
ALLOWED_HOSTS = ['localhost', '127.0.0.1']

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.environ.get('DB_NAME', 'myproject_dev'),
        'USER': os.environ.get('DB_USER', 'postgres'),
        'PASSWORD': os.environ.get('DB_PASSWORD', 'postgres'),
        'HOST': os.environ.get('DB_HOST', 'localhost'),
        'PORT': os.environ.get('DB_PORT', '5432'),
    }
}

CORS_ALLOW_ALL_ORIGINS = True
```

**production.py:**
```python
from .base import *

DEBUG = False
ALLOWED_HOSTS = os.environ.get('ALLOWED_HOSTS', '').split(',')

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.environ.get('DB_NAME'),
        'USER': os.environ.get('DB_USER'),
        'PASSWORD': os.environ.get('DB_PASSWORD'),
        'HOST': os.environ.get('DB_HOST'),
        'PORT': os.environ.get('DB_PORT', '5432'),
    }
}

CORS_ALLOWED_ORIGINS = os.environ.get(
    'CORS_ALLOWED_ORIGINS', ''
).split(',')

SECURE_SSL_REDIRECT = True
SESSION_COOKIE_SECURE = True
CSRF_COOKIE_SECURE = True
```

=================================================================================
FASTAPI BEST PRACTICES
=================================================================================

## Project Structure

```
project/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ product.py
‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ product.py
‚îÇ   ‚îú‚îÄ‚îÄ routers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ users.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ products.py
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ .env
```

## Main Application

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.routers import users, products
from app.database import engine
from app.models import Base

# Create tables
Base.metadata.create_all(bind=engine)

app = FastAPI(
    title="My API",
    description="API documentation",
    version="1.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(users.router, prefix="/api/users", tags=["users"])
app.include_router(products.router, prefix="/api/products", tags=["products"])

@app.get("/")
async def root():
    return {"message": "Welcome to the API"}
```

## Models (SQLAlchemy)

```python
from sqlalchemy import Column, Integer, String, Float, Boolean, DateTime
from sqlalchemy.sql import func
from app.database import Base

class Product(Base):
    __tablename__ = "products"
    
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String(200), nullable=False)
    description = Column(String)
    price = Column(Float, nullable=False)
    stock = Column(Integer, default=0)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
```

## Schemas (Pydantic)

```python
from pydantic import BaseModel, Field
from datetime import datetime
from typing import Optional

class ProductBase(BaseModel):
    name: str = Field(..., min_length=1, max_length=200)
    description: Optional[str] = None
    price: float = Field(..., gt=0)
    stock: int = Field(default=0, ge=0)

class ProductCreate(ProductBase):
    pass

class ProductUpdate(BaseModel):
    name: Optional[str] = Field(None, min_length=1, max_length=200)
    description: Optional[str] = None
    price: Optional[float] = Field(None, gt=0)
    stock: Optional[int] = Field(None, ge=0)

class ProductResponse(ProductBase):
    id: int
    is_active: bool
    created_at: datetime
    
    class Config:
        from_attributes = True
```

## Routers

```python
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List
from app.database import get_db
from app.models.product import Product
from app.schemas.product import ProductCreate, ProductUpdate, ProductResponse

router = APIRouter()

@router.get("/", response_model=List[ProductResponse])
async def get_products(
    skip: int = 0,
    limit: int = 20,
    db: Session = Depends(get_db)
):
    products = db.query(Product).filter(
        Product.is_active == True
    ).offset(skip).limit(limit).all()
    return products

@router.post("/", response_model=ProductResponse, status_code=status.HTTP_201_CREATED)
async def create_product(
    product: ProductCreate,
    db: Session = Depends(get_db)
):
    db_product = Product(**product.dict())
    db.add(db_product)
    db.commit()
    db.refresh(db_product)
    return db_product

@router.get("/{product_id}", response_model=ProductResponse)
async def get_product(product_id: int, db: Session = Depends(get_db)):
    product = db.query(Product).filter(Product.id == product_id).first()
    if not product:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Product not found"
        )
    return product

@router.put("/{product_id}", response_model=ProductResponse)
async def update_product(
    product_id: int,
    product_update: ProductUpdate,
    db: Session = Depends(get_db)
):
    product = db.query(Product).filter(Product.id == product_id).first()
    if not product:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Product not found"
        )
    
    for key, value in product_update.dict(exclude_unset=True).items():
        setattr(product, key, value)
    
    db.commit()
    db.refresh(product)
    return product

@router.delete("/{product_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_product(product_id: int, db: Session = Depends(get_db)):
    product = db.query(Product).filter(Product.id == product_id).first()
    if not product:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Product not found"
        )
    
    db.delete(product)
    db.commit()
    return None
```

## Database Connection

```python
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os

SQLALCHEMY_DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://user:password@localhost/dbname"
)

engine = create_engine(SQLALCHEMY_DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

=================================================================================
COMMON PATTERNS
=================================================================================

## Pagination

**Django:**
```python
from rest_framework.pagination import PageNumberPagination

class CustomPagination(PageNumberPagination):
    page_size = 20
    page_size_query_param = 'page_size'
    max_page_size = 100
```

**FastAPI:**
```python
@router.get("/")
async def get_items(skip: int = 0, limit: int = 20):
    items = db.query(Item).offset(skip).limit(limit).all()
    return items
```

## Filtering

**Django:**
```python
from django_filters import rest_framework as filters

class ProductFilter(filters.FilterSet):
    min_price = filters.NumberFilter(field_name="price", lookup_expr='gte')
    max_price = filters.NumberFilter(field_name="price", lookup_expr='lte')
    
    class Meta:
        model = Product
        fields = ['category', 'is_active']
```

**FastAPI:**
```python
@router.get("/")
async def get_products(
    category: Optional[str] = None,
    min_price: Optional[float] = None,
    max_price: Optional[float] = None,
    db: Session = Depends(get_db)
):
    query = db.query(Product)
    if category:
        query = query.filter(Product.category == category)
    if min_price:
        query = query.filter(Product.price >= min_price)
    if max_price:
        query = query.filter(Product.price <= max_price)
    return query.all()
```

## Error Handling

**Django:**
```python
from rest_framework.views import exception_handler
from rest_framework.response import Response

def custom_exception_handler(exc, context):
    response = exception_handler(exc, context)
    
    if response is not None:
        response.data['status_code'] = response.status_code
    
    return response
```

**FastAPI:**
```python
from fastapi import Request
from fastapi.responses import JSONResponse

@app.exception_handler(ValueError)
async def value_error_handler(request: Request, exc: ValueError):
    return JSONResponse(
        status_code=400,
        content={"message": str(exc)}
    )
```

=================================================================================
TESTING
=================================================================================

## Django Tests

```python
from django.test import TestCase
from rest_framework.test import APIClient
from rest_framework import status
from .models import Product

class ProductAPITest(TestCase):
    def setUp(self):
        self.client = APIClient()
        self.product = Product.objects.create(
            name="Test Product",
            price=99.99,
            stock=10
        )
    
    def test_get_products(self):
        response = self.client.get('/api/products/')
        self.assertEqual(response.status_code, status.HTTP_200_OK)
        self.assertEqual(len(response.data), 1)
    
    def test_create_product(self):
        data = {
            'name': 'New Product',
            'price': 49.99,
            'stock': 5
        }
        response = self.client.post('/api/products/', data)
        self.assertEqual(response.status_code, status.HTTP_201_CREATED)
```

## FastAPI Tests

```python
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_get_products():
    response = client.get("/api/products/")
    assert response.status_code == 200
    assert isinstance(response.json(), list)

def test_create_product():
    product_data = {
        "name": "Test Product",
        "price": 99.99,
        "stock": 10
    }
    response = client.post("/api/products/", json=product_data)
    assert response.status_code == 201
    assert response.json()["name"] == "Test Product"
```

=================================================================================
DEPLOYMENT
=================================================================================

## Django with Gunicorn

```bash
gunicorn config.wsgi:application --bind 0.0.0.0:8000 --workers 4
```

## FastAPI with Uvicorn

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

=================================================================================
END OF BACKEND PROMPT
=================================================================================


================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

- Visual regression: Percy, Chromatic

E) Performance Testing
- Load testing: k6, Locust
- Stress testing: find breaking point
- Spike testing: sudden traffic
- Endurance testing: sustained load

F) Security Testing
- SAST: Semgrep, SonarQube
- DAST: OWASP ZAP
- Dependency scanning: Snyk, npm audit
- Secret scanning: TruffleHog
- Penetration testing: annual

G) Accessibility Testing
- Automated: axe, Lighthouse
- Manual: screen reader, keyboard nav
- WCAG AA compliance

H) Quality Gates
- All tests pass
- Coverage >80%
- No critical/high vulnerabilities
- Lighthouse score >90
- No secrets in code

‚∏ª

11) DOCUMENTATION REQUIREMENTS (30+ files)

Required Files:
1. README.md - Project overview
2. docs/Inventory.md - All components, versions
3. docs/TODO.md - Prioritized task list
4. docs/DONT_DO_THIS_AGAIN.md - Lessons learned
5. docs/TechStack.md - Technologies used
6. docs/API_Contracts.md - API specifications
7. docs/DB_Schema.md - Database schema
8. docs/Security.md - Security measure
 1)
```
FILE: <repo-path> | PURPOSE: <brief> | OWNER: <team/person> | RELATED: <files> | LAST-AUDITED: <YYYY-MM-DD>
```

B) Examples
```python
# FILE: backend/src/services/auth.py | PURPOSE: Authentication service | OWNER: Security Team | RELATED: models/user.py, routes/auth.py | LAST-AUDITED: 2025-10-28
```

```typescript
// FILE: frontend/src/components/Dashboard.tsx | PURPOSE: Main dashboard component | OWNER: Frontend Team | RELATED: pages/Home.tsx | LAST-AUDITED: 2025-10-28
```

C) CI Enforcement
- Pre-commit hook: check header presence
- CI pipeline: fail if missing
- Auto-generate for new files
- Update LAST-AUDITED on changes

D) Benefits
- Quick file identification
- Ownership clarity
- Audit trail
- Related files discovery

‚∏ª

24) CLASS & TYPE CANONICAL REGISTRY (NEW in v3.1)

A) Purpose
- Single source of truth for all classes/types
- Prevent duplication
- Track relationships
- Migration history

B) Location
`/docs/Class_Registry.md` (APPEND-ONLY)

C) Entry Format
```markdow
n
## User

- **CanonicalName**: User
- **Location**: `backend/src/models/user.py`
- **DomainContext**: Authentication & Authorization
- **Purpose**: Represents system users
- **Fields**:
  - id: UUID (PK)
  - email: String (unique, indexed)
  - password_hash: String
  - role: Enum (admin, manager, user)
  - created_at: DateTime
  - updated_at: DateTime
- **Relations**:
  - has_many: sessions, activity_logs
  - belongs_to: tenant (if multi-tenant)
- **Invariants**:
  - email must be valid format
  - password_hash never null
  - role must be valid enum value
- **Visibility**: Internal (not exposed directly in API)
- **Lifecycle**: Active users can be soft-deleted
- **DTO/API**: UserDTO in `contracts/user.dto.ts`
- **FE Mapping**: `frontend/src/types/user.ts`
- **DB Mapping**: `users` table
- **Tests**: `tests/models/test_user.py`
- **Aliases**: None
- **Migration Notes**: v1.2.0 - Added role field
```

D) Workflow
1. Before creating new class: search registry
2. If exists: reuse canonica
 `/docs/File_Map.md` - Complete file inventory
   - `/docs/Class_Registry.md` - All classes/types
   - `/docs/Imports_Map.md` - Import dependencies
   - `/docs/Exports_Map.md` - Export mappings

3. **Search for Existing Files**
   ```bash
   # Search by name
   find . -name "*user*" -type f
   
   # Search by content (AST-based)
   python scripts/detect_duplicates.py --semantic --target "User"
   ```

B) FILE MAP STRUCTURE

`/docs/File_Map.md` format:
```markdown
# File Map - Generated: 2025-10-28

## Backend Files

### Models
- `backend/src/models/user.py` - User model (CANONICAL)
  - Classes: User
  - Functions: create_user(), get_user_by_email()
  - Dependencies: db, auth
  - Last Modified: 2025-10-27
  - Owner: Auth Team

### Services
- `backend/src/services/auth_service.py` - Authentication service
  - Functions: login(), logout(), verify_token()
  - Dependencies: models/user, jwt
  - Last Modified: 2025-10-26
  - Owner: Auth Team

## Frontend Files

### Components
- `frontend/src
p] [Back] [Continue]               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Step 5: Security Settings
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Security Configuration                 ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Secret Key: [Auto-generated]           ‚îÇ
‚îÇ  ‚ö†Ô∏è NEVER share this key!               ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Session Timeout: [15] minutes          ‚îÇ
‚îÇ  Max Login Attempts: [5]                ‚îÇ
‚îÇ  Password Min Length: [12]              ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Enable MFA: [‚úì] Recommended            ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  [Back] [Continue]                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Step 6: Final Review & Confirmation
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Review Configuration                   ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  ‚úÖ Admin user created                  ‚îÇ
‚îÇ  ‚úÖ Database connected                 
 of changes

‚∏ª

38) PRE-DEVELOPMENT CHECKLIST (CRITICAL - NEW in v3.2)

**PURPOSE:** Mandatory checklist before starting any development

A) THE CHECKLIST

```markdown
# Pre-Development Checklist

Before starting ANY development work, complete this checklist:

## 1. Environment Setup
- [ ] `.env` file exists and is valid
- [ ] Run `python scripts/validate_env.py` - all checks pass
- [ ] APP_ENV is set correctly (development/production)
- [ ] All required services are running (database, redis, etc.)

## 2. Documentation Review
- [ ] Read `/docs/File_Map.md` - know where files are
- [ ] Read `/docs/Class_Registry.md` - know what classes exist
- [ ] Read `/docs/Imports_Map.md` - understand dependencies
- [ ] Read `/docs/TODO.md` - know what's planned
- [ ] Read `/docs/DONT_DO_THIS_AGAIN.md` - learn from past mistakes

## 3. Search for Existing Code
- [ ] Search for similar files: `find . -name "*<keyword>*"`
- [ ] Search for similar classes: check Class_Registry.md
- [ ] Search for simila
usage in function reference

**When Creating:**
- Make it reusable from the start
- Document in function reference
- Add to module map
- Write comprehensive tests


---

## 50. Task Management System

### 50.1 TODO File Structure (APPEND-ONLY)

**Location:** `docs/TODO.md`

**Rules:**
- **APPEND-ONLY** - Never delete tasks
- Mark completed with 'x'
- Move completed to bottom
- Create `docs/completed_tasks.md` for archive

**Template:**
```markdown
# TODO List

**Last Updated:** YYYY-MM-DD

## Classification

### üî¥ Errors (P0 - Critical)
- [ ] [Module] Error description
- [ ] [Module] Error description
- [x] [Module] Fixed error (moved to bottom)

### üü† Fixes (P1 - High)
- [ ] [Module] Fix description
- [ ] [Module] Fix description

### üü° Development (P2 - Medium)
- [ ] [Module] Feature description
- [ ] [Module] Feature description

### üü¢ Integration (P3 - Low)
- [ ] [Module] Integration task
- [ ] [Module] Integration task

### üîµ Inspection
- [ ] [Module] Review/audit task
- [ ] [Modu
le] Review/audit task

---

## Completed Tasks (Move here, don't delete)

- [x] [2025-01-15] [Module] Task description
- [x] [2025-01-14] [Module] Task description
```

### 50.2 Task Classification

**Priority Levels:**
- **P0 (üî¥ Critical):** System broken, security issue, data loss
- **P1 (üü† High):** Major bug, broken feature, performance issue
- **P2 (üü° Medium):** New feature, enhancement, minor bug
- **P3 (üü¢ Low):** Integration, optimization, nice-to-have
- **Inspection (üîµ):** Code review, audit, documentation

**Task Format:**
```markdown
- [ ] [Priority] [Module] [Owner?] Task description
      Estimate: X hours/days
      Dependencies: Task #Y, #Z
      Status: Not Started / In Progress / Blocked / Done
```

**Example:**
```markdown
- [ ] [P0] [Auth] [hamfarid] Fix login bypass vulnerability
      Estimate: 4 hours
      Dependencies: None
      Status: In Progress
```

### 50.3 Workflow

**Adding Tasks:**
1. Add to appropriate classification section
2. Include priority, module, 
ps (ForeignKey, ManyToMany)
   - Custom methods (confirm(), cancel(), compute_totals())
   - State management
   - Validation logic

3. **Arabic Docstrings**
   - All classes and functions documented in Arabic
   - Clear, professional language
   - Examples where helpful

4. **Custom Reports**
   - PDF generation
   - Excel exports
   - Custom templates

5. **Smart Filters**
   - Date ranges
   - Status filters
   - Search functionality

### 54.2 Module Structure Template

```
module_name/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main_model.py
‚îÇ   ‚îî‚îÄ‚îÄ related_models.py
‚îú‚îÄ‚îÄ views/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ api_views.py
‚îÇ   ‚îî‚îÄ‚îÄ frontend_views.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ business_logic.py
‚îú‚îÄ‚îÄ serializers/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ serializers.py
‚îú‚îÄ‚îÄ permissions/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ permissions.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py
‚îÇ   ‚îú‚îÄ‚îÄ test_views.py
‚îÇ   ‚îî‚îÄ‚îÄ test_services.py
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ
# ÿßŸÑÿπŸÑÿßŸÇÿßÿ™
    user = models.ForeignKey(
        User,
        on_delete=models.CASCADE,
        verbose_name='ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ',
        related_name='%(class)s_records'
    )
    
    # ÿßŸÑÿ≠ÿßŸÑÿ©
    state = models.CharField(
        'ÿßŸÑÿ≠ÿßŸÑÿ©',
        max_length=20,
        choices=STATES,
        default=STATE_DRAFT
    )
    
    # ÿßŸÑÿ™Ÿàÿßÿ±ŸäÿÆ
    created_at = models.DateTimeField('ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ•ŸÜÿ¥ÿßÿ°', auto_now_add=True)
    updated_at = models.DateTimeField('ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ™ÿ≠ÿØŸäÿ´', auto_now=True)
    confirmed_at = models.DateTimeField('ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ™ÿ£ŸÉŸäÿØ', null=True, blank=True)
    
    # ÿßŸÑÿ≠ŸÇŸàŸÑ ÿßŸÑŸÖÿ≠ÿ≥Ÿàÿ®ÿ©
    total = models.DecimalField('ÿßŸÑÿ•ÿ¨ŸÖÿßŸÑŸä', max_digits=10, decimal_places=2, default=0)
    
    class Meta:
        verbose_name = 'ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä'
        verbose_name_plural = 'ÿßŸÑŸÜŸÖÿßÿ∞ÿ¨ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ©'
        ordering = ['-created_at']
        indexes = [
            models.Index(fields=['code']),
            models.Index(fields=['state', 'created_at']),
        ]
    
    def __str__(self):
        """ÿ™ŸÖÿ´ŸäŸÑ ŸÜÿµŸä
ion detector
2. Check if similar function exists
3. If exists (‚â•80% similarity):
   - Reuse existing function
   - Or enhance existing function
   - Do NOT create duplicate

**After Merging Modules:**

1. Run duplication detector
2. Review all duplicates
3. Merge duplicates systematically
4. Update all dependent files

### 58.5 Ignore Trivial Differences

- Variable names
- Whitespace
- Comments
- String literals (if logic is same)
- Numeric literals (if logic is same)

### 58.6 CI/CD Integration

```yaml
# .github/workflows/ci.yml
- name: Detect Code Duplication
  run: |
    python scripts/detect_code_duplication.py .
    if [ -s docs/Code_Duplication_Report.md ]; then
      echo "‚ö†Ô∏è Code duplication detected!"
      cat docs/Code_Duplication_Report.md
      exit 1
    fi
```

### 58.7 Metrics

- **Duplication Rate:** (Duplicate LOC / Total LOC) √ó 100%
- **Target:** <5%
- **Maximum Allowed:** 10%

---

================================================================================
##
===========================

### 60.1 Principle

**NEVER** merge manually when tools can do it safely.  
**ALWAYS** backup before merge.  
**ALWAYS** update all dependent files.

### 60.2 Smart Merge Tool

**Tool:** `scripts/smart_merge.py`

```bash
# Interactive merge
python scripts/smart_merge.py

# Auto-merge (with confirmation)
python scripts/smart_merge.py --auto

# Dry-run (no changes)
python scripts/smart_merge.py --dry-run
```

### 60.3 Merge Workflow

1. **Detect Duplicates**
   - Run `detect_code_duplication.py`
   - Load duplication report
   
2. **For Each Duplicate Pair:**
   
   a. **Show Comparison**
      ```
      File 1: models/user.py::create_user()
      File 2: models/user_unified.py::add_user()
      Similarity: 95%
      
      Differences:
      - Line 10: Variable name (user_data vs data)
      - Line 15: Return type annotation
      ```
   
   b. **Ask User**
      ```
      Merge these functions? (y/n/skip)
      Keep which implementation? (1/2/best)
      ``
 flows/

---

### 4.3 apply.sh

**ÿßŸÑŸàÿ∏ŸäŸÅÿ©:** ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÖŸÉŸàŸÜÿßÿ™ ÿπŸÑŸâ ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```bash
# ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÉŸÑ
.global/scripts/apply.sh

# ÿ™ÿ∑ÿ®ŸäŸÇ ŸÖŸÉŸàŸÜ ŸÖÿ≠ÿØÿØ
.global/scripts/apply.sh --only config

# ŸÖÿπ ŸÜÿ≥ÿÆ ÿßÿ≠ÿ™Ÿäÿßÿ∑Ÿä
.global/scripts/apply.sh --backup
```

---

### 4.4 update.sh

**ÿßŸÑŸàÿ∏ŸäŸÅÿ©:** ÿ™ÿ≠ÿØŸäÿ´ Global Guidelines

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```bash
# ÿ¢ÿÆÿ± ÿ•ÿµÿØÿßÿ±
.global/scripts/update.sh

# ÿ•ÿµÿØÿßÿ± ŸÖÿ≠ÿØÿØ
.global/scripts/update.sh --version 3.7.0
```

---

### 4.5 uninstall.sh

**ÿßŸÑŸàÿ∏ŸäŸÅÿ©:** ÿ•ÿ≤ÿßŸÑÿ© Global Guidelines

**ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:**
```bash
# ÿ•ÿ≤ÿßŸÑÿ© .global/ ŸÅŸÇÿ∑
.global/scripts/uninstall.sh

# ÿ•ÿ≤ÿßŸÑÿ© ŸÉÿßŸÖŸÑÿ©
.global/scripts/uninstall.sh --full
```

---

## 5. Flows / ÿ≥Ÿäÿ± ÿßŸÑÿπŸÖŸÑ üìö

### 5.1 DEVELOPMENT_FLOW.md

**ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ:**
- 7 ŸÖÿ±ÿßÿ≠ŸÑ ŸÑŸÑÿ™ÿ∑ŸàŸäÿ±
- ŸÖŸÜ ÿßŸÑÿ™ŸáŸäÿ¶ÿ© ÿ•ŸÑŸâ ÿßŸÑŸÜÿ¥ÿ±
- Best practices ŸÑŸÉŸÑ ŸÖÿ±ÿ≠ŸÑÿ©
- ÿ£ŸÖÿ´ŸÑÿ© CI/CD

---

### 5.2 INTEGRATION_FLOW.md ‚≠ê

**ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ:**
- 3 ÿ∑ÿ±ŸÇ ŸÑŸÑÿØŸÖÿ¨
- ÿÆÿ∑Ÿàÿßÿ™ ÿ™ŸÅÿµŸäŸÑŸäÿ©
- ÿ£ŸÖÿ´ŸÑÿ© ŸÑŸÄ Django, Flask, FastAPI
- FAQ ÿ¥ÿßŸÖŸÑ

**ÿßŸÑÿ£ŸáŸÖ ŸÑŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ ÿßŸÑŸÇÿßÿ¶ŸÖÿ©!**

---

### 5.3 DEPLOYMENT_FLOW.md

**ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ:**
- 3 ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿßÿ™ 
es ŸäŸàŸÅÿ±:

‚úÖ **4 ÿ£ÿØŸàÿßÿ™ ÿßÿ≠ÿ™ÿ±ÿßŸÅŸäÿ©** ŸÑŸÑÿ™ÿ≠ŸÑŸäŸÑ ŸàÿßŸÑÿµŸäÿßŸÜÿ©  
‚úÖ **ŸÇŸàÿßŸÑÿ® ÿ¨ÿßŸáÿ≤ÿ©** ŸÑŸÄ config/definitions  
‚úÖ **3 ÿ£ŸÖÿ´ŸÑÿ© ŸÉÿßŸÖŸÑÿ©** ŸÑÿ£ŸÜŸÖÿßÿ∑ ŸÖÿÆÿ™ŸÑŸÅÿ©  
‚úÖ **5 ÿ≥ŸÉÿ±Ÿäÿ®ÿ™ÿßÿ™** ŸÑŸÑÿ™ŸÉÿßŸÖŸÑ ÿßŸÑÿ≥ŸÑÿ≥  
‚úÖ **3 workflows** ÿ¥ÿßŸÖŸÑÿ©  
‚úÖ **ÿ™Ÿàÿ´ŸäŸÇ ÿ¥ÿßŸÖŸÑ** ŸÑŸÉŸÑ ÿ¥Ÿäÿ°

**ŸÑŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÅŸä Augment:**
1. ÿßŸÜÿ≥ÿÆ ÿßŸÑÿ®ÿ±ŸàŸÖÿ®ÿ™
2. ÿßŸÜÿ≥ÿÆ ÿßŸÑÿ£ÿØŸàÿßÿ™
3. ÿßŸÜÿ≥ÿÆ ÿßŸÑÿ£ŸÖÿ´ŸÑÿ©
4. ÿ£ÿ¥ÿ± ÿ•ŸÑŸäŸáÿß ŸÅŸä ÿßŸÑÿ™ŸÉŸàŸäŸÜ
5. ÿßÿ®ÿØÿ£ ÿßŸÑÿπŸÖŸÑ!

---

**Last Updated:** 2025-11-02  
**Version:** 3.9.0  
**Status:** ‚úÖ Active

================================================================================
END OF SECTION 63
================================================================================



‚∏ª

## Section 64: Interactive Project Setup & State Management

### Overview

This section defines an **interactive project setup system** that collects project information at the start and manages project state throughout development and deployment phases.

---

### 64.1 Initial Project Questions

**When to Ask:**
- At the very beginning of a new project
- When user starts working on a project for the fi
                                      ‚îÇ
‚îÇ  Step 6: Security Settings                                  ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                  ‚îÇ
‚îÇ  - Password policies                                        ‚îÇ
‚îÇ  - Session timeout                                          ‚îÇ
‚îÇ  - IP whitelist/blacklist                                   ‚îÇ
‚îÇ  - Rate limiting                                            ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 7: Integrations (Optional)                            ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                            ‚îÇ
‚îÇ  - Payment gateways                                         ‚îÇ
‚îÇ  - Analytics                                                ‚îÇ
‚îÇ  - Social login                                             ‚îÇ
‚îÇ  - Third-party APIs                                         ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 8: Final Review                                       ‚îÇ

loyment process
```

**Production Phase:**

```bash
# Database
backup-db             # Create database backup
restore-db [file]     # Restore from backup
migrate-db            # Run migrations (with backup)

# Monitoring
health-check          # Check system health
view-logs             # View application logs
monitor-stats         # View performance stats

# Management
rollback              # Rollback to previous version
restart-services      # Restart all services
update-config         # Update configuration
```

---

### 64.11 Configuration Update

**To update configuration:**

```bash
# Interactive update
update-config

# Direct edit
nano .global/project_config.json

# Reload config
reload-config
```

**Augment will ask:**

```
Which setting would you like to update?

1. Project name
2. Port configuration
3. Database settings
4. Environment settings
5. Admin settings
6. All settings

Your choice: ___
```

---

### 64.12 Best Practices

**For Augment:**

1. **Always ask questions fir
ations
- Newsletters
- Transactional emails

**Use Cases:**
- Email campaigns
- Notifications
- Marketing emails

---

### 7. AI Assistant Template ‚≠ê‚≠ê‚≠ê

**Path:** `templates/ai_assistant/`

**Description:** Intelligent AI-powered assistant

**Features:**
- Natural language processing
- Knowledge base (RAG)
- Chat interface
- Multi-model support (GPT, Claude, Gemini)
- Context awareness
- Custom training

**Tech Stack:**
- Frontend: React + TypeScript
- Backend: FastAPI + LangChain
- Vector DB: Pinecone/Chroma
- LLM: OpenAI/Anthropic

**Use Cases:**
- Customer support chatbots
- Internal knowledge assistants
- AI-powered help systems
- Virtual assistants

---

### 8. Charity Management Template ‚≠ê‚≠ê‚≠ê

**Path:** `templates/charity_management/`

**Description:** Complete charity and donation management

**Features:**
- Donation processing (Stripe, PayPal)
- Beneficiary management
- Campaign management
- Volunteer management
- Reporting & analytics

**Tech Stack:**
- Frontend: React + Materi
al-UI
- Backend: Django + DRF
- Database: PostgreSQL
- Payment: Stripe/PayPal

**Use Cases:**
- Charity organizations
- NGOs
- Fundraising platforms
- Volunteer management

---

### 9. AI Prediction Template ‚≠ê‚≠ê‚≠ê

**Path:** `templates/ai_prediction/`

**Description:** ML prediction and forecasting system

**Features:**
- Time series forecasting
- Classification & regression
- Anomaly detection
- Model training & deployment
- MLOps (MLflow)
- Monitoring & drift detection

**Tech Stack:**
- Frontend: React + Plotly
- Backend: FastAPI
- ML: Scikit-learn, XGBoost, Prophet
- MLOps: MLflow

**Use Cases:**
- Sales forecasting
- Demand prediction
- Fraud detection
- Price prediction
- Customer churn prediction

---

## Template Generator Tool

### Usage

```bash
# List available templates
python3 tools/template_generator.py --list

# Interactive mode
python3 tools/template_generator.py --interactive

# Generate with defaults
python3 tools/template_generator.py \
  --template erp_system \
  --ou
**
   - Explain template features
   - Ask for confirmation

3. **Gather variables**
   - Ask for project name
   - Ask for ports (if needed)
   - Ask for database name
   - Ask for other variables

4. **Generate project**
   - Run template generator
   - Show progress
   - Report completion

5. **Next steps**
   - Show generated files
   - Explain setup process
   - Offer to help with customization

---

## Examples

### Example 1: Generate ERP System

```
User: "I need to build an ERP system for my company"

Augment: "I can generate a complete ERP system template for you! It includes:
- Inventory Management
- Sales & Purchases
- Accounting
- HR & Payroll

All with React frontend, Django backend, and PostgreSQL database.

Would you like me to generate it?"

User: "Yes"

Augment: "Great! I need a few details:

1. Project name? (e.g., 'Company ERP')
2. Database name? (e.g., 'company_erp_db')
3. Frontend port? (default: 3000)
4. Backend port? (default: 5000)

[Collects answers]

Generati
ng project...

‚úÖ Done! Your ERP system is ready at: ~/projects/company-erp

Next steps:
1. cd ~/projects/company-erp
2. Read README.md
3. Run: docker-compose up -d

Would you like help with setup?"
```

### Example 2: Generate AI Assistant

```
User: "Create an AI chatbot for customer support"

Augment: "Perfect! I'll use our AI Assistant template which includes:
- Chat interface
- Knowledge base (RAG)
- Multi-model support (GPT-4, Claude)
- Vector database for semantic search

Generating...

‚úÖ Project created!

I've set it up with:
- React frontend with chat UI
- FastAPI backend with LangChain
- Pinecone for vector storage
- OpenAI GPT-4 integration

You'll need to add your OpenAI API key to .env

Want me to help you set it up?"
```

---

## Best Practices

### For Augment

1. **Always suggest templates** for new projects
2. **Explain template features** before generating
3. **Ask for confirmation** before generating
4. **Collect all variables** upfront
5. **Show progress** during gen
eration
6. **Provide next steps** after generation
7. **Offer customization help**

### For Users

1. **Review README.md** after generation
2. **Customize variables** in .env
3. **Read documentation** in docs/
4. **Test locally** before deployment
5. **Commit to Git** after customization

---

## Template Maintenance

### Adding New Templates

1. Create directory in `templates/`
2. Add template files
3. Create `README.md`
4. Create `config.json`
5. Test generation
6. Update this section

### Updating Templates

1. Modify template files
2. Update version in `config.json`
3. Update `README.md`
4. Test generation
5. Document changes

---

## Summary

**9 professional templates** covering:

1. ‚úÖ **ERP System** - Complete business management
2. ‚úÖ **Web Page** - Simple websites
3. ‚úÖ **Web Page with Login** - Web applications
4. ‚úÖ **ML Template** - Machine learning projects
5. ‚úÖ **Test Template** - Comprehensive testing
6. ‚úÖ **Email Template** - Professional emails
7. ‚úÖ **AI Assistant** - Int

================================================================================
CRITICAL MISSING CONTENT - Deep Search Recovery
================================================================================

```bash
   mkdir -p /unneeded/models
   mv models/user_unified.py /unneeded/models/user_unified.removed.py
   mv models/users.py /unneeded/models/users.removed.py
   ```

4. **Add Pointer File**
   ```python
   # /unneeded/models/user_unified.removed.py
   """
   REMOVED: 2025-10-28
   REASON: Duplicate of models/user.py
   COMMIT: abc123def456
   CANONICAL: models/user.py
   
   This file was a duplicate and has been removed.
   All imports should use: from models.user import User
   """
   ```

5. **Document in Duplicates Log**
   ```markdown
   # /docs/Duplicates_Log.md
   
   ## 2025-10-28: User Model Consolidation
   
   **Canonical:** `models/user.py`
   
   **Removed Duplicates:**
   - `models/user_unified.py` ‚Üí `/unneeded/models/user_unified.removed.py`
   - `models/users.py` ‚Üí `/unneeded/models/users.removed.py`
   
   **Commit:** abc123def456
   
   **Files Updated:** 8 files
   - `services/auth_service.py`
   - `routes/user_routes.py`
   - (list all updated files)
   ```

C) CI ENFORCEMENT

```

```bash
# Update imports after moving/renaming module
python scripts/update_imports.py <old_module> <new_module>

# Example
python scripts/update_imports.py models.user_unified models.user

# Dry-run
python scripts/update_imports.py models.user_unified models.user --dry-run
```

```python
# backend/src/services/error_logger.py
import logging
from datetime import datetime
from models import ErrorLog

class ErrorLogger:
    @staticmethod
    def log_error(
        trace_id: str,
        error_type: str,
        error_message: str,
        stack_trace: str,
        user_id: int = None,
        request_data: dict = None
    ):
        """Log error to database for analysis"""
        error_log = ErrorLog(
            trace_id=trace_id,
            error_type=error_type,
            error_message=error_message,
            stack_trace=stack_trace,
            user_id=user_id,
            request_data=request_data,
            timestamp=datetime.utcnow()
        )
        db.session.add(error_log)
        db.session.commit()
        
        # Also log to file
        logging.error(
            f"[{trace_id}] {error_type}: {error_message}",
            extra={'stack_trace': stack_trace}
        )
        
        # Send alert if critical
        if error_type in ['DatabaseError', 'SecurityError']:
            send_alert_to_admin(trace_id, error_type, error_message)
```

```python
# scripts/generate_env.py
import secrets

def generate_secret_key(length=32):
    """Generate secure random key"""
    return secrets.token_hex(length)

def generate_env_file():
    """Generate .env file with secure defaults"""
    template = f"""# Generated .env file - {datetime.now().isoformat()}

# IMPORTANT: Review and update all values before use!

APP_ENV=development
SECRET_KEY={generate_secret_key()}
JWT_SECRET_KEY={generate_secret_key()}

DB_HOST=localhost
DB_PORT=5432
DB_NAME={your_database_name}
DB_USER=postgres
DB_PASSWORD={generate_secret_key(16)}

# Add other variables from .env.example
"""
    
    with open('.env', 'w') as f:
        f.write(template)
    
    print("‚úÖ .env file generated!")
    print("‚ö†Ô∏è Please review and update the values before running the application.")

if __name__ == '__main__':
    generate_env_file()
```

```python
   # Before (scattered)
   from models.user import User
   from models.user_unified import User
   from models.users import User
   
   # After (consolidated)
   from models.user import User  # CANONICAL
   ```

3. **Move Duplicates to /unneeded**
   ```bash
   mkdir -p /unneeded/models
   mv models/user_unified.py /unneeded/models/user_unified.removed.py
   mv models/users.py /unneeded/models/users.removed.py
   ```

4. **Add Pointer File**
   ```python
   # /unneeded/models/user_unified.removed.py
   """
   REMOVED: 2025-10-28
   REASON: Duplicate of models/user.py
   COMMIT: abc123def456
   CANONICAL: models/user.py
   
   This file was a duplicate and has been removed.
   All imports should use: from models.user import User
   """
   ```

5. **Document in Duplicates Log**
   ```markdown
   # /docs/Duplicates_Log.md
   
   ## 2025-10-28: User Model Consolidation
   
   **Canonical:** `models/user.py`
   
   **Removed Duplicates:**
   - `models/user_unified.py` ‚Üí `/unneeded/models/user_unified.removed.py`
   - `models/users.py` ‚Üí `/unneeded/models/users.removed.py`
   
   **Commit:** abc123def456
   
   **Files Updated:** 8 files
   - `services/auth_service.py`
   - `routes/user_routes.py`
   - (list all updated files)
   ```

C) CI ENFORCEMENT

```

```python
"""Core base models and mixins"""

from datetime import datetime
from pydantic import BaseModel as PydanticBaseModel, Field

class BaseModel(PydanticBaseModel):
    """Base for all Pydantic models"""
    class Config:
        from_attributes = True
        validate_assignment = True

class TimestampMixin(BaseModel):
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)

class SoftDeleteMixin(BaseModel):
    is_deleted: bool = False
    deleted_at: datetime | None = None
```

```python
"""Central registry for all definitions"""

from .common import *
from .core import *
from .custom import *

__all__ = [
    # Common
    'Status', 'UserRole', 'APIResponse',
    # Core
    'BaseModel', 'TimestampMixin', 'SoftDeleteMixin',
    # Custom
    'ProjectStatus', 'Priority',
]
```

```python
#!/usr/bin/env python3
"""Analyze module dependencies and suggest build order."""

import ast
from pathlib import Path
from collections import defaultdict

def get_dependencies(file_path):
    """Get internal dependencies of a module."""
    with open(file_path) as f:
        try:
            tree = ast.parse(f.read())
        except SyntaxError:
            return set()
    
    deps = set()
    for node in ast.walk(tree):
        if isinstance(node, ast.ImportFrom):
            if node.module and not node.module.startswith(('os', 'sys', 'json')):
                # Only internal imports
                if not node.module.startswith(('django', 'flask', 'fastapi')):
                    deps.add(node.module.split('.')[0])
    
    return deps

def topological_sort(modules):
    """Sort modules by dependency order."""
    # Build dependency graph
    graph = {}
    in_degree = defaultdict(int)
    
    for module, deps in modules.items():
        graph[module] = deps
        for dep in deps:
            in_degree[dep] += 1
    
    # Find modules with no dependencies
    queue = [m for m in graph if in_degree[m] == 0]
    result = []
    
    while queue:
        module = queue.pop(0)
        result.append(module)
        
        for dep in graph.get(module, []):
            in_degree[dep] -= 1
            if in_degree[dep] == 0:
                queue.append(dep)
    
    return result

def main():
    """Analyze and print dependency order."""
    modules = {}
    
    for py_file in Path('.').rglob('*.py'):
        if '__pycache__' in str(py_file):
            continue
        
        module_name = str(py_file).replace('/', '.').replace('.py', '')
        deps = get_dependencies(py_file)
        modules[module_name] = deps
    
    order = topological_sort(modules)
    
    print("üìä Module Build Order (Least Dependent First):\n")
    for i, module in enumerate(order, 1):
        deps = modules.get(module, set())
        print(f"{i:3d}. {module}")
        if deps:
            print(f"     Dependencies: {', '.join(sorted(deps))}")
    
    print(f"\n‚úÖ Total modules: {len(order)}")
    print(f"‚úÖ Start with: {order[0] if order else 'None'}")

if __name__ == '__main__':
    main()
```

```python
# In multiple files
def view1(request):
    if not request.user.is_authenticated:
        return JsonResponse({'error': 'Unauthorized'}, status=401)
    # ...

def view2(request):
    if not request.user.is_authenticated:
        return JsonResponse({'error': 'Unauthorized'}, status=401)
    # ...
```

```python
"""
File: module_name/models/main_model.py
Module: module_name.models.main_model
Created: 2025-01-15
Author: Team
Description: ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä ŸÑŸÑŸàÿ≠ÿØÿ©

Dependencies:
- django.db.models
- django.contrib.auth.models
"""

from django.db import models
from django.contrib.auth.models import User
from decimal import Decimal

class MainModel(models.Model):
    """
    ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä ŸÑŸÑŸàÿ≠ÿØÿ©.
    
    Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿ¨ŸÖŸäÿπ ÿßŸÑÿ≠ŸÇŸàŸÑ ŸàÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©.
    """
    
    # ÿ≠ÿßŸÑÿßÿ™ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨
    STATE_DRAFT = 'draft'
    STATE_CONFIRMED = 'confirmed'
    STATE_CANCELLED = 'cancelled'
    
    STATES = [
        (STATE_DRAFT, 'ŸÖÿ≥ŸàÿØÿ©'),
        (STATE_CONFIRMED, 'ŸÖÿ§ŸÉÿØ'),
        (STATE_CANCELLED, 'ŸÖŸÑÿ∫Ÿä'),
    ]
    
    # ÿßŸÑÿ≠ŸÇŸàŸÑ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©
    name = models.CharField('ÿßŸÑÿßÿ≥ŸÖ', max_length=255)
    code = models.CharField('ÿßŸÑÿ±ŸÖÿ≤', max_length=50, unique=True)
    description = models.TextField('ÿßŸÑŸàÿµŸÅ', blank=True)
    
    # ÿßŸÑÿπŸÑÿßŸÇÿßÿ™
    user = models.ForeignKey(
        User,
        on_delete=models.CASCADE,
        verbose_name='ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ',
        related_name='%(class)s_records'
    )
    
    # ÿßŸÑÿ≠ÿßŸÑÿ©
    state = models.CharField(
        'ÿßŸÑÿ≠ÿßŸÑÿ©',
        max_length=20,
        choices=STATES,
        default=STATE_DRAFT
    )
    
    # ÿßŸÑÿ™Ÿàÿßÿ±ŸäÿÆ
    created_at = models.DateTimeField('ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ•ŸÜÿ¥ÿßÿ°', auto_now_add=True)
    updated_at = models.DateTimeField('ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ™ÿ≠ÿØŸäÿ´', auto_now=True)
    confirmed_at = models.DateTimeField('ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ™ÿ£ŸÉŸäÿØ', null=True, blank=True)
    
    # ÿßŸÑÿ≠ŸÇŸàŸÑ ÿßŸÑŸÖÿ≠ÿ≥Ÿàÿ®ÿ©
    total = models.DecimalField('ÿßŸÑÿ•ÿ¨ŸÖÿßŸÑŸä', max_digits=10, decimal_places=2, default=0)
    
    class Meta:
        verbose_name = 'ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä'
        verbose_name_plural = 'ÿßŸÑŸÜŸÖÿßÿ∞ÿ¨ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ©'
        ordering = ['-created_at']
        indexes = [
            models.Index(fields=['code']),
            models.Index(fields=['state', 'created_at']),
        ]
    
    def __str__(self):
        """ÿ™ŸÖÿ´ŸäŸÑ ŸÜÿµŸä ŸÑŸÑŸÜŸÖŸàÿ∞ÿ¨."""
        return f"{self.code} - {self.name}"
    
    def confirm(self):
        """
        ÿ™ÿ£ŸÉŸäÿØ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨.
        
        ŸäŸÇŸàŸÖ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿßŸÑÿ≠ÿßŸÑÿ© ÿ•ŸÑŸâ ŸÖÿ§ŸÉÿØ Ÿàÿ≠ŸÅÿ∏ ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ™ÿ£ŸÉŸäÿØ.
        
        Raises:
            ValueError: ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ŸÑŸäÿ≥ ŸÅŸä ÿ≠ÿßŸÑÿ© ŸÖÿ≥ŸàÿØÿ©
        """
        if self.state != self.STATE_DRAFT:
            raise ValueError("ŸÑÿß ŸäŸÖŸÉŸÜ ÿ™ÿ£ŸÉŸäÿØ ŸÜŸÖŸàÿ∞ÿ¨ ÿ∫Ÿäÿ± ŸÖÿ≥ŸàÿØÿ©")
        
        from django.utils import timezone
        self.state = self.STATE_CONFIRMED
        self.confirmed_at = timezone.now()
        self.save()
    
    def cancel(self):
        """
        ÿ•ŸÑÿ∫ÿßÿ° ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨.
        
        ŸäŸÇŸàŸÖ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿßŸÑÿ≠ÿßŸÑÿ© ÿ•ŸÑŸâ ŸÖŸÑÿ∫Ÿä.
        
        Raises:
            ValueError: ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ŸÖŸÑÿ∫Ÿä ÿ®ÿßŸÑŸÅÿπŸÑ
        """
        if self.state == self.STATE_CANCELLED:
            raise ValueError("ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ŸÖŸÑÿ∫Ÿä ÿ®ÿßŸÑŸÅÿπŸÑ")
        
        self.state = self.STATE_CANCELLED
        self.save()
    
    def compute_total(self):
        """
        ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿ•ÿ¨ŸÖÿßŸÑŸä.
        
        ŸäŸÇŸàŸÖ ÿ®ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿ•ÿ¨ŸÖÿßŸÑŸä ŸÖŸÜ ÿßŸÑÿπŸÜÿßÿµÿ± ÿßŸÑŸÖÿ±ÿ™ÿ®ÿ∑ÿ©.
        
        Returns:
            Decimal: ÿßŸÑÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑŸÖÿ≠ÿ≥Ÿàÿ®
        """
        total = sum(
            item.subtotal for item in self.items.all()
        )
        self.total = Decimal(str(total))
        self.save()
        return self.total
```

```python
"""
File: config/constants.py
Module: config.constants
Created: 2025-01-15
Author: Team
Description: System-wide constants and definitions

Dependencies: None
"""

from decimal import Decimal

# Application
APP_NAME = "{YOUR_PROJECT_NAME}"
APP_VERSION = "1.0.0"
APP_DESCRIPTION = "Enterprise Resource Planning System"

# Ports (SINGLE SOURCE OF TRUTH)
BACKEND_PORT = 8000
FRONTEND_PORT = 3000
API_PORT = 8000

# URLs
BACKEND_URL = f"http://{HOST}:{BACKEND_PORT}"
FRONTEND_URL = f"http://{HOST}:{FRONTEND_PORT}"
API_BASE_URL = f"{BACKEND_URL}/api"

# Database
DEFAULT_PAGE_SIZE = 20
MAX_PAGE_SIZE = 100

# Business Rules
DEFAULT_TAX_RATE = Decimal('0.15')  # 15%
DEFAULT_CURRENCY = 'SAR'
DEFAULT_LANGUAGE = 'ar'

# File Upload
MAX_UPLOAD_SIZE = 5 * 1024 * 1024  # 5MB
ALLOWED_IMAGE_TYPES = ['image/jpeg', 'image/png', 'image/gif']
ALLOWED_DOCUMENT_TYPES = ['application/pdf', 'application/msword']

# Validation
MIN_PASSWORD_LENGTH = 8
MAX_USERNAME_LENGTH = 50
EMAIL_REGEX = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'

# States
STATE_DRAFT = 'draft'
STATE_CONFIRMED = 'confirmed'
STATE_CANCELLED = 'cancelled'
STATE_DONE = 'done'

COMMON_STATES = [
    (STATE_DRAFT, 'ŸÖÿ≥ŸàÿØÿ©'),
    (STATE_CONFIRMED, 'ŸÖÿ§ŸÉÿØ'),
    (STATE_CANCELLED, 'ŸÖŸÑÿ∫Ÿä'),
    (STATE_DONE, 'ŸÖŸÜÿ™ŸáŸä'),
]

# Permissions
PERM_VIEW = 'view'
PERM_CREATE = 'create'
PERM_EDIT = 'edit'
PERM_DELETE = 'delete'
PERM_ADMIN = 'admin'

ALL_PERMISSIONS = [PERM_VIEW, PERM_CREATE, PERM_EDIT, PERM_DELETE, PERM_ADMIN]

# Error Messages
ERROR_REQUIRED_FIELD = "Ÿáÿ∞ÿß ÿßŸÑÿ≠ŸÇŸÑ ŸÖÿ∑ŸÑŸàÿ®"
ERROR_INVALID_EMAIL = "ÿßŸÑÿ®ÿ±ŸäÿØ ÿßŸÑÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸä ÿ∫Ÿäÿ± ÿµÿ≠Ÿäÿ≠"
ERROR_PASSWORD_TOO_SHORT = f"ŸÉŸÑŸÖÿ© ÿßŸÑŸÖÿ±Ÿàÿ± Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ŸÉŸàŸÜ {MIN_PASSWORD_LENGTH} ÿ£ÿ≠ÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿ£ŸÇŸÑ"
ERROR_UNAUTHORIZED = "ÿ∫Ÿäÿ± ŸÖÿµÿ±ÿ≠"
ERROR_NOT_FOUND = "ÿ∫Ÿäÿ± ŸÖŸàÿ¨ŸàÿØ"
ERROR_INTERNAL_SERVER = "ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑÿÆÿßÿØŸÖ"

# Success Messages
SUCCESS_CREATED = "ÿ™ŸÖ ÿßŸÑÿ•ŸÜÿ¥ÿßÿ° ÿ®ŸÜÿ¨ÿßÿ≠"
SUCCESS_UPDATED = "ÿ™ŸÖ ÿßŸÑÿ™ÿ≠ÿØŸäÿ´ ÿ®ŸÜÿ¨ÿßÿ≠"
SUCCESS_DELETED = "ÿ™ŸÖ ÿßŸÑÿ≠ÿ∞ŸÅ ÿ®ŸÜÿ¨ÿßÿ≠"
SUCCESS_CONFIRMED = "ÿ™ŸÖ ÿßŸÑÿ™ÿ£ŸÉŸäÿØ ÿ®ŸÜÿ¨ÿßÿ≠"
```

```python
"""
File: config/definitions/types.py
Module: config.definitions.types
Created: 2025-01-15
Author: Team
Description: Type definitions and type hints
"""

from typing import TypedDict, Literal, Optional, List, Dict, Any
from decimal import Decimal
from datetime import datetime

# State types
StateType = Literal['draft', 'confirmed', 'cancelled', 'done']
PermissionType = Literal['view', 'create', 'edit', 'delete', 'admin']

# API Response types
class APIResponse(TypedDict):
    """Standard API response structure."""
    success: bool
    message: str
    data: Optional[Dict[str, Any]]
    errors: Optional[List[str]]

class PaginatedResponse(TypedDict):
    """Paginated API response."""
    count: int
    next: Optional[str]
    previous: Optional[str]
    results: List[Dict[str, Any]]

# Business types
class OrderItem(TypedDict):
    """Order item structure."""
    product_id: int
    quantity: int
    price: Decimal
    subtotal: Decimal

class Order(TypedDict):
    """Order structure."""
    id: int
    code: str
    customer_id: int
    items: List[OrderItem]
    subtotal: Decimal
    tax: Decimal
    total: Decimal
    state: StateType
    created_at: datetime
```

```python
#!/usr/bin/env python3
"""
Analyze gaps between design and implementation.

File: scripts/analyze_gaps.py
Module: scripts.analyze_gaps
Created: 2025-01-15
Author: Team
Description: Compare design specs with actual implementation
"""

import ast
import json
from pathlib import Path
from typing import Dict, List, Set

def find_api_endpoints() -> Set[str]:
    """Find all defined API endpoints."""
    endpoints = set()
    
    for py_file in Path('.').rglob('*views.py'):
        with open(py_file) as f:
            content = f.read()
        
        # Find @api_view decorators
        import re
        patterns = re.findall(r'@api_view\([\'"]([A-Z]+)[\'"]\)', content)
        # Find route definitions
        routes = re.findall(r'path\([\'"]([^\'\"]+)[\'"]', content)
        
        endpoints.update(routes)
    
    return endpoints

def find_frontend_routes() -> Set[str]:
    """Find all frontend routes."""
    routes = set()
    
    # Check React Router
    for tsx_file in Path('.').rglob('*.tsx'):
        with open(tsx_file) as f:
            content = f.read()
        
        import re
        patterns = re.findall(r'<Route\s+path=[\'"]([^\'\"]+)[\'"]', content)
        routes.update(patterns)
    
    return routes

def find_database_models() -> Set[str]:
    """Find all database models."""
    models = set()
    
    for py_file in Path('.').rglob('models.py'):
        with open(py_file) as f:
            try:
                tree = ast.parse(f.read())
            except SyntaxError:
                continue
        
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # Check if it's a Django model
                for base in node.bases:
                    if isinstance(base, ast.Attribute):
                        if base.attr == 'Model':
                            models.add(node.name)
    
    return models

def load_design_spec(spec_file: str) -> Dict:
    """Load design specification."""
    with open(spec_file) as f:
        return json.load(f)

def analyze_gaps(spec_file: str = 'docs/design_spec.json'):
    """Analyze gaps between design and implementation."""
    print("üîç Analyzing Design vs Implementation Gaps\n")
    
    # Load design spec
    try:
        spec = load_design_spec(spec_file)
    except FileNotFoundError:
        print(f"‚ö†Ô∏è  Design spec not found: {spec_file}")
        print("   Create docs/design_spec.json with your design")
        return
    
    # Find implementation
    api_endpoints = find_api_endpoints()
    frontend_routes = find_frontend_routes()
    db_models = find_database_models()
    
    # Compare
    gaps = []
    
    # Check API endpoints
    if 'api_endpoints' in spec:
        for endpoint in spec['api_endpoints']:
            if endpoint not in api_endpoints:
                gaps.append(f"Missing API endpoint: {endpoint}")
    
    # Check frontend routes
    if 'frontend_routes' in spec:
        for route in spec['frontend_routes']:
            if route not in frontend_routes:
                gaps.append(f"Missing frontend route: {route}")
    
    # Check database models
    if 'models' in spec:
        for model in spec['models']:
            if model not in db_models:
                gaps.append(f"Missing database model: {model}")
    
    # Report
    if gaps:
        print("‚ùå Gaps Found:\n")
        for gap in gaps:
            print(f"  ‚Ä¢ {gap}")
        print(f"\nTotal gaps: {len(gaps)}")
    else:
        print("‚úÖ No gaps found! Design matches implementation.")
    
    # Summary
    print("\nüìä Summary:")
    print(f"  API Endpoints: {len(api_endpoints)} implemented")
    print(f"  Frontend Routes: {len(frontend_routes)} implemented")
    print(f"  Database Models: {len(db_models)} implemented")

if __name__ == '__main__':
    analyze_gaps()
```

```python
# Cannot be updated automatically
module_name = "models.user_unified"
mod = __import__(module_name)
```

```python
# myapp/__init__.py
"""
MyApp - Main application package

Subpackages:
    - core: Core functionality
    - models: Data models
    - services: Business logic
    - api: API endpoints
    - utils: Utility functions
"""

# Import commonly used items from subpackages
from .core import App, Config
from .models import User, Session
from .services import UserService, AuthService

# Version info
from .version import __version__, __version_info__

# Public API
__all__ = [
    # Core
    'App',
    'Config',
    # Models
    'User',
    'Session',
    # Services
    'UserService',
    'AuthService',
    # Version
    '__version__',
    '__version_info__',
]

# Subpackage references (for documentation)
__subpackages__ = [
    'core',
    'models',
    'services',
    'api',
    'utils',
]
```

```python
# ‚ùå PROBLEM: Circular dependency
# models/__init__.py
from .user import User
from .post import Post  # Post imports User, User imports Post!

# ‚úÖ SOLUTION 1: Import at function level
# models/user.py
def get_user_posts(user_id):
    from .post import Post  # Import here, not at module level
    return Post.query.filter_by(user_id=user_id).all()

# ‚úÖ SOLUTION 2: Use TYPE_CHECKING
# models/user.py
from typing import TYPE_CHECKING, List

if TYPE_CHECKING:
    from .post import Post

class User:
    def get_posts(self) -> List['Post']:  # String annotation
        from .post import Post
        return Post.query.filter_by(user_id=self.id).all()

# ‚úÖ SOLUTION 3: Restructure - create base module
# models/base.py - common base classes
# models/user.py - imports from base
# models/post.py - imports from base
# models/__init__.py - imports both
```

```python
# enterprise_app/__init__.py
"""
Enterprise Application

Large-scale application with multiple subpackages.
Import subpackages explicitly for better organization.

Usage:
    # Import main app
    from enterprise_app import App
    
    # Import specific modules
    from enterprise_app.core import Config
    from enterprise_app.models import User
    from enterprise_app.services.auth import AuthService
"""

# Only expose the absolute essentials at top level
from .core import App
from ._version import __version__

# Make subpackages easily accessible
from . import (
    core,
    models,
    services,
    api,
    utils,
    exceptions,
)

# Minimal public API at package level
__all__ = [
    'App',
    '__version__',
    # Subpackages
    'core',
    'models',
    'services',
    'api',
    'utils',
    'exceptions',
]

# Package metadata
__author__ = 'Enterprise Team'
__license__ = 'Proprietary'
__copyright__ = 'Copyright 2025, Enterprise Corp'
```



================================================================================
END OF 10_BACKEND
================================================================================


================================================================================
MODULE: 11_FRONTEND
================================================================================

=================================================================================
FRONTEND DEVELOPMENT - React, Vue, Angular
=================================================================================

Version: 5.0.0
Type: Architecture - Frontend

Comprehensive guidance for modern frontend development.

=================================================================================
FRAMEWORK SELECTION
=================================================================================

**React:**
- Component-based architecture
- Large ecosystem
- Flexible and unopinionated
- JSX syntax
- Virtual DOM

**Vue:**
- Progressive framework
- Easy learning curve
- Template-based
- Reactive data binding
- Official router and state management

**Angular:**
- Full-featured framework
- TypeScript by default
- Dependency injection
- RxJS for reactive programming
- CLI tooling

=================================================================================
REACT BEST PRACTICES
=================================================================================

## Project Structure

```
src/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ common/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Button.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Input.jsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Modal.jsx
‚îÇ   ‚îî‚îÄ‚îÄ features/
‚îÇ       ‚îú‚îÄ‚îÄ products/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ProductList.jsx
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ProductCard.jsx
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ProductDetail.jsx
‚îÇ       ‚îî‚îÄ‚îÄ users/
‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îú‚îÄ‚îÄ Home.jsx
‚îÇ   ‚îú‚îÄ‚îÄ Products.jsx
‚îÇ   ‚îî‚îÄ‚îÄ Profile.jsx
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ api.js
‚îÇ   ‚îú‚îÄ‚îÄ auth.js
‚îÇ   ‚îî‚îÄ‚îÄ products.js
‚îú‚îÄ‚îÄ store/
‚îÇ   ‚îú‚îÄ‚îÄ index.js
‚îÇ   ‚îú‚îÄ‚îÄ slices/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ authSlice.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ productsSlice.js
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îú‚îÄ‚îÄ useAuth.js
‚îÇ   ‚îî‚îÄ‚îÄ useProducts.js
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ helpers.js
‚îÇ   ‚îî‚îÄ‚îÄ constants.js
‚îú‚îÄ‚îÄ App.jsx
‚îî‚îÄ‚îÄ main.jsx
```

## Components

```jsx
import React, { useState, useEffect } from 'react';
import PropTypes from 'prop-types';

const ProductCard = ({ product, onAddToCart }) => {
  const [quantity, setQuantity] = useState(1);
  
  const handleAddToCart = () => {
    onAddToCart(product.id, quantity);
  };
  
  return (
    <div className="product-card">
      <img src={product.image} alt={product.name} />
      <h3>{product.name}</h3>
      <p>{product.description}</p>
      <p className="price">${product.price}</p>
      <div className="quantity">
        <button onClick={() => setQuantity(Math.max(1, quantity - 1))}>
          -
        </button>
        <span>{quantity}</span>
        <button onClick={() => setQuantity(quantity + 1)}>+</button>
      </div>
      <button onClick={handleAddToCart}>Add to Cart</button>
    </div>
  );
};

ProductCard.propTypes = {
  product: PropTypes.shape({
    id: PropTypes.number.isRequired,
    name: PropTypes.string.isRequired,
    description: PropTypes.string,
    price: PropTypes.number.isRequired,
    image: PropTypes.string,
  }).isRequired,
  onAddToCart: PropTypes.func.isRequired,
};

export default ProductCard;
```

## Custom Hooks

```jsx
import { useState, useEffect } from 'react';
import { getProducts } from '../services/products';

export const useProducts = () => {
  const [products, setProducts] = useState([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);
  
  useEffect(() => {
    const fetchProducts = async () => {
      try {
        setLoading(true);
        const data = await getProducts();
        setProducts(data);
      } catch (err) {
        setError(err.message);
      } finally {
        setLoading(false);
      }
    };
    
    fetchProducts();
  }, []);
  
  return { products, loading, error };
};
```

## State Management (Redux Toolkit)

```javascript
import { createSlice, createAsyncThunk } from '@reduxjs/toolkit';
import { getProducts, createProduct } from '../../services/products';

export const fetchProducts = createAsyncThunk(
  'products/fetchProducts',
  async () => {
    const response = await getProducts();
    return response;
  }
);

const productsSlice = createSlice({
  name: 'products',
  initialState: {
    items: [],
    status: 'idle',
    error: null,
  },
  reducers: {},
  extraReducers: (builder) => {
    builder
      .addCase(fetchProducts.pending, (state) => {
        state.status = 'loading';
      })
      .addCase(fetchProducts.fulfilled, (state, action) => {
        state.status = 'succeeded';
        state.items = action.payload;
      })
      .addCase(fetchProducts.rejected, (state, action) => {
        state.status = 'failed';
        state.error = action.error.message;
      });
  },
});

export default productsSlice.reducer;
```

## Routing (React Router)

```jsx
import { BrowserRouter, Routes, Route, Navigate } from 'react-router-dom';
import Home from './pages/Home';
import Products from './pages/Products';
import ProductDetail from './pages/ProductDetail';
import Profile from './pages/Profile';
import Login from './pages/Login';
import { useAuth } from './hooks/useAuth';

const PrivateRoute = ({ children }) => {
  const { isAuthenticated } = useAuth();
  return isAuthenticated ? children : <Navigate to="/login" />;
};

function App() {
  return (
    <BrowserRouter>
      <Routes>
        <Route path="/" element={<Home />} />
        <Route path="/products" element={<Products />} />
        <Route path="/products/:id" element={<ProductDetail />} />
        <Route path="/login" element={<Login />} />
        <Route
          path="/profile"
          element={
            <PrivateRoute>
              <Profile />
            </PrivateRoute>
          }
        />
      </Routes>
    </BrowserRouter>
  );
}
```

## API Service

```javascript
import axios from 'axios';

const API_URL = import.meta.env.VITE_API_URL || 'http://localhost:8000/api';

const api = axios.create({
  baseURL: API_URL,
  headers: {
    'Content-Type': 'application/json',
  },
});

// Request interceptor
api.interceptors.request.use(
  (config) => {
    const token = localStorage.getItem('token');
    if (token) {
      config.headers.Authorization = `Bearer ${token}`;
    }
    return config;
  },
  (error) => Promise.reject(error)
);

// Response interceptor
api.interceptors.response.use(
  (response) => response,
  (error) => {
    if (error.response?.status === 401) {
      localStorage.removeItem('token');
      window.location.href = '/login';
    }
    return Promise.reject(error);
  }
);

export const getProducts = async () => {
  const response = await api.get('/products/');
  return response.data;
};

export const getProduct = async (id) => {
  const response = await api.get(`/products/${id}/`);
  return response.data;
};

export const createProduct = async (data) => {
  const response = await api.post('/products/', data);
  return response.data;
};

export default api;
```

=================================================================================
VUE BEST PRACTICES
=================================================================================

## Project Structure

```
src/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ common/
‚îÇ   ‚îî‚îÄ‚îÄ features/
‚îú‚îÄ‚îÄ views/
‚îú‚îÄ‚îÄ store/
‚îÇ   ‚îú‚îÄ‚îÄ index.js
‚îÇ   ‚îî‚îÄ‚îÄ modules/
‚îú‚îÄ‚îÄ router/
‚îÇ   ‚îî‚îÄ‚îÄ index.js
‚îú‚îÄ‚îÄ services/
‚îú‚îÄ‚îÄ composables/
‚îú‚îÄ‚îÄ App.vue
‚îî‚îÄ‚îÄ main.js
```

## Components

```vue
<template>
  <div class="product-card">
    <img :src="product.image" :alt="product.name" />
    <h3>{{ product.name }}</h3>
    <p>{{ product.description }}</p>
    <p class="price">${{ product.price }}</p>
    <div class="quantity">
      <button @click="decreaseQuantity">-</button>
      <span>{{ quantity }}</span>
      <button @click="increaseQuantity">+</button>
    </div>
    <button @click="addToCart">Add to Cart</button>
  </div>
</template>

<script setup>
import { ref } from 'vue';

const props = defineProps({
  product: {
    type: Object,
    required: true,
  },
});

const emit = defineEmits(['add-to-cart']);

const quantity = ref(1);

const increaseQuantity = () => {
  quantity.value++;
};

const decreaseQuantity = () => {
  if (quantity.value > 1) {
    quantity.value--;
  }
};

const addToCart = () => {
  emit('add-to-cart', props.product.id, quantity.value);
};
</script>

<style scoped>
.product-card {
  border: 1px solid #ddd;
  padding: 1rem;
  border-radius: 8px;
}

.price {
  font-size: 1.5rem;
  font-weight: bold;
  color: #2c3e50;
}
</style>
```

## Composables

```javascript
import { ref, onMounted } from 'vue';
import { getProducts } from '@/services/products';

export function useProducts() {
  const products = ref([]);
  const loading = ref(true);
  const error = ref(null);
  
  const fetchProducts = async () => {
    try {
      loading.value = true;
      products.value = await getProducts();
    } catch (err) {
      error.value = err.message;
    } finally {
      loading.value = false;
    }
  };
  
  onMounted(() => {
    fetchProducts();
  });
  
  return {
    products,
    loading,
    error,
    fetchProducts,
  };
}
```

## State Management (Pinia)

```javascript
import { defineStore } from 'pinia';
import { getProducts } from '@/services/products';

export const useProductsStore = defineStore('products', {
  state: () => ({
    items: [],
    loading: false,
    error: null,
  }),
  
  getters: {
    activeProducts: (state) => state.items.filter(p => p.is_active),
  },
  
  actions: {
    async fetchProducts() {
      this.loading = true;
      try {
        this.items = await getProducts();
      } catch (error) {
        this.error = error.message;
      } finally {
        this.loading = false;
      }
    },
  },
});
```

=================================================================================
PERFORMANCE OPTIMIZATION
=================================================================================

## Code Splitting

**React:**
```jsx
import { lazy, Suspense } from 'react';

const Products = lazy(() => import('./pages/Products'));

function App() {
  return (
    <Suspense fallback={<div>Loading...</div>}>
      <Products />
    </Suspense>
  );
}
```

**Vue:**
```javascript
const Products = () => import('./views/Products.vue');

const routes = [
  {
    path: '/products',
    component: Products,
  },
];
```

## Memoization

**React:**
```jsx
import { useMemo, useCallback } from 'react';

const ProductList = ({ products, onSelect }) => {
  const sortedProducts = useMemo(() => {
    return [...products].sort((a, b) => a.price - b.price);
  }, [products]);
  
  const handleSelect = useCallback((id) => {
    onSelect(id);
  }, [onSelect]);
  
  return (
    <div>
      {sortedProducts.map(product => (
        <ProductCard
          key={product.id}
          product={product}
          onSelect={handleSelect}
        />
      ))}
    </div>
  );
};
```

=================================================================================
TESTING
=================================================================================

## React Testing Library

```jsx
import { render, screen, fireEvent } from '@testing-library/react';
import ProductCard from './ProductCard';

describe('ProductCard', () => {
  const mockProduct = {
    id: 1,
    name: 'Test Product',
    price: 99.99,
    description: 'Test description',
  };
  
  const mockOnAddToCart = jest.fn();
  
  it('renders product information', () => {
    render(<ProductCard product={mockProduct} onAddToCart={mockOnAddToCart} />);
    
    expect(screen.getByText('Test Product')).toBeInTheDocument();
    expect(screen.getByText('$99.99')).toBeInTheDocument();
  });
  
  it('calls onAddToCart when button clicked', () => {
    render(<ProductCard product={mockProduct} onAddToCart={mockOnAddToCart} />);
    
    const button = screen.getByText('Add to Cart');
    fireEvent.click(button);
    
    expect(mockOnAddToCart).toHaveBeenCalledWith(1, 1);
  });
});
```

=================================================================================
END OF FRONTEND PROMPT
=================================================================================


================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

Mock external dependencies
  
- **Integration Tests:** 20% of total tests
  - Test component interactions
  - Real database (test instance)
  - API integration
  
- **E2E Tests:** 10% of total tests
  - Full user workflows
  - Selenium/Playwright
  - Critical paths only

**Coverage Targets:**
- Overall: ‚â•80%
- Critical modules: ‚â•90%
- Utilities: ‚â•95%

### 46.5 Quality Tools

**Required Tools:**
```bash
# Install all verification tools
pip install \
  pre-commit \
  pytest pytest-cov pytest-xdist pytest-mock \
  flake8 pylint black isort \
  mypy types-requests types-PyYAML \
  bandit safety \
  radon vulture mccabe \
  coverage
```

**Tool Configuration:**

**`pyproject.toml`:**
```toml
[tool.black]
line-length = 120
target-version = ['py311']

[tool.isort]
profile = "black"
line_length = 120

[tool.pytest.ini_options]
minversion = "7.0"
addopts = "-ra -q --strict-markers --cov=. --cov-report=term --cov-report=html"
testpaths = ["tests"]

[tool.coverage.run]
source = ["."]
omit = ["*/t

================================================================================
CRITICAL MISSING CONTENT - Deep Search Recovery
================================================================================

```python
#!/usr/bin/env python3
"""Check that all files have proper headers."""

import re
import sys
from pathlib import Path

REQUIRED_FIELDS = ['File:', 'Module:', 'Created:', 'Author:', 'Description:']

def check_python_header(file_path):
    """Check Python file header."""
    with open(file_path) as f:
        content = f.read(500)  # First 500 chars
    
    if not content.startswith('"""'):
        return False, "Missing docstring header"
    
    for field in REQUIRED_FIELDS:
        if field not in content:
            return False, f"Missing field: {field}"
    
    return True, "OK"

def check_ts_header(file_path):
    """Check TypeScript/JavaScript file header."""
    with open(file_path) as f:
        content = f.read(500)
    
    if not content.startswith('/**'):
        return False, "Missing JSDoc header"
    
    for field in REQUIRED_FIELDS:
        if field not in content:
            return False, f"Missing field: {field}"
    
    return True, "OK"

def main():
    """Check all files."""
    issues = []
    
    for file_path in Path('.').rglob('*'):
        if file_path.suffix == '.py' and '__pycache__' not in str(file_path):
            ok, msg = check_python_header(file_path)
            if not ok:
                issues.append(f"{file_path}: {msg}")
        
        elif file_path.suffix in ('.ts', '.tsx', '.js', '.jsx'):
            ok, msg = check_ts_header(file_path)
            if not ok:
                issues.append(f"{file_path}: {msg}")
    
    if issues:
        print("‚ùå File header issues found:\n")
        for issue in issues:
            print(f"  {issue}")
        sys.exit(1)
    
    print("‚úÖ All file headers are correct")

if __name__ == '__main__':
    main()
```



================================================================================
END OF 11_FRONTEND
================================================================================


================================================================================
MODULE: 12_DATABASE
================================================================================

=================================================================================
DATABASE DESIGN & MANAGEMENT - PostgreSQL, MySQL, MongoDB
=================================================================================

Version: 5.0.0
Type: Architecture - Database

Comprehensive guidance for database design, optimization, and management.

=================================================================================
DATABASE SELECTION
=================================================================================

**PostgreSQL:**
- ACID compliance
- Advanced features (JSON, arrays, full-text search)
- Strong data integrity
- Complex queries
- Open source

**MySQL:**
- High performance
- Wide adoption
- Good for read-heavy workloads
- Simpler than PostgreSQL
- Open source

**MongoDB:**
- Document-oriented
- Flexible schema
- Horizontal scaling
- Good for unstructured data
- JSON-like documents

=================================================================================
SCHEMA DESIGN PRINCIPLES
=================================================================================

## Normalization

**1NF (First Normal Form):**
- Atomic values
- No repeating groups
- Each column contains only one value

**2NF (Second Normal Form):**
- Must be in 1NF
- No partial dependencies
- All non-key attributes depend on entire primary key

**3NF (Third Normal Form):**
- Must be in 2NF
- No transitive dependencies
- Non-key attributes depend only on primary key

## Example Schema

```sql
-- Users table
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    username VARCHAR(150) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    first_name VARCHAR(100),
    last_name VARCHAR(100),
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Products table
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name VARCHAR(200) NOT NULL,
    description TEXT,
    price DECIMAL(10, 2) NOT NULL CHECK (price >= 0),
    stock INTEGER DEFAULT 0 CHECK (stock >= 0),
    category_id INTEGER REFERENCES categories(id),
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Orders table
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    total_amount DECIMAL(10, 2) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Order items table
CREATE TABLE order_items (
    id SERIAL PRIMARY KEY,
    order_id INTEGER REFERENCES orders(id) ON DELETE CASCADE,
    product_id INTEGER REFERENCES products(id),
    quantity INTEGER NOT NULL CHECK (quantity > 0),
    price DECIMAL(10, 2) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## Indexes

```sql
-- Single column index
CREATE INDEX idx_users_email ON users(email);

-- Composite index
CREATE INDEX idx_orders_user_status ON orders(user_id, status);

-- Unique index
CREATE UNIQUE INDEX idx_users_username ON users(username);

-- Partial index
CREATE INDEX idx_active_products ON products(name) 
WHERE is_active = TRUE;

-- Full-text search index (PostgreSQL)
CREATE INDEX idx_products_search ON products 
USING GIN(to_tsvector('english', name || ' ' || description));
```

=================================================================================
QUERY OPTIMIZATION
=================================================================================

## EXPLAIN ANALYZE

```sql
EXPLAIN ANALYZE
SELECT p.*, c.name as category_name
FROM products p
JOIN categories c ON p.category_id = c.id
WHERE p.price > 100
ORDER BY p.created_at DESC
LIMIT 20;
```

## Common Optimizations

**1. Use indexes:**
```sql
-- Before
SELECT * FROM products WHERE name LIKE '%laptop%';

-- After (with index)
CREATE INDEX idx_products_name ON products(name);
SELECT * FROM products WHERE name LIKE 'laptop%';
```

**2. Avoid SELECT *:**
```sql
-- Before
SELECT * FROM products;

-- After
SELECT id, name, price FROM products;
```

**3. Use JOINs instead of subqueries:**
```sql
-- Before (slow)
SELECT * FROM orders 
WHERE user_id IN (SELECT id FROM users WHERE is_active = TRUE);

-- After (faster)
SELECT o.* FROM orders o
JOIN users u ON o.user_id = u.id
WHERE u.is_active = TRUE;
```

**4. Limit results:**
```sql
SELECT * FROM products 
ORDER BY created_at DESC 
LIMIT 20 OFFSET 0;
```

=================================================================================
MIGRATIONS
=================================================================================

## Django Migrations

```python
# Create migration
python manage.py makemigrations

# Apply migrations
python manage.py migrate

# Show migrations
python manage.py showmigrations

# Custom migration
from django.db import migrations

def add_sample_data(apps, schema_editor):
    Product = apps.get_model('products', 'Product')
    Product.objects.create(
        name='Sample Product',
        price=99.99,
        stock=10
    )

class Migration(migrations.Migration):
    dependencies = [
        ('products', '0001_initial'),
    ]
    
    operations = [
        migrations.RunPython(add_sample_data),
    ]
```

## Alembic Migrations (FastAPI)

```python
# Generate migration
alembic revision --autogenerate -m "Add products table"

# Apply migrations
alembic upgrade head

# Rollback
alembic downgrade -1

# Migration file
def upgrade():
    op.create_table(
        'products',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(200), nullable=False),
        sa.Column('price', sa.Numeric(10, 2), nullable=False),
        sa.PrimaryKeyConstraint('id')
    )

def downgrade():
    op.drop_table('products')
```

=================================================================================
BACKUP & RESTORE
=================================================================================

## PostgreSQL

```bash
# Backup
pg_dump -U postgres -d mydb > backup.sql

# Backup with compression
pg_dump -U postgres -d mydb | gzip > backup.sql.gz

# Restore
psql -U postgres -d mydb < backup.sql

# Restore from compressed
gunzip -c backup.sql.gz | psql -U postgres -d mydb
```

## MySQL

```bash
# Backup
mysqldump -u root -p mydb > backup.sql

# Restore
mysql -u root -p mydb < backup.sql
```

## MongoDB

```bash
# Backup
mongodump --db mydb --out /backup/

# Restore
mongorestore --db mydb /backup/mydb/
```

=================================================================================
SECURITY
=================================================================================

## SQL Injection Prevention

**Bad (vulnerable):**
```python
# DON'T DO THIS
query = f"SELECT * FROM users WHERE email = '{email}'"
```

**Good (safe):**
```python
# Django ORM
User.objects.filter(email=email)

# Raw SQL with parameters
cursor.execute("SELECT * FROM users WHERE email = %s", [email])
```

## Encryption

```sql
-- Encrypt sensitive data
CREATE EXTENSION IF NOT EXISTS pgcrypto;

INSERT INTO users (email, password_hash)
VALUES ('user@example.com', crypt('password123', gen_salt('bf')));

-- Verify password
SELECT * FROM users 
WHERE email = 'user@example.com' 
AND password_hash = crypt('password123', password_hash);
```

=================================================================================
MONITORING
=================================================================================

## PostgreSQL

```sql
-- Active connections
SELECT * FROM pg_stat_activity;

-- Database size
SELECT pg_size_pretty(pg_database_size('mydb'));

-- Table sizes
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Slow queries
SELECT query, mean_exec_time, calls
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;
```

=================================================================================
END OF DATABASE PROMPT
=================================================================================


================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

Swagger
- Auto-generated from code
- Interactive docs (/docs, /redoc)
- Examples for all endpoints
- Error codes documented

J) Observability Hooks
- log_activity: all requests, CRUD, exports
- system_health: /health endpoint
- system_monitoring: metrics export
- Distributed tracing: OpenTelemetry
- Correlation IDs in logs

K) Security Hardening
- HTTPS only (redirect HTTP)
- Security headers: CSP, HSTS, X-Frame-Options
- Secrets: KMS/Vault, never in code
- SSRF prevention: URL validation
- Rate limiting per endpoint
- API key rotation

L) Testing Strategy
- Unit tests: >80% coverage
- Integration tests: DB, external APIs
- Contract tests: API schemas
- Load tests: k6, Locust
- Security tests: OWASP ZAP

‚∏ª

7) DATABASE DESIGN & MIGRATIONS (Expanded in v3.0)

A) Database Selection
- PostgreSQL: ACID, JSON, full-text search
- MySQL: wide adoption, replication
- MongoDB: document store, flexible schema
- Redis: cache, sessions, queues
- Elasticsearch: full-text search, analytics

B) Schem
 resources
- Ansible for configuration
- Version controlled
- Modular, reusable
- Tested in staging

E) Monitoring & Logging
- Prometheus + Grafana for metrics
- ELK / Loki for logs
- OpenTelemetry for tracing
- Alerts: Slack, PagerDuty
- Dashboards: uptime, latency, errors

F) Disaster Recovery
- Multi-region deployment
- Automated backups (daily)
- Tested restore procedure
- RTO: <1 hour, RPO: <15 minutes
- Runbooks for incidents

‚∏ª

10) TESTING & QA FRAMEWORK (Expanded in v3.0)

A) Testing Pyramid
- Unit tests: 70% (fast, isolated)
- Integration tests: 20% (DB, APIs)
- E2E tests: 10% (critical paths)

B) Unit Testing
- Coverage: >80% (target 90%)
- Frameworks: Jest, Pytest, Go test
- Mocking: external dependencies
- Fast: <5 seconds total

C) Integration Testing
- Database: test DB, migrations
- External APIs: mocked or test env
- Message queues: test broker
- Coverage: critical flows

D) E2E Testing
- Playwright, Cypress, Selenium
- Critical user journeys
- Run in CI before deploy

h fixed"
```

### CI Check
```yaml
- name: Check Line Length
  run: |
    flake8 . --max-line-length=120 --exclude=venv,.venv,migrations
```

## Rules
1. ‚úÖ Max 120 characters per line
2. ‚úÖ Break long strings
3. ‚úÖ Use parentheses for line continuation
4. ‚úÖ CI enforced
5. ‚úÖ Auto-fix before commit

## Examples

### ‚ùå Bad (>120)
```python
result = some_very_long_function_name(parameter1, parameter2, parameter3, parameter4, parameter5, parameter6, parameter7)
```

### ‚úÖ Good (‚â§120)
```python
result = some_very_long_function_name(
    parameter1, parameter2, parameter3,
    parameter4, parameter5, parameter6,
    parameter7
)
```

================================================================================
42. ENVIRONMENT-BASED ERROR HANDLING
================================================================================

## Problem
- Same error display in Dev & Production
- Stack traces leak in Production (security risk)
- No error tracking

## Solution: Environment-Aware Error Handler
      ‚îÇ
‚îÇ  ‚úì All tests passing                                        ‚îÇ
‚îÇ  ‚úì No uncommitted changes                                   ‚îÇ
‚îÇ  ‚úì Database migrations ready                                ‚îÇ
‚îÇ  ‚úì Environment variables set                                ‚îÇ
‚îÇ  ‚úì SSL certificates valid                                   ‚îÇ
‚îÇ  ‚úì Dependencies up to date                                  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 2: Backup Current State                               ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                               ‚îÇ
‚îÇ  ‚úì Backup database                                          ‚îÇ
‚îÇ  ‚úì Backup configuration files                               ‚îÇ
‚îÇ  ‚úì Backup uploaded files                                    ‚îÇ
‚îÇ  ‚úì Create restore point                                     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 3: Build Production Assets                            ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÄ‚îÄ                            ‚îÇ
‚îÇ  ‚úì Build frontend (minified)                                ‚îÇ
‚îÇ  ‚úì Build backend (optimized)                                ‚îÇ
‚îÇ  ‚úì Compile assets                                           ‚îÇ
‚îÇ  ‚úì Generate static files                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 4: Database Setup                                     ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                      ‚îÇ
‚îÇ  ‚úì Run migrations                                           ‚îÇ
‚îÇ  ‚úì Create admin user                                        ‚îÇ
‚îÇ  ‚úì Set up initial data                                      ‚îÇ
‚îÇ  ‚úì Verify database integrity                                ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 5: Security Hardening                                 ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                     ‚îÇ
‚îÇ  ‚úì Enable HTTPS                                             ‚îÇ
‚îÇ  ‚úì Set
e = config['database']['name']
   frontend_port = config['ports']['frontend']
   
   # Never hardcode values
   # ‚ùå APP_NAME = "Gaara ERP"
   # ‚úì APP_NAME = config['project']['name']
   ```

3. **Respect project phase:**
   ```python
   if config['project']['phase'] == 'development':
       # Development behavior
       enable_debug_mode()
       allow_sample_data()
       relaxed_security()
   else:
       # Production behavior
       disable_debug_mode()
       strict_security()
       enable_monitoring()
   ```

---

### 64.10 Commands Reference

**Development Phase:**

```bash
# Database
reset-db              # Drop and recreate database
seed-data             # Add sample data
migrate-db            # Run migrations
backup-db             # Create backup

# Development
dev-server            # Start development server
hot-reload            # Enable hot reload
clear-cache           # Clear all caches
run-tests             # Run test suite

# Deployment
start deploy          # Begin dep

================================================================================
CRITICAL MISSING CONTENT - Deep Search Recovery
================================================================================

```bash
#!/bin/bash
# scripts/fix_line_length.sh

echo "Fixing line length..."

# Install tools
pip install autopep8 black isort

# Fix Python files
autopep8 --in-place --aggressive --aggressive \
  --max-line-length=120 \
  --recursive \
  --exclude=venv,.venv,migrations \
  .

black --line-length=120 .
isort --profile=black --line-length=120 .

echo "‚úÖ Line length fixed"
```

```python
# backend/src/setup/wizard.py
from flask import Blueprint, render_template, request, redirect, session
from .validators import validate_admin_user, validate_db_config, validate_smtp

setup_bp = Blueprint('setup', __name__, url_prefix='/setup')

@setup_bp.route('/wizard', methods=['GET', 'POST'])
def wizard():
    step = request.args.get('step', '1')
    
    if request.method == 'POST':
        if step == '1':
            # Requirements check passed
            return redirect('/setup/wizard?step=2')
        
        elif step == '2':
            # Create admin user
            email = request.form['email']
            password = request.form['password']
            
            if validate_admin_user(email, password):
                create_admin_user(email, password)
                return redirect('/setup/wizard?step=3')
            else:
                return render_template('setup/step2.html', error="Invalid input")
        
        elif step == '3':
            # Database config
            db_config = {
                'host': request.form['host'],
                'port': request.form['port'],
                'database': request.form['database'],
                'username': request.form['username'],
                'password': request.form['password'],
            }
            
            if validate_db_config(db_config):
                save_db_config(db_config)
                return redirect('/setup/wizard?step=4')
            else:
                return render_template('setup/step3.html', error="Connection failed")
        
        # ... more steps ...
        
        elif step == '6':
            # Complete setup
            mark_setup_complete()
            session.pop('needs_setup', None)
            return redirect('/login')
    
    return render_template(f'setup/step{step}.html')
```

```python
# scripts/validate_env.py
import os
import sys
from typing import List, Dict, Any
from dotenv import load_dotenv

# Load .env
load_dotenv()

# Define required variables
REQUIRED_VARS = {
    'APP_ENV': {
        'required': True,
        'allowed_values': ['development', 'staging', 'production'],
        'description': 'Application environment'
    },
    'SECRET_KEY': {
        'required': True,
        'min_length': 32,
        'description': 'Application secret key'
    },
    'JWT_SECRET_KEY': {
        'required': True,
        'min_length': 32,
        'description': 'JWT secret key'
    },
    'DB_HOST': {
        'required': True,
        'description': 'Database host'
    },
    # ... (code truncated for brevity) ...
    # See full example in examples/ directory
        return 0
    else:
        print(f"‚ùå Validation failed with {len(result['errors'])} error(s)")
        print()
        print("Please fix the errors above and run validation again.")
        print("See .env.example for reference.")
        return 1

if __name__ == '__main__':
    sys.exit(main())
```

```python
from sqlalchemy import Column, Integer, String
from database import db
from services.auth import hash_password
```

```python
import os
import sys

def get_port(env_var: str, default: int) -> int:
    """Get port from environment with validation"""
    try:
        port = int(os.getenv(env_var, default))
    except ValueError:
        print(f"ERROR: Invalid {env_var}. Must be integer.")
        sys.exit(1)
    
    if not (1024 <= port <= 65535):
        print(f"ERROR: {env_var}={port} invalid. Must be 1024-65535.")
        sys.exit(1)
    
    return port

BACKEND_PORT = get_port('BACKEND_PORT', 8000)
FRONTEND_PORT = get_port('FRONTEND_PORT', 3000)
DATABASE_PORT = get_port('DATABASE_PORT', 5432)
REDIS_PORT = get_port('REDIS_PORT', 6379)

# Conflict detection
ports = {
    'BACKEND': BACKEND_PORT,
    'FRONTEND': FRONTEND_PORT,
    'DATABASE': DATABASE_PORT,
    'REDIS': REDIS_PORT,
}

if len(set(ports.values())) != len(ports):
    print("ERROR: Port conflicts detected")
    sys.exit(1)
```

```python
def validate_order_data(order_data: Dict) -> None:
    """Validate order data."""
    if not order_data.get('customer_id'):
        raise ValueError("Missing customer")

def calculate_order_total(items: List[Dict]) -> Decimal:
    """Calculate order total with tax."""
    subtotal = sum(Decimal(str(item['price'])) * item['qty'] for item in items)
    tax = subtotal * Decimal('0.15')
    return subtotal + tax

def create_order(customer_id: int, total: Decimal) -> Order:
    """Create order in database."""
    return Order.objects.create(customer_id=customer_id, total=total)

def send_order_confirmation(order: Order) -> None:
    """Send order confirmation email."""
    send_email(order.customer.email, f"Order {order.id} confirmed")

def process_order(order_data: Dict) -> Order:
    """Process complete order workflow."""
    validate_order_data(order_data)
    total = calculate_order_total(order_data['items'])
    order = create_order(order_data['customer_id'], total)
    send_order_confirmation(order)
    return order
```

```python
# config/__init__.py
"""
File: config/__init__.py
Configuration package with explicit exports
"""

# Explicit imports - clear and maintainable
from .settings import Settings, DatabaseConfig
from .constants import (
    DEFAULT_TIMEOUT,
    MAX_RETRIES,
    API_VERSION
)
from .validators import validate_config, ConfigError

# Explicit __all__ definition
__all__ = [
    # Settings
    'Settings',
    'DatabaseConfig',
    # Constants
    'DEFAULT_TIMEOUT',
    'MAX_RETRIES',
    'API_VERSION',
    # Validators
    'validate_config',
    'ConfigError',
]

# Package metadata
__version__ = '1.0.0'
__author__ = 'Your Team'
```

```python
# ‚úÖ CORRECT ORDER in __init__.py

# 1. Standard library imports
import os
import sys
from typing import Dict, List

# 2. Third-party imports
import requests
from sqlalchemy import create_engine

# 3. Local imports - order matters!
from .exceptions import ConfigError  # No dependencies
from .constants import DEFAULT_CONFIG  # Uses exceptions
from .validators import validate  # Uses constants and exceptions
from .config import Config  # Uses all above

# 4. __all__ definition
__all__ = [
    'Config',
    'ConfigError',
    'DEFAULT_CONFIG',
    'validate',
]
```

```python
   admin_user = {
       "username": config["admin"]["username"],
       "email": config["admin"]["email"],
       "password": generate_secure_password(),
       "is_superuser": True,
       "is_staff": True
   }
   ```

2. **Open Admin Panel:**
   ```python
   admin_url = f"http://{config['environment']['host']}:{config['ports']['backend']}/admin"
   webbrowser.open(admin_url)
   ```

3. **Open Setup Wizard:**
   ```python
   setup_url = f"http://{config['environment']['host']}:{config['ports']['frontend']}/setup"
   webbrowser.open(setup_url)
   ```

4. **Display Credentials:**
   ```
   ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
   ‚ïë                  ADMIN CREDENTIALS                         ‚ïë
   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
   
   Admin Panel: http://{HOST}:{BACKEND_PORT}/admin
   
   Username: {ADMIN_USERNAME}
   Password: {GENERATED_PASSWORD}
   
   ‚ö†Ô∏è  IMPORTANT: Save these credentials securely!
   ‚ö†Ô∏è  Change the password after first login.
   
   Setup Wizard: http://{HOST}:{FRONTEND_PORT}/setup
   
   Follow the setup wizard to:
   - Configure application settings
   - Set up database connections
   - Configure email settings
   - Set up payment gateways (if applicable)
   - Configure integrations
   ```

---

### 64.8 Setup Wizard Flow

**After deployment, setup wizard guides through:**

```

```python
   if not os.path.exists('.global/project_config.json'):
       # Ask all questions
       collect_project_info()
   else:
       # Load existing config
       config = load_config()
       print(f"Loaded config for: {config['project']['name']}")
       print(f"Phase: {config['project']['phase']}")
   ```

2. **Use config throughout:**
   ```python
   # Always use config values
   project_name = config['project']['name']
   db_name = config['database']['name']
   frontend_port = config['ports']['frontend']
   
   # Never hardcode values
   # ‚ùå APP_NAME = "Gaara ERP"
   # ‚úì APP_NAME = config['project']['name']
   ```

3. **Respect project phase:**
   ```python
   if config['project']['phase'] == 'development':
       # Development behavior
       enable_debug_mode()
       allow_sample_data()
       relaxed_security()
   else:
       # Production behavior
       disable_debug_mode()
       strict_security()
       enable_monitoring()
   ```

---

### 64.10 Commands Reference

**Development Phase:**

```



================================================================================
END OF 12_DATABASE
================================================================================


================================================================================
MODULE: 13_API
================================================================================

=================================================================================
API DESIGN & DEVELOPMENT - REST, GraphQL, gRPC
=================================================================================

Version: 5.0.0
Type: Architecture - API

Comprehensive guidance for API design, development, and documentation.

=================================================================================
REST API BEST PRACTICES
=================================================================================

## Resource Naming

**Good:**
- GET /api/products
- GET /api/products/{id}
- POST /api/products
- PUT /api/products/{id}
- DELETE /api/products/{id}

**Bad:**
- GET /api/getAllProducts
- POST /api/createProduct
- GET /api/product-detail?id=1

## HTTP Methods

- **GET:** Retrieve resources (idempotent, safe)
- **POST:** Create new resources
- **PUT:** Update entire resource (idempotent)
- **PATCH:** Partial update
- **DELETE:** Remove resource (idempotent)

## Status Codes

**Success:**
- 200 OK - Successful GET, PUT, PATCH
- 201 Created - Successful POST
- 204 No Content - Successful DELETE

**Client Errors:**
- 400 Bad Request - Invalid data
- 401 Unauthorized - Not authenticated
- 403 Forbidden - Not authorized
- 404 Not Found - Resource doesn't exist
- 422 Unprocessable Entity - Validation error

**Server Errors:**
- 500 Internal Server Error
- 503 Service Unavailable

## Request/Response Format

**Request:**
```json
POST /api/products
Content-Type: application/json

{
  "name": "Laptop",
  "price": 999.99,
  "stock": 10,
  "category_id": 1
}
```

**Response:**
```json
HTTP/1.1 201 Created
Content-Type: application/json

{
  "id": 123,
  "name": "Laptop",
  "price": 999.99,
  "stock": 10,
  "category_id": 1,
  "created_at": "2024-01-01T12:00:00Z"
}
```

## Pagination

```json
GET /api/products?page=2&page_size=20

{
  "count": 150,
  "next": "/api/products?page=3&page_size=20",
  "previous": "/api/products?page=1&page_size=20",
  "results": [...]
}
```

## Filtering & Sorting

```
GET /api/products?category=electronics&min_price=100&max_price=1000&sort=-price
```

## Versioning

**URL Versioning:**
```
/api/v1/products
/api/v2/products
```

**Header Versioning:**
```
Accept: application/vnd.myapi.v1+json
```

## Error Responses

```json
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Invalid input data",
    "details": {
      "price": ["Price must be positive"],
      "stock": ["Stock cannot be negative"]
    }
  }
}
```

=================================================================================
API DOCUMENTATION
=================================================================================

## OpenAPI/Swagger (FastAPI)

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI(
    title="My API",
    description="API for managing products",
    version="1.0.0"
)

class Product(BaseModel):
    """Product model."""
    name: str
    price: float
    stock: int = 0

@app.post("/api/products/", response_model=Product, tags=["products"])
async def create_product(product: Product):
    """
    Create a new product.
    
    - **name**: Product name
    - **price**: Product price (must be positive)
    - **stock**: Available stock (default: 0)
    """
    return product
```

Access docs at: `http://localhost:8000/docs`

## Django REST Framework

```python
from rest_framework import serializers, viewsets
from rest_framework.decorators import api_view
from rest_framework.response import Response
from drf_yasg.utils import swagger_auto_schema
from drf_yasg import openapi

@swagger_auto_schema(
    method='post',
    request_body=ProductSerializer,
    responses={
        201: ProductSerializer,
        400: 'Bad Request'
    }
)
@api_view(['POST'])
def create_product(request):
    """Create a new product."""
    serializer = ProductSerializer(data=request.data)
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=201)
    return Response(serializer.errors, status=400)
```

=================================================================================
AUTHENTICATION & AUTHORIZATION
=================================================================================

## JWT Authentication

**Login:**
```
POST /api/auth/login
{
  "email": "user@example.com",
  "password": "password123"
}

Response:
{
  "access_token": "eyJ0eXAiOiJKV1QiLCJhbGc...",
  "refresh_token": "eyJ0eXAiOiJKV1QiLCJhbGc...",
  "token_type": "Bearer"
}
```

**Using Token:**
```
GET /api/products
Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGc...
```

## API Keys

```
GET /api/products
X-API-Key: your-api-key-here
```

## OAuth 2.0

```
GET /api/products
Authorization: Bearer oauth-access-token
```

=================================================================================
RATE LIMITING
=================================================================================

## Django

```python
REST_FRAMEWORK = {
    'DEFAULT_THROTTLE_CLASSES': [
        'rest_framework.throttling.AnonRateThrottle',
        'rest_framework.throttling.UserRateThrottle'
    ],
    'DEFAULT_THROTTLE_RATES': {
        'anon': '100/day',
        'user': '1000/day'
    }
}
```

## FastAPI

```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.get("/api/products/")
@limiter.limit("5/minute")
async def get_products(request: Request):
    return {"products": []}
```

## Response Headers

```
X-RateLimit-Limit: 1000
X-RateLimit-Remaining: 999
X-RateLimit-Reset: 1640995200
```

=================================================================================
CACHING
=================================================================================

## HTTP Caching

```
Cache-Control: public, max-age=3600
ETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"
Last-Modified: Wed, 21 Oct 2024 07:28:00 GMT
```

## Redis Caching

```python
import redis
from functools import wraps

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cache_response(timeout=300):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            cache_key = f"{func.__name__}:{args}:{kwargs}"
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
            result = await func(*args, **kwargs)
            redis_client.setex(cache_key, timeout, json.dumps(result))
            return result
        return wrapper
    return decorator

@cache_response(timeout=600)
async def get_products():
    # Expensive database query
    return products
```

=================================================================================
WEBHOOKS
=================================================================================

## Implementing Webhooks

```python
import requests

def send_webhook(event_type, data, webhook_url):
    payload = {
        "event": event_type,
        "data": data,
        "timestamp": datetime.now().isoformat()
    }
    
    try:
        response = requests.post(
            webhook_url,
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=5
        )
        response.raise_for_status()
    except requests.RequestException as e:
        logger.error(f"Webhook failed: {e}")

# Usage
send_webhook("product.created", product_data, user.webhook_url)
```

## Receiving Webhooks

```python
@app.post("/webhooks/stripe")
async def stripe_webhook(request: Request):
    payload = await request.body()
    sig_header = request.headers.get('stripe-signature')
    
    try:
        event = stripe.Webhook.construct_event(
            payload, sig_header, webhook_secret
        )
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid payload")
    except stripe.error.SignatureVerificationError:
        raise HTTPException(status_code=400, detail="Invalid signature")
    
    # Handle event
    if event['type'] == 'payment_intent.succeeded':
        handle_payment_success(event['data']['object'])
    
    return {"status": "success"}
```

=================================================================================
GRAPHQL
=================================================================================

## Schema Definition

```python
import graphene

class Product(graphene.ObjectType):
    id = graphene.ID()
    name = graphene.String()
    price = graphene.Float()
    stock = graphene.Int()

class Query(graphene.ObjectType):
    products = graphene.List(Product)
    product = graphene.Field(Product, id=graphene.ID())
    
    def resolve_products(self, info):
        return Product.objects.all()
    
    def resolve_product(self, info, id):
        return Product.objects.get(pk=id)

class CreateProduct(graphene.Mutation):
    class Arguments:
        name = graphene.String()
        price = graphene.Float()
        stock = graphene.Int()
    
    product = graphene.Field(Product)
    
    def mutate(self, info, name, price, stock):
        product = Product(name=name, price=price, stock=stock)
        product.save()
        return CreateProduct(product=product)

class Mutation(graphene.ObjectType):
    create_product = CreateProduct.Field()

schema = graphene.Schema(query=Query, mutation=Mutation)
```

## Query Example

```graphql
query {
  products {
    id
    name
    price
  }
}

mutation {
  createProduct(name: "Laptop", price: 999.99, stock: 10) {
    product {
      id
      name
    }
  }
}
```

=================================================================================
API TESTING
=================================================================================

## pytest (FastAPI)

```python
from fastapi.testclient import TestClient

client = TestClient(app)

def test_create_product():
    response = client.post(
        "/api/products/",
        json={"name": "Test", "price": 99.99, "stock": 10}
    )
    assert response.status_code == 201
    assert response.json()["name"] == "Test"

def test_get_products():
    response = client.get("/api/products/")
    assert response.status_code == 200
    assert isinstance(response.json(), list)
```

## Django REST Framework

```python
from rest_framework.test import APITestCase

class ProductAPITest(APITestCase):
    def test_create_product(self):
        data = {"name": "Test", "price": 99.99}
        response = self.client.post('/api/products/', data)
        self.assertEqual(response.status_code, 201)
```

=================================================================================
END OF API PROMPT
=================================================================================


================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

management with Redis
- Lockout after N failed attempts
- Password: bcrypt/argon2, min 12 chars

E) Input Validation & Sanitization
- Schema validation: Pydantic, Zod, Joi
- SQL injection prevention: parameterized queries
- XSS prevention: DOMPurify, escape HTML
- CSRF tokens for state-changing ops
- File upload: type/size validation, virus scan
- Rate limiting: 100 req/min default

F) Database Integration
- Connection pooling (min 5, max 20)
- Transactions for multi-step ops
- Read replicas for scaling
- Query optimization: indexes, EXPLAIN
- N+1 query prevention
- Soft deletes preferred

G) Caching Strategy
- Redis for session, rate limits, cache
- Cache invalidation: TTL + manual
- Cache keys: namespaced, versioned
- CDN for static assets
- HTTP caching headers

H) Background Jobs
- Celery (Python), Bull (Node.js)
- Job queues: Redis, RabbitMQ
- Retry logic with exponential backoff
- Dead letter queue for failures
- Monitoring: job success rate

I) API Documentation
- OpenAPI 3.0 / 
ow queries
- Connection pooling
- Read replicas for scaling
- Partitioning for large tables

G) Backup & Recovery
- Daily automated backups
- Point-in-time recovery (PITR)
- Backup retention: 30 days
- Offsite storage (S3, GCS)
- Tested restore procedure
- RTO: <1 hour, RPO: <15 minutes

H) Security
- Least privilege: app user has minimal permissions
- No root/admin access from app
- Encrypted at rest (TDE)
- Encrypted in transit (SSL/TLS)
- Audit logging for DDL/DML
- Row-level security (RLS) where applicable

I) Monitoring
- Query performance metrics
- Connection pool usage
- Replication lag
- Disk usage alerts
- Slow query log

‚∏ª

8) SECURITY & AUTHENTICATION (Expanded in v3.0)

A) Authentication Mechanisms
- JWT: access (15min) + refresh (7d) tokens
- OAuth 2.0 / OIDC for SSO
- MFA: TOTP (Google Authenticator), SMS, Email
- Biometric (optional): Face ID, Touch ID
- API keys for service-to-service
- Session management: Redis-backed

B) Password Policy
- Min length: 12 characters
- C
res_str)
        if time.time() > expires:
            return False
        expected = generate_route_token(route, user_id, 0).split('.')[0]
        return hmac.compare_digest(signature, expected)
    except:
        return False
```

D) Frontend
```typescript
// Use obfuscated routes
const obfuscatedRoute = await api.getRouteToken('/admin/users');
navigate(obfuscatedRoute);
```

E) Benefits
- Security through obscurity (additional layer)
- Harder to enumerate endpoints
- Time-limited access

F) Considerations
- Not a replacement for proper auth
- Adds complexity
- Cache implications

‚∏ª

26) BACKUP POLICY (Enhanced in v3.1)

A) Trigger Conditions
- After any module completion
- After any 3 TODO items completed
- Daily automated (3 AM)
- Before major deployments
- On-demand via admin panel

B) Exclusions
- `.env`, `.env.*`
- `.venv`, `venv`, `node_modules`
- `__pycache__`, `.pytest_cache`, `.mypy_cache`
- `caches/`, `temp/`, `build/`, `dist/`
- `.git/` (separate Git backup)
- Secrets, A

================================================================================
CRITICAL MISSING CONTENT - Deep Search Recovery
================================================================================

```python
# Backend
def generate_route_token(route: str, user_id: str, ttl: int = 300) -> str:
    """Generate HMAC-signed route token"""
    expires = int(time.time()) + ttl
    payload = f"{route}:{user_id}:{expires}"
    signature = hmac.new(
        SECRET_KEY.encode(),
        payload.encode(),
        hashlib.sha256
    ).hexdigest()[:16]
    return f"{signature}.{expires}"

def verify_route_token(token: str, route: str, user_id: str) -> bool:
    """Verify route token"""
    try:
        signature, expires_str = token.split('.')
        expires = int(expires_str)
        if time.time() > expires:
            return False
        expected = generate_route_token(route, user_id, 0).split('.')[0]
        return hmac.compare_digest(signature, expected)
    except:
        return False
```

```python
# backend/src/error_handlers.py
from flask import jsonify
import logging
import traceback
import uuid

logger = logging.getLogger(__name__)

def generate_trace_id():
    """Generate unique trace ID for error tracking"""
    return str(uuid.uuid4())

@app.errorhandler(Exception)
def handle_exception(e):
    """Handle all unhandled exceptions"""
    trace_id = generate_trace_id()
    
    # Log detailed error internally
    logger.error(
        f"Unhandled exception [TraceID: {trace_id}]",
        exc_info=True,
        extra={
            'trace_id': trace_id,
            'error_type': type(e).__name__,
            'error_message': str(e),
            'stack_trace': traceback.format_exc(),
        }
    )
    
    # Return generic error to client
    if app.config['ENV'] == 'production':
        return jsonify({
            'error': 'An unexpected error occurred',
            'code': 'INTERNAL_ERROR',
            'traceId': trace_id,
            'message': 'Please contact support if the problem persists'
        }), 500
    else:
        # In development, return detailed error
        return jsonify({
            'error': str(e),
            'type': type(e).__name__,
            'traceback': traceback.format_exc().split('\n'),
            'traceId': trace_id
        }), 500

@app.errorhandler(404)
def handle_not_found(e):
    """Handle 404 errors"""
    # Don't reveal route structure
    return jsonify({
        'error': 'Resource not found',
        'code': 'NOT_FOUND'
    }), 404

@app.errorhandler(403)
def handle_forbidden(e):
    """Handle 403 errors"""
    # Don't reveal permission structure
    return jsonify({
        'error': 'Access denied',
        'code': 'FORBIDDEN'
    }), 403
```

```python
"""Environment-based error handling middleware"""

import os
import uuid
import traceback
from fastapi import Request
from fastapi.responses import JSONResponse
from datetime import datetime

APP_ENV = os.getenv('APP_ENV', 'development')

async def error_handler_middleware(request: Request, call_next):
    """Handle errors based on environment"""
    try:
        return await call_next(request)
    
    except Exception as e:
        error_id = str(uuid.uuid4())
        
        # Log error (always)
        log_error(error_id, e, request)
        
        if APP_ENV == 'production':
            # Production: Generic error
            return JSONResponse(
                status_code=500,
                content={
                    "success": False,
                    "message": "An error occurred. Please contact support.",
                    "error_id": error_id,
                    "timestamp": datetime.utcnow().isoformat()
                }
            )
        else:
            # Development: Detailed error
            return JSONResponse(
                status_code=500,
                content={
                    "success": False,
                    "message": str(e),
                    "error_type": type(e).__name__,
                    "error_id": error_id,
                    "traceback": traceback.format_exc(),
                    "request": {
                        "method": request.method,
                        "url": str(request.url),
                        "headers": dict(request.headers)
                    },
                    "timestamp": datetime.utcnow().isoformat()
                }
            )

def log_error(error_id: str, error: Exception, request: Request):
    """Log error to file/service"""
    import logging
    logger = logging.getLogger(__name__)
    
    logger.error(
        f"Error ID: {error_id}\n"
        f"Type: {type(error).__name__}\n"
        f"Message: {str(error)}\n"
        f"URL: {request.url}\n"
        f"Method: {request.method}\n"
        f"Traceback:\n{traceback.format_exc()}"
    )
```

```python
from config.definitions import (
    Status,           # ACTIVE, INACTIVE, PENDING, DELETED
    UserRole,         # ADMIN, USER, GUEST, MODERATOR
    Environment,      # DEV, STAGING, PROD
    APIResponse,      # ÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© API ŸÖŸàÿ≠ÿØÿ©
    ErrorResponse     # ÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© ÿÆÿ∑ÿ£ ŸÖŸàÿ≠ÿØÿ©
)
```



================================================================================
END OF 13_API
================================================================================


================================================================================
MODULE: 14_BLUEPRINT
================================================================================

================================================================================
BLUEPRINT PATTERNS - Project Templates and Scaffolding
================================================================================

Version: 5.3.0
Module: 14_blueprint.txt
Purpose: Blueprint patterns for rapid project scaffolding and code generation
Status: Production Ready

================================================================================
OVERVIEW
================================================================================

Blueprint is a powerful pattern for creating reusable project templates and code
scaffolding. This module covers:

1. Blueprint Concept and Architecture
2. VS Code Blueprint Extension (johh/blueprint-templates)
3. Python Blueprint Repository (Limych/py-blueprint)
4. Best Practices for Template Creation
5. Integration with Development Workflows

================================================================================
1. BLUEPRINT CONCEPT
================================================================================

## What is a Blueprint?

A Blueprint is a **template-based code generation pattern** that allows developers
to quickly scaffold new projects, components, or modules with consistent structure
and best practices.

### Core Principles

‚úÖ **Consistency** - Enforce project structure and coding standards
‚úÖ **Reusability** - Create once, use many times
‚úÖ **Maintainability** - Centralized template management
‚úÖ **Productivity** - Reduce boilerplate code writing
‚úÖ **Best Practices** - Embed proven patterns in templates

### Blueprint vs Traditional Templates

| Aspect | Traditional | Blueprint |
|--------|-------------|-----------|
| **Flexibility** | Static | Dynamic with variables |
| **Customization** | Manual editing | Interactive prompts |
| **Updates** | Manual | Centralized updates |
| **Complexity** | Simple | Supports complex structures |
| **Integration** | Standalone | IDE/Editor integrated |

### Use Cases

1. **Project Initialization** - Create new projects with complete structure
2. **Component Generation** - Add new features/modules consistently
3. **Boilerplate Reduction** - Eliminate repetitive code writing
4. **Team Standardization** - Ensure all team members follow same patterns
5. **Documentation** - Include documentation templates
6. **Testing** - Generate test files automatically

================================================================================
2. VS CODE BLUEPRINT EXTENSION
================================================================================

Based on: johh/blueprint-templates
Repository: https://github.com/johh/blueprint-templates

## Overview

VS Code Blueprint extension allows creating file templates with variable
substitution and interactive prompts.

## Installation

```bash
# Install Blueprint extension from VS Code Marketplace
# Extension ID: teamchilla.blueprint

# Clone template repository
git clone https://github.com/johh/blueprint-templates.git
cd blueprint-templates
```

## Configuration

Add to VS Code `settings.json`:

```json
{
  "blueprint.templatesPath": [
    "~/git/blueprint-templates/templates"
  ]
}
```

## Template Structure

### Basic Template Example

```
templates/
‚îî‚îÄ‚îÄ react-component/
    ‚îî‚îÄ‚îÄ __pascalCase_name__/
        ‚îú‚îÄ‚îÄ __pascalCase_name__.tsx
        ‚îú‚îÄ‚îÄ __pascalCase_name__.module.css
        ‚îî‚îÄ‚îÄ __pascalCase_name__.test.tsx
```

### Variable Naming Conventions

| Pattern | Example Input | Output |
|---------|---------------|--------|
| `__name__` | my component | my component |
| `__camelCase_name__` | my component | myComponent |
| `__pascalCase_name__` | my component | MyComponent |
| `__kebabCase_name__` | my component | my-component |
| `__snakeCase_name__` | my component | my_component |
| `__upperCase_name__` | my component | MY COMPONENT |
| `__lowerCase_name__` | my component | my component |

### React Component Template

**File:** `templates/react-fc/__pascalCase_name__.tsx`

```typescript
import React from 'react';
import styles from './__pascalCase_name__.module.css';

interface __pascalCase_name__Props {
  // Define props here
}

export const __pascalCase_name__: React.FC<__pascalCase_name__Props> = (props) => {
  return (
    <div className={styles.container}>
      <h1>__pascalCase_name__</h1>
    </div>
  );
};
```

**File:** `templates/react-fc/__pascalCase_name__.module.css`

```css
.container {
  padding: 20px;
}
```

**File:** `templates/react-fc/__pascalCase_name__.test.tsx`

```typescript
import { render, screen } from '@testing-library/react';
import { __pascalCase_name__ } from './__pascalCase_name__';

describe('__pascalCase_name__', () => {
  it('renders correctly', () => {
    render(<__pascalCase_name__ />);
    expect(screen.getByText('__pascalCase_name__')).toBeInTheDocument();
  });
});
```

### Three.js Object Template

**File:** `templates/three-object/__pascalCase_name__/__pascalCase_name__.ts`

```typescript
import * as THREE from 'three';
import { __pascalCase_name__Material } from './__pascalCase_name__Material';

export class __pascalCase_name__ extends THREE.Mesh {
  constructor() {
    const geometry = new THREE.BoxGeometry(1, 1, 1);
    const material = new __pascalCase_name__Material();
    
    super(geometry, material);
    
    this.name = '__pascalCase_name__';
  }
  
  update(time: number): void {
    // Update logic here
    this.rotation.y = time * 0.001;
  }
}
```

### Usage

```bash
# In VS Code Command Palette (Ctrl+Shift+P)
> Blueprint: Create New File from Template

# Select template: react-fc
# Enter name: UserProfile
# Creates: UserProfile/UserProfile.tsx, UserProfile.module.css, UserProfile.test.tsx
```

## Advanced Features

### Multiple File Templates

Create complex structures with multiple files:

```
templates/
‚îî‚îÄ‚îÄ full-feature/
    ‚îú‚îÄ‚îÄ __kebabCase_name__/
    ‚îÇ   ‚îú‚îÄ‚îÄ components/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __pascalCase_name__.tsx
    ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ use__pascalCase_name__.ts
    ‚îÇ   ‚îú‚îÄ‚îÄ types/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __pascalCase_name__.types.ts
    ‚îÇ   ‚îú‚îÄ‚îÄ utils/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __camelCase_name__Utils.ts
    ‚îÇ   ‚îî‚îÄ‚îÄ index.ts
```

### Conditional Content

Use comments to include conditional sections:

```typescript
// __IF_TYPESCRIPT__
interface Props {
  name: string;
}
// __ENDIF__

export const Component = (/* __IF_TYPESCRIPT__ props: Props __ENDIF__ */) => {
  // Component logic
};
```

================================================================================
3. PYTHON BLUEPRINT REPOSITORY
================================================================================

Based on: Limych/py-blueprint
Repository: https://github.com/Limych/py-blueprint

## Overview

Py-Blueprint is a complete Python project template that developers can use as a
starting point for new projects. It includes best practices, CI/CD, testing,
and documentation setup.

## Features

‚úÖ **Modern Python Setup** - pyproject.toml, setup.py
‚úÖ **Testing Framework** - pytest with coverage
‚úÖ **Code Quality** - pre-commit hooks, linters (Ruff)
‚úÖ **CI/CD** - GitHub Actions workflows
‚úÖ **Documentation** - README, CONTRIBUTING, LICENSE
‚úÖ **Package Structure** - Proper Python package layout
‚úÖ **Development Scripts** - Setup and update automation

## Quick Start

### Create New Repository from Blueprint

```bash
# Initialize your new origin repository
git init
git remote add origin https://github.com/YOUR_NEW_REPOSITORY

# Apply blueprint repository
git remote add blueprint https://github.com/Limych/py-blueprint.git
git fetch blueprint dev
git reset --hard blueprint/dev
git branch -M dev

# Push changes to origin repository
git push -u origin dev
```

### Apply Blueprint to Existing Repository

```bash
# Apply blueprint repository
git remote add blueprint https://github.com/Limych/py-blueprint.git
git fetch blueprint dev
git merge blueprint/dev --allow-unrelated-histories

# Push changes to origin repository
git push -u origin dev
```

### Update Blueprint

```bash
# Update blueprint to latest version
./scripts/update
git merge blueprint/dev
```

## Project Structure

```
py-blueprint/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îú‚îÄ‚îÄ workflows/          # CI/CD workflows
‚îÇ   ‚îî‚îÄ‚îÄ PULL_REQUEST_TEMPLATE.md
‚îú‚îÄ‚îÄ blueprint_client/       # Main package
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ client.py          # Main client code
‚îÇ   ‚îî‚îÄ‚îÄ const.py           # Constants
‚îú‚îÄ‚îÄ tests/                 # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py        # pytest configuration
‚îÇ   ‚îú‚îÄ‚îÄ const.py
‚îÇ   ‚îî‚îÄ‚îÄ test_client.py
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup              # Development setup script
‚îÇ   ‚îî‚îÄ‚îÄ update             # Blueprint update script
‚îú‚îÄ‚îÄ .editorconfig          # Editor configuration
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .pre-commit-config.yaml # Pre-commit hooks
‚îú‚îÄ‚îÄ pyproject.toml         # Modern Python configuration
‚îú‚îÄ‚îÄ setup.py               # Package setup
‚îú‚îÄ‚îÄ requirements-dev.txt   # Development dependencies
‚îú‚îÄ‚îÄ requirements-test.txt  # Testing dependencies
‚îú‚îÄ‚îÄ CONTRIBUTING.md        # Contribution guidelines
‚îú‚îÄ‚îÄ LICENSE.md             # License file
‚îî‚îÄ‚îÄ README.md              # Project documentation
```

## Configuration Files

### pyproject.toml

```toml
[build-system]
requires = ["setuptools>=45", "wheel", "setuptools_scm>=6.2"]
build-backend = "setuptools.build_meta"

[project]
name = "blueprint-client"
version = "1.0.0"
description = "Blueprint sample client library"
authors = [{name = "Your Name", email = "your.email@example.com"}]
license = {text = "MIT"}
readme = "README.md"
requires-python = ">=3.8"
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
]
dependencies = [
    "requests>=2.28.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=3.0.0",
    "ruff>=0.0.260",
    "pre-commit>=2.20.0",
]

[tool.setuptools]
packages = ["blueprint_client"]

[tool.ruff]
line-length = 88
target-version = "py38"
select = ["E", "F", "W", "C", "I"]
ignore = []

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
```

### .pre-commit-config.yaml

```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
      - id: check-json
      - id: check-toml
      - id: check-merge-conflict
      - id: debug-statements

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.0.260
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]

  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
        language_version: python3
```

## Package Implementation

### Main Client Code

**File:** `blueprint_client/client.py`

```python
"""Main client implementation."""
from typing import Any, Dict, Optional
import requests
from .const import API_BASE_URL, DEFAULT_TIMEOUT

class Client:
    """Blueprint sample client."""
    
    def __init__(
        self,
        username: str,
        password: str,
        base_url: str = API_BASE_URL,
        timeout: int = DEFAULT_TIMEOUT,
    ):
        """Initialize client.
        
        Args:
            username: API username
            password: API password
            base_url: Base API URL
            timeout: Request timeout in seconds
        """
        self.username = username
        self.password = password
        self.base_url = base_url
        self.timeout = timeout
        self._session = requests.Session()
        self._session.auth = (username, password)
    
    def get_data(self) -> Dict[str, Any]:
        """Get data from API.
        
        Returns:
            API response data
            
        Raises:
            requests.HTTPError: If request fails
        """
        response = self._session.get(
            f"{self.base_url}/data",
            timeout=self.timeout,
        )
        response.raise_for_status()
        return response.json()
    
    def change_something(self, value: bool) -> bool:
        """Change a setting.
        
        Args:
            value: New setting value
            
        Returns:
            True if successful
            
        Raises:
            requests.HTTPError: If request fails
        """
        response = self._session.post(
            f"{self.base_url}/settings",
            json={"value": value},
            timeout=self.timeout,
        )
        response.raise_for_status()
        return True
```

### Constants

**File:** `blueprint_client/const.py`

```python
"""Constants for blueprint client."""

API_BASE_URL = "https://api.example.com/v1"
DEFAULT_TIMEOUT = 30
USER_AGENT = "blueprint-client/1.0.0"
```

### Testing

**File:** `tests/test_client.py`

```python
"""Tests for client module."""
import pytest
from unittest.mock import Mock, patch
from blueprint_client.client import Client

@pytest.fixture
def client():
    """Create test client."""
    return Client(username="test", password="test")

def test_client_initialization(client):
    """Test client initialization."""
    assert client.username == "test"
    assert client.password == "test"

@patch("blueprint_client.client.requests.Session")
def test_get_data(mock_session, client):
    """Test get_data method."""
    mock_response = Mock()
    mock_response.json.return_value = {"key": "value"}
    mock_session.return_value.get.return_value = mock_response
    
    data = client.get_data()
    
    assert data == {"key": "value"}
    mock_session.return_value.get.assert_called_once()

@patch("blueprint_client.client.requests.Session")
def test_change_something(mock_session, client):
    """Test change_something method."""
    mock_response = Mock()
    mock_response.raise_for_status.return_value = None
    mock_session.return_value.post.return_value = mock_response
    
    result = client.change_something(True)
    
    assert result is True
    mock_session.return_value.post.assert_called_once()
```

## Development Scripts

### Setup Script

**File:** `scripts/setup`

```bash
#!/bin/bash
set -e

echo "Setting up development environment..."

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install --upgrade pip
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

echo "‚úÖ Development environment ready!"
echo "Activate with: source venv/bin/activate"
```

### Update Script

**File:** `scripts/update`

```bash
#!/bin/bash
set -e

echo "Updating blueprint..."

# Fetch latest blueprint
git fetch blueprint dev

echo "‚úÖ Blueprint updated!"
echo "Merge with: git merge blueprint/dev"
```

## Usage Example

```python
from blueprint_client.client import Client

# Initialize client
username = "user"
password = "pass"
client = Client(username, password)

# Get data
data = client.get_data()
print(f"Received data: {data}")

# Change setting
success = client.change_something(True)
print(f"Setting changed: {success}")
```

================================================================================
4. BEST PRACTICES FOR BLUEPRINT CREATION
================================================================================

## Template Design Principles

### 1. Keep Templates Simple

‚ùå **Bad:** Complex templates with too many options
```
templates/
‚îî‚îÄ‚îÄ mega-component/  # Too many files, too complex
    ‚îú‚îÄ‚îÄ 50+ files...
```

‚úÖ **Good:** Focused templates for specific use cases
```
templates/
‚îú‚îÄ‚îÄ simple-component/     # Basic component
‚îú‚îÄ‚îÄ component-with-state/ # Component with state management
‚îî‚îÄ‚îÄ component-with-api/   # Component with API integration
```

### 2. Use Consistent Naming

‚úÖ **Consistent variable naming across templates**
```typescript
// Always use same pattern
__pascalCase_name__Component.tsx
__pascalCase_name__Service.ts
__pascalCase_name__Types.ts
```

### 3. Include Documentation

‚úÖ **Add comments and documentation in templates**
```typescript
/**
 * __pascalCase_name__ Component
 * 
 * Description: [Add component description]
 * Author: [Your Name]
 * Created: __date__
 */
export const __pascalCase_name__: React.FC = () => {
  // Implementation
};
```

### 4. Provide Examples

‚úÖ **Include example usage in templates**
```typescript
/**
 * Example usage:
 * 
 * ```tsx
 * <__pascalCase_name__ 
 *   prop1="value1"
 *   prop2="value2"
 * />
 * ```
 */
```

### 5. Follow Project Conventions

‚úÖ **Match existing project structure and style**
```
# Analyze existing project
src/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ Button/
‚îÇ       ‚îú‚îÄ‚îÄ Button.tsx
‚îÇ       ‚îú‚îÄ‚îÄ Button.module.css
‚îÇ       ‚îî‚îÄ‚îÄ Button.test.tsx

# Create matching template
templates/
‚îî‚îÄ‚îÄ component/
    ‚îî‚îÄ‚îÄ __pascalCase_name__/
        ‚îú‚îÄ‚îÄ __pascalCase_name__.tsx
        ‚îú‚îÄ‚îÄ __pascalCase_name__.module.css
        ‚îî‚îÄ‚îÄ __pascalCase_name__.test.tsx
```

## Template Organization

### Directory Structure

```
templates/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ react-component/
‚îÇ   ‚îú‚îÄ‚îÄ vue-component/
‚îÇ   ‚îî‚îÄ‚îÄ angular-component/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ django-app/
‚îÇ   ‚îú‚îÄ‚îÄ fastapi-router/
‚îÇ   ‚îî‚îÄ‚îÄ flask-blueprint/
‚îú‚îÄ‚îÄ fullstack/
‚îÇ   ‚îú‚îÄ‚îÄ crud-feature/
‚îÇ   ‚îî‚îÄ‚îÄ auth-module/
‚îî‚îÄ‚îÄ documentation/
    ‚îú‚îÄ‚îÄ api-doc/
    ‚îî‚îÄ‚îÄ readme/
```

### Template Metadata

**File:** `template.json` (optional)

```json
{
  "name": "React Component",
  "description": "Create a new React functional component with TypeScript",
  "author": "Your Name",
  "version": "1.0.0",
  "tags": ["react", "typescript", "component"],
  "prompts": [
    {
      "name": "name",
      "message": "Component name:",
      "type": "input"
    },
    {
      "name": "withState",
      "message": "Include state management?",
      "type": "confirm",
      "default": false
    }
  ]
}
```

## Version Control

### Blueprint Repository Structure

```
blueprint-repo/
‚îú‚îÄ‚îÄ .git/
‚îú‚îÄ‚îÄ templates/           # Template files
‚îú‚îÄ‚îÄ docs/               # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ usage.md
‚îÇ   ‚îî‚îÄ‚îÄ contributing.md
‚îú‚îÄ‚îÄ examples/           # Example outputs
‚îú‚îÄ‚îÄ tests/             # Template tests
‚îú‚îÄ‚îÄ CHANGELOG.md       # Version history
‚îî‚îÄ‚îÄ README.md          # Main documentation
```

### Updating Templates

```bash
# Create feature branch
git checkout -b feature/new-template

# Add template
mkdir -p templates/new-feature
# ... create template files ...

# Commit changes
git add templates/new-feature
git commit -m "feat: add new-feature template"

# Push and create PR
git push origin feature/new-template
```

================================================================================
5. INTEGRATION WITH DEVELOPMENT WORKFLOWS
================================================================================

## CI/CD Integration

### GitHub Actions Workflow

**File:** `.github/workflows/blueprint.yml`

```yaml
name: Blueprint Templates

on:
  push:
    branches: [main, dev]
  pull_request:
    branches: [main, dev]

jobs:
  test-templates:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Test Template Generation
        run: |
          # Test each template
          for template in templates/*; do
            echo "Testing $template"
            # Add template testing logic
          done
      
      - name: Validate Template Structure
        run: |
          # Validate template files
          npm run validate-templates
```

## IDE Integration

### VS Code Settings

**File:** `.vscode/settings.json`

```json
{
  "blueprint.templatesPath": [
    "${workspaceFolder}/templates",
    "~/.vscode/templates"
  ],
  "blueprint.defaultAuthor": "Your Name",
  "blueprint.dateFormat": "YYYY-MM-DD"
}
```

### JetBrains IDEs

Use File Templates feature:
- Settings ‚Üí Editor ‚Üí File and Code Templates
- Create custom templates with variables
- Use Velocity Template Language (VTL)

## Team Collaboration

### Shared Template Repository

```bash
# Team template repository
git clone https://github.com/team/blueprints.git ~/.blueprints

# Configure in VS Code
{
  "blueprint.templatesPath": [
    "~/.blueprints/templates"
  ]
}

# Update templates
cd ~/.blueprints
git pull origin main
```

### Template Review Process

1. **Propose Template** - Create PR with new template
2. **Team Review** - Review structure and content
3. **Test Generation** - Test template with real use cases
4. **Documentation** - Update docs with usage examples
5. **Merge** - Merge to main branch
6. **Announce** - Notify team of new template

================================================================================
BLUEPRINT BEST PRACTICES SUMMARY
================================================================================

‚úÖ **DO:**
- Keep templates simple and focused
- Use consistent naming conventions
- Include comprehensive documentation
- Provide usage examples
- Follow project conventions
- Version control templates
- Test template generation
- Update templates regularly

‚ùå **DON'T:**
- Create overly complex templates
- Use inconsistent naming
- Skip documentation
- Hardcode values
- Ignore project style guides
- Forget to test templates
- Leave templates outdated

================================================================================
RESOURCES
================================================================================

## VS Code Blueprint Extension
- Extension: https://marketplace.visualstudio.com/items?itemName=teamchilla.blueprint
- Templates: https://github.com/johh/blueprint-templates

## Python Blueprint
- Repository: https://github.com/Limych/py-blueprint
- Documentation: See README.md

## Related Tools
- Yeoman: https://yeoman.io/
- Cookiecutter: https://cookiecutter.readthedocs.io/
- Plop: https://plopjs.com/

================================================================================
END OF BLUEPRINT MODULE
================================================================================



================================================================================
END OF 14_BLUEPRINT
================================================================================


================================================================================
MODULE: 15_MCP
================================================================================

================================================================================
MODULE 15: MODEL CONTEXT PROTOCOL (MCP) INTEGRATION
================================================================================

OVERVIEW
--------
Model Context Protocol (MCP) ŸáŸà ÿ®ÿ±Ÿàÿ™ŸàŸÉŸàŸÑ ŸÖŸÅÿ™Ÿàÿ≠ ÿßŸÑŸÖÿµÿØÿ± Ÿäÿ±ÿ®ÿ∑ ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä
ÿ®ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿÆÿßÿ±ÿ¨Ÿäÿ© ŸàÿßŸÑÿ£ÿØŸàÿßÿ™. ŸäŸàŸÅÿ± MCP ÿ∑ÿ±ŸäŸÇÿ© ŸÖŸàÿ≠ÿØÿ© ŸÑÿ™Ÿàÿ≥Ÿäÿπ ŸÇÿØÿ±ÿßÿ™ LLMs ŸÖŸÜ ÿÆŸÑÿßŸÑ
ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ÿßŸÑÿÆŸàÿßÿØŸÖ ÿßŸÑŸÖÿ™ÿÆÿµÿµÿ©.

CORE CONCEPTS
-------------

1. MCP Architecture
   - Client: ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ∞Ÿä Ÿäÿ≥ÿ™ÿÆÿØŸÖ MCP (VS Code, Claude, Cursor)
   - Server: ÿßŸÑÿÆÿßÿØŸÖ ÿßŸÑÿ∞Ÿä ŸäŸàŸÅÿ± ÿßŸÑÿ£ÿØŸàÿßÿ™ ŸàÿßŸÑŸÖŸàÿßÿ±ÿØ
   - Transport: ÿ∑ÿ±ŸäŸÇÿ© ÿßŸÑÿßÿ™ÿµÿßŸÑ (SSE, stdio, HTTP)
   - Protocol: ÿßŸÑÿ®ÿ±Ÿàÿ™ŸàŸÉŸàŸÑ ÿßŸÑŸÖŸàÿ≠ÿØ ŸÑŸÑÿ™ŸàÿßÿµŸÑ

2. MCP Components
   - Tools: Ÿàÿ∏ÿßÿ¶ŸÅ ŸÇÿßÿ®ŸÑÿ© ŸÑŸÑÿßÿ≥ÿ™ÿØÿπÿßÿ°
   - Resources: ÿ®ŸäÿßŸÜÿßÿ™ ŸàŸÖÿ≠ÿ™ŸàŸâ
   - Prompts: ŸÇŸàÿßŸÑÿ® ŸÑŸÑÿ™ŸÅÿßÿπŸÑ
   - Sampling: ÿ∑ŸÑÿ®ÿßÿ™ LLM

3. MCP Benefits
   - ÿ™Ÿàÿ≠ŸäÿØ ÿßŸÑÿ™ŸÉÿßŸÖŸÑ ŸÖÿπ ÿßŸÑÿ£ÿØŸàÿßÿ™ ÿßŸÑÿÆÿßÿ±ÿ¨Ÿäÿ©
   - ÿ£ŸÖÿßŸÜ ŸÖÿ≠ÿ≥ŸëŸÜ ŸÖÿπ ÿµŸÑÿßÿ≠Ÿäÿßÿ™ ŸÖÿ≠ÿØÿØÿ©
   - ŸÇÿßÿ®ŸÑŸäÿ© ÿßŸÑÿ™Ÿàÿ≥ÿπ ŸàÿßŸÑÿµŸäÿßŸÜÿ©
   - ÿØÿπŸÖ ŸÖÿ™ÿπÿØÿØ ÿßŸÑŸÖŸÜÿµÿßÿ™

================================================================================
SECTION 1: PLAYWRIGHT MCP SERVER
================================================================================

OVERVIEW
--------
Playwright MCP Server ŸäŸàŸÅÿ± ŸÇÿØÿ±ÿßÿ™ ÿ£ÿ™ŸÖÿ™ÿ© ÿßŸÑŸÖÿ™ÿµŸÅÿ≠ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Playwright.
ŸäŸÖŸÉŸëŸÜ LLMs ŸÖŸÜ ÿßŸÑÿ™ŸÅÿßÿπŸÑ ŸÖÿπ ÿµŸÅÿ≠ÿßÿ™ ÿßŸÑŸàŸäÿ® ŸÖŸÜ ÿÆŸÑÿßŸÑ snapshots ŸÖŸÜÿ∏ŸÖÿ©.

Repository: https://github.com/microsoft/playwright-mcp
Package: @playwright/mcp

KEY FEATURES
------------

1. Fast and Lightweight
   - Ÿäÿ≥ÿ™ÿÆÿØŸÖ accessibility tree ÿ®ÿØŸÑÿßŸã ŸÖŸÜ ÿßŸÑÿµŸàÿ±
   - ŸÑÿß Ÿäÿ≠ÿ™ÿßÿ¨ ŸÑŸÜŸÖÿßÿ∞ÿ¨ vision
   - ÿ£ÿØÿßÿ° ÿ≥ÿ±Ÿäÿπ ŸàŸÖÿ≠ÿØÿØ

2. LLM-Friendly
   - ÿ®ŸäÿßŸÜÿßÿ™ ŸÖŸÜÿ∏ŸÖÿ© structured data
   - ŸÑÿß Ÿäÿ≠ÿ™ÿßÿ¨ ŸÑŸÖÿπÿßŸÑÿ¨ÿ© ÿµŸàÿ±
   - ŸÜÿ™ÿßÿ¶ÿ¨ ŸÖÿ≠ÿØÿØÿ© deterministic

3. Browser Automation
   - ÿØÿπŸÖ Chrome, Firefox, WebKit
   - headless Ÿà headed modes
   - device emulation
   - network interception

INSTALLATION
------------

```bash
# ÿ™ÿ´ÿ®Ÿäÿ™ ÿπÿ®ÿ± npm
npx @playwright/mcp@latest

# ÿ™ÿ´ÿ®Ÿäÿ™ ÿßŸÑŸÖÿ™ÿµŸÅÿ≠ÿßÿ™
npx playwright install chrome

# ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Docker
docker run -i --rm --init --pull=always mcr.microsoft.com/playwright/mcp
```

CONFIGURATION
-------------

### VS Code Configuration

```json
{
  "mcpServers": {
    "playwright": {
      "command": "npx",
      "args": ["@playwright/mcp@latest"]
    }
  }
}
```

### Claude Desktop Configuration

```json
{
  "mcpServers": {
    "playwright": {
      "command": "npx",
      "args": [
        "@playwright/mcp@latest",
        "--browser", "chrome",
        "--headless"
      ]
    }
  }
}
```

### Docker Configuration

```json
{
  "mcpServers": {
    "playwright": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm", "--init",
        "--pull=always",
        "mcr.microsoft.com/playwright/mcp"
      ]
    }
  }
}
```

AVAILABLE TOOLS
---------------

### Navigation Tools

1. browser_navigate
   - ÿßŸÑÿ™ŸÜŸÇŸÑ ÿ•ŸÑŸâ URL ŸÖÿ≠ÿØÿØ
   - ÿØÿπŸÖ timeout Ÿàwait conditions

```typescript
{
  "name": "browser_navigate",
  "arguments": {
    "url": "https://example.com",
    "waitUntil": "networkidle"
  }
}
```

2. browser_close
   - ÿ•ÿ∫ŸÑÿßŸÇ ÿßŸÑÿµŸÅÿ≠ÿ© ÿ£Ÿà ÿßŸÑŸÖÿ™ÿµŸÅÿ≠
   - ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑŸÖŸàÿßÿ±ÿØ

### Interaction Tools

3. browser_click
   - ÿßŸÑŸÜŸÇÿ± ÿπŸÑŸâ ÿπŸÜÿµÿ±
   - ÿØÿπŸÖ selectors ŸÖÿ™ÿπÿØÿØÿ©

```typescript
{
  "name": "browser_click",
  "arguments": {
    "selector": "button[data-testid='submit']"
  }
}
```

4. browser_type
   - ŸÉÿ™ÿßÿ®ÿ© ŸÜÿµ ŸÅŸä ÿ≠ŸÇŸÑ
   - ÿØÿπŸÖ keyboard events

```typescript
{
  "name": "browser_type",
  "arguments": {
    "selector": "input[name='email']",
    "text": "user@example.com"
  }
}
```

5. browser_fill_form
   - ŸÖŸÑÿ° ŸÜŸÖŸàÿ∞ÿ¨ ŸÉÿßŸÖŸÑ
   - ÿØÿπŸÖ ÿ≠ŸÇŸàŸÑ ŸÖÿ™ÿπÿØÿØÿ©

```typescript
{
  "name": "browser_fill_form",
  "arguments": {
    "fields": [
      {"selector": "input[name='username']", "value": "admin"},
      {"selector": "input[name='password']", "value": "secret"}
    ]
  }
}
```

6. browser_select_option
   - ÿßÿÆÿ™Ÿäÿßÿ± ŸÖŸÜ dropdown
   - ÿØÿπŸÖ value, label, index

7. browser_hover
   - ÿ™ÿ≠ÿ±ŸäŸÉ ÿßŸÑŸÖÿ§ÿ¥ÿ± ŸÅŸàŸÇ ÿπŸÜÿµÿ±
   - ÿ™ŸÅÿπŸäŸÑ hover effects

8. browser_drag
   - ÿ≥ÿ≠ÿ® Ÿàÿ•ŸÅŸÑÿßÿ™ ÿ®ŸäŸÜ ÿπŸÜÿßÿµÿ±
   - ÿØÿπŸÖ drag and drop

### Data Extraction Tools

9. browser_snapshot
   - ÿßŸÑÿ™ŸÇÿßÿ∑ accessibility snapshot
   - ÿ®ŸäÿßŸÜÿßÿ™ ŸÖŸÜÿ∏ŸÖÿ© ŸÑŸÑÿµŸÅÿ≠ÿ©

```typescript
{
  "name": "browser_snapshot",
  "arguments": {
    "selector": "main" // optional
  }
}
```

10. browser_take_screenshot
    - ÿßŸÑÿ™ŸÇÿßÿ∑ ÿµŸàÿ±ÿ© ŸÑŸÑÿµŸÅÿ≠ÿ©
    - ÿØÿπŸÖ full page Ÿà viewport

```typescript
{
  "name": "browser_take_screenshot",
  "arguments": {
    "fullPage": true,
    "path": "screenshot.png"
  }
}
```

11. browser_evaluate
    - ÿ™ŸÜŸÅŸäÿ∞ JavaScript
    - ÿ•ÿ±ÿ¨ÿßÿπ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨

```typescript
{
  "name": "browser_evaluate",
  "arguments": {
    "expression": "document.title"
  }
}
```

### Network Tools

12. browser_network_requests
    - ŸÇÿßÿ¶ŸÖÿ© ÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑÿ¥ÿ®ŸÉÿ©
    - ÿ™ÿ≠ŸÑŸäŸÑ API calls

13. browser_console_messages
    - ÿ±ÿ≥ÿßÿ¶ŸÑ console
    - ÿ£ÿÆÿ∑ÿßÿ° JavaScript

### File Operations

14. browser_file_upload
    - ÿ±ŸÅÿπ ŸÖŸÑŸÅÿßÿ™
    - ÿØÿπŸÖ multiple files

```typescript
{
  "name": "browser_file_upload",
  "arguments": {
    "selector": "input[type='file']",
    "files": ["/path/to/file.pdf"]
  }
}
```

### Wait Operations

15. browser_wait_for
    - ÿßŸÜÿ™ÿ∏ÿßÿ± ÿ¥ÿ±Ÿàÿ∑ ŸÖÿ≠ÿØÿØÿ©
    - timeout configurable

```typescript
{
  "name": "browser_wait_for",
  "arguments": {
    "selector": ".loading",
    "state": "hidden",
    "timeout": 5000
  }
}
```

ADVANCED CONFIGURATION
----------------------

### Security Options

```bash
# ÿ≠ÿ∏ÿ± service workers
npx @playwright/mcp@latest --block-service-workers

# ÿ™ÿ≠ÿØŸäÿØ origins ŸÖÿ≥ŸÖŸàÿ≠ÿ©
npx @playwright/mcp@latest --allowed-origins "https://example.com;https://api.example.com"

# ÿ≠ÿ∏ÿ± origins ŸÖÿπŸäŸÜÿ©
npx @playwright/mcp@latest --blocked-origins "https://ads.example.com"

# ŸÖŸÜÿ≠ ÿµŸÑÿßÿ≠Ÿäÿßÿ™
npx @playwright/mcp@latest --grant-permissions "geolocation,clipboard-read"
```

### Performance Options

```bash
# headless mode
npx @playwright/mcp@latest --headless

# device emulation
npx @playwright/mcp@latest --device "iPhone 15"

# viewport size
npx @playwright/mcp@latest --viewport-size "1920x1080"

# timeout settings
npx @playwright/mcp@latest --timeout-action 10000 --timeout-navigation 60000
```

### Recording Options

```bash
# ÿ≠ŸÅÿ∏ trace
npx @playwright/mcp@latest --save-trace

# ÿ≠ŸÅÿ∏ video
npx @playwright/mcp@latest --save-video "1280x720"

# ÿ≠ŸÅÿ∏ session
npx @playwright/mcp@latest --save-session

# ŸÖÿ¨ŸÑÿØ ÿßŸÑÿ•ÿÆÿ±ÿßÿ¨
npx @playwright/mcp@latest --output-dir "./test-results"
```

TESTING USE CASES
-----------------

### 1. Frontend Testing Complete

```typescript
// ÿßÿÆÿ™ÿ®ÿßÿ± ÿµŸÅÿ≠ÿ© ÿ™ÿ≥ÿ¨ŸäŸÑ ÿßŸÑÿØÿÆŸàŸÑ
{
  "workflow": [
    {
      "tool": "browser_navigate",
      "args": {"url": "https://app.example.com/login"}
    },
    {
      "tool": "browser_fill_form",
      "args": {
        "fields": [
          {"selector": "#email", "value": "test@example.com"},
          {"selector": "#password", "value": "testpass123"}
        ]
      }
    },
    {
      "tool": "browser_click",
      "args": {"selector": "button[type='submit']"}
    },
    {
      "tool": "browser_wait_for",
      "args": {"selector": ".dashboard", "state": "visible"}
    },
    {
      "tool": "browser_snapshot",
      "args": {}
    }
  ]
}
```

### 2. API Route Testing

```typescript
// ÿßÿÆÿ™ÿ®ÿßÿ± API endpoints ŸÖŸÜ ÿßŸÑŸàÿßÿ¨Ÿáÿ©
{
  "workflow": [
    {
      "tool": "browser_navigate",
      "args": {"url": "https://app.example.com"}
    },
    {
      "tool": "browser_network_requests",
      "args": {"filter": "api/*"}
    },
    {
      "tool": "browser_evaluate",
      "args": {
        "expression": `
          fetch('/api/users')
            .then(r => r.json())
            .then(data => data)
        `
      }
    }
  ]
}
```

### 3. Security Testing

```typescript
// ÿßÿÆÿ™ÿ®ÿßÿ± ÿ£ŸÖÿßŸÜ ÿßŸÑÿµŸÅÿ≠ÿ©
{
  "workflow": [
    {
      "tool": "browser_navigate",
      "args": {"url": "https://app.example.com"}
    },
    {
      "tool": "browser_console_messages",
      "args": {"level": "error"}
    },
    {
      "tool": "browser_evaluate",
      "args": {
        "expression": `
          // ŸÅÿ≠ÿµ CSP headers
          document.querySelector('meta[http-equiv="Content-Security-Policy"]')?.content
        `
      }
    }
  ]
}
```

### 4. Performance Testing

```typescript
// ŸÇŸäÿßÿ≥ ÿ£ÿØÿßÿ° ÿßŸÑÿµŸÅÿ≠ÿ©
{
  "workflow": [
    {
      "tool": "browser_navigate",
      "args": {"url": "https://app.example.com"}
    },
    {
      "tool": "browser_evaluate",
      "args": {
        "expression": `
          JSON.stringify(performance.getEntriesByType('navigation')[0])
        `
      }
    },
    {
      "tool": "browser_network_requests",
      "args": {"includeTimings": true}
    }
  ]
}
```

PROGRAMMATIC USAGE
------------------

```javascript
import http from 'http';
import { createConnection } from '@playwright/mcp';
import { SSEServerTransport } from '@modelcontextprotocol/sdk/server/sse.js';

http.createServer(async (req, res) => {
  // ÿ•ŸÜÿ¥ÿßÿ° ÿßÿ™ÿµÿßŸÑ Playwright MCP
  const connection = await createConnection({
    browser: {
      launchOptions: {
        headless: true,
        args: ['--no-sandbox']
      }
    }
  });

  // ÿ•ŸÜÿ¥ÿßÿ° SSE transport
  const transport = new SSEServerTransport('/messages', res);
  
  // ÿ±ÿ®ÿ∑ ÿßŸÑÿßÿ™ÿµÿßŸÑ
  await connection.connect(transport);
}).listen(3000);
```

================================================================================
SECTION 2: CONTEXT7 MCP SERVER
================================================================================

OVERVIEW
--------
Context7 MCP Server ŸäŸàŸÅÿ± Ÿàÿ´ÿßÿ¶ŸÇ ŸÖÿ≠ÿØÿ´ÿ© Ÿàÿ£ŸÖÿ´ŸÑÿ© ŸÉŸàÿØ ŸÖÿ®ÿßÿ¥ÿ±ÿ© ŸÖŸÜ ÿßŸÑŸÖÿµÿØÿ±.
Ÿäÿ∂ŸÖŸÜ ÿ≠ÿµŸàŸÑ LLMs ÿπŸÑŸâ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿØŸÇŸäŸÇÿ© ŸàŸÖÿ≠ÿØÿ´ÿ© ŸÑŸÑŸÖŸÉÿ™ÿ®ÿßÿ™ ŸàÿßŸÑÿ£ÿ∑ÿ±.

Repository: https://github.com/upstash/context7
Website: https://context7.com

KEY FEATURES
------------

1. Up-to-Date Documentation
   - Ÿàÿ´ÿßÿ¶ŸÇ ŸÖÿ≠ÿØÿ´ÿ© ŸÖŸÜ ÿßŸÑŸÖÿµÿØÿ±
   - ÿØÿπŸÖ ÿ•ÿµÿØÿßÿ±ÿßÿ™ ŸÖÿ™ÿπÿØÿØÿ©
   - ÿ£ŸÖÿ´ŸÑÿ© ŸÉŸàÿØ ÿ≠ŸÇŸäŸÇŸäÿ©

2. Library Support
   - ÿØÿπŸÖ ÿ¢ŸÑÿßŸÅ ÿßŸÑŸÖŸÉÿ™ÿ®ÿßÿ™
   - JavaScript, Python, Go, Rust
   - Frameworks ÿ¥ÿßÿ¶ÿπÿ©

3. Version-Specific
   - Ÿàÿ´ÿßÿ¶ŸÇ ÿÆÿßÿµÿ© ÿ®ÿßŸÑÿ•ÿµÿØÿßÿ±
   - changelog Ÿàmigratio guides
   - breaking changes

INSTALLATION
------------

```bash
# ÿ™ÿ´ÿ®Ÿäÿ™ ÿπÿ®ÿ± npm
npx @upstash/context7-mcp@latest

# ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Docker
docker run -i --rm mcp/context7
```

CONFIGURATION
-------------

### VS Code Configuration

```json
{
  "mcpServers": {
    "context7": {
      "command": "npx",
      "args": ["@upstash/context7-mcp@latest"]
    }
  }
}
```

### Claude Desktop Configuration

```json
{
  "mcpServers": {
    "context7": {
      "command": "npx",
      "args": ["-y", "@upstash/context7-mcp@latest"]
    }
  }
}
```

AVAILABLE TOOLS
---------------

### 1. search_libraries

ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ŸÖŸÉÿ™ÿ®ÿßÿ™ ŸÖÿ™ÿßÿ≠ÿ©

```typescript
{
  "name": "search_libraries",
  "arguments": {
    "query": "react",
    "language": "javascript"
  }
}
```

### 2. resolve_library_id

ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÖÿπÿ±ŸÅ ŸÖŸÉÿ™ÿ®ÿ© ŸÖÿ≠ÿØÿØ

```typescript
{
  "name": "resolve_library_id",
  "arguments": {
    "name": "react",
    "version": "18.2.0"
  }
}
```

### 3. get_documentation

ÿ¨ŸÑÿ® Ÿàÿ´ÿßÿ¶ŸÇ ŸÖŸÉÿ™ÿ®ÿ©

```typescript
{
  "name": "get_documentation",
  "arguments": {
    "libraryId": "react@18.2.0",
    "topic": "hooks"
  }
}
```

### 4. get_code_examples

ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ£ŸÖÿ´ŸÑÿ© ŸÉŸàÿØ

```typescript
{
  "name": "get_code_examples",
  "arguments": {
    "libraryId": "react@18.2.0",
    "feature": "useState"
  }
}
```

USE CASES
---------

### 1. Framework Documentation

```typescript
// ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ Ÿàÿ´ÿßÿ¶ŸÇ Next.js
{
  "workflow": [
    {
      "tool": "search_libraries",
      "args": {"query": "next.js"}
    },
    {
      "tool": "resolve_library_id",
      "args": {"name": "next", "version": "14.0.0"}
    },
    {
      "tool": "get_documentation",
      "args": {
        "libraryId": "next@14.0.0",
        "topic": "app-router"
      }
    }
  ]
}
```

### 2. API Reference

```typescript
// ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ŸÖÿ±ÿ¨ÿπ API
{
  "workflow": [
    {
      "tool": "resolve_library_id",
      "args": {"name": "express", "version": "latest"}
    },
    {
      "tool": "get_documentation",
      "args": {
        "libraryId": "express@latest",
        "topic": "middleware"
      }
    },
    {
      "tool": "get_code_examples",
      "args": {
        "libraryId": "express@latest",
        "feature": "error-handling"
      }
    }
  ]
}
```

### 3. Migration Guide

```typescript
// ÿØŸÑŸäŸÑ ÿßŸÑÿ™ÿ±ŸÇŸäÿ©
{
  "workflow": [
    {
      "tool": "get_documentation",
      "args": {
        "libraryId": "react@17.0.0",
        "topic": "migration"
      }
    },
    {
      "tool": "get_documentation",
      "args": {
        "libraryId": "react@18.0.0",
        "topic": "breaking-changes"
      }
    }
  ]
}
```

INTEGRATION WITH PLAYWRIGHT
----------------------------

```typescript
// ÿØŸÖÿ¨ Context7 ŸÖÿπ Playwright ŸÑŸÑÿßÿÆÿ™ÿ®ÿßÿ± ÿßŸÑŸÖÿ≥ÿ™ŸÜŸäÿ±
{
  "workflow": [
    // 1. ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ Ÿàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÖŸÉÿ™ÿ®ÿ©
    {
      "tool": "context7.get_documentation",
      "args": {
        "libraryId": "react-testing-library@latest",
        "topic": "queries"
      }
    },
    // 2. ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Playwright ŸÑŸÑÿßÿÆÿ™ÿ®ÿßÿ±
    {
      "tool": "playwright.browser_navigate",
      "args": {"url": "https://app.example.com"}
    },
    {
      "tool": "playwright.browser_snapshot",
      "args": {}
    }
  ]
}
```

================================================================================
SECTION 3: GITHUB MCP SERVER
================================================================================

OVERVIEW
--------
GitHub MCP Server Ÿäÿ±ÿ®ÿ∑ ÿ£ÿØŸàÿßÿ™ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÖÿ®ÿßÿ¥ÿ±ÿ© ÿ®ŸÖŸÜÿµÿ© GitHub.
ŸäŸàŸÅÿ± ŸÇÿØÿ±ÿßÿ™ ÿ¥ÿßŸÖŸÑÿ© ŸÑÿ•ÿØÿßÿ±ÿ© ÿßŸÑŸÖÿ≥ÿ™ŸàÿØÿπÿßÿ™ÿå Issuesÿå PRsÿå ŸàÿßŸÑŸÖÿ≤ŸäÿØ.

Repository: https://github.com/github/github-mcp-server
Remote Server: https://api.githubcopilot.com/mcp/

KEY FEATURES
------------

1. Repository Management
   - ÿ™ÿµŸÅÿ≠ ÿßŸÑŸÉŸàÿØ ŸàÿßŸÑŸÖŸÑŸÅÿßÿ™
   - ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑŸÖÿ≥ÿ™ŸàÿØÿπÿßÿ™
   - ÿ™ÿ≠ŸÑŸäŸÑ commits
   - ŸÅŸáŸÖ ÿ®ŸÜŸäÿ© ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ

2. Issue & PR Automation
   - ÿ•ŸÜÿ¥ÿßÿ° Ÿàÿ™ÿ≠ÿØŸäÿ´ Issues
   - ÿ•ÿØÿßÿ±ÿ© Pull Requests
   - code review
   - project boards

3. CI/CD Intelligence
   - ŸÖÿ±ÿßŸÇÿ®ÿ© GitHub Actions
   - ÿ™ÿ≠ŸÑŸäŸÑ build failures
   - ÿ•ÿØÿßÿ±ÿ© releases
   - workflow insights

4. Code Analysis
   - security findings
   - Dependabot alerts
   - code patterns
   - codebase insights

5. Team Collaboration
   - discussions
   - notifications
   - team activity
   - process automation

INSTALLATION
------------

### Remote Server (Recommended)

```json
{
  "servers": {
    "github": {
      "type": "http",
      "url": "https://api.githubcopilot.com/mcp/"
    }
  }
}
```

### Local Server with Docker

```bash
# ÿ•ŸÜÿ¥ÿßÿ° GitHub Personal Access Token
# https://github.com/settings/tokens

# ÿ™ÿ¥ÿ∫ŸäŸÑ ÿπÿ®ÿ± Docker
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=your_token \
  ghcr.io/github/github-mcp-server
```

CONFIGURATION
-------------

### VS Code Configuration (OAuth)

```json
{
  "servers": {
    "github": {
      "type": "http",
      "url": "https://api.githubcopilot.com/mcp/"
    }
  }
}
```

### VS Code Configuration (PAT)

```json
{
  "servers": {
    "github": {
      "type": "http",
      "url": "https://api.githubcopilot.com/mcp/",
      "headers": {
        "Authorization": "Bearer ${input:github_mcp_pat}"
      }
    }
  },
  "inputs": [
    {
      "type": "promptString",
      "id": "github_mcp_pat",
      "description": "GitHub Personal Access Token",
      "password": true
    }
  ]
}
```

### Local Server Configuration

```json
{
  "mcpServers": {
    "github": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm",
        "-e", "GITHUB_PERSONAL_ACCESS_TOKEN",
        "ghcr.io/github/github-mcp-server"
      ],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "your_token_here"
      }
    }
  }
}
```

### GitHub Enterprise Configuration

```json
{
  "mcpServers": {
    "github": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm",
        "-e", "GITHUB_PERSONAL_ACCESS_TOKEN",
        "-e", "GITHUB_HOST",
        "ghcr.io/github/github-mcp-server"
      ],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "your_token",
        "GITHUB_HOST": "https://github.enterprise.com"
      }
    }
  }
}
```

AVAILABLE TOOLS
---------------

### Repository Operations

1. list_repositories
   - ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÖÿ≥ÿ™ŸàÿØÿπÿßÿ™
   - ŸÅŸÑÿ™ÿ±ÿ© Ÿàÿ™ÿ±ÿ™Ÿäÿ®

2. get_repository
   - ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÖÿ≥ÿ™ŸàÿØÿπ
   - ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™

3. search_repositories
   - ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑŸÖÿ≥ÿ™ŸàÿØÿπÿßÿ™
   - advanced queries

4. get_file_contents
   - ŸÇÿ±ÿßÿ°ÿ© ŸÖÿ≠ÿ™ŸàŸâ ŸÖŸÑŸÅ
   - ÿØÿπŸÖ branches

5. search_code
   - ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑŸÉŸàÿØ
   - regex support

### Issue Management

6. list_issues
   - ŸÇÿßÿ¶ŸÖÿ© Issues
   - ŸÅŸÑÿ™ÿ±ÿ© ÿ®ÿßŸÑÿ≠ÿßŸÑÿ©

7. create_issue
   - ÿ•ŸÜÿ¥ÿßÿ° issue ÿ¨ÿØŸäÿØ
   - labels Ÿàassignees

8. update_issue
   - ÿ™ÿ≠ÿØŸäÿ´ issue
   - ÿ•ÿ∫ŸÑÿßŸÇ ÿ£Ÿà ÿ•ÿπÿßÿØÿ© ŸÅÿ™ÿ≠

9. add_issue_comment
   - ÿ•ÿ∂ÿßŸÅÿ© ÿ™ÿπŸÑŸäŸÇ
   - markdown support

### Pull Request Operations

10. list_pull_requests
    - ŸÇÿßÿ¶ŸÖÿ© PRs
    - ŸÅŸÑÿ™ÿ±ÿ© ÿ®ÿßŸÑÿ≠ÿßŸÑÿ©

11. create_pull_request
    - ÿ•ŸÜÿ¥ÿßÿ° PR ÿ¨ÿØŸäÿØ
    - ŸÖŸÜ branch ÿ•ŸÑŸâ branch

12. update_pull_request
    - ÿ™ÿ≠ÿØŸäÿ´ PR
    - merge ÿ£Ÿà close

13. get_pull_request_diff
    - ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ diff
    - ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ™ÿ∫ŸäŸäÿ±ÿßÿ™

14. request_review
    - ÿ∑ŸÑÿ® ŸÖÿ±ÿßÿ¨ÿπÿ©
    - assign reviewers

### Workflow Operations

15. list_workflows
    - ŸÇÿßÿ¶ŸÖÿ© workflows
    - GitHub Actions

16. get_workflow_run
    - ŸÖÿπŸÑŸàŸÖÿßÿ™ workflow run
    - logs Ÿàstatus

17. trigger_workflow
    - ÿ™ÿ¥ÿ∫ŸäŸÑ workflow
    - ŸÖÿπ parameters

### Release Management

18. list_releases
    - ŸÇÿßÿ¶ŸÖÿ© releases
    - latest Ÿàpre-releases

19. create_release
    - ÿ•ŸÜÿ¥ÿßÿ° release ÿ¨ÿØŸäÿØ
    - ŸÖÿπ assets

20. get_latest_release
    - ÿ£ÿ≠ÿØÿ´ release
    - download URLs

USE CASES
---------

### 1. Issue Tracking and Search

```typescript
// ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ issues ŸàÿßŸÑŸÖÿ¥ÿßŸÉŸÑ
{
  "workflow": [
    {
      "tool": "search_repositories",
      "args": {
        "query": "language:javascript stars:>1000"
      }
    },
    {
      "tool": "list_issues",
      "args": {
        "owner": "facebook",
        "repo": "react",
        "state": "open",
        "labels": "bug"
      }
    },
    {
      "tool": "create_issue",
      "args": {
        "owner": "myorg",
        "repo": "myproject",
        "title": "Found security vulnerability",
        "body": "Details...",
        "labels": ["security", "high-priority"]
      }
    }
  ]
}
```

### 2. Latest Release Check

```typescript
// ŸÅÿ≠ÿµ ÿ£ÿ≠ÿØÿ´ ÿßŸÑÿ•ÿµÿØÿßÿ±ÿßÿ™
{
  "workflow": [
    {
      "tool": "get_latest_release",
      "args": {
        "owner": "nodejs",
        "repo": "node"
      }
    },
    {
      "tool": "list_releases",
      "args": {
        "owner": "nodejs",
        "repo": "node",
        "per_page": 5
      }
    }
  ]
}
```

### 3. Code Review Automation

```typescript
// ŸÖÿ±ÿßÿ¨ÿπÿ© ŸÉŸàÿØ ÿ™ŸÑŸÇÿßÿ¶Ÿäÿ©
{
  "workflow": [
    {
      "tool": "list_pull_requests",
      "args": {
        "owner": "myorg",
        "repo": "myproject",
        "state": "open"
      }
    },
    {
      "tool": "get_pull_request_diff",
      "args": {
        "owner": "myorg",
        "repo": "myproject",
        "pull_number": 123
      }
    },
    {
      "tool": "add_issue_comment",
      "args": {
        "owner": "myorg",
        "repo": "myproject",
        "issue_number": 123,
        "body": "LGTM! ‚úÖ"
      }
    }
  ]
}
```

### 4. CI/CD Monitoring

```typescript
// ŸÖÿ±ÿßŸÇÿ®ÿ© workflows
{
  "workflow": [
    {
      "tool": "list_workflows",
      "args": {
        "owner": "myorg",
        "repo": "myproject"
      }
    },
    {
      "tool": "get_workflow_run",
      "args": {
        "owner": "myorg",
        "repo": "myproject",
        "run_id": 123456
      }
    }
  ]
}
```

SECURITY BEST PRACTICES
------------------------

### Token Management

```bash
# ÿ™ÿÆÿ≤ŸäŸÜ ÿ¢ŸÖŸÜ ŸÑŸÑŸÄ token
export GITHUB_PAT=ghp_xxxxxxxxxxxx

# ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ .env file
echo "GITHUB_PERSONAL_ACCESS_TOKEN=ghp_xxxx" > .env
echo ".env" >> .gitignore

# ÿµŸÑÿßÿ≠Ÿäÿßÿ™ ŸÖÿ≠ÿØŸàÿØÿ©
# ŸÖŸÜÿ≠ ŸÅŸÇÿ∑ ÿßŸÑÿµŸÑÿßÿ≠Ÿäÿßÿ™ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©:
# - repo: ŸÑŸÑŸàÿµŸàŸÑ ŸÑŸÑŸÖÿ≥ÿ™ŸàÿØÿπÿßÿ™
# - read:packages: ŸÑÿµŸàÿ± Docker
# - read:org: ŸÑŸÅÿ±ŸÇ ÿßŸÑŸÖŸÜÿ∏ŸÖÿ©
```

### Token Rotation

```bash
# ÿ™ÿØŸàŸäÿ± ÿØŸàÿ±Ÿä ŸÑŸÑŸÄ tokens
# ÿ•ŸÜÿ¥ÿßÿ° token ÿ¨ÿØŸäÿØ ŸÉŸÑ 90 ŸäŸàŸÖ
# ÿ≠ÿ∞ŸÅ tokens ÿßŸÑŸÇÿØŸäŸÖÿ©

# ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ tokens ŸÖŸÜŸÅÿµŸÑÿ© ŸÑŸÑÿ®Ÿäÿ¶ÿßÿ™ ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ©
GITHUB_PAT_DEV=...
GITHUB_PAT_PROD=...
```

================================================================================
SECTION 4: COMPREHENSIVE TESTING WORKFLOW
================================================================================

COMPLETE FRONTEND TESTING
--------------------------

### Test Plan Structure

```typescript
{
  "testPlan": {
    "name": "Complete Frontend Test Suite",
    "phases": [
      "1. Setup and Navigation",
      "2. API Route Testing",
      "3. Security Testing",
      "4. Performance Testing",
      "5. Issue Reporting"
    ]
  }
}
```

### Phase 1: Setup and Navigation

```typescript
{
  "phase": "Setup",
  "tools": ["playwright"],
  "steps": [
    {
      "tool": "browser_navigate",
      "args": {
        "url": "https://app.example.com",
        "waitUntil": "networkidle"
      }
    },
    {
      "tool": "browser_snapshot",
      "args": {},
      "validate": "page loaded successfully"
    }
  ]
}
```

### Phase 2: API Route Testing

```typescript
{
  "phase": "API Testing",
  "tools": ["playwright"],
  "steps": [
    // ÿßÿÆÿ™ÿ®ÿßÿ± GET endpoints
    {
      "tool": "browser_evaluate",
      "args": {
        "expression": `
          fetch('/api/users')
            .then(r => ({status: r.status, data: r.json()}))
        `
      },
      "validate": "status === 200"
    },
    // ÿßÿÆÿ™ÿ®ÿßÿ± POST endpoints
    {
      "tool": "browser_evaluate",
      "args": {
        "expression": `
          fetch('/api/users', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({name: 'Test User'})
          }).then(r => r.json())
        `
      }
    },
    // ŸÖÿ±ÿßŸÇÿ®ÿ© network requests
    {
      "tool": "browser_network_requests",
      "args": {
        "filter": "api/*",
        "includeTimings": true
      }
    }
  ]
}
```

### Phase 3: Security Testing

```typescript
{
  "phase": "Security",
  "tools": ["playwright", "context7"],
  "steps": [
    // ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ best practices
    {
      "tool": "context7.get_documentation",
      "args": {
        "libraryId": "owasp-top-10@latest",
        "topic": "web-security"
      }
    },
    // ŸÅÿ≠ÿµ CSP headers
    {
      "tool": "browser_evaluate",
      "args": {
        "expression": `
          ({
            csp: document.querySelector('meta[http-equiv="Content-Security-Policy"]')?.content,
            xframe: document.querySelector('meta[http-equiv="X-Frame-Options"]')?.content
          })
        `
      }
    },
    // ŸÅÿ≠ÿµ console errors
    {
      "tool": "browser_console_messages",
      "args": {"level": "error"}
    },
    // ÿßÿÆÿ™ÿ®ÿßÿ± authentication
    {
      "tool": "browser_fill_form",
      "args": {
        "fields": [
          {"selector": "#username", "value": "admin"},
          {"selector": "#password", "value": "wrongpass"}
        ]
      }
    },
    {
      "tool": "browser_click",
      "args": {"selector": "button[type='submit']"}
    },
    {
      "tool": "browser_wait_for",
      "args": {
        "selector": ".error-message",
        "state": "visible"
      }
    }
  ]
}
```

### Phase 4: Performance Testing

```typescript
{
  "phase": "Performance",
  "tools": ["playwright"],
  "steps": [
    // ŸÇŸäÿßÿ≥ page load
    {
      "tool": "browser_evaluate",
      "args": {
        "expression": `
          JSON.stringify({
            navigation: performance.getEntriesByType('navigation')[0],
            resources: performance.getEntriesByType('resource').length,
            paint: performance.getEntriesByType('paint')
          })
        `
      }
    },
    // ŸÇŸäÿßÿ≥ network performance
    {
      "tool": "browser_network_requests",
      "args": {
        "includeTimings": true,
        "includeSizes": true
      }
    },
    // ÿßŸÑÿ™ŸÇÿßÿ∑ screenshots
    {
      "tool": "browser_take_screenshot",
      "args": {
        "fullPage": true,
        "path": "performance-test.png"
      }
    }
  ]
}
```

### Phase 5: Issue Reporting

```typescript
{
  "phase": "Reporting",
  "tools": ["github"],
  "steps": [
    // ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ issues ŸÖÿ¥ÿßÿ®Ÿáÿ©
    {
      "tool": "github.list_issues",
      "args": {
        "owner": "myorg",
        "repo": "myproject",
        "state": "open",
        "labels": "bug"
      }
    },
    // ÿ•ŸÜÿ¥ÿßÿ° issue ÿ¨ÿØŸäÿØ
    {
      "tool": "github.create_issue",
      "args": {
        "owner": "myorg",
        "repo": "myproject",
        "title": "Security: Missing CSP header",
        "body": `
## Issue Description
Missing Content-Security-Policy header detected.

## Steps to Reproduce
1. Navigate to https://app.example.com
2. Inspect response headers
3. CSP header is missing

## Expected Behavior
CSP header should be present with strict policy

## Test Results
- Browser: Chrome
- Date: 2025-01-02
- Tester: MCP Automation

## Screenshots
See attached screenshot.
        `,
        "labels": ["security", "high-priority"]
      }
    }
  ]
}
```

AUTOMATED TESTING WORKFLOW
---------------------------

```typescript
{
  "automatedWorkflow": {
    "trigger": "on_push",
    "steps": [
      // 1. ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ£ÿ≠ÿØÿ´ ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ
      {
        "mcp": "context7",
        "action": "get_documentation",
        "library": "testing-library"
      },
      // 2. ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßÿÆÿ™ÿ®ÿßÿ±ÿßÿ™ Playwright
      {
        "mcp": "playwright",
        "action": "run_test_suite",
        "config": "playwright.config.ts"
      },
      // 3. ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨
      {
        "mcp": "playwright",
        "action": "analyze_results",
        "generateReport": true
      },
      // 4. ÿ±ŸÅÿπ issues ŸÑŸÑŸÅÿ¥ŸÑ
      {
        "mcp": "github",
        "action": "create_issue_if_failed",
        "assignees": ["@qa-team"]
      },
      // 5. ÿ™ÿ≠ÿØŸäÿ´ PR
      {
        "mcp": "github",
        "action": "add_pr_comment",
        "summary": "test_results"
      }
    ]
  }
}
```

================================================================================
SECTION 5: BEST PRACTICES
================================================================================

MCP INTEGRATION BEST PRACTICES
-------------------------------

### 1. Server Selection

```typescript
// ÿßÿÆÿ™ÿ± ÿßŸÑÿÆŸàÿßÿØŸÖ ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ÿ© ŸÑÿßÿ≠ÿ™Ÿäÿßÿ¨ŸÉ
{
  "development": ["playwright", "context7"],
  "testing": ["playwright", "github"],
  "production": ["github"],
  "documentation": ["context7"]
}
```

### 2. Configuration Management

```bash
# ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸÖŸÑŸÅÿßÿ™ ÿ™ŸÉŸàŸäŸÜ ŸÖŸÜŸÅÿµŸÑÿ©
.mcp/
‚îú‚îÄ‚îÄ development.json
‚îú‚îÄ‚îÄ testing.json
‚îî‚îÄ‚îÄ production.json

# ŸÑÿß ÿ™ÿ±ŸÅÿπ secrets ÿ•ŸÑŸâ Git
echo ".mcp/*.json" >> .gitignore
echo ".env" >> .gitignore
```

### 3. Error Handling

```typescript
{
  "errorHandling": {
    "retry": {
      "maxAttempts": 3,
      "backoff": "exponential"
    },
    "fallback": {
      "onTimeout": "skip_and_continue",
      "onError": "log_and_report"
    },
    "logging": {
      "level": "info",
      "destination": "logs/mcp.log"
    }
  }
}
```

### 4. Performance Optimization

```typescript
{
  "optimization": {
    "caching": {
      "enabled": true,
      "ttl": 3600,
      "storage": "memory"
    },
    "parallelization": {
      "maxConcurrent": 5,
      "queueSize": 100
    },
    "timeout": {
      "default": 30000,
      "navigation": 60000,
      "action": 5000
    }
  }
}
```

### 5. Security Guidelines

```typescript
{
  "security": {
    "tokens": {
      "storage": "environment_variables",
      "rotation": "90_days",
      "scope": "minimum_required"
    },
    "permissions": {
      "principle": "least_privilege",
      "review": "quarterly"
    },
    "audit": {
      "enabled": true,
      "logActions": true,
      "alertOnSuspicious": true
    }
  }
}
```

TESTING BEST PRACTICES
-----------------------

### 1. Test Organization

```typescript
{
  "testStructure": {
    "unit": "playwright/unit/",
    "integration": "playwright/integration/",
    "e2e": "playwright/e2e/",
    "security": "playwright/security/",
    "performance": "playwright/performance/"
  }
}
```

### 2. Test Data Management

```typescript
{
  "testData": {
    "fixtures": "fixtures/",
    "mocks": "mocks/",
    "seeds": "seeds/",
    "cleanup": "after_each_test"
  }
}
```

### 3. Reporting

```typescript
{
  "reporting": {
    "formats": ["html", "json", "junit"],
    "screenshots": "on_failure",
    "videos": "on_failure",
    "traces": "on_failure",
    "artifacts": "test-results/"
  }
}
```

### 4. CI/CD Integration

```yaml
# .github/workflows/mcp-tests.yml
name: MCP Testing
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install Playwright
        run: |
          npm install -D @playwright/test
          npx playwright install --with-deps
      
      - name: Run MCP Tests
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: npx playwright test
      
      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: test-results
          path: test-results/
      
      - name: Report to GitHub
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'MCP Test Failure',
              body: 'Automated tests failed. See artifacts.'
            })
```

TROUBLESHOOTING
---------------

### Common Issues

1. **Connection Timeout**
   ```bash
   # ÿ≤ŸäÿßÿØÿ© timeout
   npx @playwright/mcp@latest --timeout-navigation 120000
   ```

2. **Authentication Errors**
   ```bash
   # ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ token
   echo $GITHUB_PERSONAL_ACCESS_TOKEN
   
   # ÿ•ÿπÿßÿØÿ© ÿ•ŸÜÿ¥ÿßÿ° token
   # https://github.com/settings/tokens
   ```

3. **Browser Launch Failures**
   ```bash
   # ÿ™ÿ´ÿ®Ÿäÿ™ dependencies
   npx playwright install-deps
   
   # ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ no-sandbox
   npx @playwright/mcp@latest --no-sandbox
   ```

4. **Network Issues**
   ```bash
   # ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ proxy
   npx @playwright/mcp@latest --proxy-server http://proxy:3128
   
   # ÿ™ÿ¨ÿßŸàÿ≤ domains ŸÖÿπŸäŸÜÿ©
   npx @playwright/mcp@latest --proxy-bypass ".com,.org"
   ```

RESOURCES
---------

### Official Documentation
- Playwright MCP: https://github.com/microsoft/playwright-mcp
- Context7: https://github.com/upstash/context7
- GitHub MCP: https://github.com/github/github-mcp-server
- MCP Protocol: https://modelcontextprotocol.io

### Community Resources
- MCP Registry: https://github.com/mcp
- MCP Servers: https://github.com/modelcontextprotocol/servers
- Examples: https://modelcontextprotocol.io/examples

### Tools and Extensions
- VS Code MCP: https://code.visualstudio.com/docs/copilot/customization/mcp-servers
- Claude Desktop: https://claude.ai/download
- Cursor: https://cursor.sh

================================================================================
END OF MODULE 15: MCP INTEGRATION
================================================================================




================================================================================
SECTION 6: CODE ANALYSIS MCP SERVERS
================================================================================

OVERVIEW
--------
ÿ£ÿØŸàÿßÿ™ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÉŸàÿØ ÿ™ÿ≥ÿßÿπÿØ ŸÅŸä ÿßŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ ÿ¨ŸàÿØÿ© ÿßŸÑŸÉŸàÿØÿå ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ£ÿÆÿ∑ÿßÿ°ÿå Ÿàÿ™ÿ≠ÿ≥ŸäŸÜ
ÿßŸÑÿ£ÿØÿßÿ°. Ÿáÿ∞Ÿá ÿßŸÑÿ£ÿØŸàÿßÿ™ ÿ∂ÿ±Ÿàÿ±Ÿäÿ© ŸÑÿ£Ÿä ŸÖÿ¥ÿ±Ÿàÿπ ÿßÿ≠ÿ™ÿ±ÿßŸÅŸä.

### 6.1 RUFF MCP SERVER

OVERVIEW
--------
Ruff ŸáŸà Python linter Ÿà code formatter ÿ≥ÿ±Ÿäÿπ ÿ¨ÿØÿßŸã ŸÖŸÉÿ™Ÿàÿ® ÿ®ŸÑÿ∫ÿ© Rust.
ŸäŸàŸÅÿ± MCP server ŸÑŸÑÿ™ŸÉÿßŸÖŸÑ ŸÖÿπ ÿ£ÿØŸàÿßÿ™ AI.

Repository: https://github.com/Anselmoo/mcp-server-analyzer
Package: ruff-mcp-server

KEY FEATURES
------------

1. **Ultra-Fast Performance**
   - 10-100x ÿ£ÿ≥ÿ±ÿπ ŸÖŸÜ Flake8
   - ŸÖŸÉÿ™Ÿàÿ® ÿ®ŸÑÿ∫ÿ© Rust
   - ŸÖÿπÿßŸÑÿ¨ÿ© ŸÖÿ™Ÿàÿßÿ≤Ÿäÿ©

2. **Comprehensive Linting**
   - 800+ ŸÇÿßÿπÿØÿ© linting
   - ÿØÿπŸÖ Flake8, pylint, pycodestyle
   - ÿßŸÉÿ™ÿ¥ÿßŸÅ dead code ŸÖÿπ VULTURE
   - type checking hints

3. **Auto-Fixing**
   - ÿ•ÿµŸÑÿßÿ≠ ÿ™ŸÑŸÇÿßÿ¶Ÿä ŸÑŸÑŸÖÿ¥ÿßŸÉŸÑ
   - safe Ÿà unsafe fixes
   - bulk fixing

4. **Code Formatting**
   - ŸÖÿ™ŸàÿßŸÅŸÇ ŸÖÿπ Black
   - configurable style
   - fast formatting

INSTALLATION
------------

```bash
# ÿ™ÿ´ÿ®Ÿäÿ™ Ruff
pip install ruff

# ÿ™ÿ´ÿ®Ÿäÿ™ MCP server
npm install -g ruff-mcp-server

# ÿ£Ÿà ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ npx
npx ruff-mcp-server
```

CONFIGURATION
-------------

### VS Code Configuration

```json
{
  "mcpServers": {
    "ruff": {
      "command": "npx",
      "args": ["ruff-mcp-server"],
      "env": {
        "RUFF_CONFIG": ".ruff.toml"
      }
    }
  }
}
```

### Ruff Configuration (.ruff.toml)

```toml
[tool.ruff]
# Python version
target-version = "py311"

# Line length
line-length = 88

# Enable rules
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # Pyflakes
    "I",   # isort
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
    "UP",  # pyupgrade
]

# Ignore specific rules
ignore = [
    "E501",  # line too long
    "B008",  # function calls in argument defaults
]

# Exclude directories
exclude = [
    ".git",
    "__pycache__",
    ".venv",
    "venv",
    "build",
    "dist",
]

[tool.ruff.per-file-ignores]
"__init__.py" = ["F401"]  # unused imports in __init__.py
"tests/**/*.py" = ["S101"]  # assert usage in tests
```

AVAILABLE TOOLS
---------------

### 1. lint_code

ŸÅÿ≠ÿµ ÿßŸÑŸÉŸàÿØ Ÿàÿ•ÿ±ÿ¨ÿßÿπ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ

```python
{
  "tool": "ruff.lint_code",
  "arguments": {
    "file_path": "src/main.py",
    "fix": false
  }
}
```

### 2. format_code

ÿ™ŸÜÿ≥ŸäŸÇ ÿßŸÑŸÉŸàÿØ

```python
{
  "tool": "ruff.format_code",
  "arguments": {
    "file_path": "src/main.py",
    "check": false
  }
}
```

### 3. check_project

ŸÅÿ≠ÿµ ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ ŸÉÿßŸÖŸÑÿßŸã

```python
{
  "tool": "ruff.check_project",
  "arguments": {
    "directory": "src/",
    "fix": true,
    "show_fixes": true
  }
}
```

### 4. find_dead_code

ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑŸÉŸàÿØ ÿ∫Ÿäÿ± ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ

```python
{
  "tool": "ruff.find_dead_code",
  "arguments": {
    "directory": "src/",
    "min_confidence": 80
  }
}
```

USE CASES
---------

### 1. Pre-Commit Linting

```bash
# ÿ•ÿ∂ÿßŸÅÿ© ÿ•ŸÑŸâ .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.0
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format
```

### 2. CI/CD Integration

```yaml
# .github/workflows/lint.yml
name: Lint
on: [push, pull_request]

jobs:
  ruff:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: chartboost/ruff-action@v1
        with:
          args: check --output-format=github
```

### 3. Automated Code Review

```typescript
{
  "workflow": [
    {
      "tool": "github.list_pull_requests",
      "args": {"state": "open"}
    },
    {
      "tool": "github.get_pull_request_diff",
      "args": {"pull_number": 123}
    },
    {
      "tool": "ruff.lint_code",
      "args": {"file_path": "changed_file.py", "fix": true}
    },
    {
      "tool": "github.add_issue_comment",
      "args": {
        "issue_number": 123,
        "body": "Ruff found and fixed issues"
      }
    }
  ]
}
```

---

### 6.2 ESLINT MCP SERVER

OVERVIEW
--------
ESLint ŸáŸà linter ŸÇÿßÿ®ŸÑ ŸÑŸÑÿ™ÿÆÿµŸäÿµ ŸÑŸÄ JavaScript Ÿà TypeScript.
Ÿäÿ≥ÿßÿπÿØ ŸÅŸä ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ŸàŸÅÿ±ÿ∂ ŸÖÿπÿßŸäŸäÿ± ÿßŸÑÿ®ÿ±ŸÖÿ¨ÿ©.

Repository: https://github.com/eslint/eslint
MCP Documentation: https://eslint.org/docs/latest/use/mcp

KEY FEATURES
------------

1. **Pluggable Architecture**
   - 300+ ŸÇŸàÿßÿπÿØ ŸÖÿØŸÖÿ¨ÿ©
   - ÿ¢ŸÑÿßŸÅ ÿßŸÑŸÄ plugins
   - ŸÇŸàÿßÿπÿØ ŸÖÿÆÿµÿµÿ©

2. **Auto-Fixing**
   - ÿ•ÿµŸÑÿßÿ≠ ÿ™ŸÑŸÇÿßÿ¶Ÿä ŸÑŸÑŸÖÿ¥ÿßŸÉŸÑ
   - safe fixes ŸÅŸÇÿ∑
   - configurable

3. **TypeScript Support**
   - ÿØÿπŸÖ ŸÉÿßŸÖŸÑ ŸÑŸÄ TypeScript
   - type-aware rules
   - @typescript-eslint plugin

4. **Framework Integration**
   - React, Vue, Angular
   - Next.js, Nuxt
   - custom frameworks

INSTALLATION
------------

```bash
# ÿ™ÿ´ÿ®Ÿäÿ™ ESLint
npm install -D eslint

# ÿ™ÿ´ÿ®Ÿäÿ™ MCP server
npm install -g @eslint/mcp-server

# Initialize config
npx eslint --init
```

CONFIGURATION
-------------

### VS Code Configuration

```json
{
  "mcpServers": {
    "eslint": {
      "command": "npx",
      "args": ["@eslint/mcp-server"]
    }
  }
}
```

### ESLint Configuration (eslint.config.js)

```javascript
import js from '@eslint/js';
import typescript from '@typescript-eslint/eslint-plugin';
import react from 'eslint-plugin-react';

export default [
  js.configs.recommended,
  {
    files: ['**/*.{js,jsx,ts,tsx}'],
    plugins: {
      '@typescript-eslint': typescript,
      'react': react
    },
    rules: {
      'no-unused-vars': 'error',
      'no-console': 'warn',
      '@typescript-eslint/no-explicit-any': 'error',
      'react/prop-types': 'off'
    },
    settings: {
      react: {
        version: 'detect'
      }
    }
  }
];
```

AVAILABLE TOOLS
---------------

### 1. lint_file

ŸÅÿ≠ÿµ ŸÖŸÑŸÅ Ÿàÿßÿ≠ÿØ

```javascript
{
  "tool": "eslint.lint_file",
  "arguments": {
    "file_path": "src/App.tsx",
    "fix": false
  }
}
```

### 2. lint_directory

ŸÅÿ≠ÿµ ŸÖÿ¨ŸÑÿØ

```javascript
{
  "tool": "eslint.lint_directory",
  "arguments": {
    "directory": "src/",
    "extensions": [".js", ".jsx", ".ts", ".tsx"],
    "fix": true
  }
}
```

### 3. get_config

ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿßŸÑÿ™ŸÉŸàŸäŸÜ

```javascript
{
  "tool": "eslint.get_config",
  "arguments": {
    "file_path": "src/App.tsx"
  }
}
```

USE CASES
---------

### 1. Pre-Commit Hook

```json
{
  "husky": {
    "hooks": {
      "pre-commit": "lint-staged"
    }
  },
  "lint-staged": {
    "*.{js,jsx,ts,tsx}": [
      "eslint --fix",
      "git add"
    ]
  }
}
```

### 2. CI/CD Integration

```yaml
# .github/workflows/lint.yml
name: ESLint
on: [push, pull_request]

jobs:
  eslint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      - run: npm ci
      - run: npx eslint . --ext .js,.jsx,.ts,.tsx
```

---

### 6.3 CODE ANALYSIS MCP SERVER

OVERVIEW
--------
ÿÆÿßÿØŸÖ ÿ¥ÿßŸÖŸÑ ŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÉŸàÿØ ŸäÿØÿπŸÖ ŸÑÿ∫ÿßÿ™ ŸÖÿ™ÿπÿØÿØÿ© ŸàŸäŸàŸÅÿ± ÿ±ÿ§Ÿâ ÿπŸÖŸäŸÇÿ©.

Repository: https://github.com/saiprashanths/code-analysis-mcp
Features: Multi-language, Deep analysis, Security scanning

KEY FEATURES
------------

1. **Multi-Language Support**
   - Python, JavaScript, TypeScript
   - Go, Rust, Java
   - C/C++, C#

2. **Deep Analysis**
   - Complexity metrics
   - Code smells
   - Design patterns
   - Architecture analysis

3. **Security Scanning**
   - Vulnerability detection
   - Dependency scanning
   - OWASP Top 10
   - CWE database

4. **Performance Analysis**
   - Bottleneck detection
   - Memory leaks
   - CPU profiling
   - Optimization suggestions

INSTALLATION
------------

```bash
# ÿ™ÿ´ÿ®Ÿäÿ™ via npm
npm install -g code-analysis-mcp

# ÿ£Ÿà Docker
docker run -i --rm code-analysis-mcp
```

CONFIGURATION
-------------

```json
{
  "mcpServers": {
    "code-analysis": {
      "command": "npx",
      "args": ["code-analysis-mcp"],
      "env": {
        "ANALYSIS_DEPTH": "deep",
        "SECURITY_SCAN": "true"
      }
    }
  }
}
```

AVAILABLE TOOLS
---------------

### 1. analyze_codebase

ÿ™ÿ≠ŸÑŸäŸÑ ÿ¥ÿßŸÖŸÑ ŸÑŸÑŸÖÿ¥ÿ±Ÿàÿπ

```javascript
{
  "tool": "code-analysis.analyze_codebase",
  "arguments": {
    "directory": "src/",
    "depth": "deep",
    "include_security": true,
    "include_performance": true
  }
}
```

### 2. find_code_smells

ÿßŸÉÿ™ÿ¥ÿßŸÅ code smells

```javascript
{
  "tool": "code-analysis.find_code_smells",
  "arguments": {
    "file_path": "src/legacy.py",
    "severity": "medium"
  }
}
```

### 3. security_scan

ŸÅÿ≠ÿµ ÿ£ŸÖŸÜŸä

```javascript
{
  "tool": "code-analysis.security_scan",
  "arguments": {
    "directory": "src/",
    "check_dependencies": true,
    "owasp_check": true
  }
}
```

### 4. complexity_metrics

ŸÇŸäÿßÿ≥ ÿßŸÑÿ™ÿπŸÇŸäÿØ

```javascript
{
  "tool": "code-analysis.complexity_metrics",
  "arguments": {
    "file_path": "src/complex.py",
    "metrics": ["cyclomatic", "cognitive", "halstead"]
  }
}
```

USE CASES
---------

### Complete Code Review Workflow

```typescript
{
  "workflow": [
    // 1. ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÉŸàÿØ
    {
      "tool": "code-analysis.analyze_codebase",
      "args": {"directory": "src/", "depth": "deep"}
    },
    // 2. ŸÅÿ≠ÿµ ÿ£ŸÖŸÜŸä
    {
      "tool": "code-analysis.security_scan",
      "args": {"directory": "src/", "owasp_check": true}
    },
    // 3. Lint Python
    {
      "tool": "ruff.check_project",
      "args": {"directory": "src/", "fix": true}
    },
    // 4. Lint JavaScript
    {
      "tool": "eslint.lint_directory",
      "args": {"directory": "src/", "fix": true}
    },
    // 5. ÿ•ŸÜÿ¥ÿßÿ° ÿ™ŸÇÿ±Ÿäÿ±
    {
      "tool": "github.create_issue",
      "args": {
        "title": "Code Analysis Report",
        "body": "Analysis results...",
        "labels": ["code-quality"]
      }
    }
  ]
}
```

================================================================================
SECTION 7: TASK MANAGEMENT MCP SERVERS
================================================================================

OVERVIEW
--------
ÿ£ÿØŸàÿßÿ™ ÿ•ÿØÿßÿ±ÿ© ÿßŸÑŸÖŸáÿßŸÖ ÿ™ÿ≥ÿßÿπÿØ ŸÅŸä ÿ™ŸÜÿ∏ŸäŸÖ ÿßŸÑÿπŸÖŸÑÿå ÿ™ÿ™ÿ®ÿπ ÿßŸÑÿ™ŸÇÿØŸÖÿå Ÿàÿ£ÿ™ŸÖÿ™ÿ© ÿ≥Ÿäÿ± ÿßŸÑÿπŸÖŸÑ.

### 7.1 TASK QUEUE MCP SERVER

OVERVIEW
--------
ŸÜÿ∏ÿßŸÖ ÿ•ÿØÿßÿ±ÿ© ŸÖŸáÿßŸÖ ŸÖÿ™ŸÇÿØŸÖ ŸÑŸÑŸÄ AI assistants ŸÖÿπ ÿØÿπŸÖ ÿßŸÑÿ£ŸàŸÑŸàŸäÿßÿ™ ŸàÿßŸÑÿ¨ÿØŸàŸÑÿ©.

Repository: https://github.com/chriscarrollsmith/taskqueue-mcp
Package: taskqueue-mcp

KEY FEATURES
------------

1. **Priority Queue**
   - ŸÖŸáÿßŸÖ ÿ∞ÿßÿ™ ÿ£ŸàŸÑŸàŸäÿßÿ™
   - FIFO, LIFO, Priority-based
   - Dynamic re-prioritization

2. **Task Scheduling**
   - ÿ¨ÿØŸàŸÑÿ© ÿßŸÑŸÖŸáÿßŸÖ
   - Recurring tasks
   - Deadline management

3. **Task Dependencies**
   - ÿ™ÿ®ÿπŸäÿßÿ™ ÿ®ŸäŸÜ ÿßŸÑŸÖŸáÿßŸÖ
   - Parallel execution
   - Sequential workflows

4. **Progress Tracking**
   - ÿ™ÿ™ÿ®ÿπ ÿßŸÑÿ™ŸÇÿØŸÖ
   - Status updates
   - Completion notifications

INSTALLATION
------------

```bash
# ÿ™ÿ´ÿ®Ÿäÿ™ via npm
npm install -g taskqueue-mcp

# ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿÆÿßÿØŸÖ
npx taskqueue-mcp
```

CONFIGURATION
-------------

```json
{
  "mcpServers": {
    "taskqueue": {
      "command": "npx",
      "args": ["taskqueue-mcp"],
      "env": {
        "QUEUE_TYPE": "priority",
        "MAX_CONCURRENT": "5"
      }
    }
  }
}
```

AVAILABLE TOOLS
---------------

### 1. add_task

ÿ•ÿ∂ÿßŸÅÿ© ŸÖŸáŸÖÿ© ÿ¨ÿØŸäÿØÿ©

```javascript
{
  "tool": "taskqueue.add_task",
  "arguments": {
    "title": "Fix login bug",
    "description": "User reported login issue",
    "priority": "high",
    "deadline": "2025-01-10",
    "tags": ["bug", "urgent"]
  }
}
```

### 2. list_tasks

ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÖŸáÿßŸÖ

```javascript
{
  "tool": "taskqueue.list_tasks",
  "arguments": {
    "status": "pending",
    "priority": "high",
    "sort_by": "deadline"
  }
}
```

### 3. update_task

ÿ™ÿ≠ÿØŸäÿ´ ŸÖŸáŸÖÿ©

```javascript
{
  "tool": "taskqueue.update_task",
  "arguments": {
    "task_id": "123",
    "status": "in_progress",
    "progress": 50
  }
}
```

### 4. complete_task

ÿ•ŸÉŸÖÿßŸÑ ŸÖŸáŸÖÿ©

```javascript
{
  "tool": "taskqueue.complete_task",
  "arguments": {
    "task_id": "123",
    "notes": "Fixed and tested"
  }
}
```

### 5. schedule_task

ÿ¨ÿØŸàŸÑÿ© ŸÖŸáŸÖÿ©

```javascript
{
  "tool": "taskqueue.schedule_task",
  "arguments": {
    "task_id": "123",
    "schedule": "daily",
    "time": "09:00",
    "timezone": "UTC"
  }
}
```

USE CASES
---------

### 1. Bug Tracking Workflow

```typescript
{
  "workflow": [
    // 1. ÿ•ŸÜÿ¥ÿßÿ° ŸÖŸáŸÖÿ© ŸÖŸÜ GitHub issue
    {
      "tool": "github.list_issues",
      "args": {"state": "open", "labels": "bug"}
    },
    {
      "tool": "taskqueue.add_task",
      "args": {
        "title": "Fix bug #123",
        "priority": "high",
        "source": "github"
      }
    },
    // 2. ÿ™ÿπŸäŸäŸÜ ŸÑŸÑŸÖÿ∑Ÿàÿ±
    {
      "tool": "taskqueue.assign_task",
      "args": {"task_id": "123", "assignee": "developer@example.com"}
    },
    // 3. ÿ™ÿ™ÿ®ÿπ ÿßŸÑÿ™ŸÇÿØŸÖ
    {
      "tool": "taskqueue.update_task",
      "args": {"task_id": "123", "status": "in_progress"}
    }
  ]
}
```

### 2. Daily Standup Automation

```typescript
{
  "workflow": [
    // ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÖŸáÿßŸÖ ÿßŸÑŸÖŸÉÿ™ŸÖŸÑÿ© ÿ£ŸÖÿ≥
    {
      "tool": "taskqueue.list_tasks",
      "args": {
        "status": "completed",
        "completed_after": "yesterday"
      }
    },
    // ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÖŸáÿßŸÖ ŸÑŸÑŸäŸàŸÖ
    {
      "tool": "taskqueue.list_tasks",
      "args": {
        "status": "pending",
        "priority": "high"
      }
    },
    // ÿ•ÿ±ÿ≥ÿßŸÑ ÿ™ŸÇÿ±Ÿäÿ±
    {
      "tool": "slack.send_message",
      "args": {
        "channel": "#standup",
        "text": "Daily standup report"
      }
    }
  ]
}
```

---

### 7.2 PRODUCTIVITY MCP SERVERS

OVERVIEW
--------
ŸÖÿ¨ŸÖŸàÿπÿ© ŸÖŸÜ ÿßŸÑÿ£ÿØŸàÿßÿ™ ŸÑÿ≤ŸäÿßÿØÿ© ÿßŸÑÿ•ŸÜÿ™ÿßÿ¨Ÿäÿ© Ÿàÿ£ÿ™ŸÖÿ™ÿ© ÿßŸÑŸÖŸáÿßŸÖ ÿßŸÑŸäŸàŸÖŸäÿ©.

#### Amazing Marvin MCP

```json
{
  "server": "amazing-marvin",
  "features": [
    "Task management",
    "Time tracking",
    "Habit tracking",
    "Goal setting"
  ]
}
```

#### Todoist MCP

```json
{
  "server": "todoist",
  "features": [
    "Task lists",
    "Projects",
    "Labels and filters",
    "Reminders"
  ]
}
```

#### Notion MCP

```json
{
  "server": "notion",
  "features": [
    "Database management",
    "Page creation",
    "Content search",
    "Team collaboration"
  ]
}
```

INTEGRATION EXAMPLE
-------------------

```typescript
{
  "daily_workflow": [
    // 1. ÿ¨ŸÖÿπ ÿßŸÑŸÖŸáÿßŸÖ ŸÖŸÜ ŸÖÿµÿßÿØÿ± ŸÖÿ™ÿπÿØÿØÿ©
    {
      "tool": "github.list_issues",
      "args": {"assignee": "me", "state": "open"}
    },
    {
      "tool": "notion.query_database",
      "args": {"database_id": "tasks"}
    },
    // 2. ÿØŸÖÿ¨ ŸÅŸä task queue
    {
      "tool": "taskqueue.bulk_add_tasks",
      "args": {"tasks": "collected_tasks"}
    },
    // 3. ÿ™ÿ±ÿ™Ÿäÿ® ÿ≠ÿ≥ÿ® ÿßŸÑÿ£ŸàŸÑŸàŸäÿ©
    {
      "tool": "taskqueue.prioritize_tasks",
      "args": {"algorithm": "eisenhower_matrix"}
    },
    // 4. ÿ•ŸÜÿ¥ÿßÿ° ÿÆÿ∑ÿ© ÿßŸÑŸäŸàŸÖ
    {
      "tool": "taskqueue.create_daily_plan",
      "args": {"max_tasks": 5}
    }
  ]
}
```

================================================================================
SECTION 8: MONITORING & ERROR TRACKING
================================================================================

### 8.1 SENTRY MCP SERVER

OVERVIEW
--------
Sentry MCP ŸäŸàŸÅÿ± ÿ™ŸÉÿßŸÖŸÑ ŸÉÿßŸÖŸÑ ŸÖÿπ ŸÖŸÜÿµÿ© Sentry ŸÑÿ™ÿ™ÿ®ÿπ ÿßŸÑÿ£ÿÆÿ∑ÿßÿ° ŸàÿßŸÑÿ£ÿØÿßÿ°.

Repository: MCP Registry (configured in user environment)
Features: Error tracking, Performance monitoring, Issue management

KEY FEATURES
------------

1. **Error Monitoring**
   - Real-time error tracking
   - Stack traces
   - User context
   - Breadcrumbs

2. **Performance Monitoring**
   - Transaction tracking
   - Slow queries
   - API monitoring
   - Frontend performance

3. **Issue Management**
   - Automatic grouping
   - Assignment
   - Resolution tracking
   - Release tracking

4. **Alerts & Notifications**
   - Custom alerts
   - Slack/Email integration
   - Threshold-based
   - Anomaly detection

AVAILABLE TOOLS
---------------

### 1. list_issues

ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ

```javascript
{
  "tool": "sentry.list_issues",
  "arguments": {
    "project": "my-app",
    "status": "unresolved",
    "level": "error"
  }
}
```

### 2. get_issue_details

ÿ™ŸÅÿßÿµŸäŸÑ ŸÖÿ¥ŸÉŸÑÿ©

```javascript
{
  "tool": "sentry.get_issue_details",
  "arguments": {
    "issue_id": "123456"
  }
}
```

### 3. resolve_issue

ÿ≠ŸÑ ŸÖÿ¥ŸÉŸÑÿ©

```javascript
{
  "tool": "sentry.resolve_issue",
  "arguments": {
    "issue_id": "123456",
    "resolution": "fixed",
    "release": "v1.2.0"
  }
}
```

### 4. get_performance_metrics

ŸÖŸÇÿßŸäŸäÿ≥ ÿßŸÑÿ£ÿØÿßÿ°

```javascript
{
  "tool": "sentry.get_performance_metrics",
  "arguments": {
    "project": "my-app",
    "timeframe": "24h",
    "metrics": ["apdex", "throughput", "p95"]
  }
}
```

USE CASES
---------

### Automated Error Response

```typescript
{
  "workflow": [
    // 1. ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑÿ£ÿÆÿ∑ÿßÿ° ÿßŸÑÿ¨ÿØŸäÿØÿ©
    {
      "tool": "sentry.list_issues",
      "args": {"status": "unresolved", "age": "1h"}
    },
    // 2. ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿÆÿ∑ÿ£
    {
      "tool": "sentry.get_issue_details",
      "args": {"issue_id": "123"}
    },
    // 3. ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ÿ≠ŸÑŸàŸÑ ŸÖÿ¥ÿßÿ®Ÿáÿ©
    {
      "tool": "github.search_code",
      "args": {"query": "error_message"}
    },
    // 4. ÿ•ŸÜÿ¥ÿßÿ° issue ŸÅŸä GitHub
    {
      "tool": "github.create_issue",
      "args": {
        "title": "Sentry Error: ...",
        "body": "Stack trace...",
        "labels": ["bug", "sentry"]
      }
    },
    // 5. ÿ•ÿ∂ÿßŸÅÿ© ŸÖŸáŸÖÿ©
    {
      "tool": "taskqueue.add_task",
      "args": {
        "title": "Fix Sentry error",
        "priority": "high"
      }
    }
  ]
}
```

================================================================================
SECTION 9: INFRASTRUCTURE & CLOUD
================================================================================

### 9.1 CLOUDFLARE MCP SERVER

OVERVIEW
--------
ÿ™ŸÉÿßŸÖŸÑ ŸÖÿπ Cloudflare Workers Bindings ŸÑŸÑŸàÿµŸàŸÑ ÿ•ŸÑŸâ ÿÆÿØŸÖÿßÿ™ Cloudflare.

Repository: MCP Registry (configured in user environment)
Features: D1, R2, KV, Workers, Pages

KEY FEATURES
------------

1. **D1 Database**
   - SQL database
   - Serverless
   - Global replication

2. **R2 Storage**
   - Object storage
   - S3-compatible
   - No egress fees

3. **KV Store**
   - Key-value storage
   - Edge caching
   - Global distribution

4. **Workers**
   - Serverless functions
   - Edge computing
   - Low latency

AVAILABLE TOOLS
---------------

### 1. d1_query

ÿßÿ≥ÿ™ÿπŸÑÿßŸÖ D1

```javascript
{
  "tool": "cloudflare.d1_query",
  "arguments": {
    "database": "my-db",
    "query": "SELECT * FROM users WHERE active = 1"
  }
}
```

### 2. r2_upload

ÿ±ŸÅÿπ ÿ•ŸÑŸâ R2

```javascript
{
  "tool": "cloudflare.r2_upload",
  "arguments": {
    "bucket": "my-bucket",
    "key": "file.pdf",
    "content": "base64_content"
  }
}
```

### 3. kv_get

ŸÇÿ±ÿßÿ°ÿ© ŸÖŸÜ KV

```javascript
{
  "tool": "cloudflare.kv_get",
  "arguments": {
    "namespace": "my-kv",
    "key": "config"
  }
}
```

### 4. deploy_worker

ŸÜÿ¥ÿ± Worker

```javascript
{
  "tool": "cloudflare.deploy_worker",
  "arguments": {
    "name": "my-worker",
    "script": "worker_code.js"
  }
}
```

================================================================================
SECTION 10: ADVANCED MCP PATTERNS
================================================================================

SEQUENTIAL THINKING MCP
-----------------------

Ÿäÿ≥ÿßÿπÿØ ŸÅŸä ÿ™ŸÇÿ≥ŸäŸÖ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ÿßŸÑŸÖÿπŸÇÿØÿ© ÿ•ŸÑŸâ ÿÆÿ∑Ÿàÿßÿ™ ŸÇÿßÿ®ŸÑÿ© ŸÑŸÑÿ•ÿØÿßÿ±ÿ©.

```typescript
{
  "pattern": "sequential_thinking",
  "steps": [
    {
      "step": 1,
      "action": "understand_problem",
      "tool": "context7.get_documentation"
    },
    {
      "step": 2,
      "action": "analyze_code",
      "tool": "code-analysis.analyze_codebase"
    },
    {
      "step": 3,
      "action": "identify_issues",
      "tool": "ruff.lint_code"
    },
    {
      "step": 4,
      "action": "create_tasks",
      "tool": "taskqueue.add_task"
    },
    {
      "step": 5,
      "action": "execute_fixes",
      "tool": "playwright.browser_navigate"
    },
    {
      "step": 6,
      "action": "verify_solution",
      "tool": "playwright.browser_snapshot"
    }
  ]
}
```

COMPLETE PROJECT WORKFLOW
--------------------------

```typescript
{
  "project_workflow": {
    "name": "Complete Development Cycle",
    "phases": [
      {
        "phase": "Planning",
        "tools": [
          "taskqueue.create_project",
          "notion.create_database",
          "github.create_repository"
        ]
      },
      {
        "phase": "Development",
        "tools": [
          "context7.get_documentation",
          "code-analysis.analyze_codebase",
          "ruff.lint_code",
          "eslint.lint_directory"
        ]
      },
      {
        "phase": "Testing",
        "tools": [
          "playwright.browser_navigate",
          "playwright.browser_snapshot",
          "playwright.browser_network_requests"
        ]
      },
      {
        "phase": "Deployment",
        "tools": [
          "cloudflare.deploy_worker",
          "github.create_release"
        ]
      },
      {
        "phase": "Monitoring",
        "tools": [
          "sentry.list_issues",
          "sentry.get_performance_metrics"
        ]
      }
    ]
  }
}
```

BEST PRACTICES
--------------

### 1. Tool Selection

```typescript
{
  "guidelines": {
    "code_quality": ["ruff", "eslint", "code-analysis"],
    "task_management": ["taskqueue", "notion", "github"],
    "testing": ["playwright", "context7"],
    "monitoring": ["sentry", "cloudflare"],
    "documentation": ["context7", "github"]
  }
}
```

### 2. Error Handling

```typescript
{
  "error_handling": {
    "retry": {
      "max_attempts": 3,
      "backoff": "exponential"
    },
    "fallback": {
      "primary": "ruff",
      "secondary": "pylint",
      "tertiary": "flake8"
    },
    "logging": {
      "tool": "sentry",
      "level": "error"
    }
  }
}
```

### 3. Performance Optimization

```typescript
{
  "optimization": {
    "parallel_execution": [
      "ruff.lint_code",
      "eslint.lint_directory",
      "code-analysis.security_scan"
    ],
    "caching": {
      "tool": "cloudflare.kv",
      "ttl": 3600
    },
    "batch_operations": {
      "tool": "taskqueue.bulk_add_tasks",
      "batch_size": 100
    }
  }
}
```

================================================================================
RESOURCES
================================================================================

### Official MCP Resources
- MCP Protocol: https://modelcontextprotocol.io
- MCP Registry: https://github.com/punkpeye/awesome-mcp-servers
- MCP Servers: https://github.com/modelcontextprotocol/servers

### Code Analysis Tools
- Ruff: https://github.com/astral-sh/ruff
- ESLint: https://eslint.org
- Code Analysis MCP: https://github.com/saiprashanths/code-analysis-mcp

### Task Management
- Task Queue MCP: https://github.com/chriscarrollsmith/taskqueue-mcp
- Notion API: https://developers.notion.com
- Todoist API: https://developer.todoist.com

### Monitoring & Infrastructure
- Sentry: https://sentry.io
- Cloudflare: https://developers.cloudflare.com

### Community
- Reddit r/mcp: https://reddit.com/r/mcp
- Discord: https://discord.gg/mcp
- Glama.ai: https://glama.ai/mcp/servers

================================================================================
END OF MODULE 15: MCP INTEGRATION (EXTENDED)
================================================================================



================================================================================
END OF 15_MCP
================================================================================


================================================================================
MODULE: 16_MCP_INTEGRATION
================================================================================

================================================================================
MODULE 16: MCP INTEGRATION LAYER
================================================================================

OVERVIEW
--------
Ÿáÿ∞ÿß ÿßŸÑŸÖŸàÿØŸàŸÑ ŸäŸàŸÅÿ± ÿ∑ÿ®ŸÇÿ© ÿ∞ŸÉŸäÿ© ŸÑŸÑÿ™ŸÉÿßŸÖŸÑ ŸÖÿπ Model Context Protocol (MCP) serversÿå
ÿ™ŸÖŸÉŸëŸÜ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÖŸÜ ÿßÿ™ÿÆÿßÿ∞ ŸÇÿ±ÿßÿ±ÿßÿ™ ÿ∞ŸÉŸäÿ©ÿå ÿ™ŸÜÿ≥ŸäŸÇ ÿßŸÑÿ£ÿØŸàÿßÿ™ÿå Ÿàÿ£ÿ™ŸÖÿ™ÿ© ÿ≥Ÿäÿ± ÿßŸÑÿπŸÖŸÑ
ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑÿ≥ŸäÿßŸÇ ŸàÿßŸÑÿ£ŸáÿØÿßŸÅ.

CORE PHILOSOPHY
---------------
"ŸÖŸÜ ÿØŸÑŸäŸÑ ÿ≥ŸÑÿ®Ÿä ÿ•ŸÑŸâ ŸÖÿ≥ÿßÿπÿØ ÿ∞ŸÉŸä ŸÜÿ¥ÿ∑"

ÿ®ÿØŸÑÿßŸã ŸÖŸÜ ÿßŸÜÿ™ÿ∏ÿßÿ± ÿßŸÑŸÖÿ∑Ÿàÿ± ŸÑÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑÿ£ÿØŸàÿßÿ™ÿå ÿßŸÑÿ®ÿ±ŸàŸÖÿ®ÿ™:
- Ÿäÿ≠ŸÑŸÑ ÿßŸÑÿ≥ŸäÿßŸÇ ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã
- ŸäÿÆÿ™ÿßÿ± ÿßŸÑÿ£ÿØŸàÿßÿ™ ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ÿ©
- ŸäŸÜÿ≥ŸÇ ÿ≥Ÿäÿ± ÿßŸÑÿπŸÖŸÑ
- Ÿäÿ™ÿÆÿ∞ ÿßŸÑŸÇÿ±ÿßÿ±ÿßÿ™ ÿßŸÑÿ∞ŸÉŸäÿ©
- Ÿäÿ™ÿπŸÑŸÖ ŸàŸäÿ™ÿ≠ÿ≥ŸÜ

================================================================================
SECTION 1: MANDATORY PROJECT MAPPING
================================================================================

OVERVIEW
--------
**ÿ•ŸÑÿ≤ÿßŸÖŸä:** ŸÇÿ®ŸÑ ÿßŸÑÿ®ÿØÿ° ŸÅŸä ÿ£Ÿä ŸÖÿ¥ÿ±Ÿàÿπÿå Ÿäÿ¨ÿ® ÿπŸÑŸâ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ÿ±ÿ≥ŸÖ ÿÆÿ±Ÿäÿ∑ÿ© ÿ¥ÿßŸÖŸÑÿ©
ŸÑŸÑÿ®ÿ±ŸÜÿßŸÖÿ¨ ÿ™Ÿàÿ´ŸÇ ÿ¨ŸÖŸäÿπ ÿßŸÑÿ£ÿ±ŸÉÿßŸÜ ŸàÿßŸÑŸÖŸÉŸàŸÜÿßÿ™.

REQUIRED MAPPING COMPONENTS
---------------------------

### 1. PROJECT STRUCTURE MAP

**Format:** Mermaid Diagram

```mermaid
graph TB
    Root[Project Root]
    
    Root --> Frontend[Frontend]
    Root --> Backend[Backend]
    Root --> Database[Database]
    Root --> Config[Configuration]
    Root --> Tests[Tests]
    Root --> Docs[Documentation]
    
    Frontend --> Components[Components]
    Frontend --> Pages[Pages]
    Frontend --> Hooks[Hooks]
    Frontend --> Utils[Utils]
    Frontend --> Assets[Assets]
    
    Backend --> Routes[Routes]
    Backend --> Controllers[Controllers]
    Backend --> Models[Models]
    Backend --> Services[Services]
    Backend --> Middleware[Middleware]
    
    Database --> Schemas[Schemas]
    Database --> Migrations[Migrations]
    Database --> Seeds[Seeds]
    
    Config --> Env[Environment]
    Config --> Settings[Settings]
    Config --> Secrets[Secrets]
```

**Tool:** `mermaid.generate_diagram`

```bash
# ÿ•ŸÜÿ¥ÿßÿ° ÿÆÿ±Ÿäÿ∑ÿ© ÿßŸÑÿ®ŸÜŸäÿ©
manus-render-diagram project_structure.mmd project_structure.png
```

---

### 2. IMPORTS & EXPORTS MAP

**Purpose:** ÿ™Ÿàÿ´ŸäŸÇ ÿ¨ŸÖŸäÿπ ÿßŸÑÿßÿ≥ÿ™Ÿäÿ±ÿßÿØÿßÿ™ ŸàÿßŸÑÿ™ÿµÿØŸäÿ±ÿßÿ™ ŸÅŸä ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ

**Format:** JSON + Diagram

```json
{
  "project": "my-app",
  "modules": [
    {
      "file": "src/main.py",
      "imports": [
        {"module": "flask", "items": ["Flask", "request", "jsonify"]},
        {"module": "sqlalchemy", "items": ["create_engine", "Column", "Integer"]},
        {"module": "./models", "items": ["User", "Post"]},
        {"module": "./utils", "items": ["validate_email", "hash_password"]}
      ],
      "exports": [
        {"name": "app", "type": "Flask", "description": "Main Flask application"},
        {"name": "db", "type": "SQLAlchemy", "description": "Database instance"}
      ]
    },
    {
      "file": "src/models/user.py",
      "imports": [
        {"module": "sqlalchemy", "items": ["Column", "Integer", "String"]},
        {"module": "../database", "items": ["Base"]}
      ],
      "exports": [
        {"name": "User", "type": "class", "description": "User model"}
      ]
    }
  ],
  "dependency_graph": {
    "main.py": ["models/user.py", "utils/validation.py"],
    "models/user.py": ["database.py"],
    "utils/validation.py": []
  }
}
```

**Mermaid Diagram:**

```mermaid
graph LR
    main[main.py] --> models[models/user.py]
    main --> utils[utils/validation.py]
    models --> db[database.py]
    
    main -.import.-> flask[flask]
    main -.import.-> sqlalchemy[sqlalchemy]
    models -.import.-> sqlalchemy
```

**Tool:** `code-analysis.map_imports_exports`

```bash
# ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿßÿ≥ÿ™Ÿäÿ±ÿßÿØÿßÿ™ ŸàÿßŸÑÿ™ÿµÿØŸäÿ±ÿßÿ™
python3 << 'ANALYZE_IMPORTS'
import ast
import json
from pathlib import Path

def analyze_python_file(file_path):
    with open(file_path, 'r') as f:
        tree = ast.parse(f.read())
    
    imports = []
    exports = []
    
    for node in ast.walk(tree):
        # Analyze imports
        if isinstance(node, ast.Import):
            for alias in node.names:
                imports.append({
                    "module": alias.name,
                    "items": [alias.asname or alias.name]
                })
        elif isinstance(node, ast.ImportFrom):
            imports.append({
                "module": node.module,
                "items": [alias.name for alias in node.names]
            })
        
        # Analyze exports (functions, classes)
        elif isinstance(node, (ast.FunctionDef, ast.ClassDef)):
            if not node.name.startswith('_'):
                exports.append({
                    "name": node.name,
                    "type": "function" if isinstance(node, ast.FunctionDef) else "class"
                })
    
    return {"imports": imports, "exports": exports}

# Analyze all Python files
project_map = {}
for py_file in Path('src').rglob('*.py'):
    project_map[str(py_file)] = analyze_python_file(py_file)

print(json.dumps(project_map, indent=2))
ANALYZE_IMPORTS
```

---

### 3. CLASS DEFINITIONS MAP

**Purpose:** ÿ™Ÿàÿ´ŸäŸÇ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÄ Classes ŸÅŸä ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ

**Format:** UML Class Diagram

```mermaid
classDiagram
    class User {
        +int id
        +string username
        +string email
        +string password_hash
        +datetime created_at
        +validate_email() bool
        +check_password(password) bool
        +to_dict() dict
    }
    
    class Post {
        +int id
        +string title
        +string content
        +int user_id
        +datetime created_at
        +User author
        +get_author() User
        +to_dict() dict
    }
    
    class Comment {
        +int id
        +string content
        +int post_id
        +int user_id
        +datetime created_at
        +Post post
        +User author
        +to_dict() dict
    }
    
    User "1" --> "*" Post : writes
    User "1" --> "*" Comment : writes
    Post "1" --> "*" Comment : has
```

**Tool:** `code-analysis.generate_class_diagram`

```python
# ÿ™ÿ≠ŸÑŸäŸÑ Classes
import ast
import inspect

def analyze_class(cls):
    return {
        "name": cls.__name__,
        "bases": [base.__name__ for base in cls.__bases__],
        "attributes": [
            {
                "name": name,
                "type": type(value).__name__
            }
            for name, value in vars(cls).items()
            if not name.startswith('_')
        ],
        "methods": [
            {
                "name": name,
                "signature": str(inspect.signature(method)),
                "docstring": method.__doc__
            }
            for name, method in inspect.getmembers(cls, predicate=inspect.isfunction)
            if not name.startswith('_')
        ]
    }

# Example usage
from models import User, Post, Comment

classes_map = {
    "User": analyze_class(User),
    "Post": analyze_class(Post),
    "Comment": analyze_class(Comment)
}
```

---

### 4. LIBRARIES & DEPENDENCIES MAP

**Purpose:** ÿ™Ÿàÿ´ŸäŸÇ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖŸÉÿ™ÿ®ÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖÿ©

**Format:** JSON + Dependency Tree

```json
{
  "project": "my-app",
  "dependencies": {
    "production": [
      {
        "name": "flask",
        "version": "3.0.0",
        "purpose": "Web framework",
        "used_in": ["main.py", "routes/*.py"],
        "critical": true
      },
      {
        "name": "sqlalchemy",
        "version": "2.0.23",
        "purpose": "ORM for database",
        "used_in": ["models/*.py", "database.py"],
        "critical": true
      },
      {
        "name": "pydantic",
        "version": "2.5.0",
        "purpose": "Data validation",
        "used_in": ["schemas/*.py"],
        "critical": false
      }
    ],
    "development": [
      {
        "name": "pytest",
        "version": "7.4.3",
        "purpose": "Testing framework",
        "used_in": ["tests/*.py"],
        "critical": false
      },
      {
        "name": "ruff",
        "version": "0.1.6",
        "purpose": "Linting and formatting",
        "used_in": ["CI/CD"],
        "critical": false
      }
    ]
  },
  "dependency_tree": {
    "flask": ["werkzeug", "jinja2", "click"],
    "sqlalchemy": ["greenlet", "typing-extensions"],
    "pydantic": ["typing-extensions", "annotated-types"]
  },
  "security_vulnerabilities": [],
  "outdated_packages": [
    {
      "name": "flask",
      "current": "3.0.0",
      "latest": "3.0.1",
      "severity": "low"
    }
  ]
}
```

**Mermaid Diagram:**

```mermaid
graph TD
    App[My App]
    
    App --> Flask[flask 3.0.0]
    App --> SQLAlchemy[sqlalchemy 2.0.23]
    App --> Pydantic[pydantic 2.5.0]
    
    Flask --> Werkzeug[werkzeug]
    Flask --> Jinja2[jinja2]
    Flask --> Click[click]
    
    SQLAlchemy --> Greenlet[greenlet]
    SQLAlchemy --> TypingExt1[typing-extensions]
    
    Pydantic --> TypingExt2[typing-extensions]
    Pydantic --> AnnotatedTypes[annotated-types]
```

**Tool:** `code-analysis.analyze_dependencies`

```bash
# Python dependencies
pip list --format=json > dependencies.json
pip-audit --format=json > security_audit.json

# JavaScript dependencies
npm list --json > dependencies.json
npm audit --json > security_audit.json

# Analyze with MCP
{
  "tool": "code-analysis.analyze_dependencies",
  "arguments": {
    "project_dir": ".",
    "include_dev": true,
    "check_security": true,
    "check_updates": true
  }
}
```

---

### 5. API ENDPOINTS MAP

**Purpose:** ÿ™Ÿàÿ´ŸäŸÇ ÿ¨ŸÖŸäÿπ API endpoints

**Format:** OpenAPI/Swagger + Diagram

```yaml
openapi: 3.0.0
info:
  title: My App API
  version: 1.0.0

paths:
  /api/users:
    get:
      summary: List all users
      parameters:
        - name: page
          in: query
          schema:
            type: integer
      responses:
        '200':
          description: Success
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/User'
    
    post:
      summary: Create new user
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UserCreate'
      responses:
        '201':
          description: Created

  /api/users/{id}:
    get:
      summary: Get user by ID
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: integer
      responses:
        '200':
          description: Success
        '404':
          description: Not found

components:
  schemas:
    User:
      type: object
      properties:
        id:
          type: integer
        username:
          type: string
        email:
          type: string
```

**Mermaid Diagram:**

```mermaid
graph LR
    Client[Client]
    
    Client -->|GET| ListUsers[/api/users]
    Client -->|POST| CreateUser[/api/users]
    Client -->|GET| GetUser[/api/users/:id]
    Client -->|PUT| UpdateUser[/api/users/:id]
    Client -->|DELETE| DeleteUser[/api/users/:id]
    
    ListUsers --> DB[(Database)]
    CreateUser --> DB
    GetUser --> DB
    UpdateUser --> DB
    DeleteUser --> DB
```

**Tool:** `code-analysis.generate_api_docs`

```python
# ÿ™ÿ≠ŸÑŸäŸÑ API endpoints (Flask example)
from flask import Flask
import json

def analyze_flask_routes(app: Flask):
    routes = []
    for rule in app.url_map.iter_rules():
        routes.append({
            "endpoint": rule.endpoint,
            "methods": list(rule.methods - {'HEAD', 'OPTIONS'}),
            "path": str(rule),
            "parameters": [
                {
                    "name": arg,
                    "type": "path",
                    "required": True
                }
                for arg in rule.arguments
            ]
        })
    return routes

# Usage
from main import app
api_map = analyze_flask_routes(app)
print(json.dumps(api_map, indent=2))
```

---

### 6. DATABASE SCHEMA MAP

**Purpose:** ÿ™Ÿàÿ´ŸäŸÇ ÿ®ŸÜŸäÿ© ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™

**Format:** ERD (Entity Relationship Diagram)

```mermaid
erDiagram
    USER ||--o{ POST : writes
    USER ||--o{ COMMENT : writes
    POST ||--o{ COMMENT : has
    POST }o--|| CATEGORY : belongs_to
    
    USER {
        int id PK
        string username UK
        string email UK
        string password_hash
        datetime created_at
        datetime updated_at
    }
    
    POST {
        int id PK
        string title
        text content
        int user_id FK
        int category_id FK
        datetime created_at
        datetime updated_at
    }
    
    COMMENT {
        int id PK
        text content
        int post_id FK
        int user_id FK
        datetime created_at
    }
    
    CATEGORY {
        int id PK
        string name UK
        string description
    }
```

**Tool:** `code-analysis.generate_erd`

```python
# ÿ™ÿ≠ŸÑŸäŸÑ Database schema (SQLAlchemy example)
from sqlalchemy import inspect
from sqlalchemy.orm import Session

def analyze_database_schema(engine):
    inspector = inspect(engine)
    schema = {}
    
    for table_name in inspector.get_table_names():
        columns = []
        for column in inspector.get_columns(table_name):
            columns.append({
                "name": column['name'],
                "type": str(column['type']),
                "nullable": column['nullable'],
                "primary_key": column.get('primary_key', False)
            })
        
        foreign_keys = []
        for fk in inspector.get_foreign_keys(table_name):
            foreign_keys.append({
                "column": fk['constrained_columns'][0],
                "references": f"{fk['referred_table']}.{fk['referred_columns'][0]}"
            })
        
        schema[table_name] = {
            "columns": columns,
            "foreign_keys": foreign_keys
        }
    
    return schema

# Usage
from database import engine
db_schema = analyze_database_schema(engine)
```

---

### 7. CONFIGURATION MAP

**Purpose:** ÿ™Ÿàÿ´ŸäŸÇ ÿ¨ŸÖŸäÿπ ÿßŸÑÿ•ÿπÿØÿßÿØÿßÿ™ ŸàÿßŸÑŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™

**Format:** JSON + Diagram

```json
{
  "configuration": {
    "environment_variables": [
      {
        "name": "DATABASE_URL",
        "required": true,
        "default": null,
        "description": "PostgreSQL connection string",
        "example": "postgresql://user:pass@localhost/db"
      },
      {
        "name": "SECRET_KEY",
        "required": true,
        "default": null,
        "description": "Flask secret key for sessions",
        "example": "your-secret-key-here"
      },
      {
        "name": "DEBUG",
        "required": false,
        "default": "False",
        "description": "Enable debug mode",
        "example": "True"
      }
    ],
    "config_files": [
      {
        "path": "config/settings.py",
        "format": "python",
        "variables": ["DATABASE_URL", "SECRET_KEY", "DEBUG"]
      },
      {
        "path": ".env.example",
        "format": "env",
        "variables": ["DATABASE_URL", "SECRET_KEY"]
      }
    ],
    "secrets": [
      {
        "name": "API_KEY",
        "storage": "environment",
        "required": true
      },
      {
        "name": "JWT_SECRET",
        "storage": "secrets_manager",
        "required": true
      }
    ]
  }
}
```

---

## MANDATORY DOCUMENTATION WORKFLOW

### Step 1: Initial Project Scan

```typescript
{
  "workflow": "project_mapping",
  "steps": [
    {
      "step": 1,
      "action": "Scan project structure",
      "tool": "code-analysis.scan_directory",
      "output": "project_structure.json"
    },
    {
      "step": 2,
      "action": "Analyze imports/exports",
      "tool": "code-analysis.map_imports_exports",
      "output": "imports_exports.json"
    },
    {
      "step": 3,
      "action": "Extract class definitions",
      "tool": "code-analysis.extract_classes",
      "output": "classes.json"
    },
    {
      "step": 4,
      "action": "Analyze dependencies",
      "tool": "code-analysis.analyze_dependencies",
      "output": "dependencies.json"
    },
    {
      "step": 5,
      "action": "Map API endpoints",
      "tool": "code-analysis.generate_api_docs",
      "output": "api_docs.json"
    },
    {
      "step": 6,
      "action": "Generate database ERD",
      "tool": "code-analysis.generate_erd",
      "output": "database_erd.mmd"
    },
    {
      "step": 7,
      "action": "Document configuration",
      "tool": "code-analysis.extract_config",
      "output": "configuration.json"
    }
  ]
}
```

### Step 2: Generate Visual Diagrams

```bash
# Generate all diagrams
manus-render-diagram project_structure.mmd project_structure.png
manus-render-diagram imports_exports.mmd imports_exports.png
manus-render-diagram class_diagram.mmd class_diagram.png
manus-render-diagram api_endpoints.mmd api_endpoints.png
manus-render-diagram database_erd.mmd database_erd.png
```

### Step 3: Create Documentation

```markdown
# Project Documentation

## 1. Project Structure
![Project Structure](project_structure.png)

## 2. Imports & Exports
![Imports & Exports](imports_exports.png)

## 3. Class Diagram
![Class Diagram](class_diagram.png)

## 4. API Endpoints
![API Endpoints](api_endpoints.png)

## 5. Database Schema
![Database ERD](database_erd.png)

## 6. Dependencies
[See dependencies.json]

## 7. Configuration
[See configuration.json]
```

### Step 4: Store in Project

```bash
# Create docs directory
mkdir -p docs/architecture

# Move all documentation
mv *.png docs/architecture/
mv *.json docs/architecture/
mv *.mmd docs/architecture/

# Create README
cat > docs/architecture/README.md << 'EOF'
# Architecture Documentation

This directory contains comprehensive project documentation:

- **project_structure.png** - Project directory structure
- **imports_exports.png** - Module dependencies
- **class_diagram.png** - Class relationships
- **api_endpoints.png** - API routes
- **database_erd.png** - Database schema
- **dependencies.json** - Library dependencies
- **configuration.json** - Configuration variables

Generated: $(date)
EOF
```

---

## ENFORCEMENT RULES

### Rule 1: Before Starting Any Task

```typescript
{
  "rule": "mandatory_project_mapping",
  "trigger": "new_project || first_interaction",
  "actions": [
    "scan_project_structure",
    "analyze_imports_exports",
    "extract_classes",
    "analyze_dependencies",
    "map_api_endpoints",
    "generate_database_erd",
    "document_configuration"
  ],
  "output": "docs/architecture/",
  "required": true,
  "skip_allowed": false
}
```

### Rule 2: Update Documentation on Changes

```typescript
{
  "rule": "update_documentation",
  "trigger": "code_change || new_file || dependency_change",
  "actions": [
    "update_affected_diagrams",
    "regenerate_documentation",
    "commit_to_git"
  ],
  "auto": true
}
```

### Rule 3: Validate Documentation

```typescript
{
  "rule": "validate_documentation",
  "trigger": "before_commit || before_deploy",
  "checks": [
    "all_diagrams_exist",
    "all_classes_documented",
    "all_apis_documented",
    "all_dependencies_listed",
    "no_missing_imports"
  ],
  "fail_on_error": true
}
```

================================================================================
SECTION 2: CONTEXT ANALYZER
================================================================================

OVERVIEW
--------
Context Analyzer Ÿäÿ≠ŸÑŸÑ ÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã ŸàŸäÿ≠ÿØÿØ ÿßŸÑÿ£ÿØŸàÿßÿ™ ŸàÿßŸÑÿ•ÿ¨ÿ±ÿßÿ°ÿßÿ™ ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ÿ©.

CONTEXT LAYERS
--------------

### 1. Project Context

```typescript
{
  "project_context": {
    "type": "web_app | mobile_app | api | library | cli_tool",
    "stack": {
      "frontend": ["react", "nextjs", "tailwind"],
      "backend": ["flask", "fastapi", "express"],
      "database": ["postgresql", "mongodb", "redis"],
      "infrastructure": ["docker", "kubernetes", "cloudflare"]
    },
    "phase": "planning | development | testing | deployment | maintenance",
    "size": "small | medium | large | enterprise",
    "team_size": 5,
    "methodology": "agile | waterfall | kanban"
  }
}
```

**Tool:** `context-analyzer.analyze_project`

```python
# ÿ™ÿ≠ŸÑŸäŸÑ ÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ
def analyze_project_context(project_dir):
    context = {
        "type": detect_project_type(project_dir),
        "stack": detect_tech_stack(project_dir),
        "phase": determine_current_phase(project_dir),
        "size": estimate_project_size(project_dir)
    }
    return context

def detect_project_type(project_dir):
    # Check for indicators
    if Path(project_dir / "package.json").exists():
        pkg = json.load(open(project_dir / "package.json"))
        if "react" in pkg.get("dependencies", {}):
            return "web_app"
    elif Path(project_dir / "requirements.txt").exists():
        reqs = open(project_dir / "requirements.txt").read()
        if "flask" in reqs or "fastapi" in reqs:
            return "api"
    return "unknown"
```

---

### 2. Code Context

```typescript
{
  "code_context": {
    "languages": ["python", "javascript", "typescript"],
    "frameworks": ["flask", "react", "nextjs"],
    "quality_metrics": {
      "test_coverage": 85,
      "code_complexity": "medium",
      "technical_debt": "low",
      "security_score": 92
    },
    "recent_changes": [
      {
        "file": "src/main.py",
        "type": "modification",
        "lines_changed": 45,
        "timestamp": "2025-01-03T10:30:00Z"
      }
    ],
    "issues": [
      {
        "type": "code_smell",
        "severity": "medium",
        "file": "src/legacy.py",
        "line": 123
      }
    ]
  }
}
```

**Tool:** `context-analyzer.analyze_code`

```bash
# ÿ™ÿ≠ŸÑŸäŸÑ ÿ¨ŸàÿØÿ© ÿßŸÑŸÉŸàÿØ
{
  "tool": "code-analysis.analyze_codebase",
  "arguments": {
    "directory": "src/",
    "metrics": ["complexity", "coverage", "debt", "security"]
  }
}
```

---

### 3. Task Context

```typescript
{
  "task_context": {
    "current_task": {
      "id": "TASK-123",
      "title": "Fix login bug",
      "type": "bug_fix",
      "priority": "high",
      "assigned_to": "developer@example.com",
      "status": "in_progress"
    },
    "related_tasks": [
      {
        "id": "TASK-120",
        "title": "Improve authentication",
        "relation": "parent"
      }
    ],
    "blockers": [],
    "dependencies": ["TASK-115"]
  }
}
```

**Tool:** `taskqueue.get_context`

---

### 4. Environment Context

```typescript
{
  "environment_context": {
    "current_env": "development | staging | production",
    "available_tools": [
      "ruff", "eslint", "playwright", "sentry", "cloudflare"
    ],
    "mcp_servers": [
      {"name": "playwright", "status": "active"},
      {"name": "github", "status": "active"},
      {"name": "sentry", "status": "active"}
    ],
    "resources": {
      "cpu": "available",
      "memory": "available",
      "disk": "available"
    }
  }
}
```

---

## CONTEXT-BASED DECISION MAKING

### Decision Rules

```typescript
{
  "decision_rules": [
    {
      "condition": {
        "phase": "development",
        "code_quality": {"$lt": 80}
      },
      "action": "run_linters_and_fix",
      "tools": ["ruff", "eslint"],
      "priority": "high",
      "auto_execute": true
    },
    {
      "condition": {
        "task_type": "bug_fix",
        "error_rate": {"$gt": 5}
      },
      "action": "investigate_errors",
      "tools": ["sentry", "code-analysis"],
      "priority": "critical",
      "auto_execute": true
    },
    {
      "condition": {
        "phase": "testing",
        "test_coverage": {"$lt": 80}
      },
      "action": "increase_test_coverage",
      "tools": ["playwright", "pytest"],
      "priority": "medium",
      "auto_execute": false
    },
    {
      "condition": {
        "phase": "deployment",
        "environment": "production"
      },
      "action": "deploy_and_monitor",
      "tools": ["cloudflare", "sentry", "github"],
      "priority": "high",
      "auto_execute": false
    }
  ]
}
```

### Implementation

```python
# Context-based decision engine
def make_decision(context):
    for rule in decision_rules:
        if evaluate_condition(rule['condition'], context):
            return {
                "action": rule['action'],
                "tools": rule['tools'],
                "priority": rule['priority'],
                "auto_execute": rule['auto_execute']
            }
    return None

def evaluate_condition(condition, context):
    for key, value in condition.items():
        if key not in context:
            return False
        
        if isinstance(value, dict):
            # Handle operators like $lt, $gt
            for op, threshold in value.items():
                if op == "$lt" and context[key] >= threshold:
                    return False
                elif op == "$gt" and context[key] <= threshold:
                    return False
        elif context[key] != value:
            return False
    
    return True
```

================================================================================
SECTION 3: TOOL ORCHESTRATOR
================================================================================

OVERVIEW
--------
Tool Orchestrator ŸäŸÜÿ≥ŸÇ ÿπÿØÿ© MCP servers ŸÑÿ™ŸÜŸÅŸäÿ∞ ŸÖŸáÿßŸÖ ŸÖÿπŸÇÿØÿ©.

ORCHESTRATION PATTERNS
----------------------

### 1. Sequential Execution

```typescript
{
  "pattern": "sequential",
  "workflow": [
    {
      "step": 1,
      "tool": "context7.get_documentation",
      "input": {"library": "flask"},
      "output_var": "flask_docs"
    },
    {
      "step": 2,
      "tool": "code-analysis.analyze_codebase",
      "input": {"directory": "src/"},
      "output_var": "analysis_results"
    },
    {
      "step": 3,
      "tool": "ruff.lint_code",
      "input": {"file": "src/main.py", "fix": true},
      "output_var": "lint_results"
    },
    {
      "step": 4,
      "tool": "github.create_issue",
      "input": {
        "title": "Code quality improvements",
        "body": "{{analysis_results}} + {{lint_results}}"
      },
      "output_var": "issue_url"
    }
  ]
}
```

---

### 2. Parallel Execution

```typescript
{
  "pattern": "parallel",
  "workflow": [
    {
      "parallel_tasks": [
        {
          "tool": "ruff.check_project",
          "input": {"directory": "src/"},
          "output_var": "python_lint"
        },
        {
          "tool": "eslint.lint_directory",
          "input": {"directory": "frontend/"},
          "output_var": "js_lint"
        },
        {
          "tool": "code-analysis.security_scan",
          "input": {"directory": "."},
          "output_var": "security_scan"
        }
      ]
    },
    {
      "step": 2,
      "tool": "aggregate_results",
      "input": {
        "results": ["{{python_lint}}", "{{js_lint}}", "{{security_scan}}"]
      },
      "output_var": "combined_report"
    }
  ]
}
```

---

### 3. Conditional Execution

```typescript
{
  "pattern": "conditional",
  "workflow": [
    {
      "step": 1,
      "tool": "sentry.list_issues",
      "input": {"status": "unresolved"},
      "output_var": "issues"
    },
    {
      "step": 2,
      "condition": "{{issues.length}} > 0",
      "then": [
        {
          "tool": "sentry.get_issue_details",
          "input": {"issue_id": "{{issues[0].id}}"},
          "output_var": "issue_details"
        },
        {
          "tool": "taskqueue.add_task",
          "input": {
            "title": "Fix Sentry issue {{issues[0].id}}",
            "priority": "high"
          }
        }
      ],
      "else": [
        {
          "tool": "notify",
          "input": {"message": "No issues found!"}
        }
      ]
    }
  ]
}
```

---

### 4. Loop Execution

```typescript
{
  "pattern": "loop",
  "workflow": [
    {
      "step": 1,
      "tool": "github.list_pull_requests",
      "input": {"state": "open"},
      "output_var": "pull_requests"
    },
    {
      "step": 2,
      "loop": "{{pull_requests}}",
      "loop_var": "pr",
      "actions": [
        {
          "tool": "github.get_pull_request_diff",
          "input": {"pull_number": "{{pr.number}}"},
          "output_var": "diff"
        },
        {
          "tool": "ruff.lint_code",
          "input": {"content": "{{diff}}"},
          "output_var": "lint_results"
        },
        {
          "tool": "github.add_issue_comment",
          "input": {
            "issue_number": "{{pr.number}}",
            "body": "Lint results: {{lint_results}}"
          }
        }
      ]
    }
  ]
}
```

---

## ERROR HANDLING & RECOVERY

### Retry Strategy

```typescript
{
  "error_handling": {
    "retry": {
      "max_attempts": 3,
      "backoff": "exponential",
      "backoff_factor": 2,
      "retry_on": ["timeout", "rate_limit", "server_error"]
    },
    "fallback": {
      "primary_tool": "ruff",
      "fallback_tools": ["pylint", "flake8"],
      "fallback_on": ["tool_unavailable", "tool_error"]
    },
    "recovery": {
      "on_error": [
        {
          "action": "log_error",
          "tool": "sentry.capture_exception"
        },
        {
          "action": "create_task",
          "tool": "taskqueue.add_task",
          "input": {
            "title": "Tool execution failed",
            "priority": "high"
          }
        },
        {
          "action": "notify_team",
          "tool": "slack.send_message"
        }
      ]
    }
  }
}
```

### Implementation

```python
# Error handling implementation
import time
from typing import Callable, Any

def execute_with_retry(
    func: Callable,
    max_attempts: int = 3,
    backoff_factor: int = 2,
    retry_on: list = None
):
    retry_on = retry_on or ["timeout", "rate_limit"]
    
    for attempt in range(max_attempts):
        try:
            return func()
        except Exception as e:
            error_type = type(e).__name__.lower()
            
            if error_type not in retry_on:
                raise
            
            if attempt < max_attempts - 1:
                wait_time = backoff_factor ** attempt
                print(f"Retry {attempt + 1}/{max_attempts} after {wait_time}s...")
                time.sleep(wait_time)
            else:
                raise

def execute_with_fallback(
    primary_func: Callable,
    fallback_funcs: list[Callable]
):
    try:
        return primary_func()
    except Exception as e:
        print(f"Primary tool failed: {e}")
        
        for i, fallback_func in enumerate(fallback_funcs):
            try:
                print(f"Trying fallback {i + 1}...")
                return fallback_func()
            except Exception as fallback_error:
                print(f"Fallback {i + 1} failed: {fallback_error}")
                continue
        
        raise Exception("All tools failed")
```

================================================================================
SECTION 4: INTELLIGENT WORKFLOWS
================================================================================

OVERVIEW
--------
ŸÖÿ¨ŸÖŸàÿπÿ© ŸÖŸÜ ÿ≥Ÿäÿ± ÿßŸÑÿπŸÖŸÑ ÿßŸÑÿ∞ŸÉŸäÿ© ÿßŸÑŸÖÿ≠ÿØÿØÿ© ŸÖÿ≥ÿ®ŸÇÿßŸã ŸÑŸÑŸÖŸáÿßŸÖ ÿßŸÑÿ¥ÿßÿ¶ÿπÿ©.

WORKFLOW TEMPLATES
------------------

### 1. Complete Bug Fix Workflow

```typescript
{
  "workflow": "bug_fix_complete",
  "trigger": "error_detected || issue_reported",
  "mandatory_mapping": true,
  "steps": [
    {
      "phase": "Documentation",
      "mandatory": true,
      "actions": [
        {
          "action": "Generate project map",
          "tools": ["code-analysis.scan_directory"],
          "output": "docs/architecture/"
        },
        {
          "action": "Map affected components",
          "tools": ["code-analysis.map_imports_exports"],
          "output": "affected_components.json"
        }
      ]
    },
    {
      "phase": "Detection",
      "actions": [
        {
          "tool": "sentry.get_issue_details",
          "input": {"issue_id": "{{issue_id}}"},
          "output_var": "error_details"
        },
        {
          "tool": "code-analysis.find_root_cause",
          "input": {"error": "{{error_details}}"},
          "output_var": "root_cause"
        }
      ]
    },
    {
      "phase": "Analysis",
      "actions": [
        {
          "tool": "code-analysis.analyze_codebase",
          "input": {"focus": "{{root_cause.file}}"},
          "output_var": "code_analysis"
        },
        {
          "tool": "github.search_similar_issues",
          "input": {"query": "{{error_details.message}}"},
          "output_var": "similar_issues"
        }
      ]
    },
    {
      "phase": "Planning",
      "actions": [
        {
          "tool": "sequential-thinking.decompose_problem",
          "input": {"problem": "{{root_cause}}"},
          "output_var": "solution_steps"
        },
        {
          "tool": "taskqueue.add_task",
          "input": {
            "title": "Fix: {{error_details.title}}",
            "description": "{{solution_steps}}",
            "priority": "high"
          },
          "output_var": "task_id"
        },
        {
          "tool": "github.create_issue",
          "input": {
            "title": "Bug: {{error_details.title}}",
            "body": "Root cause: {{root_cause}}\nSolution: {{solution_steps}}",
            "labels": ["bug", "high-priority"]
          },
          "output_var": "github_issue"
        }
      ]
    },
    {
      "phase": "Implementation",
      "manual": true,
      "guidance": [
        "Review solution steps",
        "Implement fix",
        "Add tests",
        "Run linters"
      ],
      "auto_actions": [
        {
          "tool": "ruff.lint_code",
          "input": {"file": "{{root_cause.file}}", "fix": true}
        },
        {
          "tool": "playwright.test",
          "input": {"test_file": "tests/test_{{root_cause.module}}.py"}
        }
      ]
    },
    {
      "phase": "Review",
      "actions": [
        {
          "tool": "code-analysis.review_changes",
          "input": {"files": "{{changed_files}}"},
          "output_var": "review_results"
        },
        {
          "tool": "github.create_pull_request",
          "input": {
            "title": "Fix: {{error_details.title}}",
            "body": "Fixes #{{github_issue.number}}",
            "labels": ["bug-fix"]
          },
          "output_var": "pull_request"
        }
      ]
    },
    {
      "phase": "Deployment",
      "manual": true,
      "actions": [
        {
          "tool": "cloudflare.deploy",
          "input": {"environment": "staging"}
        },
        {
          "tool": "playwright.test_all",
          "input": {"environment": "staging"}
        },
        {
          "condition": "{{tests_passed}}",
          "tool": "cloudflare.deploy",
          "input": {"environment": "production"}
        }
      ]
    },
    {
      "phase": "Monitoring",
      "actions": [
        {
          "tool": "sentry.monitor_issue",
          "input": {"issue_id": "{{issue_id}}"},
          "duration": "24h"
        },
        {
          "tool": "sentry.resolve_issue",
          "input": {"issue_id": "{{issue_id}}"},
          "condition": "{{no_new_errors}}"
        },
        {
          "tool": "taskqueue.complete_task",
          "input": {"task_id": "{{task_id}}"}
        },
        {
          "tool": "github.close_issue",
          "input": {"issue_number": "{{github_issue.number}}"}
        }
      ]
    },
    {
      "phase": "Documentation Update",
      "mandatory": true,
      "actions": [
        {
          "action": "Update architecture docs",
          "tools": ["code-analysis.regenerate_diagrams"],
          "output": "docs/architecture/"
        },
        {
          "action": "Document fix",
          "tools": ["notion.create_page"],
          "input": {
            "title": "Bug Fix: {{error_details.title}}",
            "content": "{{solution_steps}}"
          }
        }
      ]
    }
  ]
}
```

---

### 2. Feature Development Workflow

```typescript
{
  "workflow": "feature_development",
  "trigger": "feature_request",
  "mandatory_mapping": true,
  "steps": [
    {
      "phase": "Initial Documentation",
      "mandatory": true,
      "actions": [
        {
          "action": "Generate complete project map",
          "tools": [
            "code-analysis.scan_directory",
            "code-analysis.map_imports_exports",
            "code-analysis.extract_classes",
            "code-analysis.analyze_dependencies",
            "code-analysis.generate_api_docs",
            "code-analysis.generate_erd"
          ],
          "output": "docs/architecture/"
        }
      ]
    },
    {
      "phase": "Research",
      "actions": [
        {
          "tool": "context7.search",
          "input": {"query": "{{feature_description}}"},
          "output_var": "research_results"
        },
        {
          "tool": "github.search_code",
          "input": {"query": "{{feature_keywords}}"},
          "output_var": "similar_implementations"
        }
      ]
    },
    {
      "phase": "Design",
      "actions": [
        {
          "tool": "sequential-thinking.design_solution",
          "input": {"requirements": "{{feature_description}}"},
          "output_var": "design_doc"
        },
        {
          "tool": "notion.create_page",
          "input": {
            "title": "Feature Design: {{feature_name}}",
            "content": "{{design_doc}}"
          }
        },
        {
          "action": "Generate architecture diagrams",
          "tools": ["mermaid.generate_diagram"],
          "input": {"design": "{{design_doc}}"},
          "output": "docs/features/{{feature_name}}/"
        }
      ]
    },
    {
      "phase": "Planning",
      "actions": [
        {
          "tool": "sequential-thinking.decompose",
          "input": {"feature": "{{design_doc}}"},
          "output_var": "task_breakdown"
        },
        {
          "tool": "taskqueue.bulk_add_tasks",
          "input": {"tasks": "{{task_breakdown}}"},
          "output_var": "task_ids"
        },
        {
          "tool": "github.create_milestone",
          "input": {
            "title": "Feature: {{feature_name}}",
            "description": "{{design_doc}}"
          }
        }
      ]
    },
    {
      "phase": "Implementation",
      "manual": true,
      "guidance": [
        "Follow design document",
        "Write tests first (TDD)",
        "Implement feature",
        "Run linters continuously"
      ],
      "auto_actions": [
        {
          "trigger": "on_file_save",
          "tool": "ruff.lint_code",
          "input": {"fix": true}
        },
        {
          "trigger": "on_commit",
          "tool": "playwright.test_affected",
          "input": {"changed_files": "{{git_diff}}"}
        }
      ]
    },
    {
      "phase": "Testing",
      "actions": [
        {
          "tool": "playwright.test_all",
          "input": {"suite": "feature_{{feature_name}}"}
        },
        {
          "tool": "code-analysis.check_coverage",
          "input": {"target": 80}
        },
        {
          "tool": "sentry.check_errors",
          "input": {"environment": "staging"}
        }
      ]
    },
    {
      "phase": "Review",
      "actions": [
        {
          "tool": "code-analysis.review_changes",
          "input": {"feature": "{{feature_name}}"}
        },
        {
          "tool": "github.create_pull_request",
          "input": {
            "title": "Feature: {{feature_name}}",
            "body": "Implements {{design_doc}}",
            "labels": ["feature", "needs-review"]
          }
        }
      ]
    },
    {
      "phase": "Deployment",
      "actions": [
        {
          "tool": "cloudflare.deploy",
          "input": {"environment": "production"}
        },
        {
          "tool": "github.create_release",
          "input": {
            "tag": "v{{version}}",
            "name": "Release {{version}} - {{feature_name}}"
          }
        }
      ]
    },
    {
      "phase": "Monitoring",
      "actions": [
        {
          "tool": "sentry.monitor",
          "input": {"feature": "{{feature_name}}"},
          "duration": "7d"
        },
        {
          "tool": "cloudflare.get_metrics",
          "input": {"feature": "{{feature_name}}"}
        }
      ]
    },
    {
      "phase": "Final Documentation",
      "mandatory": true,
      "actions": [
        {
          "action": "Update all architecture docs",
          "tools": [
            "code-analysis.regenerate_all_diagrams",
            "code-analysis.update_api_docs",
            "code-analysis.update_erd"
          ],
          "output": "docs/architecture/"
        },
        {
          "action": "Create feature documentation",
          "tools": ["notion.create_page"],
          "input": {
            "title": "Feature: {{feature_name}}",
            "content": "Complete documentation with diagrams"
          }
        },
        {
          "action": "Update README",
          "tools": ["github.update_file"],
          "input": {
            "file": "README.md",
            "content": "Add {{feature_name}} to features list"
          }
        }
      ]
    }
  ]
}
```

---

### 3. Code Quality Workflow

```typescript
{
  "workflow": "code_quality_check",
  "trigger": "scheduled || on_commit || manual",
  "mandatory_mapping": true,
  "steps": [
    {
      "phase": "Documentation Check",
      "mandatory": true,
      "actions": [
        {
          "action": "Verify architecture docs exist",
          "check": [
            "docs/architecture/project_structure.png",
            "docs/architecture/imports_exports.json",
            "docs/architecture/classes.json",
            "docs/architecture/dependencies.json",
            "docs/architecture/api_docs.json",
            "docs/architecture/database_erd.mmd"
          ]
        },
        {
          "action": "Regenerate if missing",
          "condition": "{{any_missing}}",
          "tools": ["code-analysis.generate_all_docs"]
        }
      ]
    },
    {
      "phase": "Linting",
      "parallel": true,
      "actions": [
        {
          "tool": "ruff.check_project",
          "input": {"directory": "src/", "fix": true},
          "output_var": "python_lint"
        },
        {
          "tool": "eslint.lint_directory",
          "input": {"directory": "frontend/", "fix": true},
          "output_var": "js_lint"
        }
      ]
    },
    {
      "phase": "Analysis",
      "parallel": true,
      "actions": [
        {
          "tool": "code-analysis.analyze_codebase",
          "input": {"depth": "deep"},
          "output_var": "code_analysis"
        },
        {
          "tool": "code-analysis.security_scan",
          "input": {"owasp_check": true},
          "output_var": "security_scan"
        },
        {
          "tool": "code-analysis.find_dead_code",
          "input": {"min_confidence": 80},
          "output_var": "dead_code"
        }
      ]
    },
    {
      "phase": "Reporting",
      "actions": [
        {
          "tool": "aggregate_results",
          "input": {
            "results": [
              "{{python_lint}}",
              "{{js_lint}}",
              "{{code_analysis}}",
              "{{security_scan}}",
              "{{dead_code}}"
            ]
          },
          "output_var": "quality_report"
        },
        {
          "tool": "github.create_issue",
          "input": {
            "title": "Code Quality Report - {{date}}",
            "body": "{{quality_report}}",
            "labels": ["code-quality", "automated"]
          }
        },
        {
          "tool": "notion.create_page",
          "input": {
            "title": "Code Quality Report",
            "content": "{{quality_report}}"
          }
        }
      ]
    },
    {
      "phase": "Task Creation",
      "actions": [
        {
          "tool": "taskqueue.bulk_add_tasks",
          "input": {
            "tasks": "{{quality_report.issues}}",
            "auto_prioritize": true
          }
        }
      ]
    }
  ]
}
```

================================================================================
SECTION 5: BEST PRACTICES & GUIDELINES
================================================================================

## MANDATORY PRACTICES

### 1. Always Map Before Starting

```typescript
{
  "rule": "map_before_start",
  "enforcement": "strict",
  "applies_to": "all_projects",
  "actions": [
    "Generate project structure diagram",
    "Map all imports and exports",
    "Document all classes",
    "List all dependencies",
    "Map all API endpoints",
    "Generate database ERD",
    "Document configuration"
  ],
  "output_location": "docs/architecture/",
  "update_frequency": "on_change"
}
```

### 2. Keep Documentation Updated

```typescript
{
  "rule": "update_docs_on_change",
  "enforcement": "strict",
  "triggers": [
    "new_file_created",
    "class_added",
    "api_endpoint_added",
    "dependency_added",
    "database_schema_changed"
  ],
  "actions": [
    "Regenerate affected diagrams",
    "Update documentation",
    "Commit to git"
  ]
}
```

### 3. Use Context-Aware Tool Selection

```typescript
{
  "rule": "context_aware_tools",
  "guidance": [
    "Analyze context before choosing tools",
    "Consider project phase",
    "Check available resources",
    "Evaluate task requirements",
    "Select optimal tool combination"
  ]
}
```

### 4. Automate Repetitive Tasks

```typescript
{
  "rule": "automate_repetitive",
  "examples": [
    "Linting on save",
    "Testing on commit",
    "Documentation on change",
    "Deployment on merge",
    "Monitoring on deploy"
  ]
}
```

### 5. Monitor and Learn

```typescript
{
  "rule": "monitor_and_learn",
  "actions": [
    "Track tool effectiveness",
    "Measure workflow efficiency",
    "Collect feedback",
    "Adjust strategies",
    "Improve continuously"
  ]
}
```

================================================================================
RESOURCES
================================================================================

### Documentation Tools
- **Mermaid:** https://mermaid.js.org/
- **PlantUML:** https://plantuml.com/
- **Swagger/OpenAPI:** https://swagger.io/

### Code Analysis Tools
- **Ruff:** https://github.com/astral-sh/ruff
- **ESLint:** https://eslint.org/
- **SonarQube:** https://www.sonarqube.org/

### MCP Resources
- **MCP Protocol:** https://modelcontextprotocol.io/
- **MCP Servers:** https://github.com/punkpeye/awesome-mcp-servers

================================================================================
END OF MODULE 16: MCP INTEGRATION LAYER
================================================================================



================================================================================
END OF 16_MCP_INTEGRATION
================================================================================


================================================================================
MODULE: 17_THINKING_FRAMEWORK
================================================================================

================================================================================
MODULE 17: THINKING FRAMEWORK
================================================================================

OVERVIEW
--------
Ÿáÿ∞ÿß ÿßŸÑŸÖŸàÿØŸàŸÑ ŸäŸàŸÅÿ± ÿ•ÿ∑ÿßÿ± ÿπŸÖŸÑ ŸÖŸÜŸáÿ¨Ÿä ŸÑŸÑÿ™ŸÅŸÉŸäÿ± Ÿàÿ≠ŸÑ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑÿå ŸäŸÖŸÉŸëŸÜ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä
ŸÖŸÜ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ÿßŸÑŸÖÿπŸÇÿØÿ©ÿå ÿ™ŸÇÿ≥ŸäŸÖŸáÿß ÿ•ŸÑŸâ ŸÖŸáÿßŸÖ ŸÇÿßÿ®ŸÑÿ© ŸÑŸÑÿ™ŸÜŸÅŸäÿ∞ÿå Ÿàÿ™ÿµŸÖŸäŸÖ ÿ≠ŸÑŸàŸÑ ŸÅÿπÿßŸÑÿ©.

CORE PHILOSOPHY
---------------
"Think systematically, solve methodically, learn continuously"

ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä Ÿäÿ¨ÿ® ÿ£ŸÜ:
- ŸäŸÅŸÉÿ± ÿ®ÿ¥ŸÉŸÑ ŸÖŸÜŸáÿ¨Ÿä ŸàŸÖŸÜÿ∑ŸÇŸä
- Ÿäÿ≠ŸÑŸÑ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ÿ®ÿπŸÖŸÇ
- ŸäŸÇÿ≥ŸÖ ÿßŸÑŸÖŸáÿßŸÖ ÿßŸÑŸÖÿπŸÇÿØÿ©
- ŸäÿµŸÖŸÖ ÿ≠ŸÑŸàŸÑ ŸÅÿπÿßŸÑÿ©
- Ÿäÿ™ÿπŸÑŸÖ ŸÖŸÜ ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ®

================================================================================
SECTION 1: SEQUENTIAL THINKING
================================================================================

OVERVIEW
--------
Sequential Thinking ŸáŸà ŸÜŸáÿ¨ ŸÖŸÜŸáÿ¨Ÿä ŸÑÿ≠ŸÑ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ÿÆÿ∑Ÿàÿ© ÿ®ÿÆÿ∑Ÿàÿ©ÿå ÿ≠Ÿäÿ´ ŸÉŸÑ ÿÆÿ∑Ÿàÿ©
ÿ™ÿ®ŸÜŸä ÿπŸÑŸâ ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿÆÿ∑Ÿàÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©.

THINKING PROCESS
----------------

### Step 1: Problem Understanding

**Purpose:** ŸÅŸáŸÖ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ®ÿπŸÖŸÇ ŸÇÿ®ŸÑ ŸÖÿ≠ÿßŸàŸÑÿ© ÿ≠ŸÑŸáÿß

**Questions to Ask:**
- ŸÖÿß ŸáŸä ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ≠ŸÇŸäŸÇŸäÿ©ÿü
- ŸÖÿß ŸáŸä ÿßŸÑÿ£ÿπÿ±ÿßÿ∂ vs ÿßŸÑÿ£ÿ≥ÿ®ÿßÿ® ÿßŸÑÿ¨ÿ∞ÿ±Ÿäÿ©ÿü
- ŸÖŸÜ ÿßŸÑŸÖÿ™ÿ£ÿ´ÿ±ŸàŸÜ ÿ®Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©ÿü
- ŸÖÿß ŸáŸà ÿßŸÑÿ™ÿ£ÿ´Ÿäÿ± ÿßŸÑÿ≠ÿßŸÑŸäÿü
- ŸÖÿß ŸáŸä ÿßŸÑŸÇŸäŸàÿØ ŸàÿßŸÑŸÖÿ≠ÿØÿØÿßÿ™ÿü

**Tools:**
```typescript
{
  "step": "problem_understanding",
  "tools": [
    "context7.get_documentation",
    "github.search_issues",
    "sentry.get_issue_details"
  ],
  "output": {
    "problem_statement": "Clear description of the problem",
    "affected_components": ["list", "of", "components"],
    "impact_assessment": {
      "severity": "low | medium | high | critical",
      "users_affected": 100,
      "business_impact": "description"
    },
    "constraints": ["technical", "time", "resource"]
  }
}
```

**Example:**

```python
# Problem Understanding Template
def understand_problem(issue_id):
    # Gather information
    issue = sentry.get_issue_details(issue_id)
    similar = github.search_similar_issues(issue.message)
    docs = context7.get_documentation(issue.component)
    
    # Analyze
    problem = {
        "statement": extract_problem_statement(issue),
        "root_cause": analyze_root_cause(issue, similar),
        "affected_components": identify_components(issue),
        "impact": assess_impact(issue),
        "constraints": identify_constraints()
    }
    
    return problem
```

---

### Step 2: Context Analysis

**Purpose:** ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠Ÿäÿ∑ ÿ®ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©

**Aspects to Analyze:**
- **Technical Context:** ÿßŸÑÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖÿ©ÿå ÿßŸÑÿ®ŸÜŸäÿ© ÿßŸÑÿ≠ÿßŸÑŸäÿ©
- **Code Context:** ÿ¨ŸàÿØÿ© ÿßŸÑŸÉŸàÿØÿå ÿßŸÑÿ™ÿ®ÿπŸäÿßÿ™ÿå ÿßŸÑÿ™ÿπŸÇŸäÿØ
- **Historical Context:** ŸÖÿ¥ÿßŸÉŸÑ ŸÖÿ¥ÿßÿ®Ÿáÿ© ÿ≥ÿßÿ®ŸÇÿ©ÿå ÿ≠ŸÑŸàŸÑ ÿ≥ÿßÿ®ŸÇÿ©
- **Team Context:** ÿßŸÑÿÆÿ®ÿ±ÿßÿ™ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ©ÿå ÿßŸÑŸÖŸàÿßÿ±ÿØ
- **Business Context:** ÿßŸÑÿ£ŸàŸÑŸàŸäÿßÿ™ÿå ÿßŸÑŸÖŸàÿßÿπŸäÿØ ÿßŸÑŸÜŸáÿßÿ¶Ÿäÿ©

**Tools:**
```typescript
{
  "step": "context_analysis",
  "tools": [
    "code-analysis.analyze_codebase",
    "ruff.check_project",
    "github.get_commit_history",
    "taskqueue.get_related_tasks"
  ],
  "output": {
    "technical_context": {...},
    "code_quality": {...},
    "historical_data": [...],
    "team_capacity": {...}
  }
}
```

**Example:**

```python
# Context Analysis
def analyze_context(problem):
    context = {
        "technical": {
            "stack": detect_tech_stack(),
            "architecture": analyze_architecture(),
            "dependencies": analyze_dependencies()
        },
        "code": {
            "quality_score": ruff.check_project(),
            "complexity": code_analysis.measure_complexity(),
            "test_coverage": pytest.get_coverage()
        },
        "historical": {
            "similar_issues": github.search_similar_issues(),
            "past_solutions": extract_solutions(),
            "lessons_learned": get_lessons_learned()
        },
        "team": {
            "available_skills": assess_team_skills(),
            "capacity": calculate_capacity(),
            "expertise": identify_experts()
        }
    }
    
    return context
```

---

### Step 3: Solution Design

**Purpose:** ÿ™ÿµŸÖŸäŸÖ ÿ≠ŸÑ ŸÅÿπÿßŸÑ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÅŸáŸÖ ŸàÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ

**Design Principles:**
- **KISS:** Keep It Simple, Stupid
- **DRY:** Don't Repeat Yourself
- **YAGNI:** You Aren't Gonna Need It
- **SOLID:** Single responsibility, Open-closed, Liskov substitution, Interface segregation, Dependency inversion

**Approach:**
1. Brainstorm multiple solutions
2. Evaluate each solution
3. Select the best approach
4. Design detailed implementation plan

**Tools:**
```typescript
{
  "step": "solution_design",
  "tools": [
    "sequential-thinking.generate_solutions",
    "code-analysis.suggest_patterns",
    "context7.search_best_practices"
  ],
  "output": {
    "solutions": [
      {
        "approach": "description",
        "pros": ["list", "of", "pros"],
        "cons": ["list", "of", "cons"],
        "complexity": "low | medium | high",
        "estimated_effort": "hours",
        "risk_level": "low | medium | high"
      }
    ],
    "recommended_solution": {...},
    "implementation_plan": [...]
  }
}
```

**Example:**

```python
# Solution Design
def design_solution(problem, context):
    # Generate multiple solutions
    solutions = []
    
    # Solution 1: Quick fix
    solutions.append({
        "name": "Quick Fix",
        "approach": "Patch the immediate issue",
        "pros": ["Fast", "Low risk"],
        "cons": ["Technical debt", "Not addressing root cause"],
        "complexity": "low",
        "effort": "2 hours",
        "risk": "low"
    })
    
    # Solution 2: Proper fix
    solutions.append({
        "name": "Proper Fix",
        "approach": "Refactor and fix root cause",
        "pros": ["Long-term solution", "Improves code quality"],
        "cons": ["More time", "Higher risk"],
        "complexity": "medium",
        "effort": "8 hours",
        "risk": "medium"
    })
    
    # Solution 3: Complete rewrite
    solutions.append({
        "name": "Complete Rewrite",
        "approach": "Rewrite the component",
        "pros": ["Best quality", "Modern approach"],
        "cons": ["Very time consuming", "High risk"],
        "complexity": "high",
        "effort": "40 hours",
        "risk": "high"
    })
    
    # Evaluate and select
    recommended = evaluate_solutions(solutions, context)
    
    return {
        "solutions": solutions,
        "recommended": recommended,
        "rationale": explain_selection(recommended)
    }
```

---

### Step 4: Task Breakdown

**Purpose:** ÿ™ŸÇÿ≥ŸäŸÖ ÿßŸÑÿ≠ŸÑ ÿ•ŸÑŸâ ŸÖŸáÿßŸÖ ŸÇÿßÿ®ŸÑÿ© ŸÑŸÑÿ™ŸÜŸÅŸäÿ∞

**Breakdown Strategy:**
- ÿ™ŸÇÿ≥ŸäŸÖ ÿ≠ÿ≥ÿ® ÿßŸÑŸÖŸÉŸàŸÜÿßÿ™
- ÿ™ŸÇÿ≥ŸäŸÖ ÿ≠ÿ≥ÿ® ÿßŸÑÿ∑ÿ®ŸÇÿßÿ™ (Frontend, Backend, Database)
- ÿ™ŸÇÿ≥ŸäŸÖ ÿ≠ÿ≥ÿ® ÿßŸÑÿ£ŸàŸÑŸàŸäÿ©
- ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑÿ™ÿ®ÿπŸäÿßÿ™ ÿ®ŸäŸÜ ÿßŸÑŸÖŸáÿßŸÖ

**Tools:**
```typescript
{
  "step": "task_breakdown",
  "tools": [
    "sequential-thinking.decompose_problem",
    "taskqueue.bulk_add_tasks",
    "github.create_milestone"
  ],
  "output": {
    "tasks": [
      {
        "id": "TASK-1",
        "title": "Task title",
        "description": "Detailed description",
        "type": "bug | feature | refactor | test",
        "priority": "low | medium | high | critical",
        "estimated_effort": "hours",
        "dependencies": ["TASK-0"],
        "assigned_to": "developer@example.com",
        "labels": ["backend", "database"]
      }
    ],
    "execution_order": ["TASK-1", "TASK-2", "TASK-3"],
    "critical_path": ["TASK-1", "TASK-3"]
  }
}
```

**Example:**

```python
# Task Breakdown
def breakdown_tasks(solution):
    tasks = []
    
    # Phase 1: Preparation
    tasks.append({
        "id": "TASK-1",
        "title": "Setup test environment",
        "description": "Create isolated test environment",
        "type": "setup",
        "priority": "high",
        "effort": "1 hour",
        "dependencies": [],
        "phase": "preparation"
    })
    
    tasks.append({
        "id": "TASK-2",
        "title": "Write failing tests",
        "description": "TDD: Write tests that demonstrate the bug",
        "type": "test",
        "priority": "high",
        "effort": "2 hours",
        "dependencies": ["TASK-1"],
        "phase": "preparation"
    })
    
    # Phase 2: Implementation
    tasks.append({
        "id": "TASK-3",
        "title": "Implement fix",
        "description": "Fix the root cause",
        "type": "bug-fix",
        "priority": "high",
        "effort": "4 hours",
        "dependencies": ["TASK-2"],
        "phase": "implementation"
    })
    
    # Phase 3: Verification
    tasks.append({
        "id": "TASK-4",
        "title": "Verify fix",
        "description": "Run all tests and verify",
        "type": "test",
        "priority": "high",
        "effort": "1 hour",
        "dependencies": ["TASK-3"],
        "phase": "verification"
    })
    
    # Phase 4: Deployment
    tasks.append({
        "id": "TASK-5",
        "title": "Deploy to production",
        "description": "Deploy and monitor",
        "type": "deployment",
        "priority": "high",
        "effort": "1 hour",
        "dependencies": ["TASK-4"],
        "phase": "deployment"
    })
    
    return {
        "tasks": tasks,
        "total_effort": sum(t["effort"] for t in tasks),
        "critical_path": identify_critical_path(tasks)
    }
```

---

### Step 5: Execution Planning

**Purpose:** ÿ™ÿÆÿ∑Ÿäÿ∑ ÿßŸÑÿ™ŸÜŸÅŸäÿ∞ ÿßŸÑŸÅÿπŸÑŸä

**Planning Aspects:**
- **Timeline:** ŸÖÿ™Ÿâ ÿ≥Ÿäÿ™ŸÖ ÿ™ŸÜŸÅŸäÿ∞ ŸÉŸÑ ŸÖŸáŸÖÿ©ÿü
- **Resources:** ŸÖŸÜ ÿ≥ŸäŸÜŸÅÿ∞ ŸÉŸÑ ŸÖŸáŸÖÿ©ÿü
- **Dependencies:** ŸÖÿß ŸáŸä ÿßŸÑÿ™ÿ®ÿπŸäÿßÿ™ÿü
- **Risks:** ŸÖÿß ŸáŸä ÿßŸÑŸÖÿÆÿßÿ∑ÿ± ÿßŸÑŸÖÿ≠ÿ™ŸÖŸÑÿ©ÿü
- **Contingencies:** ŸÖÿß ŸáŸä ÿßŸÑÿÆÿ∑ÿ∑ ÿßŸÑÿ®ÿØŸäŸÑÿ©ÿü

**Tools:**
```typescript
{
  "step": "execution_planning",
  "tools": [
    "taskqueue.schedule_tasks",
    "github.create_project_board",
    "notion.create_project_page"
  ],
  "output": {
    "timeline": {
      "start_date": "2025-01-03",
      "end_date": "2025-01-05",
      "milestones": [...]
    },
    "resource_allocation": {
      "developer_1": ["TASK-1", "TASK-3"],
      "developer_2": ["TASK-2", "TASK-4"]
    },
    "risk_mitigation": [...]
  }
}
```

---

### Step 6: Monitoring & Adjustment

**Purpose:** ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑÿ™ŸÇÿØŸÖ Ÿàÿ™ÿπÿØŸäŸÑ ÿßŸÑÿÆÿ∑ÿ© ÿ≠ÿ≥ÿ® ÿßŸÑÿ≠ÿßÿ¨ÿ©

**Monitoring Aspects:**
- **Progress Tracking:** ÿ™ÿ™ÿ®ÿπ ÿ•ŸÉŸÖÿßŸÑ ÿßŸÑŸÖŸáÿßŸÖ
- **Quality Metrics:** ŸÖŸÇÿßŸäŸäÿ≥ ÿßŸÑÿ¨ŸàÿØÿ©
- **Performance Metrics:** ŸÖŸÇÿßŸäŸäÿ≥ ÿßŸÑÿ£ÿØÿßÿ°
- **Issue Detection:** ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ŸÖÿ®ŸÉÿ±ÿßŸã

**Tools:**
```typescript
{
  "step": "monitoring",
  "tools": [
    "taskqueue.get_progress",
    "sentry.monitor_errors",
    "cloudflare.get_metrics",
    "github.get_pr_status"
  ],
  "output": {
    "progress": {
      "completed": 3,
      "in_progress": 1,
      "blocked": 0,
      "total": 5
    },
    "quality": {
      "test_coverage": 85,
      "code_quality": 92,
      "security_score": 95
    },
    "issues": [...]
  }
}
```

---

### Step 7: Learning & Documentation

**Purpose:** ÿßŸÑÿ™ÿπŸÑŸÖ ŸÖŸÜ ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© Ÿàÿ™Ÿàÿ´ŸäŸÇ ÿßŸÑÿØÿ±Ÿàÿ≥ ÿßŸÑŸÖÿ≥ÿ™ŸÅÿßÿØÿ©

**Documentation:**
- **What worked well:** ŸÖÿß ÿßŸÑÿ∞Ÿä ŸÜÿ¨ÿ≠ÿü
- **What didn't work:** ŸÖÿß ÿßŸÑÿ∞Ÿä ŸÑŸÖ ŸäŸÜÿ¨ÿ≠ÿü
- **Lessons learned:** ÿßŸÑÿØÿ±Ÿàÿ≥ ÿßŸÑŸÖÿ≥ÿ™ŸÅÿßÿØÿ©
- **Best practices:** ÿ£ŸÅÿ∂ŸÑ ÿßŸÑŸÖŸÖÿßÿ±ÿ≥ÿßÿ™
- **Recommendations:** ÿßŸÑÿ™ŸàÿµŸäÿßÿ™ ŸÑŸÑŸÖÿ≥ÿ™ŸÇÿ®ŸÑ

**Tools:**
```typescript
{
  "step": "learning",
  "tools": [
    "notion.create_retrospective",
    "github.update_wiki",
    "learning-system.record_lesson"
  ],
  "output": {
    "retrospective": {
      "what_worked": [...],
      "what_didnt": [...],
      "lessons": [...],
      "action_items": [...]
    },
    "documentation": "url_to_docs",
    "knowledge_base_updated": true
  }
}
```

================================================================================
SECTION 2: PROBLEM DECOMPOSITION
================================================================================

OVERVIEW
--------
Problem Decomposition ŸáŸà ŸÅŸÜ ÿ™ŸÇÿ≥ŸäŸÖ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ÿßŸÑŸÖÿπŸÇÿØÿ© ÿ•ŸÑŸâ ŸÖÿ¥ÿßŸÉŸÑ ÿ£ÿµÿ∫ÿ± Ÿàÿ£ÿ®ÿ≥ÿ∑
ŸäŸÖŸÉŸÜ ÿ≠ŸÑŸáÿß ÿ®ÿ¥ŸÉŸÑ ŸÖÿ≥ÿ™ŸÇŸÑ.

DECOMPOSITION STRATEGIES
------------------------

### 1. Functional Decomposition

**Approach:** ÿ™ŸÇÿ≥ŸäŸÖ ÿ≠ÿ≥ÿ® ÿßŸÑŸàÿ∏ÿßÿ¶ŸÅ

```typescript
{
  "problem": "Build e-commerce platform",
  "decomposition": {
    "user_management": {
      "registration": [...],
      "authentication": [...],
      "profile_management": [...]
    },
    "product_catalog": {
      "product_listing": [...],
      "search": [...],
      "filtering": [...]
    },
    "shopping_cart": {
      "add_to_cart": [...],
      "update_cart": [...],
      "checkout": [...]
    },
    "payment": {
      "payment_processing": [...],
      "refunds": [...],
      "invoicing": [...]
    },
    "order_management": {
      "order_tracking": [...],
      "shipping": [...],
      "returns": [...]
    }
  }
}
```

---

### 2. Layer Decomposition

**Approach:** ÿ™ŸÇÿ≥ŸäŸÖ ÿ≠ÿ≥ÿ® ÿßŸÑÿ∑ÿ®ŸÇÿßÿ™ ÿßŸÑŸÖÿπŸÖÿßÿ±Ÿäÿ©

```typescript
{
  "problem": "Implement new feature",
  "layers": {
    "presentation": {
      "ui_components": [...],
      "forms": [...],
      "validation": [...]
    },
    "business_logic": {
      "services": [...],
      "workflows": [...],
      "rules": [...]
    },
    "data_access": {
      "repositories": [...],
      "queries": [...],
      "caching": [...]
    },
    "database": {
      "schema": [...],
      "migrations": [...],
      "indexes": [...]
    }
  }
}
```

---

### 3. Temporal Decomposition

**Approach:** ÿ™ŸÇÿ≥ŸäŸÖ ÿ≠ÿ≥ÿ® ÿßŸÑÿ≤ŸÖŸÜ/ÿßŸÑŸÖÿ±ÿßÿ≠ŸÑ

```typescript
{
  "problem": "Launch new product",
  "phases": {
    "phase_1_mvp": {
      "duration": "2 weeks",
      "features": ["core_features"],
      "goal": "Validate concept"
    },
    "phase_2_beta": {
      "duration": "4 weeks",
      "features": ["additional_features", "polish"],
      "goal": "Get user feedback"
    },
    "phase_3_launch": {
      "duration": "2 weeks",
      "features": ["final_features", "optimization"],
      "goal": "Public launch"
    },
    "phase_4_growth": {
      "duration": "ongoing",
      "features": ["scaling", "new_features"],
      "goal": "Grow user base"
    }
  }
}
```

---

### 4. Component Decomposition

**Approach:** ÿ™ŸÇÿ≥ŸäŸÖ ÿ≠ÿ≥ÿ® ÿßŸÑŸÖŸÉŸàŸÜÿßÿ™

```typescript
{
  "problem": "Refactor legacy system",
  "components": {
    "authentication_service": {
      "complexity": "medium",
      "priority": "high",
      "dependencies": ["user_service"]
    },
    "user_service": {
      "complexity": "low",
      "priority": "high",
      "dependencies": []
    },
    "payment_service": {
      "complexity": "high",
      "priority": "critical",
      "dependencies": ["user_service", "order_service"]
    },
    "notification_service": {
      "complexity": "low",
      "priority": "medium",
      "dependencies": ["user_service"]
    }
  }
}
```

---

### 5. Dependency-Based Decomposition

**Approach:** ÿ™ŸÇÿ≥ŸäŸÖ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑÿ™ÿ®ÿπŸäÿßÿ™

```python
# Dependency Graph
def decompose_by_dependencies(problem):
    # Build dependency graph
    graph = {
        "database_schema": [],
        "data_models": ["database_schema"],
        "repositories": ["data_models"],
        "services": ["repositories"],
        "api_endpoints": ["services"],
        "frontend_components": ["api_endpoints"]
    }
    
    # Topological sort for execution order
    execution_order = topological_sort(graph)
    
    return {
        "dependency_graph": graph,
        "execution_order": execution_order,
        "parallel_groups": identify_parallel_tasks(graph)
    }
```

================================================================================
SECTION 3: SOLUTION DESIGN PATTERNS
================================================================================

OVERVIEW
--------
ŸÖÿ¨ŸÖŸàÿπÿ© ŸÖŸÜ ÿ£ŸÜŸÖÿßÿ∑ ÿßŸÑÿ™ÿµŸÖŸäŸÖ ÿßŸÑŸÖÿ¨ÿ±ÿ®ÿ© ŸÑÿ≠ŸÑ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ ÿßŸÑÿ¥ÿßÿ¶ÿπÿ©.

ARCHITECTURAL PATTERNS
---------------------

### 1. Microservices Pattern

**When to Use:**
- ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ŸÉÿ®Ÿäÿ±ÿ© ŸàŸÖÿπŸÇÿØÿ©
- ŸÅÿ±ŸÇ ŸÖÿ™ÿπÿØÿØÿ© ÿ™ÿπŸÖŸÑ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ≥ÿ™ŸÇŸÑ
- ÿ≠ÿßÿ¨ÿ© ŸÑŸÑÿ™Ÿàÿ≥ÿπ ÿßŸÑŸÖÿ≥ÿ™ŸÇŸÑ ŸÑŸÑŸÖŸÉŸàŸÜÿßÿ™

**Structure:**
```typescript
{
  "pattern": "microservices",
  "services": {
    "user_service": {
      "responsibility": "User management",
      "database": "users_db",
      "api": "/api/users",
      "dependencies": []
    },
    "product_service": {
      "responsibility": "Product catalog",
      "database": "products_db",
      "api": "/api/products",
      "dependencies": []
    },
    "order_service": {
      "responsibility": "Order processing",
      "database": "orders_db",
      "api": "/api/orders",
      "dependencies": ["user_service", "product_service"]
    }
  },
  "communication": "REST APIs + Message Queue",
  "api_gateway": "Kong/Nginx"
}
```

---

### 2. Event-Driven Pattern

**When to Use:**
- ÿ≠ÿßÿ¨ÿ© ŸÑŸÑÿ™ŸÅÿßÿπŸÑ ÿßŸÑŸÅŸàÿ±Ÿä ŸÖÿπ ÿßŸÑÿ£ÿ≠ÿØÿßÿ´
- ÿ£ŸÜÿ∏ŸÖÿ© ŸÖŸàÿ≤ÿπÿ©
- ÿ≠ÿßÿ¨ÿ© ŸÑŸÅÿµŸÑ ÿßŸÑŸÖŸÉŸàŸÜÿßÿ™

**Structure:**
```typescript
{
  "pattern": "event_driven",
  "events": {
    "user_registered": {
      "publisher": "user_service",
      "subscribers": [
        "email_service",
        "analytics_service",
        "notification_service"
      ]
    },
    "order_placed": {
      "publisher": "order_service",
      "subscribers": [
        "payment_service",
        "inventory_service",
        "shipping_service"
      ]
    }
  },
  "message_broker": "RabbitMQ/Kafka",
  "event_store": "EventStoreDB"
}
```

---

### 3. CQRS Pattern

**When to Use:**
- ŸÇÿ±ÿßÿ°ÿßÿ™ ŸàŸÉÿ™ÿßÿ®ÿßÿ™ ŸÖÿÆÿ™ŸÑŸÅÿ© ÿ¨ÿØÿßŸã
- ÿ≠ÿßÿ¨ÿ© ŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿ£ÿØÿßÿ°
- ÿ£ŸÜÿ∏ŸÖÿ© ŸÖÿπŸÇÿØÿ©

**Structure:**
```typescript
{
  "pattern": "cqrs",
  "command_side": {
    "purpose": "Handle writes",
    "database": "write_db (normalized)",
    "models": "domain_models",
    "validation": "strict"
  },
  "query_side": {
    "purpose": "Handle reads",
    "database": "read_db (denormalized)",
    "models": "view_models",
    "optimization": "heavy"
  },
  "synchronization": "Event sourcing"
}
```

---

### 4. Layered Architecture

**When to Use:**
- ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿ™ŸÇŸÑŸäÿØŸäÿ©
- ŸÅÿ±ŸÇ ÿµÿ∫Ÿäÿ±ÿ© ÿ•ŸÑŸâ ŸÖÿ™Ÿàÿ≥ÿ∑ÿ©
- ŸÖÿ™ÿ∑ŸÑÿ®ÿßÿ™ Ÿàÿßÿ∂ÿ≠ÿ©

**Structure:**
```typescript
{
  "pattern": "layered",
  "layers": {
    "presentation": {
      "responsibility": "UI/UX",
      "technologies": ["React", "Vue", "Angular"],
      "depends_on": ["application"]
    },
    "application": {
      "responsibility": "Business logic",
      "technologies": ["Services", "Use cases"],
      "depends_on": ["domain", "infrastructure"]
    },
    "domain": {
      "responsibility": "Core business rules",
      "technologies": ["Entities", "Value objects"],
      "depends_on": []
    },
    "infrastructure": {
      "responsibility": "Technical concerns",
      "technologies": ["Database", "APIs", "Cache"],
      "depends_on": []
    }
  }
}
```

================================================================================
SECTION 4: DECISION TREES
================================================================================

OVERVIEW
--------
ÿ£ÿ¥ÿ¨ÿßÿ± ŸÇÿ±ÿßÿ±ÿßÿ™ ŸÑŸÖÿ≥ÿßÿπÿØÿ© ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÅŸä ÿßÿ™ÿÆÿßÿ∞ ŸÇÿ±ÿßÿ±ÿßÿ™ ÿ∞ŸÉŸäÿ©.

DECISION TREE: CHOOSING ARCHITECTURE
------------------------------------

```typescript
{
  "decision": "choose_architecture",
  "tree": {
    "question": "What is the project size?",
    "options": {
      "small": {
        "question": "Is it a simple CRUD app?",
        "options": {
          "yes": {
            "recommendation": "Monolithic + MVC",
            "rationale": "Simple, fast to develop"
          },
          "no": {
            "recommendation": "Layered Architecture",
            "rationale": "Good separation of concerns"
          }
        }
      },
      "medium": {
        "question": "Do you have multiple teams?",
        "options": {
          "yes": {
            "recommendation": "Microservices",
            "rationale": "Independent development"
          },
          "no": {
            "recommendation": "Modular Monolith",
            "rationale": "Balance between simplicity and modularity"
          }
        }
      },
      "large": {
        "question": "Is high scalability required?",
        "options": {
          "yes": {
            "recommendation": "Microservices + Event-Driven",
            "rationale": "Maximum scalability and flexibility"
          },
          "no": {
            "recommendation": "Microservices",
            "rationale": "Good for large teams"
          }
        }
      }
    }
  }
}
```

---

DECISION TREE: CHOOSING DATABASE
--------------------------------

```typescript
{
  "decision": "choose_database",
  "tree": {
    "question": "What type of data?",
    "options": {
      "structured": {
        "question": "Do you need ACID transactions?",
        "options": {
          "yes": {
            "question": "What scale?",
            "options": {
              "small_medium": {
                "recommendation": "PostgreSQL",
                "rationale": "Best relational DB"
              },
              "large": {
                "recommendation": "CockroachDB",
                "rationale": "Distributed SQL"
              }
            }
          },
          "no": {
            "recommendation": "NoSQL (MongoDB)",
            "rationale": "Flexible schema"
          }
        }
      },
      "unstructured": {
        "question": "What access pattern?",
        "options": {
          "key_value": {
            "recommendation": "Redis/DynamoDB",
            "rationale": "Fast key-value access"
          },
          "document": {
            "recommendation": "MongoDB/Elasticsearch",
            "rationale": "Document storage and search"
          },
          "graph": {
            "recommendation": "Neo4j",
            "rationale": "Graph relationships"
          }
        }
      },
      "time_series": {
        "recommendation": "TimescaleDB/InfluxDB",
        "rationale": "Optimized for time-series data"
      }
    }
  }
}
```

---

DECISION TREE: CHOOSING TESTING STRATEGY
----------------------------------------

```typescript
{
  "decision": "choose_testing_strategy",
  "tree": {
    "question": "What are you testing?",
    "options": {
      "backend_api": {
        "tests": [
          {
            "type": "unit",
            "coverage": "70%",
            "tools": ["pytest", "jest"],
            "focus": "Business logic"
          },
          {
            "type": "integration",
            "coverage": "20%",
            "tools": ["pytest", "supertest"],
            "focus": "API endpoints"
          },
          {
            "type": "e2e",
            "coverage": "10%",
            "tools": ["playwright"],
            "focus": "Critical flows"
          }
        ]
      },
      "frontend": {
        "tests": [
          {
            "type": "unit",
            "coverage": "60%",
            "tools": ["jest", "vitest"],
            "focus": "Components, utils"
          },
          {
            "type": "integration",
            "coverage": "30%",
            "tools": ["testing-library"],
            "focus": "Component interactions"
          },
          {
            "type": "e2e",
            "coverage": "10%",
            "tools": ["playwright", "cypress"],
            "focus": "User journeys"
          }
        ]
      },
      "full_stack": {
        "tests": [
          {
            "type": "unit",
            "coverage": "65%",
            "tools": ["pytest", "jest"],
            "focus": "All units"
          },
          {
            "type": "integration",
            "coverage": "25%",
            "tools": ["pytest", "testing-library"],
            "focus": "API + Components"
          },
          {
            "type": "e2e",
            "coverage": "10%",
            "tools": ["playwright"],
            "focus": "Critical user flows"
          }
        ]
      }
    }
  }
}
```

================================================================================
SECTION 5: COGNITIVE FRAMEWORKS
================================================================================

OVERVIEW
--------
ÿ£ÿ∑ÿ± ÿπŸÖŸÑ ŸÖÿπÿ±ŸÅŸäÿ© ŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿ™ŸÅŸÉŸäÿ± Ÿàÿ≠ŸÑ ÿßŸÑŸÖÿ¥ÿßŸÉŸÑ.

FIRST PRINCIPLES THINKING
-------------------------

**Concept:** ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ•ŸÑŸâ ÿßŸÑŸÖÿ®ÿßÿØÿ¶ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© Ÿàÿ•ÿπÿßÿØÿ© ÿßŸÑÿ®ŸÜÿßÿ° ŸÖŸÜ ÿßŸÑÿµŸÅÿ±

**Process:**
1. **Identify assumptions:** ÿ≠ÿØÿØ ÿßŸÑÿßŸÅÿ™ÿ±ÿßÿ∂ÿßÿ™ ÿßŸÑÿ≠ÿßŸÑŸäÿ©
2. **Break down:** ŸÇÿ≥ŸëŸÖ ÿ•ŸÑŸâ ÿßŸÑŸÖÿ®ÿßÿØÿ¶ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©
3. **Reconstruct:** ÿ£ÿπÿØ ÿßŸÑÿ®ŸÜÿßÿ° ŸÖŸÜ ÿßŸÑÿµŸÅÿ±
4. **Innovate:** ÿßÿ®ÿ™ŸÉÿ± ÿ≠ŸÑŸàŸÑ ÿ¨ÿØŸäÿØÿ©

**Example:**

```python
# First Principles: "We need to store user data"

# Traditional thinking:
"We need a database" ‚Üí "Let's use MySQL"

# First principles thinking:
assumptions = [
    "We need to store data",
    "Data must be persistent",
    "Data must be queryable",
    "Data must be secure"
]

fundamental_truths = [
    "Data is just bytes",
    "Bytes can be stored in many ways",
    "Different storage has different trade-offs"
]

solutions = [
    {
        "approach": "File system",
        "pros": ["Simple", "No dependencies"],
        "cons": ["No queries", "No transactions"]
    },
    {
        "approach": "SQLite",
        "pros": ["Simple", "SQL", "Transactions"],
        "cons": ["Single file", "Limited concurrency"]
    },
    {
        "approach": "PostgreSQL",
        "pros": ["Full SQL", "High concurrency", "ACID"],
        "cons": ["More complex", "Separate service"]
    },
    {
        "approach": "Redis",
        "pros": ["Very fast", "Simple"],
        "cons": ["In-memory", "Limited queries"]
    }
]

# Choose based on actual requirements, not assumptions
```

---

SYSTEMS THINKING
---------------

**Concept:** ŸÅŸáŸÖ ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ŸÉŸÉŸÑ ŸÖÿ™ŸÉÿßŸÖŸÑ ŸàŸÑŸäÿ≥ ÿ£ÿ¨ÿ≤ÿßÿ° ŸÖŸÜŸÅÿµŸÑÿ©

**Key Concepts:**
- **Interconnections:** ŸÉŸÑ ÿ¥Ÿäÿ° ŸÖÿ™ÿ±ÿßÿ®ÿ∑
- **Feedback loops:** ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ÿ™ÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿ≠ŸÑŸÇÿßÿ™ ÿ™ÿ∫ÿ∞Ÿäÿ© ÿ±ÿßÿ¨ÿπÿ©
- **Emergence:** ÿßŸÑÿ≥ŸÑŸàŸÉ ÿßŸÑŸÉŸÑŸä ŸäÿÆÿ™ŸÑŸÅ ÿπŸÜ ŸÖÿ¨ŸÖŸàÿπ ÿßŸÑÿ£ÿ¨ÿ≤ÿßÿ°
- **Delays:** ÿßŸÑÿ™ÿ£ÿ´Ÿäÿ±ÿßÿ™ ŸÇÿØ ÿ™ÿ∏Ÿáÿ± ÿ®ÿπÿØ ŸàŸÇÿ™

**Example:**

```typescript
{
  "system": "e-commerce_platform",
  "components": {
    "users": {
      "behavior": "Purchase products",
      "affects": ["inventory", "revenue", "shipping"]
    },
    "inventory": {
      "behavior": "Track stock",
      "affects": ["product_availability", "purchasing"],
      "feedback_loop": "Low stock ‚Üí Reorder ‚Üí High stock"
    },
    "pricing": {
      "behavior": "Dynamic pricing",
      "affects": ["demand", "revenue"],
      "feedback_loop": "High demand ‚Üí Higher price ‚Üí Lower demand"
    },
    "shipping": {
      "behavior": "Deliver orders",
      "affects": ["customer_satisfaction", "costs"],
      "delay": "2-5 days"
    }
  },
  "emergent_properties": [
    "Customer lifetime value",
    "Platform reputation",
    "Market position"
  ]
}
```

---

PARETO PRINCIPLE (80/20 RULE)
-----------------------------

**Concept:** 80% ŸÖŸÜ ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿ™ÿ£ÿ™Ÿä ŸÖŸÜ 20% ŸÖŸÜ ÿßŸÑÿ¨ŸáÿØ

**Application:**
- **Features:** 20% ŸÖŸÜ ÿßŸÑŸÖŸäÿ≤ÿßÿ™ ÿ™ÿ≥ÿ™ÿÆÿØŸÖ 80% ŸÖŸÜ ÿßŸÑŸàŸÇÿ™
- **Bugs:** 20% ŸÖŸÜ ÿßŸÑÿ£ŸÉŸàÿßÿØ ÿ™ÿ≥ÿ®ÿ® 80% ŸÖŸÜ ÿßŸÑÿ£ÿÆÿ∑ÿßÿ°
- **Performance:** 20% ŸÖŸÜ ÿßŸÑŸÉŸàÿØ Ÿäÿ≥ÿ™ŸáŸÑŸÉ 80% ŸÖŸÜ ÿßŸÑŸÖŸàÿßÿ±ÿØ
- **Users:** 20% ŸÖŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ŸäŸàŸÑÿØŸàŸÜ 80% ŸÖŸÜ ÿßŸÑŸÇŸäŸÖÿ©

**Example:**

```python
# Identify high-impact areas
def apply_pareto_principle(project):
    # Analyze features
    features = analyze_feature_usage()
    top_20_percent = features[:len(features)//5]
    
    # Focus optimization efforts
    optimization_plan = {
        "high_priority": [
            f for f in top_20_percent
            if f.usage > 0.8 and f.performance < 0.8
        ],
        "medium_priority": [...],
        "low_priority": [...]
    }
    
    return optimization_plan
```

---

OCCAM'S RAZOR
-------------

**Concept:** ÿßŸÑÿ≠ŸÑ ÿßŸÑÿ£ÿ®ÿ≥ÿ∑ ÿπÿßÿØÿ© ŸáŸà ÿßŸÑÿ£ŸÅÿ∂ŸÑ

**Application:**
- ÿπŸÜÿØ ÿßŸÑÿ™ÿµŸÖŸäŸÖ: ÿßÿÆÿ™ÿ± ÿßŸÑÿ≠ŸÑ ÿßŸÑÿ£ÿ®ÿ≥ÿ∑ ÿßŸÑÿ∞Ÿä Ÿäÿ≠ŸÑ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©
- ÿπŸÜÿØ ÿßŸÑÿ™ÿµÿ≠Ÿäÿ≠: ÿßÿ®ÿØÿ£ ÿ®ÿßŸÑÿ£ÿ≥ÿ®ÿßÿ® ÿßŸÑÿ£ŸÉÿ´ÿ± ÿßÿ≠ÿ™ŸÖÿßŸÑÿßŸã
- ÿπŸÜÿØ ÿßŸÑÿ™ÿ≠ÿ≥ŸäŸÜ: ŸÑÿß ÿ™ÿ∂ŸÅ ÿ™ÿπŸÇŸäÿØ ÿ∫Ÿäÿ± ÿ∂ÿ±Ÿàÿ±Ÿä

**Example:**

```python
# Problem: Slow API response

# Complex solution:
"Add caching layer + CDN + Load balancer + Database replication"

# Occam's Razor: Start simple
steps = [
    "1. Profile the code - find the bottleneck",
    "2. Optimize the bottleneck",
    "3. Measure improvement",
    "4. If still slow, add caching",
    "5. If still slow, consider infrastructure"
]

# Often, the bottleneck is a simple N+1 query or missing index
```

================================================================================
RESOURCES
================================================================================

### Books
- "Thinking, Fast and Slow" by Daniel Kahneman
- "The Art of Problem Solving" by Russell L. Ackoff
- "Systems Thinking" by Donella H. Meadows
- "Design Patterns" by Gang of Four

### Online Resources
- **Problem Solving:** https://www.problemsolving.com/
- **Design Patterns:** https://refactoring.guru/design-patterns
- **Systems Thinking:** https://thesystemsthinker.com/

### Tools
- **Mermaid:** For diagrams
- **PlantUML:** For UML diagrams
- **Draw.io:** For flowcharts

================================================================================
END OF MODULE 17: THINKING FRAMEWORK
================================================================================



================================================================================
END OF 17_THINKING_FRAMEWORK
================================================================================


================================================================================
MODULE: 18_TASK_AI
================================================================================

================================================================================
MODULE 18: TASK AI & AUTOMATION
================================================================================

OVERVIEW
--------
Ÿáÿ∞ÿß ÿßŸÑŸÖŸàÿØŸàŸÑ ŸäŸàŸÅÿ± ŸÜÿ∏ÿßŸÖ ÿ∞ŸÉŸä ŸÑÿ•ÿØÿßÿ±ÿ© ÿßŸÑŸÖŸáÿßŸÖ ŸàÿßŸÑÿ£ÿ™ŸÖÿ™ÿ© ÿßŸÑŸÉÿßŸÖŸÑÿ© ŸÑÿ≥Ÿäÿ± ÿßŸÑÿπŸÖŸÑÿå
ŸäŸÖŸÉŸëŸÜ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÖŸÜ ÿ•ŸÜÿ¥ÿßÿ°ÿå ÿ™ÿ±ÿ™Ÿäÿ®ÿå ÿ™ÿπŸäŸäŸÜÿå Ÿàÿ™ÿ™ÿ®ÿπ ÿßŸÑŸÖŸáÿßŸÖ ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã.

CORE PHILOSOPHY
---------------
"Automate the routine, focus on the creative"

ÿßŸÑŸÜÿ∏ÿßŸÖ Ÿäÿ¨ÿ® ÿ£ŸÜ:
- ŸäŸÜÿ¥ÿ¶ ÿßŸÑŸÖŸáÿßŸÖ ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã ÿπŸÜÿØ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿßŸÑÿ≠ÿßÿ¨ÿ©
- Ÿäÿ±ÿ™ÿ® ÿßŸÑÿ£ŸàŸÑŸàŸäÿßÿ™ ÿ®ÿ∞ŸÉÿßÿ°
- ŸäÿπŸäŸÜ ÿßŸÑŸÖŸáÿßŸÖ ŸÑŸÑÿ£ÿ¥ÿÆÿßÿµ ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ŸäŸÜ
- Ÿäÿ™ÿ™ÿ®ÿπ ÿßŸÑÿ™ŸÇÿØŸÖ ŸàŸäÿ≠ÿØÿ´ ÿßŸÑÿ≠ÿßŸÑÿ©
- Ÿäÿ™ÿπŸÑŸÖ ŸÖŸÜ ÿßŸÑÿ£ŸÜŸÖÿßÿ∑ ŸàŸäÿ≠ÿ≥ŸÜ ÿßŸÑÿ£ÿØÿßÿ°

================================================================================
SECTION 1: INTELLIGENT TASK MANAGER
================================================================================

OVERVIEW
--------
ŸÖÿØŸäÿ± ŸÖŸáÿßŸÖ ÿ∞ŸÉŸä ŸäŸÅŸáŸÖ ÿßŸÑÿ≥ŸäÿßŸÇ ŸàŸäÿ™ÿÆÿ∞ ŸÇÿ±ÿßÿ±ÿßÿ™ ÿ™ŸÑŸÇÿßÿ¶Ÿäÿ©.

AUTO TASK CREATION
------------------

### Trigger-Based Creation

```typescript
{
  "auto_task_creation": {
    "triggers": [
      {
        "event": "error_detected",
        "source": "sentry",
        "action": "create_bug_task",
        "template": {
          "title": "Fix: {{error.message}}",
          "description": "Error detected in {{error.file}}:{{error.line}}\n\nStack trace:\n{{error.stack}}",
          "type": "bug",
          "priority": "{{calculate_priority(error.severity)}}",
          "labels": ["bug", "auto-created", "{{error.component}}"],
          "assigned_to": "{{find_last_modifier(error.file)}}"
        }
      },
      {
        "event": "feature_requested",
        "source": "github.issues",
        "action": "create_feature_task",
        "template": {
          "title": "Feature: {{issue.title}}",
          "description": "{{issue.body}}",
          "type": "feature",
          "priority": "{{analyze_priority(issue)}}",
          "labels": ["feature", "{{issue.labels}}"],
          "assigned_to": "{{suggest_owner(issue)}}"
        }
      },
      {
        "event": "code_smell_found",
        "source": "code-analysis",
        "action": "create_refactor_task",
        "template": {
          "title": "Refactor: {{smell.description}}",
          "description": "Code smell detected:\n- Type: {{smell.type}}\n- Location: {{smell.file}}:{{smell.line}}\n- Severity: {{smell.severity}}",
          "type": "refactor",
          "priority": "{{smell.severity}}",
          "labels": ["refactor", "code-quality"],
          "assigned_to": "{{find_expert(smell.area)}}"
        }
      },
      {
        "event": "security_issue",
        "source": "security-scan",
        "action": "create_security_task",
        "template": {
          "title": "Security: {{issue.title}}",
          "description": "Security vulnerability found:\n- CVE: {{issue.cve}}\n- Severity: {{issue.severity}}\n- Package: {{issue.package}}\n- Fix: {{issue.fix}}",
          "type": "security",
          "priority": "critical",
          "labels": ["security", "urgent"],
          "assigned_to": "security_team"
        }
      },
      {
        "event": "test_coverage_low",
        "source": "coverage-report",
        "action": "create_test_task",
        "template": {
          "title": "Improve test coverage for {{file}}",
          "description": "Current coverage: {{coverage}}%\nTarget: 80%\n\nUncovered lines:\n{{uncovered_lines}}",
          "type": "test",
          "priority": "medium",
          "labels": ["testing", "coverage"],
          "assigned_to": "{{find_owner(file)}}"
        }
      },
      {
        "event": "dependency_outdated",
        "source": "dependency-check",
        "action": "create_update_task",
        "template": {
          "title": "Update {{package}} to {{latest_version}}",
          "description": "Current: {{current_version}}\nLatest: {{latest_version}}\n\nChangelog:\n{{changelog}}",
          "type": "maintenance",
          "priority": "{{assess_update_priority(package)}}",
          "labels": ["dependencies", "maintenance"],
          "assigned_to": "{{find_maintainer()}}"
        }
      }
    ]
  }
}
```

### Implementation

```python
# Auto Task Creation System
class TaskAI:
    def __init__(self):
        self.triggers = load_triggers()
        self.task_queue = TaskQueue()
        self.github = GitHubClient()
        
    def on_event(self, event_type, event_data):
        """Handle incoming events and create tasks"""
        # Find matching triggers
        triggers = [t for t in self.triggers if t['event'] == event_type]
        
        for trigger in triggers:
            # Create task from template
            task = self.create_task_from_template(
                trigger['template'],
                event_data
            )
            
            # Add to queue
            self.task_queue.add(task)
            
            # Create GitHub issue
            if trigger.get('create_github_issue'):
                self.github.create_issue(task)
            
            # Notify assignee
            self.notify_assignee(task)
    
    def create_task_from_template(self, template, data):
        """Create task by filling template with data"""
        task = {}
        
        for key, value in template.items():
            if isinstance(value, str) and '{{' in value:
                # Replace template variables
                task[key] = self.render_template(value, data)
            else:
                task[key] = value
        
        return task
    
    def render_template(self, template, data):
        """Render template with data"""
        import re
        
        def replace_var(match):
            var = match.group(1)
            
            # Handle function calls
            if '(' in var:
                func_name = var.split('(')[0]
                func = getattr(self, func_name)
                args = eval(var.split('(')[1].rstrip(')'))
                return str(func(args))
            
            # Handle nested access
            parts = var.split('.')
            value = data
            for part in parts:
                value = value.get(part, '')
            
            return str(value)
        
        return re.sub(r'\{\{(.+?)\}\}', replace_var, template)
```

---

## SMART PRIORITY CALCULATION

```python
def calculate_priority(error_severity, impact, urgency):
    """Calculate task priority using multiple factors"""
    
    # Severity score (0-10)
    severity_scores = {
        'critical': 10,
        'high': 7,
        'medium': 5,
        'low': 2
    }
    severity_score = severity_scores.get(error_severity, 5)
    
    # Impact score (0-10)
    impact_score = impact  # users affected, revenue impact, etc.
    
    # Urgency score (0-10)
    urgency_score = urgency  # deadline, SLA, etc.
    
    # Weighted calculation
    priority_score = (
        severity_score * 0.4 +
        impact_score * 0.4 +
        urgency_score * 0.2
    )
    
    # Map to priority level
    if priority_score >= 8:
        return 'critical'
    elif priority_score >= 6:
        return 'high'
    elif priority_score >= 4:
        return 'medium'
    else:
        return 'low'
```

================================================================================
SECTION 2: AUTO-PRIORITIZATION
================================================================================

OVERVIEW
--------
ŸÜÿ∏ÿßŸÖ ÿ∞ŸÉŸä ŸÑÿ™ÿ±ÿ™Ÿäÿ® ÿ£ŸàŸÑŸàŸäÿßÿ™ ÿßŸÑŸÖŸáÿßŸÖ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿπŸàÿßŸÖŸÑ ŸÖÿ™ÿπÿØÿØÿ©.

PRIORITIZATION ALGORITHMS
-------------------------

### 1. Eisenhower Matrix

```python
def eisenhower_matrix(task):
    """Categorize task using Eisenhower Matrix"""
    
    urgent = task.deadline_soon or task.blocking_others
    important = task.impact_high or task.strategic_value
    
    if urgent and important:
        return {
            'quadrant': 'Q1 - Do First',
            'priority': 'critical',
            'action': 'execute_immediately'
        }
    elif not urgent and important:
        return {
            'quadrant': 'Q2 - Schedule',
            'priority': 'high',
            'action': 'schedule_for_later'
        }
    elif urgent and not important:
        return {
            'quadrant': 'Q3 - Delegate',
            'priority': 'medium',
            'action': 'delegate_to_team'
        }
    else:
        return {
            'quadrant': 'Q4 - Eliminate',
            'priority': 'low',
            'action': 'consider_removing'
        }
```

---

### 2. Weighted Scoring

```python
def weighted_scoring(task):
    """Calculate priority using weighted factors"""
    
    factors = {
        'business_value': {
            'weight': 0.25,
            'score': task.business_value  # 0-10
        },
        'urgency': {
            'weight': 0.20,
            'score': calculate_urgency(task.deadline)
        },
        'complexity': {
            'weight': 0.15,
            'score': 10 - task.complexity  # Lower complexity = higher priority
        },
        'dependencies': {
            'weight': 0.15,
            'score': count_blocked_tasks(task)
        },
        'risk': {
            'weight': 0.15,
            'score': task.risk_level
        },
        'effort': {
            'weight': 0.10,
            'score': 10 - task.estimated_effort  # Lower effort = higher priority
        }
    }
    
    total_score = sum(
        f['weight'] * f['score']
        for f in factors.values()
    )
    
    return {
        'score': total_score,
        'priority': score_to_priority(total_score),
        'factors': factors
    }
```

---

### 3. RICE Framework

```python
def rice_score(task):
    """Calculate RICE score (Reach, Impact, Confidence, Effort)"""
    
    reach = task.users_affected  # How many users?
    impact = task.impact_score  # 0.25, 0.5, 1, 2, 3
    confidence = task.confidence  # 0-100%
    effort = task.estimated_hours  # Person-hours
    
    rice = (reach * impact * confidence) / effort
    
    return {
        'rice_score': rice,
        'priority': rice_to_priority(rice),
        'breakdown': {
            'reach': reach,
            'impact': impact,
            'confidence': confidence,
            'effort': effort
        }
    }
```

---

### 4. Dynamic Re-Prioritization

```python
class DynamicPrioritizer:
    def __init__(self):
        self.tasks = []
        self.context = {}
    
    def reprioritize(self, event=None):
        """Re-prioritize all tasks based on current context"""
        
        # Update context
        if event:
            self.update_context(event)
        
        # Re-calculate priorities
        for task in self.tasks:
            # Get current priority
            old_priority = task.priority
            
            # Calculate new priority
            new_priority = self.calculate_priority(task, self.context)
            
            # Update if changed
            if new_priority != old_priority:
                task.priority = new_priority
                self.notify_priority_change(task, old_priority, new_priority)
        
        # Re-sort tasks
        self.tasks.sort(key=lambda t: t.priority_score, reverse=True)
    
    def update_context(self, event):
        """Update context based on events"""
        if event['type'] == 'deadline_approaching':
            self.context['urgency_multiplier'] = 1.5
        elif event['type'] == 'production_issue':
            self.context['critical_mode'] = True
        elif event['type'] == 'team_capacity_low':
            self.context['focus_on_quick_wins'] = True
```

================================================================================
SECTION 3: WORKFLOW AUTOMATION
================================================================================

OVERVIEW
--------
ÿ£ÿ™ŸÖÿ™ÿ© ŸÉÿßŸÖŸÑÿ© ŸÑÿ≥Ÿäÿ± ÿßŸÑÿπŸÖŸÑ ŸÖŸÜ ÿßŸÑÿ®ÿØÿßŸäÿ© ŸÑŸÑŸÜŸáÿßŸäÿ©.

AUTOMATED WORKFLOWS
------------------

### 1. Complete Bug Fix Automation

```typescript
{
  "workflow": "automated_bug_fix",
  "trigger": "error_detected",
  "steps": [
    {
      "phase": "Detection",
      "auto": true,
      "actions": [
        {
          "tool": "sentry.get_issue_details",
          "output": "error_details"
        },
        {
          "tool": "code-analysis.find_root_cause",
          "input": "{{error_details}}",
          "output": "root_cause"
        }
      ]
    },
    {
      "phase": "Task Creation",
      "auto": true,
      "actions": [
        {
          "tool": "taskqueue.add_task",
          "input": {
            "title": "Fix: {{error_details.message}}",
            "priority": "{{calculate_priority(error_details)}}",
            "assigned_to": "{{find_expert(root_cause)}}"
          },
          "output": "task_id"
        },
        {
          "tool": "github.create_issue",
          "input": {
            "title": "Bug: {{error_details.message}}",
            "body": "{{format_bug_report(error_details, root_cause)}}",
            "labels": ["bug", "auto-created"]
          },
          "output": "github_issue"
        }
      ]
    },
    {
      "phase": "Notification",
      "auto": true,
      "actions": [
        {
          "tool": "slack.send_message",
          "input": {
            "channel": "#bugs",
            "message": "New bug detected: {{error_details.message}}\nAssigned to: {{task.assigned_to}}\nGitHub: {{github_issue.url}}"
          }
        }
      ]
    },
    {
      "phase": "Monitoring",
      "auto": true,
      "actions": [
        {
          "tool": "sentry.monitor_issue",
          "input": {"issue_id": "{{error_details.id}}"},
          "duration": "24h"
        }
      ]
    },
    {
      "phase": "Auto-Close",
      "auto": true,
      "condition": "{{no_new_errors_for_24h}}",
      "actions": [
        {
          "tool": "taskqueue.complete_task",
          "input": {"task_id": "{{task_id}}"}
        },
        {
          "tool": "github.close_issue",
          "input": {"issue_number": "{{github_issue.number}}"}
        },
        {
          "tool": "slack.send_message",
          "input": {
            "channel": "#bugs",
            "message": "Bug automatically resolved: {{error_details.message}}"
          }
        }
      ]
    }
  ]
}
```

---

### 2. Code Quality Automation

```typescript
{
  "workflow": "code_quality_automation",
  "trigger": "on_commit || scheduled_daily",
  "steps": [
    {
      "phase": "Analysis",
      "auto": true,
      "parallel": true,
      "actions": [
        {"tool": "ruff.check_project", "output": "python_issues"},
        {"tool": "eslint.lint_directory", "output": "js_issues"},
        {"tool": "code-analysis.security_scan", "output": "security_issues"},
        {"tool": "code-analysis.find_dead_code", "output": "dead_code"}
      ]
    },
    {
      "phase": "Auto-Fix",
      "auto": true,
      "actions": [
        {
          "tool": "ruff.fix_issues",
          "input": "{{python_issues.auto_fixable}}",
          "output": "python_fixed"
        },
        {
          "tool": "eslint.fix_issues",
          "input": "{{js_issues.auto_fixable}}",
          "output": "js_fixed"
        }
      ]
    },
    {
      "phase": "Task Creation",
      "auto": true,
      "condition": "{{has_unfixable_issues}}",
      "actions": [
        {
          "tool": "taskqueue.bulk_add_tasks",
          "input": {
            "tasks": "{{generate_tasks_from_issues(python_issues, js_issues, security_issues)}}"
          }
        }
      ]
    },
    {
      "phase": "Reporting",
      "auto": true,
      "actions": [
        {
          "tool": "github.create_pr",
          "condition": "{{python_fixed || js_fixed}}",
          "input": {
            "title": "Auto-fix: Code quality improvements",
            "body": "Automatically fixed issues:\n{{format_fixes(python_fixed, js_fixed)}}",
            "labels": ["auto-fix", "code-quality"]
          }
        },
        {
          "tool": "slack.send_message",
          "input": {
            "channel": "#code-quality",
            "message": "Daily code quality report:\n{{format_report(python_issues, js_issues, security_issues)}}"
          }
        }
      ]
    }
  ]
}
```

---

### 3. Deployment Automation

```typescript
{
  "workflow": "automated_deployment",
  "trigger": "pr_merged_to_main",
  "steps": [
    {
      "phase": "Pre-Deployment Checks",
      "auto": true,
      "actions": [
        {
          "tool": "playwright.test_all",
          "fail_on_error": true
        },
        {
          "tool": "code-analysis.security_scan",
          "fail_on_critical": true
        },
        {
          "tool": "ruff.check_project",
          "fail_on_error": true
        }
      ]
    },
    {
      "phase": "Build",
      "auto": true,
      "actions": [
        {
          "tool": "docker.build_image",
          "input": {"tag": "{{git.commit_sha}}"}
        }
      ]
    },
    {
      "phase": "Deploy to Staging",
      "auto": true,
      "actions": [
        {
          "tool": "cloudflare.deploy",
          "input": {"environment": "staging"}
        },
        {
          "tool": "playwright.test_all",
          "input": {"environment": "staging"}
        }
      ]
    },
    {
      "phase": "Deploy to Production",
      "auto": false,
      "require_approval": true,
      "actions": [
        {
          "tool": "cloudflare.deploy",
          "input": {"environment": "production"}
        },
        {
          "tool": "sentry.create_release",
          "input": {"version": "{{git.commit_sha}}"}
        }
      ]
    },
    {
      "phase": "Post-Deployment",
      "auto": true,
      "actions": [
        {
          "tool": "sentry.monitor",
          "duration": "1h"
        },
        {
          "tool": "cloudflare.get_metrics",
          "duration": "1h"
        },
        {
          "tool": "slack.send_message",
          "input": {
            "channel": "#deployments",
            "message": "Deployed {{git.commit_sha}} to production\n{{format_metrics()}}"
          }
        }
      ]
    }
  ]
}
```

================================================================================
SECTION 4: PROGRESS TRACKING
================================================================================

OVERVIEW
--------
ÿ™ÿ™ÿ®ÿπ ÿ™ŸÑŸÇÿßÿ¶Ÿä ŸÑÿ™ŸÇÿØŸÖ ÿßŸÑŸÖŸáÿßŸÖ ŸàÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ.

AUTO PROGRESS UPDATES
---------------------

```python
class ProgressTracker:
    def __init__(self):
        self.tasks = {}
        self.projects = {}
    
    def track_task(self, task_id):
        """Track task progress automatically"""
        task = self.get_task(task_id)
        
        # Monitor various signals
        signals = {
            'git_commits': self.count_commits(task),
            'pr_status': self.get_pr_status(task),
            'test_results': self.get_test_results(task),
            'code_changes': self.analyze_code_changes(task),
            'time_spent': self.calculate_time_spent(task)
        }
        
        # Update progress
        progress = self.calculate_progress(signals)
        task.progress = progress
        
        # Update status
        new_status = self.determine_status(task, signals)
        if new_status != task.status:
            self.update_status(task, new_status)
        
        # Check for blockers
        blockers = self.detect_blockers(task, signals)
        if blockers:
            self.handle_blockers(task, blockers)
        
        return {
            'progress': progress,
            'status': new_status,
            'signals': signals,
            'blockers': blockers
        }
    
    def calculate_progress(self, signals):
        """Calculate task progress percentage"""
        factors = []
        
        # Code changes
        if signals['code_changes']:
            factors.append(min(signals['code_changes'] / 100, 1.0) * 30)
        
        # Tests
        if signals['test_results']:
            factors.append(signals['test_results']['pass_rate'] * 30)
        
        # PR status
        if signals['pr_status'] == 'approved':
            factors.append(20)
        elif signals['pr_status'] == 'open':
            factors.append(10)
        
        # Commits
        if signals['git_commits'] > 0:
            factors.append(min(signals['git_commits'] / 5, 1.0) * 20)
        
        return min(sum(factors), 100)
    
    def detect_blockers(self, task, signals):
        """Detect potential blockers"""
        blockers = []
        
        # No activity for 3 days
        if signals['time_spent'] == 0 and task.age_days > 3:
            blockers.append({
                'type': 'no_activity',
                'severity': 'medium',
                'message': 'No activity for 3 days'
            })
        
        # Tests failing
        if signals['test_results'] and signals['test_results']['pass_rate'] < 0.8:
            blockers.append({
                'type': 'failing_tests',
                'severity': 'high',
                'message': f"Only {signals['test_results']['pass_rate']*100}% tests passing"
            })
        
        # PR not reviewed
        if signals['pr_status'] == 'open' and task.age_days > 2:
            blockers.append({
                'type': 'needs_review',
                'severity': 'medium',
                'message': 'PR waiting for review'
            })
        
        return blockers
```

---

## AUTOMATED REPORTING

```python
def generate_progress_report(project_id):
    """Generate automated progress report"""
    
    project = get_project(project_id)
    tasks = get_project_tasks(project_id)
    
    # Calculate metrics
    metrics = {
        'total_tasks': len(tasks),
        'completed': len([t for t in tasks if t.status == 'done']),
        'in_progress': len([t for t in tasks if t.status == 'in_progress']),
        'blocked': len([t for t in tasks if t.status == 'blocked']),
        'not_started': len([t for t in tasks if t.status == 'todo']),
        'completion_rate': calculate_completion_rate(tasks),
        'velocity': calculate_velocity(tasks),
        'estimated_completion': estimate_completion_date(tasks)
    }
    
    # Identify issues
    issues = []
    
    if metrics['blocked'] > 0:
        issues.append(f"{metrics['blocked']} tasks are blocked")
    
    if metrics['velocity'] < project.target_velocity:
        issues.append(f"Velocity ({metrics['velocity']}) below target ({project.target_velocity})")
    
    # Generate report
    report = f"""
# Progress Report: {project.name}

## Overview
- Total Tasks: {metrics['total_tasks']}
- Completed: {metrics['completed']} ({metrics['completion_rate']}%)
- In Progress: {metrics['in_progress']}
- Blocked: {metrics['blocked']}
- Not Started: {metrics['not_started']}

## Velocity
- Current: {metrics['velocity']} tasks/week
- Target: {project.target_velocity} tasks/week

## Estimated Completion
{metrics['estimated_completion']}

## Issues
{format_issues(issues)}

## Top Tasks
{format_top_tasks(tasks)}
"""
    
    return report
```

================================================================================
SECTION 5: TEAM COLLABORATION
================================================================================

OVERVIEW
--------
ÿ™ÿ≥ŸáŸäŸÑ ÿßŸÑÿ™ÿπÿßŸàŸÜ ÿ®ŸäŸÜ ÿ£ÿπÿ∂ÿßÿ° ÿßŸÑŸÅÿ±ŸäŸÇ.

AUTO ASSIGNMENT
--------------

```python
def auto_assign_task(task):
    """Automatically assign task to best team member"""
    
    # Get team members
    team = get_team_members()
    
    # Score each member
    scores = {}
    for member in team:
        score = 0
        
        # Expertise match
        if task.required_skills & member.skills:
            score += 40
        
        # Availability
        if member.current_workload < member.capacity:
            score += 30
        
        # Past performance
        if task.type in member.successful_tasks:
            score += 20
        
        # Interest
        if task.area in member.interests:
            score += 10
        
        scores[member.id] = score
    
    # Select best member
    best_member = max(scores, key=scores.get)
    
    return {
        'assigned_to': best_member,
        'score': scores[best_member],
        'rationale': explain_assignment(best_member, task, scores)
    }
```

================================================================================
RESOURCES
================================================================================

### Task Management Tools
- **Jira:** https://www.atlassian.com/software/jira
- **Linear:** https://linear.app/
- **Asana:** https://asana.com/

### Automation Tools
- **Zapier:** https://zapier.com/
- **n8n:** https://n8n.io/
- **GitHub Actions:** https://github.com/features/actions

================================================================================
END OF MODULE 18: TASK AI & AUTOMATION
================================================================================



================================================================================
END OF 18_TASK_AI
================================================================================


================================================================================
MODULE: 19_CONTEXT_ENGINEERING
================================================================================

================================================================================
MODULE 19: CONTEXT ENGINEERING & LEARNING SYSTEM
================================================================================

OVERVIEW
--------
Ÿáÿ∞ÿß ÿßŸÑŸÖŸàÿØŸàŸÑ ŸäŸàŸÅÿ± ŸÜÿ∏ÿßŸÖ ŸáŸÜÿØÿ≥ÿ© ÿßŸÑÿ≥ŸäÿßŸÇ ŸàÿßŸÑÿ™ÿπŸÑŸÖ ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ±ÿå ŸäŸÖŸÉŸëŸÜ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä
ŸÖŸÜ ŸÅŸáŸÖ ÿßŸÑÿ≥ŸäÿßŸÇ ÿ®ÿπŸÖŸÇÿå ÿßÿ™ÿÆÿßÿ∞ ŸÇÿ±ÿßÿ±ÿßÿ™ ÿ∞ŸÉŸäÿ©ÿå ÿßŸÑÿ™ŸÉŸäŸÅ ŸÖÿπ ÿßŸÑŸÖŸàÿßŸÇŸÅÿå ŸàÿßŸÑÿ™ÿπŸÑŸÖ ŸÖŸÜ ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ®.

CORE PHILOSOPHY
---------------
"Understand deeply, decide wisely, adapt continuously, learn constantly"

ÿßŸÑŸÜÿ∏ÿßŸÖ Ÿäÿ¨ÿ® ÿ£ŸÜ:
- ŸäŸÅŸáŸÖ ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÉÿßŸÖŸÑ ŸÇÿ®ŸÑ ÿßÿ™ÿÆÿßÿ∞ ÿßŸÑŸÇÿ±ÿßÿ±ÿßÿ™
- Ÿäÿ™ÿÆÿ∞ ŸÇÿ±ÿßÿ±ÿßÿ™ ŸÖÿ®ŸÜŸäÿ© ÿπŸÑŸâ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ŸàÿßŸÑÿ™ÿ¨ÿßÿ±ÿ®
- Ÿäÿ™ŸÉŸäŸÅ ŸÖÿπ ÿßŸÑÿ™ÿ∫ŸäŸäÿ±ÿßÿ™ ŸàÿßŸÑŸÖŸàÿßŸÇŸÅ ÿßŸÑÿ¨ÿØŸäÿØÿ©
- Ÿäÿ™ÿπŸÑŸÖ ŸÖŸÜ ÿßŸÑŸÜÿ¨ÿßÿ≠ÿßÿ™ ŸàÿßŸÑÿ•ÿÆŸÅÿßŸÇÿßÿ™
- Ÿäÿ≠ÿ≥ŸÜ ÿ£ÿØÿßÿ°Ÿá ÿ®ÿ¥ŸÉŸÑ ŸÖÿ≥ÿ™ŸÖÿ±

================================================================================
SECTION 1: CONTEXT AWARENESS
================================================================================

OVERVIEW
--------
ŸÅŸáŸÖ ÿ¥ÿßŸÖŸÑ ŸÑŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠Ÿäÿ∑ ÿ®ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ ŸàÿßŸÑŸÖŸáŸÖÿ© ÿßŸÑÿ≠ÿßŸÑŸäÿ©.

MULTI-DIMENSIONAL CONTEXT
-------------------------

```typescript
{
  "context_dimensions": {
    "project_context": {
      "name": "string",
      "type": "web_app | mobile_app | api | library | tool",
      "phase": "planning | development | testing | deployment | maintenance",
      "size": "small | medium | large | enterprise",
      "complexity": "low | medium | high | very_high",
      "tech_stack": {
        "frontend": ["React", "TypeScript", "Tailwind"],
        "backend": ["FastAPI", "Python", "PostgreSQL"],
        "infrastructure": ["Docker", "Cloudflare", "GitHub Actions"]
      },
      "team": {
        "size": 5,
        "experience": "junior | mid | senior | mixed",
        "timezone": "UTC+2",
        "availability": "full_time | part_time"
      }
    },
    
    "code_context": {
      "languages": ["Python", "TypeScript", "SQL"],
      "frameworks": ["FastAPI", "React", "Prisma"],
      "architecture": "microservices | monolith | serverless",
      "design_patterns": ["Repository", "Factory", "Observer"],
      "code_quality": {
        "test_coverage": 85,
        "maintainability_index": 78,
        "technical_debt_ratio": 5.2,
        "code_smells": 12
      },
      "dependencies": {
        "total": 45,
        "outdated": 3,
        "vulnerable": 0
      }
    },
    
    "task_context": {
      "current_task": {
        "id": "TASK-123",
        "type": "bug | feature | refactor | test | docs",
        "priority": "low | medium | high | critical",
        "complexity": "low | medium | high",
        "estimated_effort": "hours",
        "actual_effort": "hours",
        "progress": 45,
        "blockers": []
      },
      "related_tasks": ["TASK-120", "TASK-121"],
      "dependencies": ["TASK-100"],
      "blocked_by": [],
      "blocking": ["TASK-125"]
    },
    
    "environment_context": {
      "current_environment": "local | staging | production",
      "available_tools": [
        "playwright", "ruff", "eslint", "sentry",
        "github", "cloudflare", "context7"
      ],
      "resource_limits": {
        "memory": "8GB",
        "cpu": "4 cores",
        "storage": "256GB"
      },
      "network": {
        "internet": true,
        "vpn": false,
        "proxy": false
      }
    },
    
    "business_context": {
      "objectives": [
        "Increase user engagement",
        "Reduce technical debt",
        "Improve performance"
      ],
      "constraints": {
        "budget": "limited",
        "timeline": "tight",
        "resources": "constrained"
      },
      "stakeholders": [
        {"role": "Product Manager", "priority": "features"},
        {"role": "CTO", "priority": "quality"},
        {"role": "Users", "priority": "performance"}
      ]
    },
    
    "historical_context": {
      "similar_tasks_completed": 15,
      "success_rate": 87,
      "common_issues": ["Performance", "Edge cases"],
      "lessons_learned": [
        "Always write tests first",
        "Profile before optimizing",
        "Document complex logic"
      ]
    }
  }
}
```

---

## CONTEXT GATHERING

```python
class ContextEngine:
    def __init__(self):
        self.context = {}
        self.tools = self.init_tools()
    
    async def gather_full_context(self):
        """Gather complete context from all sources"""
        
        # Gather in parallel
        results = await asyncio.gather(
            self.gather_project_context(),
            self.gather_code_context(),
            self.gather_task_context(),
            self.gather_environment_context(),
            self.gather_business_context(),
            self.gather_historical_context()
        )
        
        self.context = {
            'project': results[0],
            'code': results[1],
            'task': results[2],
            'environment': results[3],
            'business': results[4],
            'historical': results[5],
            'timestamp': datetime.now(),
            'confidence': self.calculate_confidence()
        }
        
        return self.context
    
    async def gather_code_context(self):
        """Gather code-related context"""
        return {
            'quality': await self.tools.ruff.check_project(),
            'coverage': await self.tools.pytest.get_coverage(),
            'complexity': await self.tools.code_analysis.measure_complexity(),
            'dependencies': await self.tools.pip.list_packages(),
            'security': await self.tools.security_scan.check()
        }
    
    async def gather_historical_context(self):
        """Gather historical data"""
        return {
            'similar_tasks': await self.tools.github.search_similar_issues(),
            'past_solutions': await self.learning_system.get_solutions(),
            'lessons': await self.learning_system.get_lessons(),
            'patterns': await self.learning_system.get_patterns()
        }
```

================================================================================
SECTION 2: INTELLIGENT DECISION MAKING
================================================================================

OVERVIEW
--------
ÿßÿ™ÿÆÿßÿ∞ ŸÇÿ±ÿßÿ±ÿßÿ™ ÿ∞ŸÉŸäÿ© ŸÖÿ®ŸÜŸäÿ© ÿπŸÑŸâ ÿßŸÑÿ≥ŸäÿßŸÇ ŸàÿßŸÑÿ®ŸäÿßŸÜÿßÿ™.

DECISION FRAMEWORK
-----------------

```python
class DecisionEngine:
    def __init__(self, context_engine, learning_system):
        self.context = context_engine
        self.learning = learning_system
        self.rules = self.load_decision_rules()
    
    def make_decision(self, decision_type, options):
        """Make intelligent decision"""
        
        # Get current context
        context = self.context.get_current()
        
        # Get historical data
        history = self.learning.get_similar_decisions(decision_type)
        
        # Evaluate each option
        scores = {}
        for option in options:
            scores[option] = self.evaluate_option(
                option,
                context,
                history
            )
        
        # Select best option
        best_option = max(scores, key=scores.get)
        
        # Explain decision
        explanation = self.explain_decision(
            best_option,
            scores,
            context
        )
        
        # Record decision for learning
        self.learning.record_decision({
            'type': decision_type,
            'context': context,
            'options': options,
            'scores': scores,
            'selected': best_option,
            'explanation': explanation,
            'timestamp': datetime.now()
        })
        
        return {
            'decision': best_option,
            'confidence': scores[best_option],
            'explanation': explanation,
            'alternatives': sorted(
                scores.items(),
                key=lambda x: x[1],
                reverse=True
            )[1:3]
        }
    
    def evaluate_option(self, option, context, history):
        """Evaluate a single option"""
        score = 0
        
        # Rule-based evaluation
        for rule in self.rules:
            if rule.applies(option, context):
                score += rule.score(option, context)
        
        # Historical performance
        if history:
            similar = [h for h in history if h['option'] == option]
            if similar:
                success_rate = sum(h['success'] for h in similar) / len(similar)
                score += success_rate * 30
        
        # Context fit
        context_score = self.calculate_context_fit(option, context)
        score += context_score * 20
        
        return score
```

---

## DECISION RULES

```python
# Example Decision Rules

class ChooseArchitectureRule:
    def applies(self, option, context):
        return context['decision_type'] == 'architecture'
    
    def score(self, option, context):
        score = 0
        
        # Small project + simple requirements ‚Üí Monolith
        if (context['project']['size'] == 'small' and 
            context['project']['complexity'] == 'low'):
            if option == 'monolith':
                score += 40
        
        # Large project + multiple teams ‚Üí Microservices
        elif (context['project']['size'] == 'large' and 
              context['team']['size'] > 10):
            if option == 'microservices':
                score += 40
        
        # High scalability requirement ‚Üí Microservices
        if 'high_scalability' in context['business']['objectives']:
            if option in ['microservices', 'serverless']:
                score += 30
        
        return score


class ChooseDatabaseRule:
    def applies(self, option, context):
        return context['decision_type'] == 'database'
    
    def score(self, option, context):
        score = 0
        
        # Structured data + ACID ‚Üí PostgreSQL
        if (context['data_type'] == 'structured' and 
            context['needs_acid']):
            if option == 'postgresql':
                score += 40
        
        # Flexible schema + high write ‚Üí MongoDB
        elif (context['schema'] == 'flexible' and 
              context['write_heavy']):
            if option == 'mongodb':
                score += 40
        
        # Time-series data ‚Üí TimescaleDB
        if context['data_type'] == 'time_series':
            if option == 'timescaledb':
                score += 50
        
        return score
```

================================================================================
SECTION 3: ADAPTIVE BEHAVIOR
================================================================================

OVERVIEW
--------
ÿßŸÑÿ™ŸÉŸäŸÅ ŸÖÿπ ÿßŸÑÿ™ÿ∫ŸäŸäÿ±ÿßÿ™ ŸàÿßŸÑŸÖŸàÿßŸÇŸÅ ÿßŸÑÿ¨ÿØŸäÿØÿ©.

ADAPTATION STRATEGIES
--------------------

```python
class AdaptiveSystem:
    def __init__(self):
        self.strategies = {}
        self.current_strategy = None
        self.performance_history = []
    
    def adapt_to_context(self, context):
        """Adapt behavior based on context"""
        
        # Detect context changes
        changes = self.detect_changes(context)
        
        if changes:
            # Select appropriate strategy
            new_strategy = self.select_strategy(context, changes)
            
            if new_strategy != self.current_strategy:
                self.switch_strategy(new_strategy, context)
        
        return self.current_strategy
    
    def detect_changes(self, context):
        """Detect significant context changes"""
        changes = []
        
        if not hasattr(self, 'previous_context'):
            self.previous_context = context
            return changes
        
        prev = self.previous_context
        
        # Project phase changed
        if context['project']['phase'] != prev['project']['phase']:
            changes.append({
                'type': 'phase_change',
                'from': prev['project']['phase'],
                'to': context['project']['phase']
            })
        
        # Priority shift
        if context['task']['priority'] != prev['task']['priority']:
            changes.append({
                'type': 'priority_change',
                'from': prev['task']['priority'],
                'to': context['task']['priority']
            })
        
        # Resource constraints
        if context['business']['constraints'] != prev['business']['constraints']:
            changes.append({
                'type': 'constraints_change',
                'details': context['business']['constraints']
            })
        
        # Performance issues
        if context['code']['quality'] < prev['code']['quality'] - 10:
            changes.append({
                'type': 'quality_degradation',
                'from': prev['code']['quality'],
                'to': context['code']['quality']
            })
        
        self.previous_context = context
        return changes
    
    def select_strategy(self, context, changes):
        """Select appropriate strategy"""
        
        # Critical production issue
        if context['task']['priority'] == 'critical':
            return 'emergency_mode'
        
        # Development phase
        elif context['project']['phase'] == 'development':
            if context['business']['constraints']['timeline'] == 'tight':
                return 'fast_delivery'
            else:
                return 'quality_focused'
        
        # Maintenance phase
        elif context['project']['phase'] == 'maintenance':
            return 'stability_focused'
        
        # Testing phase
        elif context['project']['phase'] == 'testing':
            return 'quality_assurance'
        
        return 'balanced'
```

---

## STRATEGY DEFINITIONS

```typescript
{
  "strategies": {
    "emergency_mode": {
      "description": "Handle critical production issues",
      "priorities": ["Fix immediately", "Minimal testing", "Quick deployment"],
      "tools": ["sentry", "cloudflare", "github"],
      "workflow": "hotfix",
      "quality_threshold": 70,
      "speed_multiplier": 2.0
    },
    
    "fast_delivery": {
      "description": "Deliver quickly with acceptable quality",
      "priorities": ["Speed", "Core features", "Basic testing"],
      "tools": ["ruff", "pytest", "playwright"],
      "workflow": "agile",
      "quality_threshold": 75,
      "speed_multiplier": 1.5
    },
    
    "quality_focused": {
      "description": "Prioritize code quality and maintainability",
      "priorities": ["Quality", "Testing", "Documentation"],
      "tools": ["ruff", "eslint", "pytest", "code-analysis"],
      "workflow": "thorough",
      "quality_threshold": 90,
      "speed_multiplier": 0.8
    },
    
    "stability_focused": {
      "description": "Maintain stability and reliability",
      "priorities": ["Stability", "Monitoring", "Gradual changes"],
      "tools": ["sentry", "cloudflare", "playwright"],
      "workflow": "cautious",
      "quality_threshold": 95,
      "speed_multiplier": 0.7
    },
    
    "quality_assurance": {
      "description": "Comprehensive testing and validation",
      "priorities": ["Testing", "Bug fixing", "Performance"],
      "tools": ["playwright", "pytest", "code-analysis"],
      "workflow": "testing",
      "quality_threshold": 95,
      "speed_multiplier": 0.6
    },
    
    "balanced": {
      "description": "Balance between speed and quality",
      "priorities": ["Features", "Quality", "Testing"],
      "tools": ["all"],
      "workflow": "standard",
      "quality_threshold": 80,
      "speed_multiplier": 1.0
    }
  }
}
```

================================================================================
SECTION 4: LEARNING SYSTEM
================================================================================

OVERVIEW
--------
ŸÜÿ∏ÿßŸÖ ÿ™ÿπŸÑŸÖ ŸÖÿ≥ÿ™ŸÖÿ± Ÿäÿ≠ÿ≥ŸÜ ÿßŸÑÿ£ÿØÿßÿ° ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ®.

LEARNING ARCHITECTURE
--------------------

```python
class LearningSystem:
    def __init__(self):
        self.knowledge_base = KnowledgeBase()
        self.pattern_detector = PatternDetector()
        self.performance_tracker = PerformanceTracker()
    
    def learn_from_experience(self, experience):
        """Learn from a completed task or decision"""
        
        # Extract lessons
        lessons = self.extract_lessons(experience)
        
        # Detect patterns
        patterns = self.pattern_detector.find_patterns(experience)
        
        # Update knowledge base
        for lesson in lessons:
            self.knowledge_base.add_lesson(lesson)
        
        for pattern in patterns:
            self.knowledge_base.add_pattern(pattern)
        
        # Update performance metrics
        self.performance_tracker.record(experience)
        
        # Identify improvements
        improvements = self.identify_improvements(experience)
        
        return {
            'lessons': lessons,
            'patterns': patterns,
            'improvements': improvements
        }
    
    def extract_lessons(self, experience):
        """Extract lessons from experience"""
        lessons = []
        
        # Success lessons
        if experience['success']:
            lessons.append({
                'type': 'success',
                'context': experience['context'],
                'action': experience['action'],
                'result': experience['result'],
                'lesson': f"In {experience['context']}, doing {experience['action']} leads to {experience['result']}"
            })
        
        # Failure lessons
        else:
            lessons.append({
                'type': 'failure',
                'context': experience['context'],
                'action': experience['action'],
                'result': experience['result'],
                'lesson': f"In {experience['context']}, avoid {experience['action']} because {experience['result']}"
            })
        
        # Performance lessons
        if 'performance' in experience:
            if experience['performance']['actual'] < experience['performance']['expected']:
                lessons.append({
                    'type': 'performance',
                    'lesson': f"Task took longer than expected. Reason: {experience['performance']['reason']}"
                })
        
        return lessons
```

---

## PATTERN DETECTION

```python
class PatternDetector:
    def __init__(self):
        self.patterns = []
    
    def find_patterns(self, experience):
        """Detect patterns in experiences"""
        patterns = []
        
        # Recurring issues
        similar = self.find_similar_experiences(experience)
        if len(similar) >= 3:
            pattern = {
                'type': 'recurring_issue',
                'frequency': len(similar),
                'context': self.extract_common_context(similar),
                'solution': self.extract_best_solution(similar),
                'confidence': len(similar) / 10.0
            }
            patterns.append(pattern)
        
        # Success patterns
        if experience['success']:
            successful_similar = [e for e in similar if e['success']]
            if len(successful_similar) >= 2:
                pattern = {
                    'type': 'success_pattern',
                    'context': self.extract_common_context(successful_similar),
                    'actions': self.extract_common_actions(successful_similar),
                    'confidence': len(successful_similar) / 5.0
                }
                patterns.append(pattern)
        
        return patterns
    
    def extract_best_solution(self, experiences):
        """Extract the best solution from similar experiences"""
        solutions = {}
        
        for exp in experiences:
            solution = exp['solution']
            if solution not in solutions:
                solutions[solution] = {
                    'count': 0,
                    'success_rate': 0,
                    'avg_time': 0
                }
            
            solutions[solution]['count'] += 1
            if exp['success']:
                solutions[solution]['success_rate'] += 1
            solutions[solution]['avg_time'] += exp['time']
        
        # Calculate averages
        for solution in solutions.values():
            solution['success_rate'] /= solution['count']
            solution['avg_time'] /= solution['count']
        
        # Select best
        best = max(
            solutions.items(),
            key=lambda x: x[1]['success_rate'] * 0.7 + (1 / x[1]['avg_time']) * 0.3
        )
        
        return best[0]
```

---

## KNOWLEDGE BASE

```python
class KnowledgeBase:
    def __init__(self):
        self.lessons = []
        self.patterns = []
        self.best_practices = []
        self.anti_patterns = []
    
    def add_lesson(self, lesson):
        """Add a lesson to the knowledge base"""
        # Check if similar lesson exists
        similar = self.find_similar_lesson(lesson)
        
        if similar:
            # Reinforce existing lesson
            similar['confidence'] += 0.1
            similar['occurrences'] += 1
        else:
            # Add new lesson
            lesson['confidence'] = 0.5
            lesson['occurrences'] = 1
            lesson['timestamp'] = datetime.now()
            self.lessons.append(lesson)
    
    def get_relevant_lessons(self, context):
        """Get lessons relevant to current context"""
        relevant = []
        
        for lesson in self.lessons:
            similarity = self.calculate_context_similarity(
                lesson['context'],
                context
            )
            
            if similarity > 0.7:
                relevant.append({
                    'lesson': lesson,
                    'relevance': similarity,
                    'confidence': lesson['confidence']
                })
        
        # Sort by relevance and confidence
        relevant.sort(
            key=lambda x: x['relevance'] * x['confidence'],
            reverse=True
        )
        
        return relevant[:5]
    
    def evolve_to_best_practice(self, lesson):
        """Evolve a lesson into a best practice"""
        if (lesson['confidence'] > 0.9 and 
            lesson['occurrences'] > 10):
            
            best_practice = {
                'title': self.generate_title(lesson),
                'description': lesson['lesson'],
                'context': lesson['context'],
                'examples': self.find_examples(lesson),
                'confidence': lesson['confidence']
            }
            
            self.best_practices.append(best_practice)
            return True
        
        return False
```

---

## PERFORMANCE TRACKING

```python
class PerformanceTracker:
    def __init__(self):
        self.metrics = {}
        self.trends = {}
    
    def record(self, experience):
        """Record performance metrics"""
        metric_type = experience['type']
        
        if metric_type not in self.metrics:
            self.metrics[metric_type] = []
        
        self.metrics[metric_type].append({
            'timestamp': datetime.now(),
            'duration': experience['duration'],
            'success': experience['success'],
            'quality': experience.get('quality', 0),
            'context': experience['context']
        })
        
        # Update trends
        self.update_trends(metric_type)
    
    def update_trends(self, metric_type):
        """Update performance trends"""
        data = self.metrics[metric_type]
        
        if len(data) < 5:
            return
        
        recent = data[-10:]
        
        self.trends[metric_type] = {
            'avg_duration': sum(d['duration'] for d in recent) / len(recent),
            'success_rate': sum(d['success'] for d in recent) / len(recent),
            'avg_quality': sum(d.get('quality', 0) for d in recent) / len(recent),
            'trend': self.calculate_trend(data)
        }
    
    def calculate_trend(self, data):
        """Calculate if performance is improving or declining"""
        if len(data) < 10:
            return 'insufficient_data'
        
        recent = data[-5:]
        previous = data[-10:-5]
        
        recent_avg = sum(d['duration'] for d in recent) / len(recent)
        previous_avg = sum(d['duration'] for d in previous) / len(previous)
        
        if recent_avg < previous_avg * 0.9:
            return 'improving'
        elif recent_avg > previous_avg * 1.1:
            return 'declining'
        else:
            return 'stable'
    
    def get_insights(self):
        """Get performance insights"""
        insights = []
        
        for metric_type, trend in self.trends.items():
            if trend['trend'] == 'declining':
                insights.append({
                    'type': 'warning',
                    'metric': metric_type,
                    'message': f"Performance declining for {metric_type}",
                    'recommendation': "Review recent changes and identify bottlenecks"
                })
            
            if trend['success_rate'] < 0.8:
                insights.append({
                    'type': 'alert',
                    'metric': metric_type,
                    'message': f"Low success rate ({trend['success_rate']*100}%) for {metric_type}",
                    'recommendation': "Investigate common failure causes"
                })
        
        return insights
```

---

## CONTINUOUS IMPROVEMENT

```python
class ContinuousImprovement:
    def __init__(self, learning_system):
        self.learning = learning_system
        self.improvement_cycles = []
    
    def run_improvement_cycle(self):
        """Run a continuous improvement cycle"""
        
        # 1. Analyze current performance
        performance = self.learning.performance_tracker.get_insights()
        
        # 2. Identify improvement opportunities
        opportunities = self.identify_opportunities(performance)
        
        # 3. Generate improvement actions
        actions = self.generate_actions(opportunities)
        
        # 4. Prioritize actions
        prioritized = self.prioritize_actions(actions)
        
        # 5. Execute top actions
        results = self.execute_actions(prioritized[:3])
        
        # 6. Measure impact
        impact = self.measure_impact(results)
        
        # 7. Learn from cycle
        self.learning.learn_from_experience({
            'type': 'improvement_cycle',
            'opportunities': opportunities,
            'actions': actions,
            'results': results,
            'impact': impact,
            'timestamp': datetime.now()
        })
        
        return {
            'opportunities': opportunities,
            'actions': prioritized,
            'impact': impact
        }
    
    def identify_opportunities(self, performance):
        """Identify improvement opportunities"""
        opportunities = []
        
        for insight in performance:
            if insight['type'] in ['warning', 'alert']:
                opportunities.append({
                    'area': insight['metric'],
                    'issue': insight['message'],
                    'potential_impact': 'high' if insight['type'] == 'alert' else 'medium'
                })
        
        return opportunities
```

================================================================================
SECTION 5: META-LEARNING
================================================================================

OVERVIEW
--------
ÿßŸÑÿ™ÿπŸÑŸÖ ÿπŸÜ ÿßŸÑÿ™ÿπŸÑŸÖ - ÿ™ÿ≠ÿ≥ŸäŸÜ ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ™ÿπŸÑŸÖ ŸÜŸÅÿ≥Ÿáÿß.

META-LEARNING SYSTEM
-------------------

```python
class MetaLearner:
    def __init__(self, learning_system):
        self.learning = learning_system
        self.learning_strategies = []
        self.strategy_performance = {}
    
    def optimize_learning(self):
        """Optimize the learning process itself"""
        
        # Analyze learning effectiveness
        effectiveness = self.analyze_learning_effectiveness()
        
        # Identify best learning strategies
        best_strategies = self.identify_best_strategies()
        
        # Adjust learning parameters
        adjustments = self.adjust_learning_parameters(effectiveness)
        
        # Apply improvements
        self.apply_improvements(best_strategies, adjustments)
        
        return {
            'effectiveness': effectiveness,
            'best_strategies': best_strategies,
            'adjustments': adjustments
        }
    
    def analyze_learning_effectiveness(self):
        """Analyze how effective the learning has been"""
        
        # Get all lessons
        lessons = self.learning.knowledge_base.lessons
        
        # Calculate metrics
        total_lessons = len(lessons)
        high_confidence = len([l for l in lessons if l['confidence'] > 0.8])
        applied_successfully = len([l for l in lessons if l.get('applied', False)])
        
        return {
            'total_lessons': total_lessons,
            'high_confidence_rate': high_confidence / total_lessons if total_lessons > 0 else 0,
            'application_rate': applied_successfully / total_lessons if total_lessons > 0 else 0,
            'learning_velocity': total_lessons / self.get_days_active()
        }
```

================================================================================
RESOURCES
================================================================================

### Context Engineering
- **Context-Aware Computing:** https://en.wikipedia.org/wiki/Context-aware_computing
- **Adaptive Systems:** https://en.wikipedia.org/wiki/Adaptive_system

### Machine Learning
- **Reinforcement Learning:** https://en.wikipedia.org/wiki/Reinforcement_learning
- **Transfer Learning:** https://en.wikipedia.org/wiki/Transfer_learning

### Knowledge Management
- **Knowledge Base Systems:** https://en.wikipedia.org/wiki/Knowledge_base
- **Expert Systems:** https://en.wikipedia.org/wiki/Expert_system

================================================================================
END OF MODULE 19: CONTEXT ENGINEERING & LEARNING SYSTEM
================================================================================



================================================================================
END OF 19_CONTEXT_ENGINEERING
================================================================================


================================================================================
MODULE: 20_SECURITY
================================================================================

=================================================================================
SECURITY - Authentication, Authorization, Best Practices
=================================================================================

Version: 5.0.0
Type: Security

Comprehensive security guidance for web applications.

=================================================================================
AUTHENTICATION
=================================================================================

## Password Security

**Hashing:**
```python
import bcrypt

# Hash password
password = "user_password"
hashed = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())

# Verify password
if bcrypt.checkpw(password.encode('utf-8'), hashed):
    print("Password correct")
```

**Django:**
```python
from django.contrib.auth.hashers import make_password, check_password

hashed = make_password("password123")
is_correct = check_password("password123", hashed)
```

## JWT Tokens

**Generate:**
```python
import jwt
from datetime import datetime, timedelta

def create_access_token(user_id):
    payload = {
        'user_id': user_id,
        'exp': datetime.utcnow() + timedelta(hours=1),
        'iat': datetime.utcnow()
    }
    return jwt.encode(payload, SECRET_KEY, algorithm='HS256')
```

**Verify:**
```python
def verify_token(token):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=['HS256'])
        return payload['user_id']
    except jwt.ExpiredSignatureError:
        return None
    except jwt.InvalidTokenError:
        return None
```

## Session Management

```python
# Django
request.session['user_id'] = user.id
request.session.set_expiry(3600)  # 1 hour

# Flask
from flask import session
session['user_id'] = user.id
session.permanent = True
app.permanent_session_lifetime = timedelta(hours=1)
```

=================================================================================
AUTHORIZATION
=================================================================================

## Role-Based Access Control (RBAC)

```python
class User(models.Model):
    ROLES = (
        ('admin', 'Administrator'),
        ('manager', 'Manager'),
        ('user', 'Regular User'),
    )
    role = models.CharField(max_length=20, choices=ROLES, default='user')
    
    def has_permission(self, permission):
        permissions = {
            'admin': ['create', 'read', 'update', 'delete'],
            'manager': ['create', 'read', 'update'],
            'user': ['read'],
        }
        return permission in permissions.get(self.role, [])
```

## Permission Decorators

```python
from functools import wraps
from flask import abort

def require_role(role):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            if current_user.role != role:
                abort(403)
            return func(*args, **kwargs)
        return wrapper
    return decorator

@app.route('/admin')
@require_role('admin')
def admin_panel():
    return "Admin Panel"
```

=================================================================================
INPUT VALIDATION
=================================================================================

## SQL Injection Prevention

**Bad:**
```python
# NEVER DO THIS
query = f"SELECT * FROM users WHERE email = '{email}'"
cursor.execute(query)
```

**Good:**
```python
# Use parameterized queries
cursor.execute("SELECT * FROM users WHERE email = %s", (email,))

# Or use ORM
User.objects.filter(email=email)
```

## XSS Prevention

```python
from markupsafe import escape

# Escape user input
safe_text = escape(user_input)

# Django templates auto-escape
{{ user_input }}  # Automatically escaped

# To mark as safe (use carefully)
from django.utils.safestring import mark_safe
safe_html = mark_safe(trusted_html)
```

## CSRF Protection

**Django:**
```python
# In forms
{% csrf_token %}

# In views
from django.views.decorators.csrf import csrf_protect

@csrf_protect
def my_view(request):
    pass
```

**Flask:**
```python
from flask_wtf.csrf import CSRFProtect

csrf = CSRFProtect(app)
```

=================================================================================
HTTPS & TLS
=================================================================================

## Force HTTPS

**Django:**
```python
SECURE_SSL_REDIRECT = True
SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')
```

**Flask:**
```python
from flask_talisman import Talisman

Talisman(app, force_https=True)
```

## Security Headers

```python
# Django
SECURE_HSTS_SECONDS = 31536000
SECURE_HSTS_INCLUDE_SUBDOMAINS = True
SECURE_CONTENT_TYPE_NOSNIFF = True
SECURE_BROWSER_XSS_FILTER = True
X_FRAME_OPTIONS = 'DENY'

# Flask
@app.after_request
def set_security_headers(response):
    response.headers['X-Content-Type-Options'] = 'nosniff'
    response.headers['X-Frame-Options'] = 'DENY'
    response.headers['X-XSS-Protection'] = '1; mode=block'
    return response
```

=================================================================================
RATE LIMITING
=================================================================================

```python
from functools import wraps
import time

# Simple rate limiter
rate_limit_storage = {}

def rate_limit(max_requests=5, window=60):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            client_id = request.remote_addr
            now = time.time()
            
            if client_id not in rate_limit_storage:
                rate_limit_storage[client_id] = []
            
            # Remove old requests
            rate_limit_storage[client_id] = [
                req_time for req_time in rate_limit_storage[client_id]
                if now - req_time < window
            ]
            
            if len(rate_limit_storage[client_id]) >= max_requests:
                abort(429, "Too many requests")
            
            rate_limit_storage[client_id].append(now)
            return func(*args, **kwargs)
        return wrapper
    return decorator

@app.route('/api/login')
@rate_limit(max_requests=5, window=300)  # 5 requests per 5 minutes
def login():
    pass
```

=================================================================================
FILE UPLOAD SECURITY
=================================================================================

```python
import os
from werkzeug.utils import secure_filename

ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'pdf'}
MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB

def allowed_file(filename):
    return '.' in filename and            filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return "No file", 400
    
    file = request.files['file']
    
    if file.filename == '':
        return "No file selected", 400
    
    if not allowed_file(file.filename):
        return "File type not allowed", 400
    
    # Check file size
    file.seek(0, os.SEEK_END)
    file_size = file.tell()
    if file_size > MAX_FILE_SIZE:
        return "File too large", 400
    file.seek(0)
    
    # Secure filename
    filename = secure_filename(file.filename)
    
    # Save file
    file.save(os.path.join(UPLOAD_FOLDER, filename))
    
    return "File uploaded", 200
```

=================================================================================
SECRETS MANAGEMENT
=================================================================================

## Environment Variables

```python
import os
from dotenv import load_dotenv

load_dotenv()

SECRET_KEY = os.getenv('SECRET_KEY')
DATABASE_URL = os.getenv('DATABASE_URL')
API_KEY = os.getenv('API_KEY')
```

## Never Commit Secrets

**.gitignore:**
```
.env
.env.local
secrets.json
*.key
*.pem
```

=================================================================================
SECURITY CHECKLIST
=================================================================================

## Before Deployment

- [ ] All passwords hashed with bcrypt/Argon2
- [ ] JWT tokens with expiration
- [ ] HTTPS enabled
- [ ] Security headers configured
- [ ] CSRF protection enabled
- [ ] SQL injection prevented (parameterized queries)
- [ ] XSS prevented (input escaping)
- [ ] Rate limiting implemented
- [ ] File upload validation
- [ ] Secrets in environment variables
- [ ] Dependencies up to date
- [ ] Security audit completed

=================================================================================
END OF SECURITY PROMPT
=================================================================================


================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

omplexity: uppercase, lowercase, number, symbol
- Hashing: bcrypt (cost 12) or argon2
- No password reuse (last 5)
- Expiry: 90 days (optional for high-security)
- Reset flow: email link (1-hour TTL)

C) Authorization (RBAC)
- Roles: ADMIN, MANAGER, USER, GUEST
- Permissions: granular (read, write, delete, export)
- Role hierarchy: ADMIN > MANAGER > USER > GUEST
- Permission checks: backend + frontend
- Audit log: all permission checks

D) Security Headers
- Content-Security-Policy: nonce-based
- Strict-Transport-Security: max-age=31536000
- X-Frame-Options: DENY
- X-Content-Type-Options: nosniff
- Referrer-Policy: strict-origin-when-cross-origin
- Permissions-Policy: restrictive

E) Secrets Management
- KMS/Vault for all secrets
- No secrets in code/env files
- Rotation: ‚â§90 days
- Access control: least privilege
- Audit log: all secret access

F) Threat Mitigation
- SQL Injection: parameterized queries
- XSS: DOMPurify, CSP nonces
- CSRF: tokens for state-changing ops
- SSRF: URL val
cident Response
1. Detect: monitoring alerts
2. Assess: severity (P0-P3)
3. Notify: on-call team
4. Mitigate: immediate fix or rollback
5. Communicate: status updates
6. Resolve: root cause fix
7. Post-mortem: blameless, actionable

B) Severity Levels
- P0: Complete outage, data loss
- P1: Major feature broken
- P2: Minor feature broken
- P3: Cosmetic issue

C) Rollback Procedure
- Automated: kubectl rollout undo
- Manual: deploy previous version
- Database: restore from backup if needed
- Verify: smoke tests

‚∏ª

20) FINAL CHECKLIST (before production)

Security:
- [ ] All secrets in KMS/Vault
- [ ] HTTPS enforced
- [ ] Security headers configured
- [ ] SAST/DAST passed
- [ ] Dependency scan clean
- [ ] Penetration test done

Code Quality:
- [ ] Linting passed
- [ ] Type checking passed
- [ ] No code duplication >5%
- [ ] Cyclomatic complexity <10

Testing:
- [ ] Unit tests >80% coverage
- [ ] Integration tests pass
- [ ] E2E tests pass
- [ ] Performance tests pass
- [ ] Accessibility 
  - Detailed logging: ON
   - CORS: Permissive
   - Sample data: Available

2. **Database:**
   - Can drop/recreate freely
   - Sample data can be added
   - Migrations run automatically
   - Backup optional

3. **Security:**
   - Relaxed (for development only)
   - Test credentials allowed
   - HTTPS optional
   - CSRF optional (for testing)

4. **Monitoring:**
   - Console logging
   - Detailed error messages
   - Stack traces visible
   - Performance profiling

5. **Commands Available:**
   - `reset-db` - Drop and recreate database
   - `seed-data` - Add sample data
   - `clear-cache` - Clear all caches
   - `start deploy` - Begin deployment process

---

### 64.5 Production Phase Behavior

**When `phase: "production"`:**

1. **Configuration:**
   - Debug mode: OFF
   - Hot reload: Disabled
   - Minimal logging: ON
   - CORS: Strict
   - Sample data: NOT available

2. **Database:**
   - Data preservation: MANDATORY
   - Backups: Automatic
   - Migrations: Careful, with backups
   - 
No destructive operations

3. **Security:**
   - Strict security policies
   - Strong credentials required
   - HTTPS: MANDATORY
   - CSRF protection: ON
   - Rate limiting: ON

4. **Monitoring:**
   - Production logging
   - Error tracking (Sentry, etc.)
   - Performance monitoring
   - Uptime monitoring

5. **Commands Available:**
   - `backup-db` - Create database backup
   - `restore-db` - Restore from backup
   - `rollback` - Rollback to previous version
   - `health-check` - Check system health

---

### 64.6 The `start deploy` Command

**Purpose:** Transition from Development to Production

**Workflow:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              START DEPLOY WORKFLOW                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  Step 1: Pre-Deployment Checks                              ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                        

================================================================================
END OF 20_SECURITY
================================================================================


================================================================================
MODULE: 21_AUTHENTICATION
================================================================================

=================================================================================
AUTHENTICATION SYSTEMS - JWT, OAuth, Social Auth
=================================================================================

Version: 5.0.0
Type: Security - Authentication

Detailed guidance for implementing authentication systems.

=================================================================================
JWT AUTHENTICATION
=================================================================================

## Complete Implementation (FastAPI)

```python
from fastapi import FastAPI, Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel
from datetime import datetime, timedelta
import jwt
import bcrypt

app = FastAPI()
security = HTTPBearer()

SECRET_KEY = "your-secret-key"
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

class User(BaseModel):
    email: str
    password: str

class Token(BaseModel):
    access_token: str
    token_type: str

def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    try:
        payload = jwt.decode(
            credentials.credentials,
            SECRET_KEY,
            algorithms=[ALGORITHM]
        )
        return payload
    except jwt.ExpiredSignatureError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Token expired"
        )
    except jwt.InvalidTokenError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid token"
        )

@app.post("/auth/register")
async def register(user: User):
    hashed_password = bcrypt.hashpw(
        user.password.encode('utf-8'),
        bcrypt.gensalt()
    )
    # Save user to database
    return {"message": "User created"}

@app.post("/auth/login", response_model=Token)
async def login(user: User):
    # Verify user credentials
    # ...
    access_token = create_access_token({"sub": user.email})
    return {"access_token": access_token, "token_type": "bearer"}

@app.get("/protected")
async def protected_route(payload: dict = Depends(verify_token)):
    return {"message": f"Hello {payload['sub']}"}
```

## Django JWT

```python
from rest_framework_simplejwt.views import (
    TokenObtainPairView,
    TokenRefreshView,
)

urlpatterns = [
    path('api/token/', TokenObtainPairView.as_view()),
    path('api/token/refresh/', TokenRefreshView.as_view()),
]

# Settings
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ],
}

SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(minutes=30),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=1),
}
```

=================================================================================
OAUTH 2.0
=================================================================================

## Google OAuth (FastAPI)

```python
from authlib.integrations.starlette_client import OAuth

oauth = OAuth()
oauth.register(
    name='google',
    client_id='your-client-id',
    client_secret='your-client-secret',
    server_metadata_url='https://accounts.google.com/.well-known/openid-configuration',
    client_kwargs={'scope': 'openid email profile'}
)

@app.get('/auth/google')
async def google_login(request: Request):
    redirect_uri = request.url_for('google_callback')
    return await oauth.google.authorize_redirect(request, redirect_uri)

@app.get('/auth/google/callback')
async def google_callback(request: Request):
    token = await oauth.google.authorize_access_token(request)
    user_info = token.get('userinfo')
    # Create or update user
    return {"email": user_info['email']}
```

=================================================================================
SOCIAL AUTHENTICATION
=================================================================================

## Django Social Auth

```python
# Install: pip install social-auth-app-django

INSTALLED_APPS = [
    ...
    'social_django',
]

AUTHENTICATION_BACKENDS = [
    'social_core.backends.google.GoogleOAuth2',
    'social_core.backends.facebook.FacebookOAuth2',
    'django.contrib.auth.backends.ModelBackend',
]

SOCIAL_AUTH_GOOGLE_OAUTH2_KEY = 'your-client-id'
SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET = 'your-client-secret'

# URLs
urlpatterns = [
    path('', include('social_django.urls', namespace='social')),
]
```

=================================================================================
TWO-FACTOR AUTHENTICATION (2FA)
=================================================================================

```python
import pyotp
import qrcode
from io import BytesIO

def generate_totp_secret():
    return pyotp.random_base32()

def generate_qr_code(user_email, secret):
    totp_uri = pyotp.totp.TOTP(secret).provisioning_uri(
        name=user_email,
        issuer_name="MyApp"
    )
    qr = qrcode.QRCode()
    qr.add_data(totp_uri)
    qr.make()
    img = qr.make_image()
    buffer = BytesIO()
    img.save(buffer, format='PNG')
    return buffer.getvalue()

def verify_totp(secret, code):
    totp = pyotp.TOTP(secret)
    return totp.verify(code)

# Usage
@app.post("/auth/2fa/enable")
async def enable_2fa(user_id: int):
    secret = generate_totp_secret()
    # Save secret to user
    qr_code = generate_qr_code(user.email, secret)
    return {"qr_code": qr_code}

@app.post("/auth/2fa/verify")
async def verify_2fa(user_id: int, code: str):
    # Get user's secret
    if verify_totp(user.totp_secret, code):
        return {"message": "2FA verified"}
    raise HTTPException(status_code=400, detail="Invalid code")
```

=================================================================================
PASSWORD RESET
=================================================================================

```python
from itsdangerous import URLSafeTimedSerializer

serializer = URLSafeTimedSerializer(SECRET_KEY)

def generate_reset_token(email):
    return serializer.dumps(email, salt='password-reset')

def verify_reset_token(token, max_age=3600):
    try:
        email = serializer.loads(
            token,
            salt='password-reset',
            max_age=max_age
        )
        return email
    except:
        return None

@app.post("/auth/forgot-password")
async def forgot_password(email: str):
    token = generate_reset_token(email)
    reset_link = f"https://myapp.com/reset-password?token={token}"
    # Send email with reset_link
    return {"message": "Reset link sent"}

@app.post("/auth/reset-password")
async def reset_password(token: str, new_password: str):
    email = verify_reset_token(token)
    if not email:
        raise HTTPException(status_code=400, detail="Invalid token")
    # Update password
    return {"message": "Password reset successful"}
```

=================================================================================
END OF AUTHENTICATION PROMPT
=================================================================================


================================================================================
CRITICAL MISSING CONTENT - Deep Search Recovery
================================================================================

```python
"""
File: path/to/file.py
Module: module_name
Created: YYYY-MM-DD
Last Modified: YYYY-MM-DD
Author: author_name
Description: Brief description of file purpose

Dependencies:
- dependency1
- dependency2

Related Files:
- related_file1.py
- related_file2.py
"""
```

```python
#!/usr/bin/env python3
"""Add headers to files missing them."""

from pathlib import Path
from datetime import date

PYTHON_TEMPLATE = '''"""
File: {path}
Module: {module}
Created: {date}
Last Modified: {date}
Author: {author}
Description: TODO: Add description

Dependencies:
- TODO: List dependencies

Related Files:
- TODO: List related files
"""

'''

def add_python_header(file_path, author="Team"):
    """Add header to Python file."""
    with open(file_path) as f:
        content = f.read()
    
    if content.startswith('"""'):
        print(f"‚è≠Ô∏è  {file_path} already has header")
        return
    
    module = str(file_path).replace('/', '.').replace('.py', '')
    header = PYTHON_TEMPLATE.format(
        path=file_path,
        module=module,
        date=date.today().isoformat(),
        author=author
    )
    
    with open(file_path, 'w') as f:
        f.write(header + content)
    
    print(f"‚úÖ Added header to {file_path}")

def main():
    """Add headers to all Python files."""
    for py_file in Path('.').rglob('*.py'):
        if '__pycache__' not in str(py_file):
            add_python_header(py_file)

if __name__ == '__main__':
    main()
```



================================================================================
END OF 21_AUTHENTICATION
================================================================================


================================================================================
MODULE: 30_QUALITY
================================================================================

=================================================================================
CODE QUALITY & BEST PRACTICES
=================================================================================

Version: 5.0.0
Type: Quality Assurance

Comprehensive guidance for maintaining high code quality.

=================================================================================
CODE STYLE
=================================================================================

## Python (PEP 8)

```python
# Good
def calculate_total_price(items, tax_rate=0.1):
    """Calculate total price including tax.
    
    Args:
        items: List of items with prices
        tax_rate: Tax rate (default: 0.1)
    
    Returns:
        float: Total price with tax
    """
    subtotal = sum(item.price for item in items)
    tax = subtotal * tax_rate
    return subtotal + tax

# Bad
def calc(i,t=0.1):
    s=sum(x.price for x in i)
    return s+s*t
```

## JavaScript/TypeScript

```typescript
// Good
interface Product {
  id: number;
  name: string;
  price: number;
}

function calculateTotalPrice(
  items: Product[],
  taxRate: number = 0.1
): number {
  const subtotal = items.reduce((sum, item) => sum + item.price, 0);
  const tax = subtotal * taxRate;
  return subtotal + tax;
}

// Bad
function calc(i,t=0.1){
  let s=0;
  for(let x of i)s+=x.price;
  return s+s*t;
}
```

=================================================================================
LINTING & FORMATTING
=================================================================================

## Python

**flake8:**
```bash
pip install flake8
flake8 --max-line-length=100 --exclude=venv,migrations
```

**black:**
```bash
pip install black
black --line-length 100 .
```

**pylint:**
```bash
pip install pylint
pylint --disable=C0111 myproject/
```

## JavaScript/TypeScript

**ESLint:**
```json
{
  "extends": ["eslint:recommended"],
  "rules": {
    "no-console": "warn",
    "no-unused-vars": "error",
    "semi": ["error", "always"]
  }
}
```

**Prettier:**
```json
{
  "semi": true,
  "singleQuote": true,
  "tabWidth": 2,
  "printWidth": 100
}
```

=================================================================================
TYPE CHECKING
=================================================================================

## Python (mypy)

```python
from typing import List, Optional

def get_user(user_id: int) -> Optional[dict]:
    """Get user by ID."""
    return database.get(user_id)

def process_users(users: List[dict]) -> int:
    """Process list of users."""
    return len(users)
```

```bash
pip install mypy
mypy --strict myproject/
```

## TypeScript

```typescript
interface User {
  id: number;
  name: string;
  email: string;
}

function getUser(userId: number): User | null {
  return database.get(userId);
}

function processUsers(users: User[]): number {
  return users.length;
}
```

=================================================================================
CODE REVIEW CHECKLIST
=================================================================================

## Before Submitting PR

- [ ] Code follows style guide
- [ ] All tests pass
- [ ] New tests added for new features
- [ ] Documentation updated
- [ ] No commented-out code
- [ ] No debug prints/logs
- [ ] Error handling implemented
- [ ] Security considerations addressed
- [ ] Performance optimized
- [ ] Code reviewed by yourself first

## Reviewing Others' Code

- [ ] Functionality works as expected
- [ ] Code is readable and maintainable
- [ ] No obvious bugs
- [ ] Edge cases handled
- [ ] Tests are comprehensive
- [ ] No security vulnerabilities
- [ ] Performance is acceptable
- [ ] Documentation is clear

=================================================================================
REFACTORING
=================================================================================

## Extract Function

**Before:**
```python
def process_order(order):
    # Calculate total
    total = 0
    for item in order.items:
        total += item.price * item.quantity
    
    # Apply discount
    if order.customer.is_premium:
        total *= 0.9
    
    # Add tax
    total *= 1.1
    
    return total
```

**After:**
```python
def calculate_subtotal(items):
    return sum(item.price * item.quantity for item in items)

def apply_discount(total, customer):
    if customer.is_premium:
        return total * 0.9
    return total

def add_tax(total, tax_rate=0.1):
    return total * (1 + tax_rate)

def process_order(order):
    subtotal = calculate_subtotal(order.items)
    discounted = apply_discount(subtotal, order.customer)
    return add_tax(discounted)
```

=================================================================================
DOCUMENTATION
=================================================================================

## Docstrings

```python
def calculate_discount(price: float, discount_percent: float) -> float:
    """Calculate discounted price.
    
    Args:
        price: Original price
        discount_percent: Discount percentage (0-100)
    
    Returns:
        Discounted price
    
    Raises:
        ValueError: If discount_percent is not between 0 and 100
    
    Examples:
        >>> calculate_discount(100, 10)
        90.0
        >>> calculate_discount(100, 50)
        50.0
    """
    if not 0 <= discount_percent <= 100:
        raise ValueError("Discount must be between 0 and 100")
    return price * (1 - discount_percent / 100)
```

=================================================================================
PERFORMANCE
=================================================================================

## Profiling

```python
import cProfile
import pstats

def profile_function(func):
    profiler = cProfile.Profile()
    profiler.enable()
    result = func()
    profiler.disable()
    
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(10)
    
    return result
```

## Optimization Tips

- Use list comprehensions instead of loops
- Cache expensive computations
- Use generators for large datasets
- Batch database queries
- Use appropriate data structures
- Profile before optimizing

=================================================================================
END OF QUALITY PROMPT
=================================================================================


================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

PI keys

C) Inclusions
- All source code (`.py`, `.ts`, `.tsx`, `.js`, `.jsx`)
- All documentation (`.md`, `.txt`)
- Configuration files (`.json`, `.yaml`, `.toml`)
- Database schemas
- Scripts
- Tests

D) Naming Convention
```
backup-YYYY-MM-DD-HHmmss-<trigger>.tar.gz
backup-2025-10-28-150000-module-completion.tar.gz
backup-2025-10-28-030000-daily.tar.gz
```

E) Storage
- Local: `/backups/` (last 7 days)
- S3/GCS: long-term (30 days online, 1 year archive)
- Encrypted at rest
- Versioned

F) Restoration
- Documented procedure in `/docs/Runbook.md`
- Tested monthly
- RTO: <1 hour
- RPO: <24 hours

G) Monitoring
- Alert on backup failure
- Dashboard: backup success rate
- Audit log: all backup/restore operations

‚∏ª

27) MLOPS LIFECYCLE (NEW in v3.1)

A) Data Pipeline
- Data collection & validation
- Data quality checks
- Feature engineering
- Data versioning (DVC, LFS)
- Train/val/test splits

B) Model Development
- Experiment tracking (MLflow, Weights & Biases)
- Hyperparameter tuning

 issues above before starting development.")
        return 1
    else:
        print("\n‚úÖ All pre-development checks passed!")
        print("You're ready to start coding.")
        return 0

if __name__ == '__main__':
    sys.exit(pre_development_check())
```

C) GIT HOOK

```bash
# .git/hooks/pre-commit
#!/bin/bash

echo "Running pre-development checks..."
python scripts/pre_dev_check.py

if [ $? -ne 0 ]; then
    echo "‚ùå Pre-development checks failed!"
    echo "Fix the issues or use 'git commit --no-verify' to skip (not recommended)"
    exit 1
fi
```

D) BENEFITS

‚úÖ Prevents duplicate work  
‚úÖ Ensures awareness of codebase  
‚úÖ Catches issues early  
‚úÖ Enforces best practices  
‚úÖ Improves code quality

‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª‚∏ª

END OF GLOBAL_GUIDELINES v3.2

## Summary of v3.2 Additions

**NEW SECTIONS (10):**
29. File Discovery & Mapping Protocol
30. Environment Detection & Configuration
31. Production Setup Wizard
32. Cross-Browser Testing
33. UI Asset Management
description
3. Add estimate and dependencies if known
4. Set status to "Not Started"

**Working on Tasks:**
1. Update status to "In Progress"
2. Add notes/blockers if needed
3. Update estimate if changed

**Completing Tasks:**
1. Mark with 'x'
2. Add completion date
3. Move to "Completed Tasks" section at bottom
4. **Never delete**

**Archiving:**
```bash
# Monthly archive
grep "^\- \[x\]" docs/TODO.md >> docs/completed_tasks.md
# Then manually remove from TODO.md (but keep in completed_tasks.md)
```

### 50.4 CI Integration

**Pre-commit Hook:**
```yaml
- repo: local
  hooks:
    - id: check-todo-format
      name: Check TODO file format
      entry: python scripts/check_todo_format.py
      language: python
      files: docs/TODO.md
```

---

## 51. Code Modularization

### 51.1 Modularization Rules

**Maximum Sizes:**
- **Function:** ‚â§50 lines (excluding docstring)
- **Class:** ‚â§300 lines
- **File:** ‚â§500 lines
- **Module:** ‚â§10 files

**If Exceeded:**
- Split function into smaller 
_create, order_service, sample_order_data):
        """Test order creation."""
        mock_order = Mock(id=123)
        mock_create.return_value = mock_order
        
        order = order_service.create_order(
            customer_id=sample_order_data['customer_id'],
            total=Decimal('40.25')
        )
        
        assert order.id == 123
        mock_create.assert_called_once()
```

**Running Tests:**
```bash
# All tests
pytest

# With coverage
pytest --cov=. --cov-report=html

# Specific file
pytest tests/unit/test_order_service.py

# Specific test
pytest tests/unit/test_order_service.py::TestOrderService::test_calculate_total_success

# Parallel execution
pytest -n auto
```

**Code Quality Checks:**
```bash
# Before running tests
flake8 . --max-line-length=120
autopep8 --in-place --aggressive --aggressive -r .
pylint --max-line-length=120 .
mypy --strict .
```

### 53.2 Frontend Testing (Selenium/Playwright)

**Tools:**
```bash
# Selenium
pip install selenium webdriver
overage)
```

**base.txt:**
```
# Core framework
django==4.2.0
djangorestframework==3.14.0

# Database
psycopg2-binary==2.9.5

# Utilities
python-dotenv==1.0.0
requests==2.31.0
```

**development.txt:**
```
-r base.txt

# Development tools
django-debug-toolbar==4.0.0
ipython==8.12.0

# Linting & formatting
flake8==6.0.0
black==23.3.0
isort==5.12.0
pylint==2.17.0
mypy==1.2.0

# Testing
pytest==7.3.1
pytest-django==4.5.2
pytest-cov==4.0.0
```

**production.txt:**
```
-r base.txt

# Production server
gunicorn==20.1.0

# Monitoring
sentry-sdk==1.25.0
```

**testing.txt:**
```
-r base.txt

# Testing framework
pytest==7.3.1
pytest-django==4.5.2
pytest-cov==4.0.0
pytest-mock==3.10.0
pytest-xdist==3.2.1

# Browser testing
selenium==4.9.0
playwright==1.33.0
```

### 56.3 Version Pinning

**Pin exact versions in production:**
```
# ‚úÖ GOOD - Exact version
django==4.2.0
requests==2.31.0

# ‚ùå BAD - Unpinned
django
requests>=2.0
```

**Use compatible release for development:**
```
# Development can 
              ‚îÇ
‚îÇ  - Set up 2FA (optional)                                    ‚îÇ
‚îÇ  - Configure admin email                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 4: Application Settings                               ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                               ‚îÇ
‚îÇ  - Site name and description                                ‚îÇ
‚îÇ  - Timezone and locale                                      ‚îÇ
‚îÇ  - Currency settings                                        ‚îÇ
‚îÇ  - Date/time formats                                        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Step 5: Email Configuration                                ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                ‚îÇ
‚îÇ  - SMTP settings                                            ‚îÇ
‚îÇ  - Test email sending                                       ‚îÇ
‚îÇ  - Email templates                                          ‚îÇ
‚îÇ                       

================================================================================
CRITICAL MISSING CONTENT - Deep Search Recovery
================================================================================

```bash
   python scripts/map_files.py --output docs/File_Map.md
   ```

2. **Read Mandatory Documentation**
   - `/docs/File_Map.md` - Complete file inventory
   - `/docs/Class_Registry.md` - All classes/types
   - `/docs/Imports_Map.md` - Import dependencies
   - `/docs/Exports_Map.md` - Export mappings

3. **Search for Existing Files**
   ```bash
   # Search by name
   find . -name "*user*" -type f
   
   # Search by content (AST-based)
   python scripts/detect_duplicates.py --semantic --target "User"
   ```

B) FILE MAP STRUCTURE

`/docs/File_Map.md` format:
```



================================================================================
END OF 30_QUALITY
================================================================================


================================================================================
MODULE: 31_TESTING
================================================================================

=================================================================================
TESTING - Unit, Integration, E2E
=================================================================================

Version: 5.0.0
Type: Quality Assurance - Testing

Comprehensive testing strategies and implementations.

=================================================================================
UNIT TESTING
=================================================================================

## Python (pytest)

```python
import pytest
from myapp.models import Product

def test_product_creation():
    product = Product(name="Laptop", price=999.99)
    assert product.name == "Laptop"
    assert product.price == 999.99

def test_product_discount():
    product = Product(name="Laptop", price=1000)
    discounted_price = product.apply_discount(10)
    assert discounted_price == 900

def test_invalid_price():
    with pytest.raises(ValueError):
        Product(name="Laptop", price=-100)

@pytest.fixture
def sample_product():
    return Product(name="Test Product", price=100)

def test_with_fixture(sample_product):
    assert sample_product.price == 100
```

## JavaScript (Jest)

```javascript
describe('Product', () => {
  test('creates product correctly', () => {
    const product = new Product('Laptop', 999.99);
    expect(product.name).toBe('Laptop');
    expect(product.price).toBe(999.99);
  });

  test('applies discount correctly', () => {
    const product = new Product('Laptop', 1000);
    const discounted = product.applyDiscount(10);
    expect(discounted).toBe(900);
  });

  test('throws error for invalid price', () => {
    expect(() => {
      new Product('Laptop', -100);
    }).toThrow('Price must be positive');
  });
});
```

=================================================================================
INTEGRATION TESTING
=================================================================================

## API Testing (FastAPI)

```python
from fastapi.testclient import TestClient
from myapp.main import app

client = TestClient(app)

def test_create_product():
    response = client.post(
        "/api/products/",
        json={"name": "Laptop", "price": 999.99}
    )
    assert response.status_code == 201
    data = response.json()
    assert data["name"] == "Laptop"
    assert "id" in data

def test_get_products():
    response = client.get("/api/products/")
    assert response.status_code == 200
    assert isinstance(response.json(), list)

def test_authentication_required():
    response = client.get("/api/admin/")
    assert response.status_code == 401
```

## Database Testing

```python
import pytest
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

@pytest.fixture(scope="function")
def db_session():
    engine = create_engine("sqlite:///:memory:")
    Base.metadata.create_all(engine)
    Session = sessionmaker(bind=engine)
    session = Session()
    yield session
    session.close()

def test_create_user(db_session):
    user = User(email="test@example.com")
    db_session.add(user)
    db_session.commit()
    
    retrieved = db_session.query(User).filter_by(email="test@example.com").first()
    assert retrieved is not None
    assert retrieved.email == "test@example.com"
```

=================================================================================
E2E TESTING
=================================================================================

## Playwright (Python)

```python
from playwright.sync_api import Page, expect

def test_login_flow(page: Page):
    page.goto("http://localhost:3000/login")
    
    page.fill('input[name="email"]', "user@example.com")
    page.fill('input[name="password"]', "password123")
    page.click('button[type="submit"]')
    
    expect(page).to_have_url("http://localhost:3000/dashboard")
    expect(page.locator("h1")).to_contain_text("Dashboard")

def test_create_product(page: Page):
    page.goto("http://localhost:3000/products/new")
    
    page.fill('input[name="name"]', "New Product")
    page.fill('input[name="price"]', "99.99")
    page.click('button[type="submit"]')
    
    expect(page.locator(".success-message")).to_be_visible()
```

## Cypress (JavaScript)

```javascript
describe('Login Flow', () => {
  it('logs in successfully', () => {
    cy.visit('/login');
    
    cy.get('input[name="email"]').type('user@example.com');
    cy.get('input[name="password"]').type('password123');
    cy.get('button[type="submit"]').click();
    
    cy.url().should('include', '/dashboard');
    cy.get('h1').should('contain', 'Dashboard');
  });
});
```

=================================================================================
TEST COVERAGE
=================================================================================

## Python (pytest-cov)

```bash
pip install pytest-cov
pytest --cov=myapp --cov-report=html
```

## JavaScript (Jest)

```json
{
  "scripts": {
    "test": "jest --coverage"
  },
  "jest": {
    "collectCoverageFrom": [
      "src/**/*.{js,jsx,ts,tsx}",
      "!src/**/*.test.{js,jsx,ts,tsx}"
    ],
    "coverageThreshold": {
      "global": {
        "branches": 80,
        "functions": 80,
        "lines": 80,
        "statements": 80
      }
    }
  }
}
```

=================================================================================
MOCKING
=================================================================================

## Python

```python
from unittest.mock import Mock, patch

def test_api_call():
    with patch('requests.get') as mock_get:
        mock_get.return_value.json.return_value = {"data": "test"}
        mock_get.return_value.status_code = 200
        
        result = fetch_data_from_api()
        assert result == {"data": "test"}
        mock_get.assert_called_once()
```

## JavaScript

```javascript
jest.mock('./api');

test('fetches data from API', async () => {
  const mockData = { data: 'test' };
  api.fetchData.mockResolvedValue(mockData);
  
  const result = await getData();
  expect(result).toEqual(mockData);
  expect(api.fetchData).toHaveBeenCalledTimes(1);
});
```

=================================================================================
TEST ORGANIZATION
=================================================================================

```
tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py
‚îÇ   ‚îú‚îÄ‚îÄ test_utils.py
‚îÇ   ‚îî‚îÄ‚îÄ test_services.py
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îî‚îÄ‚îÄ test_database.py
‚îú‚îÄ‚îÄ e2e/
‚îÇ   ‚îú‚îÄ‚îÄ test_login.py
‚îÇ   ‚îî‚îÄ‚îÄ test_checkout.py
‚îî‚îÄ‚îÄ conftest.py  # Shared fixtures
```

=================================================================================
END OF TESTING PROMPT
=================================================================================


================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

shared', 'core']
    functions = []
    
    for dir_name in shared_dirs:
        dir_path = Path(dir_name)
        if not dir_path.exists():
            continue
        
        for py_file in dir_path.rglob('*.py'):
            if py_file.name.startswith('test_'):
                continue
            
            with open(py_file) as f:
                tree = ast.parse(f.read())
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    if not node.name.startswith('_'):  # Public functions only
                        functions.append((str(py_file), node.name))
    
    return functions

def check_documented(functions):
    """Check if functions are documented in function_reference.md"""
    ref_file = Path('docs/function_reference.md')
    if not ref_file.exists():
        print("‚ùå docs/function_reference.md not found!")
        return False
    
    with open(ref_file) as f:
        content = f.read()
    
    un
                    PROJECT STATES                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  1. DEVELOPMENT                                             ‚îÇ
‚îÇ     ‚îú‚îÄ Active development                                   ‚îÇ
‚îÇ     ‚îú‚îÄ Testing enabled                                      ‚îÇ
‚îÇ     ‚îú‚îÄ Debug mode ON                                        ‚îÇ
‚îÇ     ‚îú‚îÄ Sample data available                                ‚îÇ
‚îÇ     ‚îú‚îÄ Hot reload enabled                                   ‚îÇ
‚îÇ     ‚îî‚îÄ Detailed logging                                     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  2. STAGING (Optional)                                      ‚îÇ
‚îÇ     ‚îú‚îÄ Pre-production testing                               ‚îÇ
‚îÇ     ‚îú‚îÄ Production-like environment                          ‚îÇ
‚îÇ     ‚îú‚îÄ Performance testing                                  ‚îÇ
‚îÇ     ‚îî‚îÄ Final QA                          
elligent chatbots
8. ‚úÖ **Charity Management** - Donation platforms
9. ‚úÖ **AI Prediction** - Forecasting systems

**Benefits:**

‚úÖ **Rapid development** - Start projects in minutes  
‚úÖ **Best practices** - Production-ready code  
‚úÖ **Fully documented** - Complete guides  
‚úÖ **Customizable** - Easy to modify  
‚úÖ **Tested** - All templates tested

**Augment can now generate complete projects instantly!** üöÄ

---

**Section Version:** 1.0.0  
**Last Updated:** 2025-11-02  
**Templates Count:** 9



================================================================================
CRITICAL MISSING CONTENT - Deep Search Recovery
================================================================================

```bash
#!/bin/bash
# Comprehensive verification script

set -e

echo "üîç Running comprehensive verification..."

# 1. Code style
echo "üìù Checking code style..."
black --check --line-length=120 . || exit 1
isort --check-only --profile=black . || exit 1

# 2. Linting
echo "üîé Linting..."
flake8 . --max-line-length=120 --extend-ignore=E203 || exit 1
pylint --max-line-length=120 --disable=C0111 . || exit 1

# 3. Type checking
echo "üî¢ Type checking..."
mypy --strict --ignore-missing-imports . || exit 1

# 4. Security
echo "üîí Security checks..."
bandit -r . -f json -o bandit-report.json || exit 1
safety check || exit 1

# 5. Complexity
echo "üìä Complexity analysis..."
radon cc . -a -s -n C || exit 1
radon mi . -s -n B || exit 1

# 6. Dead code
echo "üíÄ Dead code detection..."
vulture . --min-confidence 80 || exit 1

# 7. Tests
echo "üß™ Running tests..."
pytest --cov=. --cov-report=term --cov-report=html --cov-fail-under=80 || exit 1

# 8. Line length check
echo "üìè Checking line length..."
bash scripts/fix_line_length.sh --check || exit 1

# 9. Unused imports
echo "üóëÔ∏è  Checking unused imports..."
bash scripts/remove_unused.sh --check || exit 1

echo "‚úÖ All verification checks passed!"
```

```python
#!/usr/bin/env python3
"""Check that all shared functions are documented in function_reference.md"""

import ast
import sys
from pathlib import Path

def find_shared_functions():
    """Find all functions in shared/common modules."""
    shared_dirs = ['utils', 'common', 'shared', 'core']
    functions = []
    
    for dir_name in shared_dirs:
        dir_path = Path(dir_name)
        if not dir_path.exists():
            continue
        
        for py_file in dir_path.rglob('*.py'):
            if py_file.name.startswith('test_'):
                continue
            
            with open(py_file) as f:
                tree = ast.parse(f.read())
            
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    if not node.name.startswith('_'):  # Public functions only
                        functions.append((str(py_file), node.name))
    
    return functions

def check_documented(functions):
    """Check if functions are documented in function_reference.md"""
    ref_file = Path('docs/function_reference.md')
    if not ref_file.exists():
        print("‚ùå docs/function_reference.md not found!")
        return False
    
    with open(ref_file) as f:
        content = f.read()
    
    undocumented = []
    for file_path, func_name in functions:
        if f"`{func_name}`" not in content:
            undocumented.append(f"{file_path}::{func_name}")
    
    if undocumented:
        print("‚ùå Undocumented functions found:")
        for func in undocumented:
            print(f"  - {func}")
        print("\nPlease add them to docs/function_reference.md")
        return False
    
    print("‚úÖ All shared functions are documented")
    return True

if __name__ == '__main__':
    functions = find_shared_functions()
    if not check_documented(functions):
        sys.exit(1)
```

```python
#!/usr/bin/env python3
"""Check code for known error patterns from error log."""

import re
import sys
from pathlib import Path

def load_error_patterns():
    """Load error patterns from error log."""
    error_file = Path('docs/errors/Dont_make_this_error_again.md')
    if not error_file.exists():
        return []
    
    patterns = []
    with open(error_file) as f:
        content = f.read()
    
    # Extract code patterns that caused errors
    # This is a simplified example
    pattern_blocks = re.findall(r'```python\n# WRONG:(.*?)```', content, re.DOTALL)
    for block in pattern_blocks:
        patterns.append(block.strip())
    
    return patterns

def check_files_for_patterns(patterns):
    """Check Python files for error patterns."""
    issues_found = False
    
    for py_file in Path('.').rglob('*.py'):
        if 'test_' in str(py_file) or '__pycache__' in str(py_file):
            continue
        
        with open(py_file) as f:
            content = f.read()
        
        for pattern in patterns:
            if pattern in content:
                print(f"‚ö†Ô∏è  Known error pattern found in {py_file}")
                print(f"   Pattern: {pattern[:50]}...")
                issues_found = True
    
    return issues_found

if __name__ == '__main__':
    patterns = load_error_patterns()
    if check_files_for_patterns(patterns):
        print("\n‚ùå Known error patterns detected!")
        print("   Check docs/errors/Dont_make_this_error_again.md")
        sys.exit(1)
    
    print("‚úÖ No known error patterns found")
```

```python
"""
File: tests/unit/test_order_service.py
Module: tests.unit.test_order_service
Created: 2025-01-15
Author: Team
Description: Unit tests for order service
"""

import pytest
from decimal import Decimal
from unittest.mock import Mock, patch
from services.order_service import OrderService

class TestOrderService:
    """Test OrderService class."""
    
    @pytest.fixture
    def order_service(self):
        """Create OrderService instance."""
        return OrderService()
    
    @pytest.fixture
    def sample_order_data(self):
        """Sample order data."""
        return {
            'customer_id': 1,
            'items': [
                {'price': '10.00', 'qty': 2},
                {'price': '5.00', 'qty': 3}
            ]
        }
    
    def test_calculate_total_success(self, order_service, sample_order_data):
        """Test successful total calculation."""
        total = order_service.calculate_total(sample_order_data['items'])
        expected = Decimal('35.00') * Decimal('1.15')  # With 15% tax
        assert total == expected
    
    def test_calculate_total_empty_items(self, order_service):
        """Test calculation with empty items."""
        with pytest.raises(ValueError, match="Items list cannot be empty"):
            order_service.calculate_total([])
    
    @patch('services.order_service.Order.objects.create')
    def test_create_order(self, mock_create, order_service, sample_order_data):
        """Test order creation."""
        mock_order = Mock(id=123)
        mock_create.return_value = mock_order
        
        order = order_service.create_order(
            customer_id=sample_order_data['customer_id'],
            total=Decimal('40.25')
        )
        
        assert order.id == 123
        mock_create.assert_called_once()
```

```python
"""
File: tests/frontend/test_login.py
Module: tests.frontend.test_login
Created: 2025-01-15
Author: Team
Description: Frontend tests for login functionality
"""

import pytest
from playwright.sync_api import Page, expect

@pytest.fixture(scope="function")
def page(browser):
    """Create new page for each test."""
    page = browser.new_page()
    yield page
    page.close()

def test_login_success(page: Page):
    """Test successful login."""
    # Navigate
    page.goto("http://{HOST}:{FRONTEND_PORT}/login")
    
    # Fill form
    page.fill('input[name="username"]', 'testuser')
    page.fill('input[name="password"]', 'testpass123')
    
    # Submit
    page.click('button[type="submit"]')
    
    # Verify redirect
    expect(page).to_have_url("http://{HOST}:{FRONTEND_PORT}/dashboard")
    
    # Verify welcome message
    expect(page.locator('text=Welcome, testuser')).to_be_visible()

def test_login_invalid_credentials(page: Page):
    """Test login with invalid credentials."""
    page.goto("http://{HOST}:{FRONTEND_PORT}/login")
    
    page.fill('input[name="username"]', 'invalid')
    page.fill('input[name="password"]', 'wrong')
    page.click('button[type="submit"]')
    
    # Should show error
    expect(page.locator('text=Invalid credentials')).to_be_visible()
    
    # Should stay on login page
    expect(page).to_have_url("http://{HOST}:{FRONTEND_PORT}/login")

def test_login_validation(page: Page):
    """Test form validation."""
    page.goto("http://{HOST}:{FRONTEND_PORT}/login")
    
    # Try to submit empty form
    page.click('button[type="submit"]')
    
    # Should show validation errors
    expect(page.locator('text=Username is required')).to_be_visible()
    expect(page.locator('text=Password is required')).to_be_visible()
```

```python
"""
File: tests/frontend/test_dashboard_selenium.py
Module: tests.frontend.test_dashboard_selenium
Created: 2025-01-15
Author: Team
Description: Selenium tests for dashboard
"""

import pytest
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

@pytest.fixture
def driver():
    """Create WebDriver instance."""
    driver = webdriver.Chrome()
    driver.implicitly_wait(10)
    yield driver
    driver.quit()

def test_dashboard_loads(driver):
    """Test dashboard page loads correctly."""
    driver.get("http://{HOST}:{FRONTEND_PORT}/dashboard")
    
    # Wait for page load
    WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CLASS_NAME, "dashboard"))
    )
    
    # Check title
    assert "Dashboard" in driver.title
    
    # Check key elements
    assert driver.find_element(By.ID, "user-menu")
    assert driver.find_element(By.CLASS_NAME, "stats-widget")

def test_dashboard_navigation(driver):
    """Test navigation from dashboard."""
    driver.get("http://{HOST}:{FRONTEND_PORT}/dashboard")
    
    # Click on Orders link
    orders_link = driver.find_element(By.LINK_TEXT, "Orders")
    orders_link.click()
    
    # Should navigate to orders page
    WebDriverWait(driver, 10).until(
        EC.url_contains("/orders")
    )
    
    assert "/orders" in driver.current_url
```

```python
"""
File: tests/integration/test_order_api.py
Module: tests.integration.test_order_api
Created: 2025-01-15
Author: Team
Description: Integration tests for order API
"""

import pytest
from django.test import Client
from decimal import Decimal
from models import Order, Customer

@pytest.fixture
def client():
    """Create test client."""
    return Client()

@pytest.fixture
def customer(db):
    """Create test customer."""
    return Customer.objects.create(
        name="Test Customer",
        email="test@example.com"
    )

@pytest.mark.django_db
def test_create_order_api(client, customer):
    """Test order creation via API."""
    data = {
        'customer_id': customer.id,
        'items': [
            {'product_id': 1, 'quantity': 2, 'price': '10.00'},
            {'product_id': 2, 'quantity': 1, 'price': '15.00'}
        ]
    }
    
    response = client.post('/api/orders/', data, content_type='application/json')
    
    assert response.status_code == 201
    assert 'id' in response.json()
    
    # Verify in database
    order = Order.objects.get(id=response.json()['id'])
    assert order.customer == customer
    assert order.total == Decimal('40.25')  # (20 + 15) * 1.15 tax
```

```python
"""
File: tests/e2e/test_order_workflow.py
Module: tests.e2e.test_order_workflow
Created: 2025-01-15
Author: Team
Description: End-to-end test for complete order workflow
"""

import pytest
from playwright.sync_api import Page, expect

def test_complete_order_workflow(page: Page):
    """Test complete order creation workflow."""
    # 1. Login
    page.goto("http://{HOST}:{FRONTEND_PORT}/login")
    page.fill('input[name="username"]', 'testuser')
    page.fill('input[name="password"]', 'testpass123')
    page.click('button[type="submit"]')
    expect(page).to_have_url("http://{HOST}:{FRONTEND_PORT}/dashboard")
    
    # 2. Navigate to orders
    page.click('text=Orders')
    expect(page).to_have_url("http://{HOST}:{FRONTEND_PORT}/orders")
    
    # 3. Create new order
    page.click('button:has-text("New Order")')
    expect(page.locator('h1:has-text("Create Order")')).to_be_visible()
    
    # 4. Fill order form
    page.select_option('select[name="customer"]', label='Test Customer')
    page.click('button:has-text("Add Item")')
    page.select_option('select[name="items[0].product"]', label='Product A')
    page.fill('input[name="items[0].quantity"]', '2')
    
    # 5. Submit order
    page.click('button[type="submit"]:has-text("Create Order")')
    
    # 6. Verify success
    expect(page.locator('text=Order created successfully')).to_be_visible()
    expect(page).to_have_url("http://{HOST}:{FRONTEND_PORT}/orders")
    
    # 7. Verify order appears in list
    expect(page.locator('table tbody tr').first).to_contain_text('Test Customer')
```

```python
"""
File: tests/integration/test_order_integration.py
Module: tests.integration.test_order_integration
Created: 2025-01-15
Author: Team
Description: Integration tests for complete order workflow
"""

import pytest
from django.test import Client
from models import Order, Customer

@pytest.mark.django_db
class TestOrderIntegration:
    """Test complete order integration."""
    
    def test_order_workflow(self, client: Client):
        """Test complete order workflow from design spec."""
        # 1. Create customer
        customer = Customer.objects.create(name="Test", email="test@example.com")
        
        # 2. Create order via API
        response = client.post('/api/orders/', {
            'customer_id': customer.id,
            'items': [{'product_id': 1, 'quantity': 2}]
        }, content_type='application/json')
        assert response.status_code == 201
        order_id = response.json()['id']
        
        # 3. Retrieve order
        response = client.get(f'/api/orders/{order_id}/')
        assert response.status_code == 200
        assert response.json()['state'] == 'draft'
        
        # 4. Confirm order
        response = client.post(f'/api/orders/{order_id}/confirm/')
        assert response.status_code == 200
        
        # 5. Verify state changed
        order = Order.objects.get(id=order_id)
        assert order.state == 'confirmed'
        
        # 6. Cancel order
        response = client.post(f'/api/orders/{order_id}/cancel/')
        assert response.status_code == 200
        
        # 7. Verify cancelled
        order.refresh_from_db()
        assert order.state == 'cancelled'
```

```python
# tests/test_package_init.py
"""Test package __init__.py structure"""

import mypackage


def test_public_api_available():
    """Test that public API is accessible"""
    assert hasattr(mypackage, 'PublicClass')
    assert hasattr(mypackage, 'public_function')


def test_private_not_exposed():
    """Test that private items are not in public API"""
    assert not hasattr(mypackage, '_private_helper')


def test_all_defined():
    """Test that __all__ is properly defined"""
    assert hasattr(mypackage, '__all__')
    assert isinstance(mypackage.__all__, list)
    assert len(mypackage.__all__) > 0


def test_all_items_exist():
    """Test that all items in __all__ actually exist"""
    for item in mypackage.__all__:
        assert hasattr(mypackage, item), f"{item} in __all__ but not found"


def test_version_available():
    """Test that version info is available"""
    assert hasattr(mypackage, '__version__')
    assert isinstance(mypackage.__version__, str)


def test_no_import_side_effects():
    """Test that importing doesn't have side effects"""
    import sys
    import importlib
    
    # Remove module if already imported
    if 'mypackage' in sys.modules:
        del sys.modules['mypackage']
    
    # Import should not raise or print anything
    import mypackage  # noqa: F401
```



================================================================================
END OF 31_TESTING
================================================================================


================================================================================
MODULE: 40_DEPLOYMENT
================================================================================

=================================================================================
DEPLOYMENT - Docker, CI/CD, Production
=================================================================================

Version: 5.0.0
Type: DevOps - Deployment

Comprehensive deployment strategies and configurations.

=================================================================================
DOCKER
=================================================================================

## Dockerfile (Python/Django)

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Create non-root user
RUN useradd -m appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Run application
CMD ["gunicorn", "--bind", "0.0.0.0:8000", "myproject.wsgi:application"]
```

## Dockerfile (Node.js)

```dockerfile
FROM node:18-alpine

WORKDIR /app

# Install dependencies
COPY package*.json ./
RUN npm ci --only=production

# Copy application
COPY . .

# Build
RUN npm run build

# Expose port
EXPOSE 3000

# Run application
CMD ["npm", "start"]
```

## docker-compose.yml

```yaml
version: '3.8'

services:
  web:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/mydb
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
    volumes:
      - ./media:/app/media
  
  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=mydb
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

volumes:
  postgres_data:
```

=================================================================================
CI/CD
=================================================================================

## GitHub Actions

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Run tests
      run: pytest --cov=myapp
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to production
      run: |
        # Your deployment script
        ./deploy.sh
      env:
        DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
```

=================================================================================
PRODUCTION SETTINGS
=================================================================================

## Django

```python
# settings/production.py

DEBUG = False

ALLOWED_HOSTS = ['yourdomain.com', 'www.yourdomain.com']

# Security
SECURE_SSL_REDIRECT = True
SESSION_COOKIE_SECURE = True
CSRF_COOKIE_SECURE = True
SECURE_HSTS_SECONDS = 31536000

# Database
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.getenv('DB_NAME'),
        'USER': os.getenv('DB_USER'),
        'PASSWORD': os.getenv('DB_PASSWORD'),
        'HOST': os.getenv('DB_HOST'),
        'PORT': '5432',
    }
}

# Static files
STATIC_ROOT = '/var/www/static/'
MEDIA_ROOT = '/var/www/media/'

# Caching
CACHES = {
    'default': {
        'BACKEND': 'django.core.cache.backends.redis.RedisCache',
        'LOCATION': os.getenv('REDIS_URL'),
    }
}

# Logging
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'handlers': {
        'file': {
            'level': 'ERROR',
            'class': 'logging.FileHandler',
            'filename': '/var/log/myapp/error.log',
        },
    },
    'loggers': {
        'django': {
            'handlers': ['file'],
            'level': 'ERROR',
            'propagate': True,
        },
    },
}
```

=================================================================================
NGINX CONFIGURATION
=================================================================================

```nginx
upstream myapp {
    server web:8000;
}

server {
    listen 80;
    server_name yourdomain.com www.yourdomain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name yourdomain.com www.yourdomain.com;

    ssl_certificate /etc/letsencrypt/live/yourdomain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/yourdomain.com/privkey.pem;

    client_max_body_size 10M;

    location / {
        proxy_pass http://myapp;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    location /static/ {
        alias /var/www/static/;
        expires 30d;
    }

    location /media/ {
        alias /var/www/media/;
        expires 30d;
    }
}
```

=================================================================================
MONITORING
=================================================================================

## Health Check Endpoint

```python
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0"
    }
```

## Prometheus Metrics

```python
from prometheus_client import Counter, Histogram, generate_latest

request_count = Counter('http_requests_total', 'Total HTTP requests')
request_duration = Histogram('http_request_duration_seconds', 'HTTP request duration')

@app.middleware("http")
async def metrics_middleware(request, call_next):
    request_count.inc()
    with request_duration.time():
        response = await call_next(request)
    return response

@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

=================================================================================
BACKUP STRATEGY
=================================================================================

## Database Backup

```bash
#!/bin/bash
# backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups"
DB_NAME="mydb"

# Create backup
pg_dump -U postgres $DB_NAME | gzip > "$BACKUP_DIR/db_$DATE.sql.gz"

# Keep only last 7 days
find $BACKUP_DIR -name "db_*.sql.gz" -mtime +7 -delete

# Upload to S3 (optional)
aws s3 cp "$BACKUP_DIR/db_$DATE.sql.gz" s3://my-backups/
```

=================================================================================
DEPLOYMENT CHECKLIST
=================================================================================

- [ ] Environment variables configured
- [ ] Database migrations applied
- [ ] Static files collected
- [ ] SSL certificate installed
- [ ] Firewall configured
- [ ] Backup strategy in place
- [ ] Monitoring enabled
- [ ] Logging configured
- [ ] Health checks working
- [ ] Load testing completed
- [ ] Rollback plan ready

=================================================================================
END OF DEPLOYMENT PROMPT
=================================================================================


================================================================================
RECOVERED CONTENT FROM v4.2.0 (Phase 2)
================================================================================

10%)
5. Performance (8%)
6. Usability (7%)
7. Scalability (5%)

Decision Rule: Choose option with highest OSF_Score; document in Solution_Tradeoff_Log.md

‚∏ª

4) Project Maturity Model

Levels:
- Level 0 (Initial üî¥): OSF 0.0-0.3 - No processes
- Level 1 (Managed üü°): OSF 0.3-0.5 - Basic processes
- Level 2 (Defined üü†): OSF 0.5-0.7 - Documented processes
- Level 3 (Managed & Measured üü¢): OSF 0.7-0.85 - Automated & measured
- Level 4 (Optimizing üîµ): OSF 0.85-1.0 - Continuous improvement

Assessment Criteria (8 dimensions):
1. Security (35% weight)
2. Code Quality (20%)
3. Testing (15%)
4. Documentation (10%)
5. CI/CD (10%)
6. Monitoring (5%)
7. Performance (3%)
8. Architecture (2%)

‚∏ª

5) Operational Framework (Phases 0‚Äì8)

Phase 0 ‚Äî Deep Chain of Thought (DCoT)
- Numbered roadmap: FE/BE/DB/Security/UI/.env/Routing/Deduplication
- Identify risks, owners, metrics
- Cross-link dependencies

Phase 1 ‚Äî First Principles
- Atomic, verifiable facts
- Evidence-based analysis
- No assumptions

Phas
 Long lines (>120)
5. ‚úÖ Error leaks in production
6. ‚úÖ Unused code
7. ‚úÖ Broken GitHub workflows

## Key Features

- **Port Management**: Validated, conflict-free
- **Definitions**: Three-tier (common/core/custom)
- **Line Length**: Enforced ‚â§120
- **Error Handling**: Environment-aware
- **Code Quality**: Auto-cleanup
- **CI/CD**: Fixed and comprehensive
- **Documentation**: Auto-generated

## Total Sections: 45
## Total Lines: ~3850
## Version: 3.3.0
## Status: Production Ready ‚úÖ


---

## 46. Comprehensive Verification System

### 46.1 Pre-commit Hooks (MANDATORY)

**Installation:**
```bash
pip install pre-commit
pre-commit install
```

**Configuration:** `.pre-commit-config.yaml`
```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: check-yaml
      - id: check-json
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-added-large-files
        args: ['--maxkb=500']
  
  - repo: https://github.com/psf/
                   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  3. PRODUCTION                                              ‚îÇ
‚îÇ     ‚îú‚îÄ Live deployment                                      ‚îÇ
‚îÇ     ‚îú‚îÄ Debug mode OFF                                       ‚îÇ
‚îÇ     ‚îú‚îÄ Optimized builds                                     ‚îÇ
‚îÇ     ‚îú‚îÄ Data preservation ON                                 ‚îÇ
‚îÇ     ‚îú‚îÄ Security hardened                                    ‚îÇ
‚îÇ     ‚îî‚îÄ Monitoring active                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**State Transitions:**

```
Development ‚îÄ‚îÄ[start deploy]‚îÄ‚îÄ> Production
     ‚Üë                              ‚îÇ
     ‚îÇ                              ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[rollback]‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### 64.4 Development Phase Behavior

**When `phase: "development"`:**

1. **Configuration:**
   - Debug mode: ON
   - Hot reload: Enabled
 

================================================================================
CRITICAL MISSING CONTENT - Deep Search Recovery
================================================================================

```bash
# User types:
start deploy

# Augment responds:
üöÄ Starting deployment process...

‚ö†Ô∏è  WARNING: This will transition your project to PRODUCTION mode.

Current configuration:
  - Project: {PROJECT_NAME}
  - Database: {DATABASE_NAME}
  - Frontend: http://{HOST}:{FRONTEND_PORT}
  - Backend: http://{HOST}:{BACKEND_PORT}

Are you sure you want to proceed? [Y/n]: _

# If Yes:
‚úì Pre-deployment checks passed
‚úì Database backed up to: backups/db_20251102_103000.sql
‚úì Production build created
‚úì Database migrations applied
‚úì Admin user created: {ADMIN_USERNAME}
‚úì Security hardening applied
‚úì Application started

üéâ Deployment successful!

Admin Panel: http://{HOST}:{BACKEND_PORT}/admin
Username: {ADMIN_USERNAME}
Password: {GENERATED_PASSWORD}

Setup Wizard: http://{HOST}:{FRONTEND_PORT}/setup

Next steps:
1. Login to admin panel
2. Complete setup wizard
3. Configure your application
4. Verify everything works

Project phase updated: PRODUCTION ‚úì
```

```bash
# Database
reset-db              # Drop and recreate database
seed-data             # Add sample data
migrate-db            # Run migrations
backup-db             # Create backup

# Development
dev-server            # Start development server
hot-reload            # Enable hot reload
clear-cache           # Clear all caches
run-tests             # Run test suite

# Deployment
start deploy          # Begin deployment process
```



================================================================================
END OF 40_DEPLOYMENT
================================================================================


================================================================================
MODULE: 50_TEMPLATES
================================================================================

=================================================================================
PROJECT TEMPLATES - ERP, Web, AI, ML
=================================================================================

Version: 5.0.0
Type: Templates

Comprehensive project templates for rapid development.

=================================================================================
AVAILABLE TEMPLATES
=================================================================================

1. **ERP System** - Enterprise Resource Planning
2. **Web Page** - Simple static website
3. **Web Page with Login** - Web application with authentication
4. **ML Template** - Machine Learning project
5. **Test Template** - Testing framework setup
6. **Email Template** - Email templates and sending
7. **AI Assistant** - AI-powered chatbot/assistant
8. **Charity Management** - Donation and beneficiary management
9. **AI Prediction** - Forecasting and prediction system

=================================================================================
USING TEMPLATES
=================================================================================

## Command Line

```bash
# List all templates
python3 tools/template_generator.py --list

# Interactive mode
python3 tools/template_generator.py --interactive

# Generate specific template
python3 tools/template_generator.py --template erp_system --output my-erp
```

## Programmatic Usage

```python
from tools.template_generator import TemplateGenerator

generator = TemplateGenerator()

# List templates
templates = generator.list_templates()

# Generate template
generator.generate_template(
    template_name="erp_system",
    output_dir="my-erp",
    variables={
        "project_name": "My ERP",
        "database_name": "my_erp_db",
        "frontend_port": 3000,
        "backend_port": 8000
    }
)
```

=================================================================================
TEMPLATE CUSTOMIZATION
=================================================================================

Each template supports these variables:

- `{PROJECT_NAME}` - Project display name
- `{project_name}` - Project slug (lowercase, underscores)
- `{DATABASE_NAME}` - Database name
- `{FRONTEND_PORT}` - Frontend port number
- `{BACKEND_PORT}` - Backend API port number
- `{DB_PORT}` - Database port number
- `{HOST}` - Host/domain name

=================================================================================
TEMPLATE DETAILS
=================================================================================

## 1. ERP System

**Features:**
- Inventory management
- Sales & purchases
- Accounting
- HR management
- Reporting

**Tech Stack:**
- Backend: Django/FastAPI
- Frontend: React
- Database: PostgreSQL
- Cache: Redis

## 2. AI Assistant

**Features:**
- Natural language understanding
- Context-aware responses
- Knowledge base (RAG)
- Multi-turn conversations

**Tech Stack:**
- LangChain
- OpenAI/Claude API
- Vector database (Pinecone/Chroma)
- FastAPI backend

## 3. Charity Management

**Features:**
- Donation processing
- Beneficiary management
- Campaign management
- Volunteer coordination

**Tech Stack:**
- Backend: Django
- Payment: Stripe/PayPal
- Frontend: React
- Database: PostgreSQL

=================================================================================
END OF TEMPLATES PROMPT
=================================================================================


================================================================================
END OF 50_TEMPLATES
================================================================================


================================================================================
MODULE: 60_MEMORY_MANAGEMENT
================================================================================

=================================================================================
MEMORY MANAGEMENT & CONTEXT RETENTION
=================================================================================
Version: 7.1.0
Last Updated: 2025-11-03
Type: Memory & Context Management
=================================================================================

OVERVIEW
=================================================================================

This module provides comprehensive strategies and techniques for managing AI
memory and maintaining context across long conversations, multiple sessions,
and complex projects. It addresses the fundamental challenge of AI systems:
limited context windows and stateless nature.

KEY CONCEPTS:
- Short-term Memory (STM): Current conversation context
- Long-term Memory (LTM): Persistent knowledge across sessions
- Working Memory: Active information being processed
- Episodic Memory: Specific events and interactions
- Semantic Memory: General knowledge and facts
- Procedural Memory: How-to knowledge and workflows

=================================================================================
SECTION 1: MEMORY ARCHITECTURE
=================================================================================

AI MEMORY HIERARCHY
-------------------

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MEMORY HIERARCHY                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  WORKING MEMORY (Active Context)                  ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - Current conversation                            ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - Immediate task context                          ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - Active variables and state                      ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  Size: Limited by context window                   ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                          ‚Üï                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  SHORT-TERM MEMORY (Session Memory)               ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - Recent interactions (last few hours)            ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - Session-specific context                        ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - Temporary decisions and preferences             ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  Storage: In-memory cache, Redis                   ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                          ‚Üï                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  LONG-TERM MEMORY (Persistent Memory)             ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - User preferences and history                    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - Project knowledge base                          ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - Learned patterns and lessons                    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  Storage: Database, Vector DB, Files               ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                          ‚Üï                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  EXTERNAL MEMORY (Knowledge Base)                 ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - Documentation and references                    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - Code repositories                               ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  - External APIs and services                      ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  Storage: GitHub, Notion, Context7, etc.           ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

MEMORY TYPES
------------

1. EPISODIC MEMORY (What happened)
   - Conversation history
   - User interactions
   - Events and milestones
   - Decisions made

2. SEMANTIC MEMORY (What we know)
   - Facts and concepts
   - Project specifications
   - Technical knowledge
   - Best practices

3. PROCEDURAL MEMORY (How to do)
   - Workflows and processes
   - Code patterns
   - Problem-solving strategies
   - User preferences for tasks

4. PROSPECTIVE MEMORY (What to do)
   - Scheduled tasks
   - Reminders
   - Follow-ups
   - Future goals

=================================================================================
SECTION 2: CONTEXT WINDOW OPTIMIZATION
=================================================================================

STRATEGIES FOR MANAGING LIMITED CONTEXT
----------------------------------------

1. CONTEXT COMPRESSION
   - Summarize old conversations
   - Extract key information
   - Remove redundant content
   - Keep only relevant context

2. HIERARCHICAL CONTEXT
   - Essential context (always included)
   - Important context (included when relevant)
   - Optional context (included if space allows)
   - Archived context (retrievable on demand)

3. DYNAMIC CONTEXT LOADING
   - Load context based on current task
   - Fetch relevant memories on demand
   - Unload irrelevant context
   - Prioritize recent and important information

4. CONTEXT CHUNKING
   - Break long context into chunks
   - Process chunks sequentially
   - Maintain summary of processed chunks
   - Merge results intelligently

IMPLEMENTATION: CONTEXT MANAGER
-------------------------------

```python
# Context Manager with Priority System
class ContextManager:
    """
    Manages AI context with priority-based retention.
    """
    
    def __init__(self, max_tokens=8000):
        self.max_tokens = max_tokens
        self.contexts = {
            'essential': [],      # Always included
            'important': [],      # Included when possible
            'optional': [],       # Included if space allows
            'archived': []        # Stored but not loaded
        }
        self.current_tokens = 0
    
    def add_context(self, content, priority='important', metadata=None):
        """
        Add context with priority level.
        
        Args:
            content: Context content
            priority: 'essential', 'important', 'optional', 'archived'
            metadata: Additional metadata (timestamp, tags, etc.)
        """
        context_item = {
            'content': content,
            'tokens': self.estimate_tokens(content),
            'timestamp': datetime.now(),
            'metadata': metadata or {}
        }
        
        self.contexts[priority].append(context_item)
        self._rebalance()
    
    def get_active_context(self):
        """
        Get context that fits within token limit.
        """
        active_context = []
        remaining_tokens = self.max_tokens
        
        # 1. Always include essential context
        for item in self.contexts['essential']:
            active_context.append(item['content'])
            remaining_tokens -= item['tokens']
        
        # 2. Include important context if space allows
        for item in sorted(self.contexts['important'], 
                          key=lambda x: x['timestamp'], 
                          reverse=True):
            if remaining_tokens >= item['tokens']:
                active_context.append(item['content'])
                remaining_tokens -= item['tokens']
        
        # 3. Include optional context if space allows
        for item in sorted(self.contexts['optional'], 
                          key=lambda x: x['timestamp'], 
                          reverse=True):
            if remaining_tokens >= item['tokens']:
                active_context.append(item['content'])
                remaining_tokens -= item['tokens']
        
        return '\n\n'.join(active_context)
    
    def _rebalance(self):
        """
        Move old important context to optional or archived.
        """
        threshold = datetime.now() - timedelta(hours=2)
        
        # Move old important to optional
        old_important = [
            item for item in self.contexts['important']
            if item['timestamp'] < threshold
        ]
        
        for item in old_important:
            self.contexts['important'].remove(item)
            self.contexts['optional'].append(item)
        
        # Archive very old optional context
        archive_threshold = datetime.now() - timedelta(hours=24)
        old_optional = [
            item for item in self.contexts['optional']
            if item['timestamp'] < archive_threshold
        ]
        
        for item in old_optional:
            self.contexts['optional'].remove(item)
            self.contexts['archived'].append(item)
    
    def estimate_tokens(self, text):
        """
        Estimate token count (rough approximation).
        """
        return len(text.split()) * 1.3  # ~1.3 tokens per word
    
    def summarize_old_context(self):
        """
        Summarize old context to save space.
        """
        # Summarize archived context
        if len(self.contexts['archived']) > 10:
            old_content = [item['content'] for item in self.contexts['archived']]
            summary = self._create_summary(old_content)
            
            # Replace archived with summary
            self.contexts['archived'] = [{
                'content': summary,
                'tokens': self.estimate_tokens(summary),
                'timestamp': datetime.now(),
                'metadata': {'type': 'summary', 'items': len(old_content)}
            }]
    
    def _create_summary(self, contents):
        """
        Create summary of multiple context items.
        """
        # This would use an AI model to summarize
        # For now, return a placeholder
        return f"Summary of {len(contents)} previous interactions"


# Usage Example
context_mgr = ContextManager(max_tokens=8000)

# Add essential context (always included)
context_mgr.add_context(
    "Project: E-commerce Platform\nStack: Python, React, PostgreSQL",
    priority='essential',
    metadata={'type': 'project_info'}
)

# Add important context
context_mgr.add_context(
    "User prefers functional programming style",
    priority='important',
    metadata={'type': 'preference'}
)

# Add conversation context
context_mgr.add_context(
    "User: How do I implement authentication?\nAI: Use JWT tokens...",
    priority='important',
    metadata={'type': 'conversation'}
)

# Get active context for AI
active_context = context_mgr.get_active_context()
```

=================================================================================
SECTION 3: MEMORY PERSISTENCE STRATEGIES
=================================================================================

PERSISTENT MEMORY STORAGE
--------------------------

1. FILE-BASED MEMORY
   ```bash
   # Create memory directory structure
   mkdir -p .memory/{conversations,knowledge,preferences,state}
   
   # Store conversation
   cat > .memory/conversations/$(date +%Y%m%d_%H%M%S).json << 'EOF'
   {
     "timestamp": "2025-11-03T10:30:00Z",
     "user_id": "user123",
     "conversation": [
       {"role": "user", "content": "..."},
       {"role": "assistant", "content": "..."}
     ],
     "context": {
       "project": "ecommerce",
       "task": "authentication"
     }
   }
   EOF
   ```

2. DATABASE-BASED MEMORY
   ```sql
   -- Memory schema
   CREATE TABLE ai_memory (
       id SERIAL PRIMARY KEY,
       user_id VARCHAR(255),
       memory_type VARCHAR(50), -- 'episodic', 'semantic', 'procedural'
       content TEXT,
       embedding VECTOR(1536), -- For semantic search
       metadata JSONB,
       importance INT DEFAULT 5, -- 1-10 scale
       created_at TIMESTAMP DEFAULT NOW(),
       accessed_at TIMESTAMP DEFAULT NOW(),
       access_count INT DEFAULT 0
   );
   
   CREATE INDEX idx_memory_user ON ai_memory(user_id);
   CREATE INDEX idx_memory_type ON ai_memory(memory_type);
   CREATE INDEX idx_memory_importance ON ai_memory(importance DESC);
   CREATE INDEX idx_memory_embedding ON ai_memory USING ivfflat (embedding vector_cosine_ops);
   
   -- Store memory
   INSERT INTO ai_memory (user_id, memory_type, content, metadata, importance)
   VALUES (
       'user123',
       'semantic',
       'User prefers PostgreSQL over MySQL for this project',
       '{"category": "preference", "project": "ecommerce"}',
       8
   );
   
   -- Retrieve relevant memories
   SELECT content, importance, metadata
   FROM ai_memory
   WHERE user_id = 'user123'
     AND memory_type = 'semantic'
   ORDER BY importance DESC, accessed_at DESC
   LIMIT 10;
   ```

3. VECTOR DATABASE MEMORY (Semantic Search)
   ```python
   from chromadb import Client
   from chromadb.config import Settings
   
   # Initialize vector database
   client = Client(Settings(
       chroma_db_impl="duckdb+parquet",
       persist_directory=".memory/vectors"
   ))
   
   # Create collection
   collection = client.create_collection(
       name="ai_memory",
       metadata={"description": "AI long-term memory"}
   )
   
   # Store memory with embedding
   collection.add(
       documents=["User prefers functional programming style"],
       metadatas=[{
           "type": "preference",
           "importance": 8,
           "timestamp": "2025-11-03T10:30:00Z"
       }],
       ids=["mem_001"]
   )
   
   # Semantic search for relevant memories
   results = collection.query(
       query_texts=["How should I write this function?"],
       n_results=5,
       where={"importance": {"$gte": 5}}
   )
   
   print("Relevant memories:", results['documents'])
   ```

4. REDIS-BASED SESSION MEMORY
   ```python
   import redis
   import json
   from datetime import timedelta
   
   # Connect to Redis
   r = redis.Redis(host='localhost', port=6379, db=0)
   
   # Store session memory (expires after 24 hours)
   session_data = {
       "user_id": "user123",
       "current_project": "ecommerce",
       "recent_context": "Working on authentication",
       "preferences": {
           "language": "python",
           "style": "functional"
       }
   }
   
   r.setex(
       "session:user123",
       timedelta(hours=24),
       json.dumps(session_data)
   )
   
   # Retrieve session memory
   session = json.loads(r.get("session:user123"))
   print("Current context:", session['recent_context'])
   ```

MEMORY RETRIEVAL STRATEGIES
----------------------------

1. RECENCY-BASED RETRIEVAL
   - Prioritize recent memories
   - Use time decay function
   - Balance with importance

2. RELEVANCE-BASED RETRIEVAL
   - Semantic similarity search
   - Keyword matching
   - Context-aware filtering

3. IMPORTANCE-BASED RETRIEVAL
   - User-defined importance
   - Access frequency
   - Impact on decisions

4. HYBRID RETRIEVAL
   ```python
   def retrieve_memories(query, user_id, top_k=10):
       """
       Hybrid memory retrieval combining multiple strategies.
       """
       # 1. Semantic search (relevance)
       semantic_results = vector_db.search(query, top_k=20)
       
       # 2. Recent memories (recency)
       recent_results = db.query(
           "SELECT * FROM ai_memory WHERE user_id = ? "
           "ORDER BY created_at DESC LIMIT 20",
           (user_id,)
       )
       
       # 3. Important memories (importance)
       important_results = db.query(
           "SELECT * FROM ai_memory WHERE user_id = ? "
           "ORDER BY importance DESC LIMIT 20",
           (user_id,)
       )
       
       # 4. Combine and rank
       all_results = {}
       
       for result in semantic_results:
           score = result['similarity'] * 0.4  # 40% weight
           all_results[result['id']] = {
               'memory': result,
               'score': score
           }
       
       for result in recent_results:
           memory_id = result['id']
           recency_score = calculate_recency_score(result['created_at']) * 0.3
           
           if memory_id in all_results:
               all_results[memory_id]['score'] += recency_score
           else:
               all_results[memory_id] = {
                   'memory': result,
                   'score': recency_score
               }
       
       for result in important_results:
           memory_id = result['id']
           importance_score = (result['importance'] / 10) * 0.3
           
           if memory_id in all_results:
               all_results[memory_id]['score'] += importance_score
           else:
               all_results[memory_id] = {
                   'memory': result,
                   'score': importance_score
               }
       
       # 5. Sort by combined score
       ranked_results = sorted(
           all_results.values(),
           key=lambda x: x['score'],
           reverse=True
       )
       
       return [r['memory'] for r in ranked_results[:top_k]]
   
   
   def calculate_recency_score(timestamp):
       """
       Calculate recency score with exponential decay.
       """
       age_hours = (datetime.now() - timestamp).total_seconds() / 3600
       return math.exp(-age_hours / 24)  # Half-life of 24 hours
   ```

=================================================================================
SECTION 4: CONTEXT RETENTION TECHNIQUES
=================================================================================

CONVERSATION SUMMARIZATION
---------------------------

```python
def summarize_conversation(messages, max_length=500):
    """
    Summarize long conversation to retain key information.
    """
    # Extract key information
    key_points = []
    decisions = []
    questions = []
    
    for msg in messages:
        # Identify important patterns
        if "decided" in msg['content'].lower() or "will" in msg['content'].lower():
            decisions.append(msg['content'])
        elif "?" in msg['content']:
            questions.append(msg['content'])
        elif any(keyword in msg['content'].lower() 
                for keyword in ['important', 'note', 'remember']):
            key_points.append(msg['content'])
    
    # Create structured summary
    summary = {
        'key_points': key_points[:5],
        'decisions': decisions[:5],
        'open_questions': questions[:3],
        'message_count': len(messages),
        'time_span': f"{messages[0]['timestamp']} to {messages[-1]['timestamp']}"
    }
    
    return summary


# Usage
old_messages = [...]  # Long conversation history
summary = summarize_conversation(old_messages)

# Store summary instead of full history
context_mgr.add_context(
    f"Previous conversation summary:\n"
    f"Key points: {', '.join(summary['key_points'])}\n"
    f"Decisions: {', '.join(summary['decisions'])}\n"
    f"Open questions: {', '.join(summary['open_questions'])}",
    priority='important',
    metadata={'type': 'summary', 'original_count': summary['message_count']}
)
```

INCREMENTAL CONTEXT UPDATES
----------------------------

```python
class IncrementalContextManager:
    """
    Manages context with incremental updates instead of full replacement.
    """
    
    def __init__(self):
        self.context_state = {
            'project': {},
            'user_preferences': {},
            'current_task': {},
            'decisions': [],
            'open_issues': []
        }
    
    def update_context(self, update_type, data):
        """
        Update specific part of context without replacing everything.
        """
        if update_type == 'project_info':
            self.context_state['project'].update(data)
        
        elif update_type == 'preference':
            self.context_state['user_preferences'].update(data)
        
        elif update_type == 'task':
            self.context_state['current_task'] = data
        
        elif update_type == 'decision':
            self.context_state['decisions'].append({
                'decision': data,
                'timestamp': datetime.now()
            })
            # Keep only recent decisions
            self.context_state['decisions'] = \
                self.context_state['decisions'][-10:]
        
        elif update_type == 'issue':
            self.context_state['open_issues'].append(data)
    
    def get_context_snapshot(self):
        """
        Get current context state as formatted string.
        """
        return f"""
PROJECT CONTEXT:
{json.dumps(self.context_state['project'], indent=2)}

USER PREFERENCES:
{json.dumps(self.context_state['user_preferences'], indent=2)}

CURRENT TASK:
{json.dumps(self.context_state['current_task'], indent=2)}

RECENT DECISIONS:
{chr(10).join(f"- {d['decision']}" for d in self.context_state['decisions'][-5:])}

OPEN ISSUES:
{chr(10).join(f"- {issue}" for issue in self.context_state['open_issues'])}
"""


# Usage
ctx = IncrementalContextManager()

# Initial setup
ctx.update_context('project_info', {
    'name': 'E-commerce Platform',
    'stack': ['Python', 'React', 'PostgreSQL']
})

# Add preference
ctx.update_context('preference', {
    'code_style': 'functional',
    'testing': 'pytest'
})

# Update task
ctx.update_context('task', {
    'current': 'Implementing authentication',
    'status': 'in_progress'
})

# Record decision
ctx.update_context('decision', 'Using JWT tokens for authentication')

# Get current context
print(ctx.get_context_snapshot())
```

CONTEXT CHECKPOINTING
----------------------

```python
class ContextCheckpoint:
    """
    Create checkpoints of context state for recovery.
    """
    
    def __init__(self, checkpoint_dir='.memory/checkpoints'):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
    
    def save_checkpoint(self, context_data, checkpoint_name=None):
        """
        Save current context state.
        """
        if checkpoint_name is None:
            checkpoint_name = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        checkpoint_file = self.checkpoint_dir / f"{checkpoint_name}.json"
        
        with open(checkpoint_file, 'w') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'context': context_data
            }, f, indent=2)
        
        print(f"‚úÖ Checkpoint saved: {checkpoint_name}")
        return checkpoint_name
    
    def load_checkpoint(self, checkpoint_name):
        """
        Load context from checkpoint.
        """
        checkpoint_file = self.checkpoint_dir / f"{checkpoint_name}.json"
        
        if not checkpoint_file.exists():
            print(f"‚ùå Checkpoint not found: {checkpoint_name}")
            return None
        
        with open(checkpoint_file, 'r') as f:
            data = json.load(f)
        
        print(f"‚úÖ Checkpoint loaded: {checkpoint_name}")
        return data['context']
    
    def list_checkpoints(self):
        """
        List all available checkpoints.
        """
        checkpoints = sorted(self.checkpoint_dir.glob('*.json'), reverse=True)
        return [cp.stem for cp in checkpoints]
    
    def auto_checkpoint(self, context_data, interval_minutes=30):
        """
        Automatically save checkpoint at intervals.
        """
        last_checkpoint = self.get_last_checkpoint_time()
        
        if last_checkpoint is None or \
           (datetime.now() - last_checkpoint).seconds >= interval_minutes * 60:
            return self.save_checkpoint(context_data)
        
        return None
    
    def get_last_checkpoint_time(self):
        """
        Get timestamp of last checkpoint.
        """
        checkpoints = list(self.checkpoint_dir.glob('*.json'))
        if not checkpoints:
            return None
        
        latest = max(checkpoints, key=lambda p: p.stat().st_mtime)
        return datetime.fromtimestamp(latest.stat().st_mtime)


# Usage
checkpoint_mgr = ContextCheckpoint()

# Save checkpoint
checkpoint_mgr.save_checkpoint({
    'project': 'ecommerce',
    'task': 'authentication',
    'progress': 0.75
}, checkpoint_name='auth_implementation')

# Auto-checkpoint every 30 minutes
checkpoint_mgr.auto_checkpoint(current_context, interval_minutes=30)

# List checkpoints
print("Available checkpoints:", checkpoint_mgr.list_checkpoints())

# Load checkpoint
restored_context = checkpoint_mgr.load_checkpoint('auth_implementation')
```

=================================================================================
SECTION 5: MEMORY CONSOLIDATION & LEARNING
=================================================================================

PATTERN DETECTION AND LEARNING
-------------------------------

```python
class MemoryConsolidation:
    """
    Consolidate memories and extract patterns for learning.
    """
    
    def __init__(self):
        self.patterns = {}
        self.lessons_learned = []
    
    def analyze_memories(self, memories):
        """
        Analyze memories to detect patterns.
        """
        # Group by type
        by_type = {}
        for memory in memories:
            mem_type = memory.get('metadata', {}).get('type', 'unknown')
            if mem_type not in by_type:
                by_type[mem_type] = []
            by_type[mem_type].append(memory)
        
        # Detect patterns
        for mem_type, mems in by_type.items():
            if len(mems) >= 3:  # Need at least 3 instances
                pattern = self._detect_pattern(mems)
                if pattern:
                    self.patterns[mem_type] = pattern
    
    def _detect_pattern(self, memories):
        """
        Detect common patterns in similar memories.
        """
        # Extract common elements
        common_keywords = self._find_common_keywords(
            [m['content'] for m in memories]
        )
        
        if len(common_keywords) >= 2:
            return {
                'keywords': common_keywords,
                'frequency': len(memories),
                'confidence': len(common_keywords) / 10
            }
        
        return None
    
    def _find_common_keywords(self, texts):
        """
        Find keywords that appear in multiple texts.
        """
        from collections import Counter
        
        all_words = []
        for text in texts:
            words = text.lower().split()
            all_words.extend([w for w in words if len(w) > 4])
        
        word_counts = Counter(all_words)
        common = [word for word, count in word_counts.items() 
                 if count >= len(texts) * 0.5]
        
        return common[:10]
    
    def extract_lessons(self, memories):
        """
        Extract lessons learned from past experiences.
        """
        # Find successful patterns
        successful = [m for m in memories 
                     if m.get('metadata', {}).get('outcome') == 'success']
        
        # Find failed patterns
        failed = [m for m in memories 
                 if m.get('metadata', {}).get('outcome') == 'failure']
        
        # Create lessons
        if successful:
            success_pattern = self._detect_pattern(successful)
            if success_pattern:
                self.lessons_learned.append({
                    'type': 'success',
                    'pattern': success_pattern,
                    'recommendation': 'Repeat this approach'
                })
        
        if failed:
            failure_pattern = self._detect_pattern(failed)
            if failure_pattern:
                self.lessons_learned.append({
                    'type': 'failure',
                    'pattern': failure_pattern,
                    'recommendation': 'Avoid this approach'
                })
    
    def get_recommendations(self, current_context):
        """
        Get recommendations based on learned patterns.
        """
        recommendations = []
        
        for lesson in self.lessons_learned:
            # Check if lesson is relevant to current context
            if any(keyword in current_context.lower() 
                  for keyword in lesson['pattern']['keywords']):
                recommendations.append(lesson['recommendation'])
        
        return recommendations


# Usage
consolidation = MemoryConsolidation()

# Analyze past memories
past_memories = [...]  # Load from database
consolidation.analyze_memories(past_memories)
consolidation.extract_lessons(past_memories)

# Get recommendations for current situation
current_context = "Implementing authentication for web application"
recommendations = consolidation.get_recommendations(current_context)
print("Based on past experience:", recommendations)
```

MEMORY IMPORTANCE SCORING
--------------------------

```python
def calculate_memory_importance(memory):
    """
    Calculate importance score for a memory (0-10).
    """
    score = 5.0  # Base score
    
    # Factor 1: Recency (0-2 points)
    age_hours = (datetime.now() - memory['timestamp']).total_seconds() / 3600
    recency_score = max(0, 2 - (age_hours / 24))
    score += recency_score
    
    # Factor 2: Access frequency (0-2 points)
    access_score = min(2, memory.get('access_count', 0) / 5)
    score += access_score
    
    # Factor 3: User-defined importance (0-2 points)
    user_importance = memory.get('metadata', {}).get('importance', 5)
    score += (user_importance / 5) * 2
    
    # Factor 4: Content type (0-2 points)
    content_type = memory.get('metadata', {}).get('type', '')
    type_scores = {
        'decision': 2.0,
        'preference': 1.5,
        'error': 1.5,
        'success': 1.0,
        'conversation': 0.5
    }
    score += type_scores.get(content_type, 0.5)
    
    # Factor 5: Outcome (0-2 points)
    outcome = memory.get('metadata', {}).get('outcome', '')
    if outcome == 'success':
        score += 1.5
    elif outcome == 'failure':
        score += 1.0  # Failures are also important to remember
    
    return min(10, score)


# Update memory importance periodically
def update_memory_importance(db):
    """
    Recalculate importance scores for all memories.
    """
    memories = db.query("SELECT * FROM ai_memory")
    
    for memory in memories:
        new_score = calculate_memory_importance(memory)
        db.execute(
            "UPDATE ai_memory SET importance = ? WHERE id = ?",
            (new_score, memory['id'])
        )
    
    print(f"‚úÖ Updated importance scores for {len(memories)} memories")
```

=================================================================================
SECTION 6: PRACTICAL IMPLEMENTATION
=================================================================================

COMPLETE MEMORY SYSTEM
-----------------------

```python
class AIMemorySystem:
    """
    Complete AI memory management system.
    """
    
    def __init__(self, user_id, max_context_tokens=8000):
        self.user_id = user_id
        self.max_context_tokens = max_context_tokens
        
        # Components
        self.context_manager = ContextManager(max_context_tokens)
        self.checkpoint_manager = ContextCheckpoint()
        self.consolidation = MemoryConsolidation()
        
        # Storage
        self.db = self._init_database()
        self.vector_db = self._init_vector_db()
        self.cache = redis.Redis()
        
        # Load existing memories
        self._load_memories()
    
    def remember(self, content, memory_type='episodic', importance=5, metadata=None):
        """
        Store new memory.
        """
        # 1. Store in database
        memory_id = self.db.execute(
            "INSERT INTO ai_memory (user_id, memory_type, content, importance, metadata) "
            "VALUES (?, ?, ?, ?, ?) RETURNING id",
            (self.user_id, memory_type, content, importance, json.dumps(metadata or {}))
        )
        
        # 2. Store in vector database for semantic search
        self.vector_db.add(
            documents=[content],
            metadatas=[metadata or {}],
            ids=[f"mem_{memory_id}"]
        )
        
        # 3. Add to context manager
        priority = 'essential' if importance >= 8 else 'important' if importance >= 5 else 'optional'
        self.context_manager.add_context(content, priority, metadata)
        
        # 4. Cache in Redis for quick access
        self.cache.setex(
            f"memory:{self.user_id}:{memory_id}",
            timedelta(hours=24),
            json.dumps({'content': content, 'importance': importance})
        )
        
        print(f"‚úÖ Memory stored: {memory_id}")
        return memory_id
    
    def recall(self, query, top_k=5):
        """
        Retrieve relevant memories.
        """
        # 1. Try cache first
        cached = self._check_cache(query)
        if cached:
            return cached
        
        # 2. Semantic search
        results = self.vector_db.query(
            query_texts=[query],
            n_results=top_k * 2
        )
        
        # 3. Get full memory details from database
        memory_ids = [r.replace('mem_', '') for r in results['ids'][0]]
        memories = self.db.query(
            f"SELECT * FROM ai_memory WHERE id IN ({','.join('?' * len(memory_ids))})",
            memory_ids
        )
        
        # 4. Rank by importance and recency
        ranked_memories = sorted(
            memories,
            key=lambda m: (m['importance'], m['created_at']),
            reverse=True
        )
        
        # 5. Update access count
        for memory in ranked_memories[:top_k]:
            self.db.execute(
                "UPDATE ai_memory SET access_count = access_count + 1, "
                "accessed_at = NOW() WHERE id = ?",
                (memory['id'],)
            )
        
        return ranked_memories[:top_k]
    
    def get_context(self):
        """
        Get current context for AI.
        """
        # 1. Get active context from context manager
        active_context = self.context_manager.get_active_context()
        
        # 2. Add user preferences
        preferences = self.db.query(
            "SELECT content FROM ai_memory WHERE user_id = ? AND memory_type = 'procedural' "
            "ORDER BY importance DESC LIMIT 5",
            (self.user_id,)
        )
        
        pref_text = "\n".join([p['content'] for p in preferences])
        
        # 3. Combine
        full_context = f"""
{active_context}

USER PREFERENCES:
{pref_text}
"""
        
        return full_context
    
    def consolidate(self):
        """
        Consolidate memories and learn patterns.
        """
        # 1. Get all memories
        memories = self.db.query(
            "SELECT * FROM ai_memory WHERE user_id = ?",
            (self.user_id,)
        )
        
        # 2. Analyze and extract patterns
        self.consolidation.analyze_memories(memories)
        self.consolidation.extract_lessons(memories)
        
        # 3. Update importance scores
        for memory in memories:
            new_importance = calculate_memory_importance(memory)
            self.db.execute(
                "UPDATE ai_memory SET importance = ? WHERE id = ?",
                (new_importance, memory['id'])
            )
        
        # 4. Archive very old, low-importance memories
        self.db.execute(
            "DELETE FROM ai_memory WHERE user_id = ? AND importance < 3 "
            "AND created_at < NOW() - INTERVAL '90 days'",
            (self.user_id,)
        )
        
        print("‚úÖ Memory consolidation complete")
    
    def checkpoint(self, name=None):
        """
        Create checkpoint of current state.
        """
        context_data = {
            'user_id': self.user_id,
            'context': self.context_manager.contexts,
            'patterns': self.consolidation.patterns,
            'lessons': self.consolidation.lessons_learned
        }
        
        return self.checkpoint_manager.save_checkpoint(context_data, name)
    
    def restore(self, checkpoint_name):
        """
        Restore from checkpoint.
        """
        data = self.checkpoint_manager.load_checkpoint(checkpoint_name)
        if data:
            self.context_manager.contexts = data['context']
            self.consolidation.patterns = data['patterns']
            self.consolidation.lessons_learned = data['lessons']
            print("‚úÖ Memory restored from checkpoint")
    
    def _init_database(self):
        # Initialize database connection
        pass
    
    def _init_vector_db(self):
        # Initialize vector database
        pass
    
    def _load_memories(self):
        # Load recent memories into context
        pass
    
    def _check_cache(self, query):
        # Check Redis cache
        pass


# Usage Example
memory_system = AIMemorySystem(user_id="user123", max_context_tokens=8000)

# Store memories
memory_system.remember(
    "User prefers PostgreSQL for this project",
    memory_type='procedural',
    importance=8,
    metadata={'category': 'preference', 'project': 'ecommerce'}
)

memory_system.remember(
    "Successfully implemented JWT authentication",
    memory_type='episodic',
    importance=7,
    metadata={'category': 'success', 'feature': 'authentication'}
)

# Recall relevant memories
relevant_memories = memory_system.recall("How to implement authentication?")
for memory in relevant_memories:
    print(f"- {memory['content']} (importance: {memory['importance']})")

# Get context for AI
context = memory_system.get_context()
print("Current context:", context)

# Consolidate memories periodically
memory_system.consolidate()

# Create checkpoint
memory_system.checkpoint(name='after_auth_implementation')
```

=================================================================================
SECTION 7: BEST PRACTICES
=================================================================================

MEMORY MANAGEMENT GUIDELINES
-----------------------------

1. PRIORITIZE RUTHLESSLY
   ‚úÖ Keep only essential information in active context
   ‚úÖ Archive or summarize old information
   ‚úÖ Use importance scoring to decide what to keep
   ‚ùå Don't try to keep everything in context

2. STRUCTURE YOUR MEMORY
   ‚úÖ Use clear categories (episodic, semantic, procedural)
   ‚úÖ Add metadata for better retrieval
   ‚úÖ Maintain consistent format
   ‚ùå Don't mix different types of information

3. UPDATE INCREMENTALLY
   ‚úÖ Update specific parts of context
   ‚úÖ Use state management patterns
   ‚úÖ Track changes over time
   ‚ùå Don't replace entire context repeatedly

4. CONSOLIDATE REGULARLY
   ‚úÖ Summarize old conversations
   ‚úÖ Extract patterns and lessons
   ‚úÖ Update importance scores
   ‚ùå Don't let memory grow unbounded

5. USE MULTIPLE STORAGE LAYERS
   ‚úÖ Working memory: Current context
   ‚úÖ Short-term: Session cache (Redis)
   ‚úÖ Long-term: Database + Vector DB
   ‚úÖ External: Files, GitHub, Notion
   ‚ùå Don't rely on single storage method

6. IMPLEMENT CHECKPOINTS
   ‚úÖ Save state at key milestones
   ‚úÖ Enable recovery from failures
   ‚úÖ Track progress over time
   ‚ùå Don't lose work due to context loss

7. LEARN FROM EXPERIENCE
   ‚úÖ Detect patterns in past interactions
   ‚úÖ Extract lessons learned
   ‚úÖ Apply knowledge to new situations
   ‚ùå Don't repeat past mistakes

CONTEXT RETENTION CHECKLIST
----------------------------

Before starting a task:
‚ñ° Load relevant long-term memories
‚ñ° Check for existing checkpoints
‚ñ° Review user preferences
‚ñ° Load project context

During the task:
‚ñ° Update context incrementally
‚ñ° Store important decisions
‚ñ° Create periodic checkpoints
‚ñ° Monitor context size

After the task:
‚ñ° Summarize the session
‚ñ° Store lessons learned
‚ñ° Update importance scores
‚ñ° Create final checkpoint

Maintenance:
‚ñ° Consolidate memories weekly
‚ñ° Archive old, low-importance memories
‚ñ° Update patterns and lessons
‚ñ° Optimize storage and retrieval

=================================================================================
SECTION 8: INTEGRATION WITH OTHER MODULES
=================================================================================

INTEGRATION POINTS
------------------

1. WITH MODULE 16 (MCP Integration)
   - Use Context7 for up-to-date documentation
   - Store project mappings in long-term memory
   - Remember tool preferences and workflows

2. WITH MODULE 17 (Thinking Framework)
   - Store problem-solving patterns
   - Remember successful approaches
   - Learn from past decisions

3. WITH MODULE 18 (Task AI)
   - Remember task preferences
   - Store workflow patterns
   - Track task history

4. WITH MODULE 19 (Context Engineering)
   - Share context state
   - Coordinate memory updates
   - Integrate learning systems

5. WITH MODULE 15 (MCP)
   - Use GitHub for code memory
   - Use Notion for documentation memory
   - Use Sentry for error memory

COMPLETE WORKFLOW EXAMPLE
--------------------------

```python
# Initialize all systems
memory_system = AIMemorySystem(user_id="user123")
context_engineer = ContextEngineer()  # From Module 19
task_ai = TaskAI()  # From Module 18

# 1. Start new task
task = "Implement user authentication"

# 2. Load relevant memories
memories = memory_system.recall(task)
context = memory_system.get_context()

# 3. Get recommendations from past experience
recommendations = memory_system.consolidation.get_recommendations(task)

# 4. Create tasks based on memory and context
tasks = task_ai.create_tasks(task, context, recommendations)

# 5. Execute tasks while updating memory
for subtask in tasks:
    result = execute_task(subtask)
    
    # Store result in memory
    memory_system.remember(
        f"Completed: {subtask.name}\nResult: {result}",
        memory_type='episodic',
        importance=7,
        metadata={'task': task, 'outcome': 'success' if result.success else 'failure'}
    )
    
    # Create checkpoint
    if subtask.is_milestone:
        memory_system.checkpoint(name=f"after_{subtask.name}")

# 6. Consolidate learnings
memory_system.consolidate()

# 7. Store final summary
summary = create_summary(tasks)
memory_system.remember(
    summary,
    memory_type='semantic',
    importance=9,
    metadata={'type': 'project_summary', 'project': task}
)
```

=================================================================================
END OF MEMORY MANAGEMENT MODULE
=================================================================================

For more information on related topics:
- Module 16: MCP Integration Layer
- Module 17: Thinking Framework
- Module 18: Task AI & Automation
- Module 19: Context Engineering & Learning System

Version: 7.1.0
Last Updated: 2025-11-03



================================================================================
END OF 60_MEMORY_MANAGEMENT
================================================================================


================================================================================
END OF GLOBAL GUIDELINES
================================================================================

Version: 7.1.0
Generated: 2025-11-03
Total Modules: 21
Total Lines: 29,950
Total Size: 710.5 KB

For updates and more information:
https://github.com/hamfarid/global

================================================================================
